#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t
#+TITLE: Code and results for the project Is Parental Illness a Risk Indicator of Future Physical Child Abuse?
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 2 5.3.1 (Org mode 9.1.6)

This is the file containing all code for data management, merging and
analysis for the project mentioned in the title - except for code
containing microdata, which will be exported into a separate R-file
and run from this file. 
** Extraction and sorting of diagnoses 
This section extracts and sorts the ICD10- and ICD8-diagnoses to fill
in the categories meant for further analysis. The full list of
diagnoses are expected to be in: 

| Register                                        | Included in code |
|-------------------------------------------------+------------------|
| lpradm                                          | X                |
| lprdiag                                         | X                |
| lprsksopr                                       | X                |
| lprsksube                                       | X                |
| psykadm                                         | X                |
| psykdiag                                        | X                |
| psyksksopr                                      | X                |
| psyksksub                                       | X                |
| uafadm                                          | X                |
| uafdiag                                         | X                |
| uafsksopr                                       | X                |
| uafsksub                                        | X                |
| privadm                                         | X                |
| privdiag                                        | X                |
| privsksopr                                      | X                |
| privsksub                                       | X                |
| dodsaars                                        | X                |
| dodsaasg                                        | X                |
|                                                 |                  |
| *Events that could be interpreted as diagnoses* |                  |
| lprfoedsler                                     |                  |
| lprfoeds                                        |                  |
| lprulyk                                         | X                |
| psykulyk                                        | X                |
| uafulyk                                         | X                |
|-------------------------------------------------+------------------|

** Code for extraction
#+begin_src R :session rsession :results output :exports both
  ##In this code, all temp-objects will be used as just what they are named - something temporary. None of the datasets are meant to  be in memory for more than a few operations, so they will be overwriting each other as the process proceeds. 
  library(data.table)
  library(fasttime)

  ##LPR
  temp <- fread("lpradm_pop_080621.csv") 
  temp[ , D_INDDTO := as.Date(D_INDDTO , "%m/%d/%Y")]
  setkey(temp , D_INDDTO)
  ##From the data (using aar to separate entries) it is seen that no admissions in 1993 use ICD10 and all admissions in 1994 use ICD10. This is used to separate entries:
  icd8 <- temp[aar %in% c(1977:1993) , C_ADIAG]
  length(icd8) #16419794 entries
  icd8 <- unique(icd8)
  length(icd8) #6772 entries
  icd10 <- temp[aar %in% c(1994:2021) , C_ADIAG]
  length(icd10) #118699959 entries
  icd10 <- unique(icd10)
  length(icd10) #20763

  temp <- fread("lprdiag_pop_110621.csv")
  ##There are several types of diagnoses available - only those that can be viewed as describing the patient's condition are listed here:
  diagtypeUseful <- c("A" , "B" , "G" , "C" , "+")
  ##Only other diagtype is H - for computational speed, H is excluded:
  temp <- temp[!C_DIAGTYPE == "H"]
  ##C_DIAGMOD is used before 1994. Two categories, "observed for" and  "not present" needs to be removed, as those does not indicate the presence of illness:
  temp <- temp[!C_DIAGMOD == 1] #Meaning: Observed for
  temp <- temp[!C_DIAGMOD == 2] #Meaning: Not found
  ##I've thrown out everything newer than 1993 by accident (will re-introduce) - thus, will use current data to add to ICD8:
  temp2 <- temp[ , C_DIAG]
  length(temp2) #26226406 entries
  temp2 <- unique(temp2)
  length(temp2) #7610
  temp3 <- temp[ , C_TILDIAG]
  length(temp3) #26226406 entries
  temp3 <- unique(temp3)
  length(temp3) #1 entry
  temp3 #This variable is empty
  icd8 <- c(icd8 , temp2)
  ##Need to extract ICD 10 from 1994 and forth:
  temp <- fread("lprdiag_pop_110621.csv")
  ##Only need  data from 1994 and forth:
  setkey(temp , aar)
  temp <- temp[aar %in%  c(1994:2021)]
  ##Only other diagtype is H - for computational speed, H is excluded:
  temp <- temp[!C_DIAGTYPE == "H"]
  temp2 <- temp[ , C_DIAG]
  length(temp2) #215520229 entries
  temp2 <- unique(temp2)
  length(temp2) #21941 entries
  temp3 <- temp[ , C_TILDIAG]
  temp3 <- unique(temp3)
  length(temp3) #40314
  ##Removing everything that is not a diagnosis of a health-related condition
  temp3 <- grep('^D.*' , temp3 , value = TRUE)
  length(temp3) #17485
  icd10 <- c(icd10 , temp2 , temp3)

  temp <- fread("lprsksopr_pop_080621.csv")
  ##For some reason everything is double quoted - removing those.
  temp2 <- temp[ , gsub('\"' , '' , c_tilopr)] 
  ##Removing everything that is not a diagnosis:
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  length(temp2) #212049 entries
  temp2 <- unique(temp2)
  length(temp2) #2210 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("lprsksube_pop_110621.csv" , select = "c_tilopr")
  temp[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  temp <- grep('^D.*' , temp[ , c_tilopr] , value = TRUE)
  length(temp) #2484898 entries
  temp <- unique(temp)
  length(temp) #5000 entries
  icd10 <- c(icd10 , temp)
  ##The file has been split into two - loading the other part:
  temp <- fread("lpr_sksube_1999_2004_pop_250621.csv" , select = "C_TILOPR")
  temp <- grep('^D.*' , temp[ , C_TILOPR] , value = TRUE)
  length(temp) #208251 entries
  temp <- unique(temp)
  length(temp) #1023 entries
  icd10 <- c(icd10 , temp)

  ##PSYK
  temp <- fread("psyk_adm_pop_110621.csv") 
  temp[ , d_inddto := as.Date(d_inddto)]
  setkey(temp , d_inddto)
  ##This registry goes back to 1995, but some admissions are much older - probably open admissions for severely ill patients, but all diagnoses are ICD 10. 
  temp2 <- temp[ , gsub('\"' , '' , c_adiag)]
  length(temp2) #4146572 entries
  temp2 <- unique(temp2)
  length(temp2) #2108
  icd10 <- c(icd10 , temp2)

  temp <- fread("psykdiag_pop_110621.csv")
  ##There are several types of diagnoses available - only those that can be viewed as describing the patient's condition are listed here:
  ##Only other diagtype is H - for computational speed, H is excluded:
  temp <- temp[!c_diagtype == "H"]
  temp2 <- temp[ , gsub('\"' , '' , c_diag)]
  length(temp2) #7924233 entries
  temp2 <- unique(temp2)
  length(temp2) #8089 entries
  temp3 <- temp[ , gsub('\"' , '' , c_tildiag)]
  temp3 <- unique(temp3)
  length(temp3) #3610
  ##Removing everything that is not a diagnosis of a health-related condition
  temp3 <- grep('^D.*' , temp3 , value = TRUE)
  length(temp3) #2210
  icd10 <- c(icd10 , temp2 , temp3)

  temp <- fread("psyksksopr_pop_110621.csv")
  temp2 <- temp[ , gsub('\"' , '' , c_tilopr)] 
  ##Removing everything that is not a diagnosis:
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  length(temp2) #10 entries
  temp2 <- unique(temp2)
  length(temp2) #8 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("psyksksube_pop_110621.csv")
  temp[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  temp <- grep('^D.*' , temp[ , c_tilopr] , value = TRUE)
  length(temp) #3694 entries
  temp <- unique(temp)
  length(temp) #189 entries
  icd10 <- c(icd10 , temp)

  ##UAF
  temp <- fread("uaf_adm2018.csv")
  temp2 <- temp[ , C_ADIAG]
  length(temp2) #1977596 entries
  temp2 <- unique(temp2)
  length(temp2) # 12120 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("uaf_diag2018.csv")
  temp <- temp[C_DIAGTYPE %in% diagtypeUseful]
  temp2 <- temp[ , C_DIAG]
  temp3 <- temp[ , C_TILDIAG]
  temp3 <- grep('^D.*' , temp3 , value = TRUE)
  temp2 <- c(temp2 , temp3)
  length(temp2) #3679838 entries
  temp2 <- unique(temp2)
  length(temp2) #14388 entries
  icd10 <- c(icd10 , temp2)
  ##Just to free a bit of memory
  icd10 <- unique(icd10)

  temp <- fread("uaf_sksopr2018.csv")
  temp2 <- temp[ , C_TILOPR]
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  icd10 <- c(icd10 , temp2)

  temp <- fread("uaf_sksube2018.csv")
  temp2 <- temp[ , C_TILOPR]
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  length(temp2) #13133 entries
  temp2 <- unique(temp2)
  length(temp2) #594 entries
  icd10 <- c(icd10 , temp2)

  ##DODSAARS
  temp <- fread("dodsaars_pop_180621.csv")
  temp[ , D_DODSDTO := as.Date(D_DODSDTO  , "%m/%d/%Y")] 
  setkey(temp , D_DODSDTO)
  ##Looking at the shift between ICD 8 and 10 - it changes perfectly with no overlap of the two diagnosis systems
  ##temp[D_DODSDTO > as.Date("1993-01-01") & D_DODSDTO < as.Date("1994-12-31") , View(.SD)]
  ##The ICD8 diagnoses are (almost all) valid - but with one cipher less than other codes. This means the amount of subclassification is limited -  ie you can  see it is breast cancer, but not where it originated. The ICD10 diagnoses are with as much or nearly as much detail as other ICD10 diagnoses.
  ##These diagnoses will be used for posthumously designate individuals to illness groups. Only the underlying cause of death will be included (but the remaining fields will be used when looking for cases with the outcome).
  ##THIS DECISION WAS REVERSED TO AVOID CONDITIONING ON THE FUTURE. 
  temp2 <- temp[D_DODSDTO < as.Date("1994-01-01") , C_DOD1]
  length(temp2) #1079430 entries
  temp2 <- unique(temp2)
  length(temp2) #2292 entries
  icd8 <- c(icd8 , temp2)
  temp2 <- temp[D_DODSDTO >= as.Date("1994-01-01") , C_DOD1]
  temp2 <- gsub('^' , 'D' , temp2)
  length(temp2) #1906664 entries
  temp2 <- unique(temp2)
  length(temp2) #1694 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("dodsaasg_pop_110621.csv")
  temp2 <-  temp[ , gsub('\"' , '' , c_dodtilgrundl_acme)]
  temp2 <- gsub('^' , 'D' , temp2)
  length(temp2) #918932 entries
  temp2 <- unique(temp2)
  length(temp2) #4164 entries
  icd10 <- c(icd10 , temp2)

  ##PRIV
  temp <- fread("privadm_pop_110621.csv")
  temp2 <- temp[ , gsub('\"' , '' , c_adiag)]
  length(temp2) #3609455 entries
  temp2 <- unique(temp2)
  length(temp2) # 9715 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("privdiag_pop_110621.csv")
  temp <- temp[gsub('\"' , '' , c_diagtype) %in% diagtypeUseful]
  temp2 <- temp[ , gsub('\"' , '' , c_diag)]
  temp3 <- temp[ , gsub('\"' , '' , c_tildiag)]
  temp3 <- grep('^D.*' , temp3 , value = TRUE)
  temp2 <- c(temp2 , temp3)
  length(temp2) #8626011 entries
  temp2 <- unique(temp2)
  length(temp2) #10891 entries
  icd10 <- c(icd10 , temp2)
  ##Just to free a bit of memory
  icd10 <- unique(icd10)

  temp <- fread("privsksopr_pop_110621.csv")
  temp2 <- temp[ , gsub('\"' , '' , c_tilopr)]
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  length(temp2) #4984 entries
  temp2 <- unique(temp2)
  length(temp2) #286 entries
  icd10 <- c(icd10 , temp2)

  temp <- fread("privsksube_pop_110621.csv")
  temp2 <- temp[ , gsub('\"' , '' , c_tilopr)]
  temp2 <- grep('^D.*' , temp2 , value = TRUE)
  length(temp2) #3734 entries
  temp2 <- unique(temp2)
  length(temp2) #169 entries
  icd10 <- c(icd10 , temp2)

  ##Cleanup
  ##Removing all non-D diagnoses:
  icd10 <- grep('^D.*' , icd10 , value = TRUE)
  icd10 <- unique(icd10)
  length(icd10)
  icd10 <- list(icd10)
  setDT(icd10)
  setkey(icd10 , V1)
  icd10 <- icd10[ , V1]
  length(icd10) #23696 entries
  fwrite(list(icd10) , "icd10.csv")
  ##For loading of list without re-doing the process above:
  icd10 <- fread("icd10.csv" , header = FALSE)
  ##List without psychiatric diagnoses:
  ##Commented out when ICD10-list is loaded from file:
  ##icd10 <- list(icd10)
  ##setDT(icd10)
  icd10[ , psych := grepl('^DF.*' , V1)]
  icd10NoPsych <- icd10[psych == FALSE , V1]
  icd10Psych <- icd10[psych == TRUE , V1]
  length(icd10NoPsych) #22663 entries
  length(icd10Psych) #1030 entries
  fwrite(list(icd10NoPsych) , "icd10NoPsych.csv")
  fwrite(list(icd10Psych) , "icd10Psych.csv")
  ##List without accidents, infections and procedures (procedures have been left out beforehand, only infections in the designated chapters will be left out in this first sorting):
  icd10NoPsych <- list(icd10NoPsych)
  setDT(icd10NoPsych)
  ##Infections
  icd10NoPsych[ , infect := grepl('^DA.*|^DB.*' , V1)]
  ##Accidents - also, U codes have been taken in here. They are supposed to be used for emergencies and new illnesses controlled by WHO and are thus now used for COVID and damage from e-cigarettes. However, this dataset is from before the first COVID-infetion in Denmark, and some of the U-codes seem to be non-ICD10-codes, eg DU[numbers][more letters]. Thus these codes are left out. As described in the algorithm, accidents are not classified. However, earlier studies have found some accident codes to be useful for unspecific diagnoses - thus, the T-chapter is included, but the remaining diagnoses are not classified. 
  icd10NoPsych[ , accident := grepl('^DS.*|^DU.*|^DV.*|^DW.*|^DX.*|^DY.*' , V1)]
  icd10NoPsychInfectSomeAccident <- icd10NoPsych[infect == FALSE & accident == FALSE , V1]
  length(icd10NoPsychInfectSomeAccident) #18164 entries
  fwrite(list(icd10NoPsychInfectSomeAccident) , "icd10NoPsychInfectSomeAccident.csv")

  icd8 <- unique(icd8)
  icd8 <- list(icd8)
  setDT(icd8)
  setkey(icd8 , V1)
  icd8 <- icd8[ , V1]
  length(icd8) #9307 entries
  fwrite(list(icd8) , "icd8.csv")
#+end_src

** Code for marking unspecific diagnoses
All relevant ICD 10 and 8 codes have now been extracted from the
data. The only codes not fully extracted are those from the death
registers not coded as the underlying cause - these were deemed not
relevant to our purpose. The diagnoses will now be coded according to
the algorithm described in the pre-registration.



#+begin_src R :session rsession :results output :exports both
  ##The following commented codeblock reduces the dataset and saves it for reloading - should only be executed once. 
  ## diagCategories <- fread("icd10NoPsychInfectSomeAccident.csv" , header = FALSE , col.names = "diagnosis")
  ## ##Pregnancy, childbirth and puerperium: these diagnoses will not be classified and thus will be left out; this was not mentioned in the pre-registration but in accordance with the sources for classification mentioned there. Nonetheless, there is an exception later in the code - premature birth and acute caesarian section is coded according to Nager et al. 
  ## diagCategories[grepl('^DO.*' , diagnosis) , pregnancy := TRUE]
  ## diagCategories <- diagCategories[is.na(pregnancy) == TRUE]
  ## fwrite(diagCategories , "icd10NoPsychInfectSomeAccidentPregnancy.csv")
  diagCategories <- fread("icd10NoPsychInfectSomeAccidentPregnancy.csv")
  diagCategories[ , unspecific := NA] ##TRUE means unspecific, FALSE means well-defined
  diagCategories[ , diagError := NA]
  diagCategories[ , .N] #16869 entries
  ##Coding categories from previous works; in all code below, results were checked visually, using the View(diagCategories) command with regular intervals:
  ##Neoplasms: coded as FALSE
  diagCategories[grepl('^DC.*' , diagnosis) , unspecific := FALSE]
  diagCategories[grepl('^DD[0-3].*|^DD4[0-8].*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the blood and immune system: coded as FALSE
  diagCategories[grepl('^DD[5-7].*|^DD8[0-9].*' , diagnosis) , unspecific := FALSE]
  diagCategories[grepl('^DE[0-8].*|^DE90.*' , diagnosis) , unspecific := FALSE]
  ##Inflammatory and atrophic diseases of the nervous system: coded as FALSE
  diagCategories[grepl('^DG0.*|^DG1[0-4].*' , diagnosis) , unspecific := FALSE]
  ##Extrapyramidal and movement disorders, other degenerative diseases fo the nervous system: coded as FALSE
  diagCategories[grepl('^DG2.*|^DG3[0-2].*' , diagnosis) , unspecific := FALSE]
  ##Demyelinating diseases of the central nervous system, epilepsy, status epilepticus, migraine
  diagCategories[grepl('^DG3.*|^DG40.*|^DG41.*|^DG43.*' , diagnosis) , unspecific := FALSE]
  ##Cluster headache syndrome, vascular headache not elsewhere classified: coded as FALSE
  ##Tension-type headache: coded as TRUE
  diagCategories[grepl('^DG44[0-1].*' , diagnosis) , unspecific := TRUE]
  ##Tension-type headache: coded as TRUE
  diagCategories[grepl('^DG442.*' , diagnosis) , unspecific := TRUE]
  ##Other types of headache: coded as FALSE
  diagCategories[grepl('^DG44[3-8].*' , diagnosis) , unspecific := FALSE]
  ##Transient cerebral ischaemic attacks and cerebral vascular syndromes: coded as FALSE
  diagCategories[grepl('^DG45.*|^DG46.*' , diagnosis) , unspecific := FALSE]
  ##Sleep disorders, nerve disorders: coded as FALSE
  diagCategories[grepl('^DG47.*|^DG5.*' , diagnosis) , unspecific := FALSE]
  ##Hereditary idiopathic neuropathy, inflammatory neuropathy, drug-induced neuropathy: coded as FALSE
  diagCategories[grepl('^DG6[0-1].*|^DG620.*' , diagnosis) , unspecific := FALSE] 
  ##Alcoholic polyneuropathy and other polyneuropathies: coded as FALSE
  diagCategories[grepl('^DG621.*|^DG622.*|^DG628.*' , diagnosis) , unspecific := FALSE]
  ##Polyneuropathy, unspecified: coded as TRUE
  diagCategories[grepl('^DG629.*' , diagnosis) , unspecific := TRUE]
  ##Polyneuropathy in diseases classified elsewhere, other disorders of the peripheral nervous system
  diagCategories[grepl('^DG63.*|^DG64.*' , diagnosis) , unspecific := FALSE]
  ##Myoneural junction and muscle, cerebral palsy and other paralytic syndromes: coded as FALSE
  diagCategories[grepl('^DG7[0-3].*|^DG8[0-3].*' , diagnosis) , unspecific := FALSE]
  ##Other disorders of the nervous system: coded as FALSE
  diagCategories[grepl('^DG9.*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the eye and adnexa, diseases of the ear and mastoid process: coded as FALSE
  diagCategories[grepl('^DH[0-8].*|^DH9[0-5].*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the circulatory system: coded as FALSE
  diagCategories[grepl('^DI.*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the respiratory system: coded as FALSE
  diagCategories[grepl('^DJ.*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the oral cavity, salivary glands and jaws, esophagitis and reflux: coded as FALSE
  diagCategories[grepl('^DK0.*|^DK1[0-4].*|^DK20.*|^DK21.*' , diagnosis) , unspecific := FALSE]
  ##Other diseases of oesophagus, diseases in oesophagus in diseases classified elsewhere, gastric and duodenal ulcers: coded as FALSE
  diagCategories[grepl('^DK22.*|^DK23.*|^DK25.*|^DK26.*' , diagnosis) , unspecific := FALSE]
  ##Peptic ulcer, gastrojejunal ulcer, gastritis and duodenitis: coded as FALSE
  diagCategories[grepl('^DK27.*|^DK28.*|^DK29.*' , diagnosis) , unspecific := FALSE]
  ##Dyspepsia: coded as TRUE
  diagCategories[grepl('^DK30.*' , diagnosis) , unspecific := TRUE]
  ##Other diseases of stomach, duodenum, appendix, noninfective enteritis and colitis: coded as FALSE
  diagCategories[grepl('^DK3[1-9].*|^DK4.*|^DK5[0-2].*' , diagnosis) , unspecific := FALSE]
  ##Vascular intestinal disorders, paralytic ileus, diverticulitis: coded as FALSE
  diagCategories[grepl('^DK5[5-7].*' , diagnosis) , unspecific := FALSE]
  ##Irritable bowel syndrome: coded as TRUE
  diagCategories[grepl('^DK58.*' , diagnosis) , unspecific := TRUE]
  ##Other functional intestinal disorders, fissure and fistula or abscess of anal and rectal regions: coded as FALSE
  diagCategories[grepl('^DK59.*|^DK6[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Other diseases of anus and rectum, intestine, peritoneum or liver: coded as FALSE
  diagCategories[grepl('^DK6[2-9].*|^DK7[0-7].*' , diagnosis) , unspecific := FALSE]
  ##Disorders of gallbladder, biliary tract and pancreas, other diseases of digestive system: coded as FALSE
  diagCategories[grepl('^DK8.*|^DK9[0-3].*' , diagnosis) , unspecific := FALSE]
  ##Diseases of the skin and subcutaneous tissue: coded as FALSE
  diagCategories[grepl('^DL.*' , diagnosis) , unspecific := FALSE]
  ##Infectious arthropaties, inflammatory polyarthropaties, arthrosis: coded as FALSE
  diagCategories[grepl('^DM[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Acquired deformities of fingers, toes and limbs, disorders of patella
  diagCategories[grepl('^DM2[0-2].*' , diagnosis) , unspecific := FALSE]
  ##Derangement of joints, fistula of joint, flail joint: coded as FALSE
  diagCategories[grepl('^DM2[3-4].*|^DM25[0-2].*|^DM25' , diagnosis) , unspecific := FALSE]
  ##Other instability of joint, effusion of joint: coded as FALSE
  diagCategories[grepl('^DM25[3-4].*' , diagnosis) , unspecific := FALSE]
  ##Pain in joint: coded as TRUE
  diagCategories[grepl('^DM255.*' , diagnosis) , unspecific := TRUE]
  ##Stiffness of joint
  diagCategories[grepl('^DM25[6-9].*' , diagnosis) , unspecific := FALSE]
  ##Systemic connective tissue disorders, deforming dorspathies
  diagCategories[grepl('^DM3.*|^DM4[0-3].*' , diagnosis) , unspecific := FALSE]
  ##Spondylopathies, cervical disc disorders, intervertebral disc disorders
  diagCategories[grepl('^DM4[5-9].*|^DM5[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Dorsopathies not elsewhere classified, panniculitis in neck and back, radiculopathy: coded as FALSE
  diagCategories[grepl('^DM53.*|^DM54[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Cervicalgia: coded as TRUE
  diagCategories[grepl('^DM542.*' , diagnosis) , unspecific := TRUE]
  ##Sciatica, lumbago with sciatica: coded as FALSE
  diagCategories[grepl('^DM54[3-4].*' , diagnosis) , unspecific := FALSE]
  ##Low back pain, pain in thoracic spine, other dorsalgia: coded as TRUE
  diagCategories[grepl('^DM54[5-9].*' , diagnosis) , unspecific := TRUE]
  ##Myositis, calcification and ossification of muscle, diastasis of muscle, other rupture of muscle: coded as FALSE
  diagCategories[grepl('^DM6[0-1].*|^DM62|^DM62[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Ischaemic infarction of muscle, immobility syndrome, muscle contracture
  diagCategories[grepl('^DM62[2-4].*' , diagnosis) , unspecific := FALSE]
  ##Muscle wasting and atrophy not elsewhere classified: coded as FALSE
  diagCategories[grepl('^DM625.*' , diagnosis) , unspecific := FALSE]
  ##Muscle strain: coded as TRUE
  diagCategories[grepl('^DM626.*' , diagnosis) , unspecific := TRUE]
  ##Other specified disorders of muscle, muscle disorders unspecified and disorders of muscle in diseases classified elsewhere: coded as FALSE
  diagCategories[grepl('^DM62[8-9].*|^DM63.*' , diagnosis) , unspecific := FALSE]
  ##Disorders of synovium and tendon, soft tissue disorders related to use, overuse and pressure, bursopathies: coded as FALSE
  diagCategories[grepl('^DM6[5-9].*|^DM7[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Fibroblastic disorders, soft tissue disorders in diseases classified elsewhere, shoulder lesions: coded as FALSE
  diagCategories[grepl('^DM7[2-5].*' , diagnosis) , unspecific := FALSE]
  ##Enthesopathies of lower limb, excluding foot, other enthesopathies: coded as FALSE
  diagCategories[grepl('^DM7[6-7].*' , diagnosis) , unspecific := FALSE]
  ##Rheumatism, unspecified and myalgia: coded as TRUE
  diagCategories[grepl('^DM79[0-1].*' , diagnosis) , unspecific := TRUE]
  ##Neuralgia and neuritis unspecified, panniculitis, unspecified, hypertrophy of infrapatellar fat pad: coded as FALSE
  diagCategories[grepl('^DM79[2-4].*' , diagnosis) , unspecific := FALSE]
  ##Residual foreign body in soft tissue: coded as FALSE
  diagCategories[grepl('^DM795.*' , diagnosis) , unspecific := FALSE]
  ##Pain in limb: coded as TRUE
  diagCategories[grepl('^DM796.*' , diagnosis) , unspecific := TRUE]
  ##Fibromyalgia: coded as TRUE
  diagCategories[grepl('^DM797.*' , diagnosis) , unspecific := TRUE]
  ##Other specified soft tissue disorders, soft tissue disorder unspecified, osteopathies: coded as FALSE
  diagCategories[grepl('^DM79[8-9].*|^DM8.*|^DM90.*' , diagnosis) , unspecific := FALSE]
  ##Chondropathies, other disorders of the musculoskeletal system and connective tissue: coded as FALSE
  diagCategories[grepl('^DM9[1-9].*' , diagnosis) , unspecific := FALSE]
  ##Glomerular diseases, renal tubulo-interstitial diseases: coded as FALSE
  diagCategories[grepl('^DN0.*|^DN1[0-6].*' , diagnosis) , unspecific := FALSE]
  ##Renal failure, urolithiasis, other disorders of kidney and ureter, acute cystitis: coded as FALSE
  diagCategories[grepl('^DN1[7-9].*|^DN2.*|^DN300.*' , diagnosis) , unspecific := FALSE]
  ##Interstitial cystitis (chronic)
  diagCategories[grepl('^DN301.*' , diagnosis) , unspecific := TRUE]
  ##Other chronic cystitis, trigonitis, irradiation cystitis, other cystitis, cystitis unspecified: coded as FALSE
  diagCategories[grepl('^DN30[2-9].*' , diagnosis) , unspecific := FALSE]
  ##Neuromuscular dysfunction of the bladder, other disorders of the bladder: coded as FALSE
  diagCategories[grepl('^DN3[1-2].*' , diagnosis) , unspecific := FALSE]
  ##Bladder disorders in diseases classified elsewhere, urethritis, urethral syndrome, urethral stricture: coded as FALSE
  diagCategories[grepl('^DN3[3-5].*' , diagnosis) , unspecific := FALSE]
  ##Other disorders of urethra, urethral disorders in diseases classified elsewhere, other disorders the urinary system: coded as FALSE
  diagCategories[grepl('^DN3[6-9].*' , diagnosis) , unspecific := FALSE]
  ##Diseases of male genital organs, disorders of breast, inflammatory diseases of female pelvic organs: coded as FALSE
  diagCategories[grepl('^DN[4-6].*|^DN7[0-7].*' , diagnosis) , unspecific := FALSE]
  ##Endometriosis, female genital prolapse, fistulae involving female genital tract: coded as FALSE
  diagCategories[grepl('^DN8[0-2].*' , diagnosis) , unspecific := FALSE]
  ##Noninflammatory disorders of ovary, fallopian tube and broad ligament, polyp of female genital tract: coded as FALSE
  diagCategories[grepl('^DN8[3-4].*' , diagnosis) , unspecific := FALSE]
  ##Other noninflammatory disorders of uterus, except cervix, erosion, ectropion of cervix uteri, dysplasia of cervix uteri: coded as FALSE
  diagCategories[grepl('^DN8[5-7].*' , diagnosis) , unspecific := FALSE]
  ##Other noninflammatory disorders of cervix uteri, other noninflammatory disorders of vagina: coded as FALSE
  diagCategories[grepl('^DN8[8-9].*' , diagnosis) , unspecific := FALSE]
  ##Other noninflammatory disorders of vulva and perineum, absent, scanty and rare menstruation: coded as FALSE
  diagCategories[grepl('^DN9[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Excessive, frequent and irregular menstruation, other abnormous bleeding from the uterus and vagina, pain during ovulation: coded as FALSE
  diagCategories[grepl('^DN9[2-3].*|^DN940.*' , diagnosis) , unspecific := FALSE]
  ##Dyspareunia: coded as TRUE
  diagCategories[grepl('^DN941.*' , diagnosis) , unspecific := TRUE]
  ##Vaginismus, premenstrual tension syndrome, primary dysmenorrhoea, secondary dysmenorrhoea: coded as FALSE
  diagCategories[grepl('^DN94[2-5].*' , diagnosis) , unspecific := FALSE]
  ##Dysmenorrhoea, unspecified, menopausal and other perimenopausal disorders, habitual abortion, female infertility: coded as FALSE
  diagCategories[grepl('^DN94[6-9].*|^DN9[5-7].*' , diagnosis) , unspecific := FALSE]
  ##Complications associated with artificial fertilization, other disorders of genitourinary tract: coded as FALSE
  diagCategories[grepl('^DN9[8-9].*' , diagnosis) , unspecific := FALSE]
  ##Certain conditions originating in the perinatal period: coded as FALSE
  diagCategories[grepl('^DP[0-8].*|^DP9[0-6].*' , diagnosis) , unspecific := FALSE]
  ##Congenital malformations, deformations and chromosomal abnormalities: coded as FALSE
  diagCategories[grepl('^DQ[0-9].*' , diagnosis) , unspecific := FALSE]
  ##Abnormalities of heart beat, cardiac murmurs and other cardiac sounds, gangrene not elsewhere classified: coded as FALSE
  diagCategories[grepl('^DR0[0-2].*' , diagnosis) , unspecific := FALSE]
  ##Abnormal blood pressure reading without diagnosis, haemorrhage from respiratory passages
  diagCategories[grepl('^DR0[3-4].*' , diagnosis) , unspecific := FALSE]
  ##Cough, abnormalities of breathing, pain in throat and chest: coded as TRUE
  diagCategories[grepl('^DR0[5-7].*' , diagnosis) , unspecific := TRUE]
  ##Other symptoms and signs involving the circulatory and respiratory systems: coded as FALSE
  diagCategories[grepl('^DR09.*' , diagnosis) , unspecific := FALSE]
  ##Abdominal and pelvic pain, nausea and vomiting, heartburn, dysphagia: coded as TRUE
  diagCategories[grepl('^DR1[0-3].*' , diagnosis) , unspecific := TRUE]
  ##Flatulence and related conditions, faecal incontinence: coded as TRUE
  diagCategories[grepl('^DR1[4-5].*' , diagnosis) , unspecific := TRUE]
  ##Hepatomegaly and splenomegaly, not elsewhere classified, unspecified jaundice, ascites: coded as FALSE
  diagCategories[grepl('^DR1[6-8].*' , diagnosis) , unspecific := FALSE]
  ##Intra-abdominal and pelvic swelling, mass and lump, abdominal bowel sounds, visible peristalsis, abdominal rigidity: coded as FALSE
  diagCategories[grepl('^DR19[0-3].*' , diagnosis) , unspecific := FALSE]
  ##Change in bowel habit, other faecal abnormalities: coded as TRUE
  diagCategories[grepl('^DR19[4-5].*' , diagnosis) , unspecific := TRUE]
  ##Halitosis: coded as FALSE
  diagCategories[grepl('^DR196.*' , diagnosis) , unspecific := FALSE]
  ##Other specified symptoms and signs involving the digestive system and abdomen: coded as TRUE
  diagCategories[grepl('^DR198.*' , diagnosis) , unspecific := TRUE]
  ##Disturbances of skin sensation: coded as TRUE
  diagCategories[grepl('^DR20.*' , diagnosis) , unspecific := TRUE]
  ##Rash and non-specific skin eruption, localized swelling, mass and lump of skin and subcutaneous tissue: coded as FALSE
  diagCategories[grepl('^DR2[1-2].*' , diagnosis) , unspecific := FALSE]
  ##Other skin changes, abnormal involuntary movements: coded as FALSE
  diagCategories[grepl('^DR2[3-5].*' , diagnosis) , unspecific := FALSE]
  ##Abnormalities of gait and mobility, other lack of coordination: coded as TRUE
  diagCategories[grepl('^DR2[6-7].*' , diagnosis) , unspecific := TRUE]
  ##Other symptoms and signs involving the nervous and musculoskeletal systems: coded as FALSE
  diagCategories[grepl('^DR29.*' , diagnosis) , unspecific := FALSE]
  ##Pain associated with micturition: coded as TRUE
  diagCategories[grepl('^DR30.*' , diagnosis) , unspecific := TRUE]
  ##Unspecified haematuria: coded as FALSE
  diagCategories[grepl('^DR31.*' , diagnosis) , unspecific := FALSE]
  ##Unspecified urinary incontinence: coded as TRUE
  diagCategories[grepl('^DR32.*' , diagnosis) , unspecific := TRUE]
  ##Retention of urine, anuria and oliguria, polyuria, urethral discharge: coded as FALSE
  diagCategories[grepl('^DR3[3-6].*' , diagnosis) , unspecific := FALSE]
  ##Other symptoms and signs involving the urinary system, somnolence, stupor and coma: coded as FALSE
  diagCategories[grepl('^DR39.*|^DR40.*' , diagnosis) , unspecific := FALSE]
  ##Other symptoms and signs involving cognitive functions and awareness, dizzinesand giddiness: coded as TRUE
  diagCategories[grepl('^DR4[1-2].*' , diagnosis) , unspecific := TRUE]
  ##Disturbances of smell and taste, other symptoms and signs involving general sensations and perceptions: coded as TRUE
  diagCategories[grepl('^DR4[3-4].*' , diagnosis) , unspecific := TRUE]
  ##Symptoms and signs involving emotional state, symptoms and signs involving appearance and behaviour: coded as TRUE
  diagCategories[grepl('^DR4[5-6].*' , diagnosis) , unspecific := TRUE]
  ##Speech and voice: coded as TRUE
  diagCategories[grepl('^DR4[7-9].*' , diagnosis) , unspecific := TRUE]
  ##Fever of unknown origin: coded as FALSE
  diagCategories[grepl('^DR50.*' , diagnosis) , unspecific := FALSE]
  ##Headache, pain not elsewhere classified, malaise and fatigue: coded as TRUE
  diagCategories[grepl('^DR5[1-3].*' , diagnosis) , unspecific := TRUE]
  ##Senility: coded as FALSE
  diagCategories[grepl('^DR54.*' , diagnosis) , unspecific := FALSE]
  ##Syncope and collapse: coded as TRUE
  diagCategories[grepl('^DR55.*' , diagnosis) , unspecific := TRUE]
  ##Convulsions not elsewhere classified, shock not elsewhere classified, haemorrhage not elsewhere classified: coded as FALSE
  diagCategories[grepl('^DR5[6-8].*' , diagnosis) , unspecific := FALSE]
  ##Enlarged lymph nodes, oedema not elsewhere classified, hyperhidrosis: coded as FALSE
  diagCategories[grepl('^DR59.*|^DR6[0-1].*' , diagnosis) , unspecific := FALSE]
  ##Lack of expected normal physiological development
  diagCategories[grepl('^DR62.*' , diagnosis) , unspecific := FALSE]
  ##Symptoms and signs concerning food and fluid intake: coded as TRUE
  diagCategories[grepl('^DR63.*' , diagnosis) , unspecific := TRUE]
  ##Cachexia: coded as FALSE
  diagCategories[grepl('^DR64.*' , diagnosis) , unspecific := FALSE]
  ##Other general symptoms and signs: coded as FALSE
  diagCategories[grepl('^DR68.*' , diagnosis) , unspecific := FALSE]
  ##Unknown and unspecified causes of morbidity: coded as TRUE
  diagCategories[grepl('^DR69.*' , diagnosis) , unspecific := TRUE]
  ##On examination of blood without diagnosis, on examination of urine without diagnosis: coded as FALSE
  diagCategories[grepl('^DR7.*|^DR8[0-2].*' , diagnosis) , unspecific := FALSE]
  ##On examination of other bodily fluids, substances and tissues without diagnosis: coded as FALSE
  diagCategories[grepl('^DR8[3-9].*' , diagnosis) , unspecific := FALSE]
  ##On diagnostic imaging and in function studies without diagnosis: coded as FALSE
  diagCategories[grepl('^DR9[0-4].*' , diagnosis) , unspecific := FALSE]
  ##Sudden infant death syndrome, other sudden death, cause unknown, unattended death: coded as FALSE
  diagCategories[grepl('^DR9[5-8].*' , diagnosis) , unspecific := FALSE]
  ##Other ill-defined and unspecified causes of mortality: coded as FALSE
  diagCategories[grepl('^DR99.*' , diagnosis) , unspecific := FALSE]
  ##The Z chapter is mainly describing interventions and encounters and is thus excluded from this sorting algorithm as described. However, two Z-diagnoses lend themselves to classification of illness, one for unspecific symptoms:
  ##Medical observation and evaluation for suspected diseases and conditions: coded as TRUE 
  diagCategories[grepl('^DZ03.*' , diagnosis) , unspecific := TRUE]
  ##Asymptomatic HIV infection status: excluded according to algorithm

  ##There are additional re-classifications according to the articles cited - they will be implemented on top of the above here and all represent codings as TRUE - for documentation see pre-registration:
  ##To avoid typing errors, this list was typed twice and compared:
  unspecificDiagnoses <- c("DG439" , "DG448" , "DG459" , "DG470" , "DG471" , "DG472" , "DG969" , "DG989" , "DH539" , "DH818" , "DH819" , "DH920" , "DH938" , "DI208" , "DI209" , "DJ11" , "DK529" , "DK590" , "DK591" , "DK599" , "DK839" , "DL509" , "DM222" , "DM239" , "DM249" , "DM253" , "DM258" , "DM259" , "DM357" , "DM539" , "DM541" , "DM544" , "DM708" , "DM709" , "DM758" , "DM759" , "DN393" , "DN394" , "DN399" , "DN645" , "DN859" , "DN920" , "DN925" , "DN926" , "DN940" , "DN944" , "DN945" , "DN946" , "DN949" , "DR000" , "DR002" , "DR194" , "DR196" , "DR252" , "DR298" , "DR391" , "DR568" , "DR569" , "DR609" , "DR940" , "DT784" , "DT887" , "DT887A" , "DT909" , "DT925" , "DT929" , "DT939" , "DT933A" , "DT983")

  ##unspecificDiagnosesCompare <- c("DG439" , "DG448" , "DG459" , "DG470" , "DG471" , "DG472" , "DG969" , "DG989" , "DH539" , "DH818" , "DH819" , "DH920" , "DH938" , "DI208" , "DI209" , "DJ11" , "DK529" , "DK590" , "DK591" , "DK599" , "DK839" , "DL509" , "DM222" , "DM239" , "DM249" , "DM253" , "DM258" , "DM259" , "DM357" , "DM539" , "DM541" , "DM544" , "DM708" , "DM709" , "DM758" , "DM759" , "DN393" , "DN394" , "DN399" , "DN645" , "DN859" , "DN920" , "DN925" , "DN926" , "DN940" , "DN944" , "DN945" , "DN946" , "DN949" , "DR000" , "DR002" , "DR194" , "DR196" , "DR252" , "DR298" , "DR391" , "DR568" , "DR569" , "DR609" , "DR940" , "DT784" , "DT887" , "DT887A" , "DT909" , "DT925" , "DT929" , "DT939" , "DT933A" , "DT983")
  ##The two sets were compared using the commands below and missing diagnoses and errors were corrected in the variable unspecificDiagnoses.
  ##setdiff(unspecificDiagnosesCompare , unspecificDiagnoses)
  ##setdiff(unspecificDiagnoses , unspecificDiagnosesCompare)

  ##Coding all diagnoses in unspecificDiagnoses as TRUE:
  ##Converting the diagnosis-list to a regular expression that can be used with grepl:
  unspecificDiagnosesRegular <- paste0("^" , unspecificDiagnoses , ".*" , "|" , collapse = "")
  ##Removing the final "|":
  unspecificDiagnosesRegular <- substr(unspecificDiagnosesRegular , 1 , (nchar(unspecificDiagnosesRegular) - 1))
  ##Using the generated expression with grepl:
  diagCategories[grepl(unspecificDiagnosesRegular , diagnosis) , unspecific := TRUE]


  ##Checking for as yet uncategorized diagnoses:
  diagCategories[is.na(unspecific) == TRUE & !grepl('^DZ.*|^DT.*' , diagnosis) , .N]
  diagCategories[is.na(unspecific) == TRUE & !grepl('^DZ.*|^DT.*' , diagnosis)]
  source("errorListNOEXPORT.R")
  ##Marking all erroneus diagnoses (errors kept in a separate file and not exported as the errors might have meanings unknown to the programmer), and could be interpreted as individual data: 
  diagCategories[diagnosis %in% errorList , diagError := TRUE]

  ##My own additions to the pre-described algorithm - these were found, but, as can be seen below, not coded as unspecific. This is to preserve the true positives of this classification, as all diagnoses coded above have been validated by expert concensus. The categories below could, however, be considered in a later classification:
  ##Headache without subspecification: coded as FALSE; this headache could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DG44$' , diagnosis) , unspecific := FALSE]
  ##Polyneuropathy without subspecification: coded as FALSE; this polyneuropathy could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DG62$' , diagnosis) , unspecific := FALSE]
  ##Back pain without subspecification: coded as FALSE; this pain could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DM54$' , diagnosis) , unspecific := FALSE]
  ##Rheumatism without subspecification: coded as FALSE; this rheumatism could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DM79$' , diagnosis) , unspecific := FALSE]
  ##Cystitis without subspecification: coded as FALSE; this cystitis could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DN30$' , diagnosis) , unspecific := FALSE]
  ##Pain related to female reproductive organs and menstruation without subspecification: coded as FALSE; these conditions could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DN94$' , diagnosis) , unspecific := FALSE]
  ##Other symptoms and abnormal findings in digestive system and abdomen: coded as FALSE; these conditions could be with well-defined etiology but not coded as such
  diagCategories[grepl('^DR19$' , diagnosis) , unspecific := FALSE]
  ##Systemic inflammatory response syndrome, unspecified: coded as FALSE: this code is not registered in the Danish use of ICD 10 but internationally used as an addition to another primary code, causing this condition. The primary code should be the source of classification here.
  diagCategories[grepl('^DR659$' , diagnosis) , unspecific := FALSE]
  ##Findings on self-reliance: coded as FALSE; this is not a diagnosis or a symptom but a clinical evaluation. A number of sub-categories are included here. 
  diagCategories[grepl('^DR67.*' , diagnosis) , unspecific := FALSE]

  ##Checking for as yet uncategorized diagnoses:
  diagCategories[is.na(unspecific) == TRUE & !grepl('^DZ.*|^DT.*' , diagnosis) & !diagError == TRUE , .N] #0 entries - all eligible diagnoses have now been categorized according to previous literature. A few diagnoses have been added, with none of these categorized as unspecific. All diagnoses in the unspecific category have thus been categorized as so by clinical practitioners with expert knowledge.
  fwrite(diagCategories , "diagCategories.csv")
  ## diagCategories[!is.na(unspecific) , table(unspecific)]
  ## unspecific
  ## FALSE  TRUE 
  ## 13958   523
  ##As can be seen from the above, 523 diagnoses are categorized as unspecific and the remaining are categorized as conventional. 
#+end_src

** Code for categorizing according to Prior, Lysell and Nager
#+begin_src R :session rsession :results output :exports both
  diagCategories <- fread("diagCategories.csv")
  ##Importing all lmdb-codes from lmdb.csv - this file is not generated routinely because of its size, but code for the generation can be found at the end of reading in diagnoses in "Code for creation of dataset for G-formula analysis". Here the file is reduced to unique codes, which will form the base of categorization:
  ##atcCategories <- fread("lmdb.csv" , select = "atc")
  ##atcCategories <- unique(atcCategories)
  ##fwrite(atcCategories , "atcCategoriesUnique.csv")
  atcCategories <- fread("atcCategoriesUnique.csv")
  ##Adding psych diagnoses
  psych <- fread("icd10Psych.csv" , header = FALSE , col.names = "diagnosis")
  psych[ , c("pregnancy" , "unspecific" , "diagError") := NA]
  diagCategories <- rbindlist(list(diagCategories , psych))
  ##Removing diagnoses known to be in error:
  ##This algorithm was run once without the following command to check if any diagnoses were classified as both unspecific and in a conditionGroup
  diagCategories <- diagCategories[!diagError == TRUE | is.na(diagError) == TRUE]
  diagCategories[ , table(diagError , useNA = "always")] #None categorized as expected
  ##Add conditionCategory and conditionGroup ad Prior's work:
  diagCategories[ , c("conditionCategory" , "conditionGroup") := character()]
  atcCategories[ , c("conditionCategory" , "conditionGroup") := character()]
  ##Adding further variables that will be present in the future dataset:
  diagCategories[ , GESTATIONSALDER_DAGE := numeric()]
  diagCategories[ , c("D_FODTDTO" , "D_TERMIN") := character()]

  ##All coding that follows is checked by the commands diagCategories[ is.na(conditionGroup) == FALSE , View(.SD)] and diagCategories[ is.na(substanceAbuse) == FALSE , .SD]. Some code still does not have the variables it is supposed to be checking, and is thus checked multiple times by eyeballing. 
  ##Coding conditionGroup for circulatory system:
  diagCategories[grepl('^DI1[0-3].*|^DI15.*' , diagnosis) , conditionGroup := "Hypertension"]
  ##diagCategories[grepl('' , atc) , conditionGroup := "Hypertension"] ##C02 is not used as it can mean both hypertension, attention-deficit hyperactivity disorder and prostate hyperplasia; C04 is not used as it can be used for treatment of claudicatio intermittens; C07 is not used as it could be a number of heart-related illnesses; C08 is not used as it can be used against uterine contractions and as a treatment of angina; C09 is not used as ACE-inhibitors can be used for treatment of heart failure and hypertension; C03 is not used as it can be used for heart failure, hypertension and urolithiasis.
  diagCategories[grepl('^DE78.*' , diagnosis) , conditionGroup := "Dyslipidemia"]
  atcCategories[grepl('^C10[A-B]A.*|^C10AX.*|^C10AX.*|^C10A[B-D].*' , atc) , conditionGroup := "Dyslipidemia"] ##Selections here were limited to drugs that only targeted dyslipidemia
  diagCategories[grepl('^DI20[0-7].*|^DI2[1-5].*' , diagnosis) , conditionGroup := "Ischemic heart disease"]##DI208 and 209 has been left out as they have been categorized as unspecific
  atcCategories[grepl('^C01DA.*' , atc) , conditionGroup := "Ischemic heart disease"]
  diagCategories[grepl('^DI48.*' , diagnosis) , conditionGroup := "Atrial fibrillation"]
  diagCategories[grepl('^DI50.*' , diagnosis) , conditionGroup := "Heart failure"]
  diagCategories[grepl('^DI7[0-4].*' , diagnosis) , conditionGroup := "Peripheral artery occlusive disease"]
  diagCategories[grepl('^DI6[0-4].*|^DI69.*' , diagnosis) , conditionGroup := "Stroke"]

  ##Coding conditionGroup for endocrine system:
  diagCategories[grepl('^DE1[0-4].*' , diagnosis) , conditionGroup := "Diabetes mellitus"]
  atcCategories[grepl('^A10A.*|^A10B.*' , atc) , conditionGroup := "Diabetes mellitus"]
  diagCategories[grepl('^DE0[0-5].*|^DE061.*|^DE069.*|^DE07.*' , diagnosis) , conditionGroup := "Thyroid disorder"]
  atcCategories[grepl('^H03.*' , atc) , conditionGroup := "Thyroid disorder"]
  diagCategories[grepl('^DE79.*|^DM10.*' , diagnosis) , conditionGroup := "Gout"]

  ##Coding conditionGroup for pulmonary system:
  ##diagCategories[grepl('' , diagnosis) , conditionGroup := "Chronic pulmonary disease"] ##No such diagnoses predefined by Prior
  atcCategories[grepl('^DR03.*' , atc) , conditionGroup := "Chronic pulmonary disease"]
  atcCategories[grepl('^R06AX.*|^R06AE07.*|^R06AE09.*|^R01AC.*|^R01AD.*' , atc) , conditionGroup := "Allergy"]
  ##In the original classification the two categories available here are both coded exclusively on prescription medicine. Will inquire about this to the author.

  ##Coding conditionGroup for gastrointestinal system:
  diagCategories[grepl('^DK221.*|^DK2[5-8].*|^DK29[3-5].*' , diagnosis) , conditionGroup := "Ulcer/chronic gastritis"]
  diagCategories[grepl('^DB1[6-9].*|^DK7[0-4].*|^DK766.*|^DI85.*' , diagnosis) , conditionGroup := "Chronic liver disease"]
  diagCategories[grepl('^DK5[0-1].*' , diagnosis) , conditionGroup := "Inflammatory bowel disease"]
  diagCategories[grepl('^DK57.*' , diagnosis) , conditionGroup := "Diverticular disease of intestine"]

  ##Coding conditionGroup for urogenital system:
  diagCategories[grepl('^DN03.*|^DN11.*|^DN1[8-9].*' , diagnosis) , conditionGroup := "Chronic kidney disease"]
  diagCategories[grepl('^DN40.*' , diagnosis) , conditionGroup := "Prostate disorders"]
  ##ATC-code C02CA is not used, as it can be used in hypertension and prostate disorders; G04C is not used with same argument.

  ##Coding conditionGroup for musculoskeletal system:
  diagCategories[grepl('^DM0[5-6].*|^DM0[8-9].*|^DM3[0-4].*|^DM35[0-6].*|^DM35[8-9].*|^DM36.*|^DD86.*' , diagnosis) , conditionGroup := "Connective tissue disorders"] ##DM357 has been left out as it is categorized as unspecific
  diagCategories[grepl('^DM8[0-2].*' , diagnosis) , conditionGroup := "Osteoporosis"]
  atcCategories[grepl('^M05B.*|^H05AA.*|^G03XC01.*' , atc) , conditionGroup := "Osteoporosis"]
  ##When coding the selection mechanism, remember that all other categories constitute a change away from the unspecific diagnostic category - but not "painful condition".
  atcCategories[grepl('^N02BA51.*|^N02BE.*|^M0[1-2]A.*' , atc) , conditionGroup := "Painful condition"] 

  ##Coding conditionGroup for hematological system:
  ##HIV is excluded here as infectious diseases are excluded according to the protocol
  diagCategories[grepl('^DD5[0-3].*|^DD5[5-9].*|^DD6[0-1].*|^DD6[3-4].*' , diagnosis) , conditionGroup := "Anemia"]

  ##Coding conditionGroup for cancers:
  diagCategories[grepl('^DC[0-3].*|^DC4[0-3].*|^DC4[5-9].*|^DC[5-8].*|^DC9[0-7].*' , diagnosis) , conditionGroup := "Cancer"]

  ##Coding conditionGroup for neurological system:
  diagCategories[grepl('^DH40.*|^DH25.*|^DH54.*' , diagnosis) , conditionGroup := "Vision problem"]
  diagCategories[grepl('^DH9[0-1].*|^DH931.*' , diagnosis) , conditionGroup := "Hearing problem"]
  diagCategories[grepl('^DG43[0-8].*' , diagnosis) , conditionGroup := "Migraine"] ##DG439 has been left out as it is categorized as unspecific
  atcCategories[grepl('^N02C.*' , atc) , conditionGroup := "Migraine"] 
  diagCategories[grepl('^DG4[0-1].*' , diagnosis) , conditionGroup := "Epilepsy"] ##There is something wrong here - migraine is included in the epilepsy category; I have corrected this, it seems 7 should have been 1 in the supplementary material in Prior's article.
  ##Drugs for epilepsy are not included here as they may be used for neurologic pain and, in the case of benzodiazepines, treatment of acute psychiatric illness such as mania. 
  diagCategories[grepl('^DG2[0-2].*' , diagnosis) , conditionGroup := "Parkinson's disease"]
  diagCategories[grepl('^DG35.*' , diagnosis) , conditionGroup := "Multiple sclerosis"]
  ##For a single diagnosis, Prior's categories conflict with the unspecific - making an exception: 
  diagCategories[grepl('^DG5.*|^DG6[0-4].*' , diagnosis) & !grepl('^DG629.*' , diagnosis), conditionGroup := "Neuropathies"]


  ##Below is additional code to achieve preterm categorization from last menstruation - use other registries for this, LPRMFRLF has D_TERMIN, more than three weeks before this would constitute premature birth according to the classification used by Nager. MFR has GESTATIONSALDER_DAGE which would correspond to premature birth with values less than 37*7=259.
  ##Preterm birth until end of 1996:
  ##Converting to dates:
  diagCategories[ , D_FODTDTODato := as.Date(D_FODTDTO , format = "%m/%d/%Y")]
  diagCategories[ , D_TERMINDato := as.Date(D_TERMIN , format = "%m/%d/%Y")]
  diagCategories[(D_TERMINDato - D_FODTDTODato) > 21 , conditionGroup := "Preterm birth"] ##If birth is more than three weeks prior to estimated 40 weeks gestational age
  ##Preterm birth from 1997 and onwards:
  diagCategories[GESTATIONSALDER_DAGE < 259 , conditionGroup := "Preterm birth"] ##If gestational age at birth is less than 259 days, that constitutes birth before 37 weeks

  ##Coding conditionGroup for mental health conditions:
  diagCategories[grepl('^DF3[2-4].*|^DF4[0-8].*' , diagnosis) , conditionGroup := "Mood, stress-related, or anxiety disorders"]
  ##diagCategories[grepl( , diagnosis) , conditionGroup := "Psychological distress"] #Psychological distress will likely not be coded unless I find something else than antidepressants to put in there - and in that case, the group will be given an entirely new meaning. 
  ##Antidepressants are not included here as they may also be used for treatment of pain. 
  diagCategories[grepl('^DF50.*' , diagnosis) , conditionGroup := "Anorexia/bulimia"]
  diagCategories[grepl('^DF3[0-1].*' , diagnosis) , conditionGroup := "Bipolar affective disorder"]
  atcCategories[grepl('^N05AN.*' , atc) , conditionGroup := "Bipolar affective disorder"] ##There is a risk of double-grouping here as treatment-refractory depressions might also be treated with lithium - however, this is considered a somewhat rare treatment according to the first auithor's clinical experience, and this treatment is not mentioned in the current Danish treatment guidelines for depression as specified by Rdet for Anvendelse af Dyr Sygehusmedicin, and the guidelines for treatment of treatment-refractory depression, as specified by the Danish Society for Psychiatry. Thus, the risk of double-grouping is considered minimal. 
  diagCategories[grepl('^DF20.*|^DF25.*' , diagnosis) , conditionGroup := "Schizophrenia or schizoaffective disorder"]
  diagCategories[grepl('^DF0[0-3].*|^DF051.*|^DG30.* ' , diagnosis) , conditionGroup := "Dementia"] ##Some versions of dementia have infectious origins (HIV and rare cases of Creutzfeldt-Jakobs) - they are included here as they mimic dementia.
  atcCategories[grepl('^N06D.*' , atc) , conditionGroup := "Dementia"]
  diagCategories[grepl('^DF60.*' , diagnosis) , conditionGroup := "Personality disorder"]##Added according to Lysell et al as mentioned in the algorithm. 

  fwrite(diagCategories , "diagCategoriesPrior.csv")
  fwrite(atcCategories , "atcCategoriesPrior.csv")
#+end_src
** Code for additional categorization after Prior, Lysell and Nager has been implemented
#+begin_src R :session rsession :results output :exports both
  library(data.table)
  ##The purpose of this codeblock is to take all diagnoses not formerly categorized and add to either one of the predefined categories, the broad category "Other" or a new category, given this makes sense as a partial cause of stress.
  diagCategories <- fread("diagCategoriesPrior.csv")
  diagCategories[ , leftOut := logical()]
  atcCategories <- fread("atcCategoriesPrior.csv")
  ##All diagnoses without a conditionGroup will be inspected piecewise by a command similar to this: 
  ##diagCategories[conditionGroup == "" & is.na(leftOut)][1:1000 , diagnosis]
  ##Categorization rules will be made based on this inspection:
  ##Non-melanoma skin cancer:
  diagCategories[grepl('^DC44.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##Local recurrence:
  diagCategories[grepl('^DC991.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##Different kinds of neoplasms in situ:
  diagCategories[grepl('^DD0.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##Benign tumors and tumors of unknown type:
  diagCategories[grepl('^DD[1-4].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD62.* is anemia after acute bleeding - this could be the result of accident, will be left out of the classification.
  diagCategories[grepl('^DD62.*' , diagnosis) , leftOut := TRUE]
  ##DD65 is a complication to infection - will be left out.
  diagCategories[grepl('^DD65.*' , diagnosis) , leftOut := TRUE]
  ##A number of coagulation defects, not anemias: 
  diagCategories[grepl('^DD6[6-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD70 describes a number of neutropenic conditions - they can be caused by medication or infection, leaving all out except for DD709C-E:
  diagCategories[grepl('^DD709[C-E].*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DD70.*' , diagnosis) & !grepl('^DD709[C-E].*' , diagnosis) , leftOut := TRUE]
  ##DD71 functional disturbances in polymorf neutrophile cells, classified as other:
  diagCategories[grepl('^DD71.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD72 other disturbances in white blood cells, classified as other:
  diagCategories[grepl('^DD72.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD73 diseases related to the spleen, classified as other:
  diagCategories[grepl('^DD73.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD74 methemoglobinemia, often related to poisoning or similar, left out:
  diagCategories[grepl('^DD74.*' , diagnosis) , leftOut := TRUE]
  ##DD75 various diseases in blood or blood-producing organs, classified as other:
  diagCategories[grepl('^DD75.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD76: other diseases involving lymph and histiocytes, classified as other (a re-classification could consider connective tissue disorders here, but would depend on individual subcategories):
  diagCategories[grepl('^DD76.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DD77: other diseases related to blood and blood-producing tissue - classified elsewhere, left out:
  diagCategories[grepl('^DD77.*' , diagnosis) , leftOut := TRUE]
  ##DD8: a number of immune system disturbances, classified as other, except for sarcoidosis, that has already been classified as connective tissue disorder:
  diagCategories[grepl('^DD8.*' , diagnosis) & !grepl('^DD86.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DE06 is too unspecific to be useful - will be left out
  diagCategories[grepl('^DE06$' , diagnosis) , leftOut := TRUE]
  ##DE060 - acute thyroiditis is an infection, will be left out
  diagCategories[grepl('^DE060.*' , diagnosis) , leftOut := TRUE]
  ##Chronic thyroiditis and other inflammatory thyroid processes
  diagCategories[grepl('^DE06[2-3].*|^DE065.*' , diagnosis) , conditionGroupAdditional := "Thyroid disorder"]
  ##DE064 - thyroiditis because of medication, will be left out
  diagCategories[grepl('^DE064.*' , diagnosis) , leftOut := TRUE]
  ##DE15 is non-diabetic hypoglycemic coma - could have many causes, will be left out.
  diagCategories[grepl('^DE15.*' , diagnosis) , leftOut := TRUE]
  ##DE16 is too unspecific, will be left out.
  diagCategories[grepl('^DE16$' , diagnosis) , leftOut := TRUE]
  ##DE160 is hypoglycemia caused by medication - could have many causes, will be left out.
  diagCategories[grepl('^DE160.*' , diagnosis) , leftOut := TRUE]
  ##DE161 is too unspecific, will be left out.
  diagCategories[grepl('^DE161$' , diagnosis) , leftOut := TRUE]
  ##DE161B is sequelae after hypoglycemia, could have many causes, will be left out.
  diagCategories[grepl('^DE161B.*' , diagnosis) , leftOut := TRUE]
  ##DE162 is hypoglycemia not further specified, could have many causes, will be left out.
  diagCategories[grepl('^DE162.*' , diagnosis) , leftOut := TRUE]
  ##A number of endocrine disease categories:
  diagCategories[grepl('^DE161A.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DE161C.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DE161D.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DE16[3-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DE2.*|^DE3[0-4].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DE35 is endocrine disease as an effect of other causes - will be left out.
  diagCategories[grepl('^DE35.*' , diagnosis) , leftOut := TRUE]
  ##DE4 and 5 up until DE64 are malnutrition and its effects - will be left out as these could be resulting from diseases classified in the F-chapter, but also for example from nausea from pregnancy or cancer treatment.
  diagCategories[grepl('^DE[4-5].*|^DE6[0-4].*' , diagnosis) , leftOut := TRUE]
  ##DE65-8 is a number of consequences of either medication or other causes of over-consumption, including habitual over-consumption and accidental intake of for example vitamins. Will be left out.
  diagCategories[grepl('^DE6[5-8].*' , diagnosis) , leftOut := TRUE]
  ##DE7[0-7]: A number of rare metabolic conditions
  diagCategories[grepl('^DE7[0-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DE8[0-8]: a number of electrolyte disturbances, uncommon metabolic conditions
  diagCategories[grepl('^DE8[0-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DE89: endocrine conditions as sequelae of other treatments, will be left out
  diagCategories[grepl('^DE89.*' , diagnosis) , leftOut := TRUE]
  ##DE90: not used in Denmark, nutritional and metabolic disorders in disease classified elsewhere, will be left out
  diagCategories[grepl('^DE9.*' , diagnosis) , leftOut := TRUE]
  ##DG0: inflammatory processes in the central nervous system, likely to be caused by infectious agents or post-infectious processes - left out
  diagCategories[grepl('^DG0.*' , diagnosis) , leftOut := TRUE]
  ##DG10: huntingtons, will be classified as dementia:
  diagCategories[grepl('^DG10.*' , diagnosis) , conditionGroupAdditional := "Dementia"]
  ##DG1[1-2] Ataxia and atrophia, will be classified as neuropathies:
  diagCategories[grepl('^DG1[1-2].*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG1[3-4] neurologic symptoms by disease defined elsewhere, will be left out
  diagCategories[grepl('^DG1[3-4].*' , diagnosis) , leftOut := TRUE]
  ##DG2[3-5]: a number of degenerative or motoric neurologic diseases, classified as Neuropathies
  diagCategories[grepl('^DG2[3-5].*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG26: neurologic disease from diseases classified elsewhere, left out
  diagCategories[grepl('^DG26.*' , diagnosis) , leftOut := TRUE]
  ##DG31: too unspecific, left out
  diagCategories[grepl('^DG31$' , diagnosis) , leftOut := TRUE]
  ##^DG31[0-1].*|^DG31[8-9].* and DG30 Other neurodegenerative diseases, classified as dementia:
  diagCategories[grepl('^DG31[0-1].*|^DG31[8-9].*|^DG30.*' , diagnosis) , conditionGroupAdditional := "Dementia"] 
  ##DG32: neurologic disease caused by diseases classified elsewhere, will be left out 
  diagCategories[grepl('^DG32.*' , diagnosis) , leftOut := TRUE]
  ##^DG36|^DG360.*|^DG368.*|^DG369.* Demyelinating diseases, classified as Neuropathies:
  diagCategories[grepl('^DG36|^DG360.*|^DG368.*|^DG369.*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG361: acute, autoimmune neurologic disease, classified as other:
  diagCategories[grepl('^DG361.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DG37: too unspecific, left out:
  diagCategories[grepl('^DG37$' , diagnosis) , leftOut := TRUE]
  ##Diffuse central sclerosis, classified as multiple sclerosis
  diagCategories[grepl('^DG370.*' , diagnosis) , conditionGroupAdditional := "Multiple sclerosis"]
  ##DG371: rare neurologic disorder, classified as other
  diagCategories[grepl('^DG371.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DG372: central pontine myelinolysis; a consequence of either accidents or treatment, left out
  diagCategories[grepl('^DG372.*' , diagnosis) , leftOut := TRUE]
  ##DG373: sequela of other disease, left out
  diagCategories[grepl('^DG373.*' , diagnosis) , leftOut := TRUE]
  ##DG374: paraesthesia and loss of function of lower limbs, classified as Neuropathies:
  diagCategories[grepl('^DG374.*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG375, encephalitis periaxialis concentrica: rare disease, hypothesized to be and classified as multiple sclerosis:
  diagCategories[grepl('^DG375.*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG37[8-9]: de-myelinating CNS disease, classified as neuropathies:
  diagCategories[grepl('^DG37[8-9].*' , diagnosis) , conditionGroupAdditional := "Neuropathies"]
  ##DG43: migraine, too unspecific, left out
  diagCategories[grepl('^DG43$' , diagnosis) , leftOut := TRUE]
  ##DG44: too unspecific, left out
  diagCategories[grepl('^DG44$' , diagnosis) , leftOut := TRUE]
  ##Commenting this out, already classified as unspecific:
  ## ##DG44[0-1]: other types of headache, classified as Other
  ## diagCategories[grepl('^DG44[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DG44[3-4]: headache caused by other disease or medication, left out
  diagCategories[grepl('^DG44[3-4].*' , diagnosis) , leftOut := TRUE]
  ##DG45: transitory cerebral ischemia: categorized as Other
  diagCategories[grepl('^DG45[0-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DG46: symptom complexes following strokes in different parts of the brain - classified as Stroke:
  diagCategories[grepl('^DG46.*' , diagnosis) , conditionGroupAdditional := "Stroke"]
  ##DG47: disturbances of sleep, with some exceptions classified as "Other" 
  diagCategories[grepl('^DG47.*' , diagnosis) & !grepl('^DG47[0-2].*|^DG4735.*|^DG4736.*|^DG4739.*|^DG4743.*|^DG4754.*|^DG4755.*|^DG4766.*|^DG4767.*' , diagnosis), conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DG4702.*|^DG4703.*|^DG4714.*|^DG4715.*|^DG4725.*|^DG4726.*|^DG4735.*|^DG4736.*|^DG4739.*|^DG4743.*|^DG4754.*|^DG4755.*|^DG4766.*|^DG4767.*' , diagnosis) , leftOut := TRUE]
  ##DG7: neuromuscular illness, classified as "Other" with some exceptions left out
  diagCategories[grepl('^DG7.*' , diagnosis) & !grepl('^DG711E.*|^DG720.*|^DG722.*|^DG73.*' , diagnosis), conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DG711E.*|^DG720.*|^DG722.*|^DG73.*' , diagnosis) , leftOut := TRUE]
  ##DG8: pareses, classified as "Other":
  diagCategories[grepl('^DG8.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DG9: other neurologic diseases, classified as "Other" with some exceptions left out 
  diagCategories[grepl('^DG9.*' , diagnosis) & !grepl('^DG913.*|^DG92.*|^DG933.*|^DG935.*|^DG936.*|^DG938A.*|^DG94.*|^DG952.*|^DG958A.*|^DG958B.*|^DG969.*|^DG97.*|^DG989.*|^DG99.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DG913.*|^DG92.*|^DG933.*|^DG935.*|^DG936.*|^DG938A.*|^DG94.*|^DG952.*|^DG958A.*|^DG958B.*|^DG97.*|^DG99.*' , diagnosis) , leftOut := TRUE]
  ##DH0[0-6] eyelids, tear channel and eye socket - mostly infectious, left out with some exceptions, see below
  diagCategories[(grepl('^DH0[0-6].*' , diagnosis) & !grepl('^DH011$|^DH011A.*|^DH011B.*|^DH011C.*|^DH011D.*|^DH011E.*|^DH02.*|^DH042.*|^DH041.*|^DH045.*|^DH046.*|^DH053.*|^DH058.*' , diagnosis)) | diagnosis == "DH028A" , leftOut := TRUE]
  diagCategories[grepl('^DH011$|^DH011A.*|^DH011B.*|^DH011C.*' , diagnosis) , conditionGroupAdditional := "Allergy"]
  diagCategories[grepl('^DH011D.*|^DH011E.*|^DH02.*|^DH042.*|^DH041.*|^DH045.*|^DH046.*|^DH053.*|^DH058.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH10: inflammation in conjunctiva, left out
  diagCategories[grepl('^DH10.*' , diagnosis) , leftOut := TRUE]
  ##DH11: other disease in conjunctiva, classified as other with exceptions
  diagCategories[grepl('^DH11.*' , diagnosis) & !grepl('^DH112.*|^DH113.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DH112.*|^DH113.*' , diagnosis) , leftOut := TRUE]
  ##DH13: disease in conjunctiva resulting from disease classified elsewhere, left out
  diagCategories[grepl('^DH13.*' , diagnosis) , leftOut := TRUE]
  ##DH15: disease in sclera: classified as other
  diagCategories[grepl('^DH15.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH16: keratitis - a number of infectious and traumatic causes, left out
  diagCategories[grepl('^DH16.*' , diagnosis) , leftOut := TRUE]
  ##DH17: scars and impurities in cornea, left out
  diagCategories[grepl('^DH17.*' , diagnosis) , leftOut := TRUE]
  ##DH18: a number of cornea-related diseases, will be classified as Other:
  diagCategories[grepl('^DH18.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH19: diseases of cornea and other parts of eye as a result of other illnesses, left out
  diagCategories[grepl('^DH19.*' , diagnosis) , leftOut := TRUE]
  ##DH20: inflammation, presumably infectious, left out
  diagCategories[grepl('^DH20.*' , diagnosis) , leftOut := TRUE]
  ##DH21: other disease in iris, many of these traumatic, left out
  diagCategories[grepl('^DH21.*' , diagnosis) , leftOut := TRUE]
  ##DH22: diseases in iris resulting from diseases classified elsewhere, left out
  diagCategories[grepl('^DH22.*' , diagnosis) , leftOut := TRUE]
  ##DH26: cataracts: classified as vision problems, with two exceptions left out
  diagCategories[grepl('^DH26.*' , diagnosis) & !grepl('DH26[1-3].*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  diagCategories[grepl('DH26[1-3].*' , diagnosis) , leftOut := TRUE]
  ##DH27: changes in the optic lens, classified as vision problem
  diagCategories[grepl('^DH27.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH28: cataracts caused by other diseases, left out
  diagCategories[grepl('^DH28.*' , diagnosis) , leftOut := TRUE]
  ##DH30: posterior inflammation in eye, could be infectious, left out
  diagCategories[grepl('^DH30.*' , diagnosis) , leftOut := TRUE]
  ##DH31: chorioretinal disease, classified as vision problem
  diagCategories[grepl('^DH31.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH32: results of illness defined elsewhere, left out
  diagCategories[grepl('^DH32.*' , diagnosis) , leftOut := TRUE]
  ##DH33: retinal detachment, classified as vision problem
  diagCategories[grepl('^DH33.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH34: occlusion of retinal blood vessels, presumably as a result of other conditions, left out
  diagCategories[grepl('^DH34.*' , diagnosis) , leftOut := TRUE]
  ##DH35: a number of retinal conditions, classified as vision problem:
  diagCategories[grepl('^DH35.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH36: results of disease defined elsewhere, left out
  diagCategories[grepl('^DH36.*' , diagnosis) , leftOut := TRUE]
  ##DH42: glaucoma as a result of other disease, left out
  diagCategories[grepl('^DH42.*' , diagnosis) , leftOut := TRUE]
  ##DH43: diseases in corpus vitreum, classified as vision problem
  diagCategories[grepl('^DH43.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH44: a number of diseases, some caused by foreign bodies and infections, left out
  diagCategories[grepl('^DH44.*' , diagnosis) , leftOut := TRUE]
  ##DH45: results of disease classified elsewhere, left out
  diagCategories[grepl('^DH45.*' , diagnosis) , leftOut := TRUE]
  ##DH4[6-7] changes in nervus opticus, overlapping with neurological diseases, left out
  diagCategories[grepl('^DH4[6-7].*' , diagnosis) , leftOut := TRUE]
  ##DH48: results of disease classified elsewhere, left out
  diagCategories[grepl('^DH48.*' , diagnosis) , leftOut := TRUE]
  ##DH49-DH52: different accomodation and stereopsis diseases, classified as Vision problem
  diagCategories[grepl('^DH49.*|^DH5[0-2].*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH53: disturbance of vision, classified as vision problem:
  diagCategories[grepl('^DH53.*' , diagnosis) & !grepl('^DH539.*' , diagnosis), conditionGroupAdditional := "Vision problem"]
  ##DH54: partial and full blindness, classified as vision problem: 
  diagCategories[grepl('^DH54.*' , diagnosis) , conditionGroupAdditional := "Vision problem"]
  ##DH5[5-9]: either highly unspecific or resulting from other disease, left out partial and full blindness, classified as vision problem: 
  diagCategories[grepl('^DH5[5-9].*' , diagnosis) , leftOut := TRUE]
  ##DH60: a number of inflammatory conditions in outer ear, most infectious; left out
  diagCategories[grepl('^DH60.*' , diagnosis) , leftOut := TRUE]
  ##DH61: a number of other conditions in outer ear, classified as other
  diagCategories[grepl('^DH61.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH62: results of diseases classified elsewhere, left out
  diagCategories[grepl('^DH62.*' , diagnosis) , leftOut := TRUE]
  ##DH6[5-6]: middle ear inflammation, mostly infectious - left out
  diagCategories[grepl('^DH6[5-6].*' , diagnosis) , leftOut := TRUE]
  ##DH67: middle ear inflammation because of disease classified elsewhere, left out
  diagCategories[grepl('^DH67.*' , diagnosis) , leftOut := TRUE]
  ##DH68: occlusion of eustachian tube, mainly inflammatory, left out
  diagCategories[grepl('^DH68.*' , diagnosis) , leftOut := TRUE]
  ##DH69: other diseases in eustachian tube, classified as Other
  diagCategories[grepl('^DH69.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH70: mastoiditis: complication to infection, left out
  diagCategories[grepl('^DH70.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH71: cholesteatoma, classified as other
  diagCategories[grepl('^DH71.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DH72: perforation of eardrum - could be trauma or infection, left out
  diagCategories[grepl('^DH72.*' , diagnosis) , leftOut := TRUE]
  ##DH73: other disease of eardrum, mostly infections, left out
  diagCategories[grepl('^DH73.*' , diagnosis) , leftOut := TRUE]
  ##DH74: a number of illnesses in middle ear, classified as hearing problem
  diagCategories[grepl('^DH74.*' , diagnosis) , conditionGroupAdditional := "Hearing problem"]
  ##DH75 result of disease classified elsewhere, left out
  diagCategories[grepl('^DH75.*' , diagnosis) , leftOut := TRUE]
  ##DH80: otosclerosis: classified as hearing problem
  diagCategories[grepl('^DH80.*' , diagnosis) , conditionGroupAdditional := "Hearing problem"]
  ##DH81: vertigo, classified as other
  diagCategories[grepl('^DH81.*' , diagnosis) &
		 !grepl('^DH81[8-9].*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DH82: result of disease classified elsewhere, left out
  diagCategories[grepl('^DH82.*' , diagnosis) , leftOut := TRUE]
  ##DH83: a number of other inner ear diseases, classified as Other with one exception
  diagCategories[grepl('^DH83.*' , diagnosis) & !grepl('^DH833.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DH833.*' , diagnosis) , leftOut := TRUE]
  ##DH92: either unspecific symptoms or infectious agent or trauma - left out
  diagCategories[grepl('^DH92.*' , diagnosis) , leftOut := TRUE]
  ##DH931, DH932: hearing problems, remaining DH93: other
  diagCategories[grepl('^DH93.*' , diagnosis) & !grepl('^DH931.*|^DH932.*|^DH938.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DH931.*|^DH932.*' , diagnosis) , conditionGroupAdditional := "Hearing problem"]
  ##DH9[4-5] ear-related diseases caused by other diseases or by treatment, left out
  diagCategories[grepl('^DH9[4-5].*' , diagnosis) , leftOut := TRUE]
  ##DI: too unspecific, left out
  diagCategories[grepl('^DI$' , diagnosis) , leftOut := TRUE]
  ##DI0[0-9]: a number of rheumatic conditions affecting the heart, classified as Other
  diagCategories[grepl('^DI0[0-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI20: angina pectoris, classified as ischemic heart disease:
  diagCategories[grepl('^DI20$' , diagnosis) , conditionGroupAdditional := "Ischemic heart disease"]
  ##DI2[6-8]: a number of blood clots and circulatory diseases related to the lungs, classified as Other:
  diagCategories[grepl('^DI2[6-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI3: a number of infectious and possible causes of infectious diseases in the heart - left out:
  diagCategories[grepl('^DI3.*' , diagnosis) , leftOut := TRUE]
  ##DI4[0-1]: Myocarditis, either infectious, toxic or idiopathic - left out:
  diagCategories[grepl('^DI4[0-1].*' , diagnosis) , leftOut := TRUE]
  ##DI42: cardiomyophathy, classified as Other:
  diagCategories[grepl('^DI42.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI43: heart disease as a consequence of other illness, left out:
  diagCategories[grepl('^DI43.*' , diagnosis) , leftOut := TRUE]
  ##DI4[4-5]: different signal interruptions in the heart, classified as "Other":
  diagCategories[grepl('^DI4[4-5].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI46: Heart stop - this is highly unspecific and could have any number of causes, left out:
  diagCategories[grepl('^DI46.*' , diagnosis) , leftOut := TRUE]
  ##DI47, DI49: a number of arrhytmias - classified as "Other":
  diagCategories[grepl('^DI47.*|^DI49.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI51: poorly defined cardiac disease, classified as "Other":
  diagCategories[grepl('^DI51.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI52: cardiac disease as a result of other disease, left out:
  diagCategories[grepl('^DI52.*' , diagnosis) , leftOut := TRUE]
  ##DI6[5-7]: different cerebrovascular diseases, classified as Other:
  diagCategories[grepl('^DI6[5-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI6[8-9]: vascular neurologic consequenses of other disease, and sequelae of cerebrovascular disease - left out:
  diagCategories[grepl('^DI6[8-9].*' , diagnosis) , leftOut := TRUE]
  ##DI7[7-8]: vascular diseases, classified as Other:
  diagCategories[grepl('^DI7[7-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI79: vascular changes caused by other disease, left out:
  diagCategories[grepl('^DI79.*' , diagnosis) , leftOut := TRUE]
  ##DI8[0-9] except DI85: venous and lymph disease, classified as Other: 
  diagCategories[grepl('^DI8[0-9].*' , diagnosis) & !grepl('^DI85.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI95: low blood pressure, not as a consequence of other disease: classified as other:
  diagCategories[grepl('^DI95.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DI9[7-8]: circulatory disease as a result of other disease, left out:
  diagCategories[grepl('^DI9[7-8].*' , diagnosis) , leftOut := TRUE]
  ##DI99: under consideration for being unspecific, so far not coded
  ##DJ[0-1] and DJ2[0-2]: infectious disease, left out:
  diagCategories[grepl('^DJ[0-1].*' , diagnosis) , leftOut := TRUE]
  diagCategories[grepl('^DJ2[0-2].*' , diagnosis) , leftOut := TRUE]
  ##DJ30: allergic reactions, coded as allergy:
  diagCategories[grepl('^DJ30.*' , diagnosis) , conditionGroupAdditional := "Allergy"]
  ##DJ3[1-4] except DJ340: various diseases in nose, classified as other:
  diagCategories[grepl('^DJ3[1-4].*' , diagnosis) & !grepl('^DJ340.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ340: infectious diseases in nose, left out:
  diagCategories[grepl('^DJ340.*' , diagnosis) , leftOut := TRUE]
  ##DJ35: chronic diseases in tonsils and adenoid vegetations, classified as other:
  diagCategories[grepl('^DJ35.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ36: Abscess located to throat, left out:
  diagCategories[grepl('^DJ36.*' , diagnosis) , leftOut := TRUE]
  ##Chronic inflammation without further definition, classified as other:
  diagCategories[grepl('^DJ37.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ38: Diseases related to the vocal cords and surroundings, classified as other:
  diagCategories[grepl('^DJ38.*' , diagnosis) , conditionGroupAdditional := "Other"]
  diagCategories[grepl('^DJ39' , diagnosis) , leftOut := TRUE]
  ##DJ39[0-1] abscesses, left out:
  diagCategories[grepl('^DJ39[0-1].*' , diagnosis) , leftOut := TRUE]
  ##DJ39[2-9]: other disease of upper respiratory tract, classified as Other:
  diagCategories[grepl('^DJ39[2-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ40: unspecific bronchitis, classified as other:
  diagCategories[grepl('^DJ40.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ4[1-7]: various chronic lung conditions, classified as chronic pulmonary disease:
  diagCategories[grepl('^DJ4[1-7].*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ6[0-7]: lung disease caused by external agents, for example dust, long-time exposure to toxins etc. - classified as chronic pulmonary disease:
  diagCategories[grepl('^DJ6[0-7].*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ68 and DJ68[0-9] except DJ684: varying acute or subacute conditions upon exposure to inflammatory agents - classified as other: 
  diagCategories[grepl('^DJ68|^DJ68[0-9].*' , diagnosis) & !grepl('DJ684.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ684: chronic disease caused by inflammatory agents - clasified as chronic pulmonary disease:
  diagCategories[grepl('DJ684.*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ68[8-9]: highly unspecific results of external agents - classified as other:
  diagCategories[grepl('DJ68[8-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DJ8[0-4] except DJ81, pulmonary edema: varying interstitial chronic lung diseases, classified as chronic pulmonary disease:
  diagCategories[grepl('^DJ8[0-4].*' , diagnosis) & !grepl('^DJ81.*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ81: pulmonary edema, highly unspecific but likely to be caused by other disease, left out:
  diagCategories[grepl('^DJ81.*' , diagnosis) , leftOut := TRUE]
  ##DJ8[5-6]: infectious diseases in lower airways, left out:
  diagCategories[grepl('^DJ8[5-6].*' , diagnosis) , leftOut := TRUE]
  ##DJ9[0-1]: pleural effusion - highly unspecific but likely to be caused by other disease, left out:
  diagCategories[grepl('^DJ9[0-1].*' , diagnosis) & !grepl('^DJ81.*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ92: symptoms likely to pertain to exposure to asbestos - classified as chronic pulmonary disease:
  diagCategories[grepl('^DJ92.*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DJ9[3-4]: highly unspecific conditions likely to pertain from other disease - left out:
  diagCategories[grepl('^DJ9[3-4].*' , diagnosis) , leftOut := TRUE]
  ##DJ9[5-9] except for DJ988A : a number of unspecific diseases likely to be derived from other diseases - left out
  diagCategories[grepl('^DJ9[5-9].*' , diagnosis) & !grepl('DJ988A.*' , diagnosis) , leftOut := TRUE]
  ##DJ988A: isolated ciliar dyskinesia: classified as chronic lung disease: 
  diagCategories[grepl('^DJ988A.*' , diagnosis) , conditionGroupAdditional := "Chronic pulmonary disease"]
  ##DK0: disruptions of teeth development, categorized as other:
  diagCategories[grepl('^DK0.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK10: not sufficiently specified, left out:
  diagCategories[grepl('^DK10$' , diagnosis) , leftOut := TRUE]
  ##DK10[0-1]: congenital malformations, classified as other:
  diagCategories[grepl('^DK10[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK10[2-3]: inflammatory, infectious conditions, left out:
  diagCategories[grepl('^DK10[2-3].*' , diagnosis) , leftOut := TRUE]
  ##DK108: various diseases related to the jaw, classified as other:
  diagCategories[grepl('^DK108.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK109: unspecified disease related to the jaw, left out:
  diagCategories[grepl('^DK109.*' , diagnosis) , leftOut := TRUE]
  ##DK11: not sufficiently specified, left out:
  diagCategories[grepl('^DK11$' , diagnosis) , leftOut := TRUE]
  ##DK11[0-1], DK11[4-9]: various diseases related to the salivary glands, classified as other:
  diagCategories[grepl('^DK11[0-1].*|^DK11[4-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK11[2-3]: infectious diseases related to the salivary glands, left out:
  diagCategories[grepl('^DK11[2-3].*' , diagnosis) , leftOut := TRUE]
  ##DK12: infectious, inflammatory processes in moutn, left out:
  diagCategories[grepl('^DK12.*' , diagnosis) , leftOut := TRUE]
  ##DK13 and DK130: not sufficiently specified, left out:
  diagCategories[grepl('^DK13$|^DK130$' , diagnosis) , leftOut := TRUE]
  ##DK130[K-L]: not documented, left out:
  diagCategories[grepl('^DK130[K-L].*' , diagnosis) , leftOut := TRUE]
  ##DK130[A-E]: infectious perioral disease, left out:
  diagCategories[grepl('^DK130[A-E].*' , diagnosis) , leftOut := TRUE]
  ##DK130[F-J] and DK13[1-7]: various oral diseases, classified as other:
  diagCategories[grepl('^DK130[F-J].*|^DK13[1-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK14: diseases in the tongue, not sufficiently specified, left out:
  diagCategories[grepl('^DK14$' , diagnosis) , leftOut := TRUE]
  ##DK140: infectious or traumatic diseases of the tongue, left out:
  diagCategories[grepl('^DK140.*' , diagnosis) , leftOut := TRUE]
  ##DK14[1-9]: various diseases of the tongue, classified as other:
  diagCategories[grepl('^DK14[1-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK20: a number of oesophageal diseases that could be derived from other disease, accidents or infections - left out: 
  diagCategories[grepl('^DK20.*' , diagnosis) , leftOut := TRUE]
  ##DK21: gastrooesophageal reflux, classified as other:
  diagCategories[grepl('^DK21.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK22: not sufficiently specified, left out:
  diagCategories[grepl('^DK22$' , diagnosis) , leftOut := TRUE]
  ##DK220: cardia acalasia - classified as other:
  diagCategories[grepl('^DK220.*' , diagnosis) , leftOut := TRUE]
  ##DK222: obstruction of oesophagus, likely to be the result of other diseases, left out:
  diagCategories[grepl('^DK222.*' , diagnosis) , leftOut := TRUE]
  ##DK223: perforation of oesophagus - likely to be caused by accident or other disease, left out:
  diagCategories[grepl('^DK223.*' , diagnosis) , leftOut := TRUE]
  ##DK224: oesophageal dyskinesia, categorized as other:
  diagCategories[grepl('^DK224.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK225: oesophageal diverticle, categorized as other:
  diagCategories[grepl('^DK225.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK226 mallory-weiss lesion - categorized as other:
  diagCategories[grepl('^DK226.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK227 barretts oesophagus, likely to be the result of other disease - left out:
  diagCategories[grepl('^DK227.*' , diagnosis) , leftOut := TRUE]
  ##DK228: a number of diseases in oesophagus, categorized as other:
  diagCategories[grepl('^DK228.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK229: diseases in oesophagus not further specified, left out:
  diagCategories[grepl('^DK229.*' , diagnosis) , leftOut := TRUE]
  ##DK23: diseases resulting from other diseases, left out: 
  diagCategories[grepl('^DK23.*' , diagnosis) , leftOut := TRUE]
  ##DK29: not sufficiently specified, left out:
  diagCategories[grepl('^DK29$' , diagnosis) , leftOut := TRUE]
  ##DK29[0-1]: acute versions of gastritis, classified as other:
  diagCategories[grepl('^DK29[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK29[6-9]: other inflammatory conditions in stomach and duodenum, classified as other:
  diagCategories[grepl('^DK29[6-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK31: a number of diseases in stomach and duodenum - classified as other:
  diagCategories[grepl('^DK31.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK3[5-7] appendicitis from infectious causes, left out:
  diagCategories[grepl('^DK3[5-7].*' , diagnosis) , leftOut := TRUE]
  ##DK38: various diseases in appendix, classified as other:
  diagCategories[grepl('^DK38.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK4: various herniations, classified as other: 
  diagCategories[grepl('^DK4.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK52: not sufficiently specified, left out:
  diagCategories[grepl('^DK52$' , diagnosis) , leftOut := TRUE]
  ##DK52[0-1]: inflammatory conditions in the bowel caused by accidents, left out:
  diagCategories[grepl('^DK52[0-1].*' , diagnosis) , leftOut := TRUE]
  ##DK52[2-9]: inflammatory conditions in the bowel of non-infectious origin, classified as Inflammatory bowel disease:
  diagCategories[grepl('^DK52[2-8].*' , diagnosis) , conditionGroupAdditional := "Inflammatory bowel disease"]
  ##DK5[5-9] and DK60: various mechanical obstructions and blood supply-related diseases in the bowel and various rare abdominal diagnoses - classified as other, except for DK57 which has already been classified as diverticular disease of intestine:
  diagCategories[grepl('^DK5[5-9].*|^DK60.*' , diagnosis) & !grepl('^DK57.*|^DK58.*|^DK59[0-1].*|^DK599.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK61: various infectious diseases in and around anus, left out: 
  diagCategories[grepl('^DK61.*' , diagnosis) , leftOut := TRUE]
  ##DK62: not sufficiently specified, left out:
  diagCategories[grepl('^DK62$' , diagnosis) , leftOut := TRUE]
  ##DK62[0-4]: various perianal conditions, categorized as other:
  diagCategories[grepl('^DK62[0-4].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK625: bleeding from anus, likely to have other disease as cause, left out:
  diagCategories[grepl('^DK625.*' , diagnosis) , leftOut := TRUE]
  ##DK626: ulcus perianally, classified as other:
  diagCategories[grepl('^DK626.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK627: inflammation perianally, likely to result from treatment, left out:
  diagCategories[grepl('^DK627.*' , diagnosis) , leftOut := TRUE]
  ##DK62[8-9] except DK628N: perianal disease, classified as other:
  diagCategories[grepl('^DK62[8-9].*' , diagnosis) & !grepl('^DK628N.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK628N: anal streptococcosis, of infectious origin, left out:
  diagCategories[grepl('^DK628N.*' , diagnosis) , leftOut := TRUE]
  ##DK63: not sufficiently specified, left out:
  diagCategories[grepl('^DK63$' , diagnosis) , leftOut := TRUE]
  ##DK630: intestinal abscess, left out:
  diagCategories[grepl('^DK630.*' , diagnosis) , leftOut := TRUE]
  ##DK63[1-9] , DK4: various intestinal and anal diseases, classified as other:
  diagCategories[grepl('^DK63[1-9].*|^DK64.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK65: peritoneal inflammation, could be caused by infections, left out:
  diagCategories[grepl('^DK65.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK66 except DK668A: a number of conditions likely to be caused by other disease, left out:
  diagCategories[grepl('^DK66.*' , diagnosis) & !grepl('^DK668A.*' , diagnosis), leftOut := TRUE]
  ##DK668A: cystis in peritoneum, classified as other:
  diagCategories[grepl('^DK668A.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK67: disease in peritoneum resulting from diseases classified elsewhere - left out:
  diagCategories[grepl('^DK67.*' , diagnosis) , leftOut := TRUE]
  ##DK75: not sufficiently specified, left out:
  diagCategories[grepl('^DK75$' , diagnosis) , leftOut := TRUE]
  ##DK75[0-1] disease in liver of infectious causes, left out:
  diagCategories[grepl('^DK75[0-1].*' , diagnosis) , leftOut := TRUE]
  ##DK75[2-9]: inflammatory disease in liver but not necessarily chronic, classified as other:
  diagCategories[grepl('^DK75[2-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK76: not sufficiently specified, left out:
  diagCategories[grepl('^DK76$' , diagnosis) , leftOut := TRUE]
  ##DK76[0-5] and DK76[7-9]: various diseases of the liver, classified as "other":
  diagCategories[grepl('^DK76[0-5].*|^DK76[7-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK77: liver diseases caused by diseases defined elsewhere, left out:
  diagCategories[grepl('^DK77.*' , diagnosis) , leftOut := TRUE]
  ##DK8[0-6] a number of diseases in the gall bladder or pancreas. Some are infectious in nature but thought to be caused by gall stones - thus, all diseases here are classified as other:
  diagCategories[grepl('^DK8[0-6].*' , diagnosis) &
		 !grepl('DK839.*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DK87: diseases caused by diseases classified elsewhere, left out:
  diagCategories[grepl('^DK87.*' , diagnosis) , leftOut := TRUE]
  ##DK90: malabsorption, classified as other:
  diagCategories[grepl('^DK90.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DK9[1-3]: either symptoms of other disease, diseases derived from other diseases, or highly unspecific codings - left out:
  diagCategories[grepl('^DK9[1-3].*' , diagnosis) , leftOut := TRUE]
  ##DL0[0-8]: infections in skin, left out:
  diagCategories[grepl('^DL0[0-8].*' , diagnosis) , leftOut := TRUE]
  ##DL1[0-3]: bullous skin disease, classified as other:
  diagCategories[grepl('^DL1[0-3]' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL14: bullous skin disease, caused by other disease, left out:
  diagCategories[grepl('^DL14.*' , diagnosis) , leftOut := TRUE]
  ##DL[2-3] except DL23: dermatitis of various forms, classified as other:
  diagCategories[grepl('^DL[2-3].*' , diagnosis) & !grepl('^DL23.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DL23: allergic contact dermatitis, classified as allergy:
  diagCategories[grepl('^DL23.*' , diagnosis) , conditionGroupAdditional := "Allergy"]
  ##DL4 except DL45: a number of papulosquamous diseases, classified as other:
  diagCategories[grepl('^DL4.*' , diagnosis) &!grepl('^DL45.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL45: papulosquamous diseases derived from other diseases, left out:
  diagCategories[grepl('^DL45.*' , diagnosis) , leftOut := TRUE]
  ##DL50 except DL500 and DL506: urticaria, classified as other:
  diagCategories[grepl('^DL50.*' , diagnosis) &!grepl('^DL500.*|^DL506.*|^DL509.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL500, DL506 allergic urticaria, classified as allergy:
  diagCategories[grepl('^DL500.*|^DL506.*' , diagnosis) , conditionGroupAdditional := "Allergy"]
  ##DL51: erythema multiforme: this is often the result of infections, left out:
  diagCategories[grepl('^DL51.*' , diagnosis) , leftOut := TRUE]
  ##DL52: erythema nodosum: often the result of infections, left out:
  diagCategories[grepl('^DL52.*' , diagnosis) , leftOut := TRUE]
  ##DL53: other erythematous conditions; all of these may be associated with disease classified elsewhere, left out:
  diagCategories[grepl('^DL5[3-4].*' , diagnosis) , leftOut := TRUE]
  ##DL5[5-9]: skin disease caused by radiation and thus most likely treatment, left out:
  diagCategories[grepl('^DL5[5-9].*' , diagnosis) , leftOut := TRUE]
  ##DL60: various diseases of nails, classified as other:
  diagCategories[grepl('^DL60.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL62: nail disease caused by disease classified elsewhere, left out:
  diagCategories[grepl('^DL62.*' , diagnosis) , leftOut := TRUE]
  ##DL6[3-8]: a number of diseases consisting of hair loss, gain or abnormalities; classified as other:
  diagCategories[grepl('^DL6[3-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL70 except DL708F and DL708H: acne, classified as other:
  diagCategories[grepl('^DL70.*' , diagnosis) & !grepl('^DL708F.*|^DL708H.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DL708F and DL708H: acne caused by medicine or toxicity, left out:
  diagCategories[grepl('^DL708F.*|^DL708H.*' , diagnosis) , leftOut := TRUE]
  ##DL71: rosacea; classified as other:
  diagCategories[grepl('^DL71.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL7[2-3]: follicular cysts, classified as other:
  diagCategories[grepl('^DL7[2-3].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL7[4-5]: diseases of sweat secretion, classified as other:
  diagCategories[grepl('^DL7[4-5].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL8[0-7]: various skin diseases, classified as other:
  diagCategories[grepl('^DL8[0-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DL8[8-9]: skin infections and pressure ulcers, left out:
  diagCategories[grepl('^DL8[8-9].*' , diagnosis) , leftOut := TRUE]
  ##DL9[0-8] except DL979B and DL979E: various skin diseases, classified as other:
  diagCategories[grepl('^DL9[0-8].*' , diagnosis) & !grepl('^DL979B.*|^DL979E.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DL979B and DL979E: arteriosclerotic ulcers, classified as "Peripheral artery occlusive disease":
  diagCategories[grepl('^DL979B.*|^DL979E.*' , diagnosis) , conditionGroupAdditional := "Peripheral artery occlusive disease"]
  ##DL99: skin manifestations of diseases classified elsewhere, left out:
  diagCategories[grepl('^DL99.*' , diagnosis) , leftOut := TRUE]
  ##DM0[0-3]: infectious or reactive arthritis - left out:
  diagCategories[grepl('^DM0[0-3].*' , diagnosis) , leftOut := TRUE]
  ##DM07: arthritis as a result of other diseases, left out: 
  diagCategories[grepl('^DM07.*' , diagnosis) , leftOut := TRUE]
  ##DM11: other forms of crystal arthropaties - classified as connective tissue disorders: 
  diagCategories[grepl('^DM11.*' , diagnosis) , conditionGroupAdditional := "Connective tissue disorders"]
  ##DM12 except DM121, DM123, DM124, and DM128: arthropaties originating from trauma or infections, left out:
  diagCategories[grepl('^DM12.*' , diagnosis) & !grepl('^DM121.*|^DM123.*|^DM124.*|^DM128.*' , diagnosis), leftOut := TRUE]
  ##DM121, DM123, DM124, DM128: arthropaties, classified as connective tissue disorders:
  diagCategories[grepl('^DM121.*|^DM123.*|^DM124.*|^DM128.*' , diagnosis) , conditionGroupAdditional := "Connective tissue disorders"]
  ##DM13 except DM138A: arthritis not sufficiently specified or as the result of infections - left out:
  diagCategories[grepl('^DM13.*' , diagnosis) & !grepl('^DM138A.*' , diagnosis), leftOut := TRUE]
  ##DM138A: arthritis caused by allergy - classified as allergy:
  diagCategories[grepl('^DM138A.*' , diagnosis) , leftOut := TRUE]
  ##DM14: arthropathy by disease classified elsewhere - left out: 
  diagCategories[grepl('^DM14.*' , diagnosis) , leftOut := TRUE]
  ##DM1[5-9] except DM191: arthrosis, classified as other:
  diagCategories[grepl('^DM1[5-9].*' , diagnosis) & !grepl('^DM191.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM191: arthrosis as a result of trauma, left out: 
  diagCategories[grepl('^DM191.*' , diagnosis) , leftOut := TRUE]
  ##DM2[0-1]: deformities of fingers and toes, classified as other:
  diagCategories[grepl('^DM2[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM22: various diseases in knee, classified as other:
  diagCategories[grepl('^DM22.*' , diagnosis) & !grepl('^DM222.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM23 except DM232: various diseases in knee, classified as other:
  diagCategories[grepl('^DM23.*' , diagnosis) & !grepl('^DM232.*|^DM239.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM232: old tear in meniscus, left out:
  diagCategories[grepl('^DM232.*' , diagnosis) , leftOut := TRUE]
  ##DM24: various mechanical diseases of the joints, classified as other:
  diagCategories[grepl('^DM24.*' , diagnosis) &
		 !grepl('^DM249.*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DM25: various joint-related diseases, classified as other:
  diagCategories[grepl('^DM25.*' , diagnosis) & !grepl('^DM253.*|^DM255.*|^DM25[8-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM35: not sufficiently specified, left out:
  diagCategories[grepl('^DM35.*' , diagnosis) , leftOut := TRUE]
  ##DM4[0-3]: kyphosis, lordosis, scoliosis and other spine-related deforming diseases, classified as other:
  diagCategories[grepl('^DM4[0-3].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM4[5-6]: various inflammatory diseases related to the spine, classified as connective tissue disorders:
  diagCategories[grepl('^DM4[5-6].*' , diagnosis) , conditionGroupAdditional := "Connective tissue disorders"]
  ##DM47: spondylosis, classified as other:
  diagCategories[grepl('^DM47.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM48[0-2]: stenosis, hyperostosis and arthrosis in the spine, classified as other:
  diagCategories[grepl('^DM48[0-2].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM48[0-2]: stenosis, hyperostosis and arthrosis in the spine, classified as other:
  diagCategories[grepl('^DM48[0-2].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM48[3-5]: diseases related to the spine likely to origin from other diseases, left out:
  diagCategories[grepl('^DM48[3-5].*' , diagnosis) , leftOut := TRUE]
  ##DM48[8-9]: other sorts of spondylopathia, classified as other:
  diagCategories[grepl('^DM48[8-9].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM48: not sufficiently specified, left out:
  diagCategories[grepl('^DM48$' , diagnosis) , leftOut := TRUE]
  ##DM49: diseases originating from other diseases, left out:
  diagCategories[grepl('^DM49.*' , diagnosis) , leftOut := TRUE]
  ##DM51: Spine-related herniations and related diseases, classified as other:
  diagCategories[grepl('^DM5[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM53: spine-related conditions not elsewhere classified, classified as other:
  diagCategories[grepl('^DM53.*' , diagnosis) &!grepl('^DM539.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM54: painful conditions related to spine, classified as other:
  diagCategories[grepl('^DM54.*' , diagnosis) &
		 !grepl('^DM54[1-2].*|^DM54[4-9].*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DM60: myositis, potentially infectious or caused by other disease, left out:
  diagCategories[grepl('^DM60.*' , diagnosis) , leftOut := TRUE]
  ##DM61: ossification of muscle - classified as other:
  diagCategories[grepl('^DM61.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM62: other diseases of muscle, classified as other:
  diagCategories[grepl('^DM62.*' , diagnosis) &
		 !grepl('^DM626.*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DM63: diseases resulting from other diseases, left out:
  diagCategories[grepl('^DM63.*' , diagnosis) , leftOut := TRUE]
  ##DM6[5-7]: diseases of the tendons and joint capsules, classified as other: 
  diagCategories[grepl('^DM6[5-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM68: diseases resulting from other diseases, left out:
  diagCategories[grepl('^DM68.*' , diagnosis) , leftOut := TRUE]
  ##DM7[0-9] except DM710, DM711, DM726: inflammatory diseases in soft tissue - this is classified as other. Connective tissue disorder would have been an option, but this category has been reserved for inflammatory disease without primary mechanical origin:
  diagCategories[grepl('^DM7[0-9].*' , diagnosis) &
		 !grepl('^DM70[8-9].*|^DM710.*|^DM711.*|^DM726.*|^DM73.*|^DM75[8-9].*|^DM79[0-1].*|^DM79[6-7].*' ,
			diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DM710, DM711, DM726: infectious bursitis and necrotizing fasciitis, and DM73, diseases resulting from other diseases, dnleft out:
  diagCategories[grepl('^DM710.*|^DM711.*|^DM726.*|^DM73.*' , diagnosis) , leftOut := TRUE]
  ##DM83: osteomalacia, classified as other:
  diagCategories[grepl('^DM83.*' , diagnosis)  , conditionGroupAdditional := "Other"]
  ##DM84: stress fractures, false joints and other results of accidents or other disease, left out:
  diagCategories[grepl('^DM84.*' , diagnosis) , leftOut := TRUE]
  ##DM85: a number of abnormalities in bone structure, classified as other:
  diagCategories[grepl('^DM85.*' , diagnosis)  , conditionGroupAdditional := "Other"]
  ##DM86: osteomyelitis, infectious, left out:
  diagCategories[grepl('^DM86.*' , diagnosis) , leftOut := TRUE]
  ##DM87 except DM870: bone necrosis because of treatment or other diseases, left out:
  diagCategories[grepl('^DM87.*' , diagnosis) & !grepl('^DM870.*' , diagnosis) , leftOut := TRUE]
  ##DM870: idiopathic bone necrosis, classified as other:
  diagCategories[grepl('^DM870.*' , diagnosis)  , conditionGroupAdditional := "Other"]
  ##DM88: Pagets disease, classified as other:
  diagCategories[grepl('^DM88.*' , diagnosis)  , conditionGroupAdditional := "Other"]
  ##DM89 except DM896 and DM898B: various other bone diseases, classified as other:
  diagCategories[grepl('^DM89.*' , diagnosis) & !grepl('^DM896.*|^DM898B.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM896: osteopathia after poliomyelitis, DM898B: posttraumatic subperiostal ossification: left out:
  diagCategories[grepl('^DM896.*|^DM898B.*' , diagnosis) , leftOut := TRUE]
  ##DM90: diseases resulting from other diseases, left out:
  diagCategories[grepl('^DM90.*' , diagnosis) , leftOut := TRUE]
  ##DM94 except DM914: various diseases of cartilage degeneration, classified as other:
  diagCategories[grepl('^DM94.*' , diagnosis) & !grepl('^DM941.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DM941: recurrent polychondritis, classified as connective tissue disorders:
  diagCategories[grepl('^DM941.*' , diagnosis) , conditionGroupAdditional := "Connective tissue disorders"]
  ##DM9[1-3]: various cartilage degeneration or malformation conditions, classified as other:
  diagCategories[grepl('^DM9[1-3].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM9[5-6]: deformities that could originate from accidents and deformities originating from treatment, classified as other:
  diagCategories[grepl('^DM9[5-6].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DM99: biomechanical dysfunctions not classified elsewhere, classified as other:
  diagCategories[grepl('^DM99.*' , diagnosis) , conditionGroupAdditional := "Other"]

  ##DN0[0-2]: nephrotic acute inflammation or blood in urine - classified as other:
  diagCategories[grepl('^DN0[0-2].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN0[4-7]: nephrotic syndrome, nephrotic inflammation, monosymptomatic proteinuria, inherited kidney disease - classified as other:
  diagCategories[grepl('^DN0[4-7].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN08: disease related to kidneys but classified elsewhere - left out:
  diagCategories[grepl('^DN08.*' , diagnosis) , leftOut := TRUE]
  ##DN10: acute tubulointerstitial nephritis, likely infectious - left out:
  diagCategories[grepl('^DN10.*' , diagnosis) , leftOut := TRUE]
  ##DN12: tubulo-interstitial nephritis not further specified, likely infectious - left out:
  diagCategories[grepl('^DN12.*' , diagnosis) , leftOut := TRUE]
  ##DN13: hydronephrosis, pyonephrosis and related diseases because of blockage of the urinary tract - classified as other (there is infectious causes here, but they are caused by the lack of drainage):
  diagCategories[grepl('^DN13.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN14: nephropatia caused by treatment or poisoning - left out: 
  diagCategories[grepl('^DN14.*' , diagnosis) , leftOut := TRUE]
  ##DN15: not sufficiently specified, left out: 
  diagCategories[grepl('^DN15$' , diagnosis) , leftOut := TRUE]
  ##DN150: balcan nephropathy - classified as Chronic kidney disease (this may be the result of poisoning, but over year-long exposure and thus comparable to for example smoking or unbalanced diet.
  diagCategories[grepl('^DN150.*' , diagnosis) , conditionGroupAdditional := "Chronic kidney disease"]
  ##DN15[1-9]: either infectious or unspecified renal disease, left out:
  diagCategories[grepl('^DN15[1-9].*' , diagnosis) , leftOut := TRUE]
  ##DN16: diseases as a result of other diseases, left out:
  diagCategories[grepl('^DN16.*' , diagnosis) , leftOut := TRUE]
  ##DN17, DN19: acute renal insufficiency, classified as other:
  diagCategories[grepl('^DN17.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN2[0-1]: renal stones, classified as other:
  diagCategories[grepl('^DN2[0-1].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN2[2-3]: renal disease as a result of disease classified elsewhere, renal-related pain - highly unspecific, left out:
  diagCategories[grepl('^DN2[2-3].*' , diagnosis) , leftOut := TRUE]
  ##DN2[5-7]: diseases as a consequence of renal disease and unspecific signs of pathology - left out:
  diagCategories[grepl('^DN2[5-7].*' , diagnosis) , leftOut := TRUE]
  ##DN28: not sufficiently specified, left out:
  diagCategories[grepl('^DN28.*' , diagnosis) , leftOut := TRUE]
  ##DN28[0-8] various renal diseases, classified as other:
  diagCategories[grepl('^DN28[0-8].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN289: nephropathy without further specification, left out: 
  diagCategories[grepl('^DN289.*' , diagnosis) , leftOut := TRUE]
  ##DN29: diseases as a result of other diseases, left out:
  diagCategories[grepl('^DN29.*' , diagnosis) , leftOut := TRUE]
  ##DN30: bladder infections, left out: 
  diagCategories[grepl('^DN30.*' , diagnosis) , leftOut := TRUE]
  ##DN31: neuromuscular bladder disturbances, classified as other:
  diagCategories[grepl('^DN31.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN32: various diseases of the bladder, classified as other:
  diagCategories[grepl('^DN32.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN33: diseases in the bladder resulting from other diseases, left out:
  diagCategories[grepl('^DN33.*' , diagnosis) , leftOut := TRUE]
  ##DN34 except DN342D: urethritis and urethral syndrome, likely from infectious causes, left out:
  diagCategories[grepl('^DN34.*' , diagnosis) & !grepl('^DN342D.*' , diagnosis), leftOut := TRUE]
  ##DN342D: allergic urethritis, classified as allergy:
  diagCategories[grepl('^DN342D.*' , diagnosis) , conditionGroupAdditional := "Allergy"]
  ##DN35: stricture of urethra on either infectious or traumatic cause - this is commonly occurring among circumsized males, which in this context could be interpreted as either treatment or trauma - thus left out:
  diagCategories[grepl('^DN35.*' , diagnosis) , leftOut := TRUE]
  ##DN36 except DN368D and DN368E: various diseases of urethra, classified as other:
  diagCategories[grepl('^DN36.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN368D and DN368E: via falsa, usually the result of catheterization, thus treatment, left out: 
  diagCategories[grepl('^DN368D.*|^DN368E.*' , diagnosis) , leftOut := TRUE]
  ##DN37: diseases as the result of other diseases, left out: 
  diagCategories[grepl('^DN37.*' , diagnosis) , leftOut := TRUE]
  ##This category is already specified as unspecific, commenting out:
  ## ##DN39: not sufficiently specified, left out:
  ## diagCategories[grepl('^DN39.*' , diagnosis) , leftOut := TRUE]
  ##DN39[0-2]: diagnoses of diseases not sufficiently specified (compared to the categorizations above), left out:
  ## diagCategories[grepl('^DN39[0-2].*' , diagnosis) , leftOut := TRUE]
  ## ##DN39[3-4]: incontinence, classified as other:
  ## diagCategories[grepl('^DN39[3-4].*' , diagnosis) , conditionGroupAdditional := "Other"]
  ## ##DN39[8-9]: diseases either not sufficiently specified or the result of treatment, left out:
  ## diagCategories[grepl('^DN39[8-9].*' , diagnosis) , leftOut := TRUE]
  ##DN41 except DN412 and DN413: prostate inflammation, classified as other:
  diagCategories[grepl('^DN41.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN412 and DN413: prostate abscess and prostate inflammation associated with disease from bladder, left out:
  diagCategories[grepl('^DN41[2-3].*' , diagnosis) , leftOut := TRUE]
  ##DN41[8-9]: prostatitis not sufficiently specified, left out:
  diagCategories[grepl('^DN41[8-9].*' , diagnosis) , leftOut := TRUE]
  ##DN42: various diseases in prostate, classified as other: 
  diagCategories[grepl('^DN42.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN43 except DN431: hydrocele and spermatocele, classified as other:
  diagCategories[grepl('^DN43.*' , diagnosis) & !grepl('^DN431.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DN431: infected hydrocele, left out:
  diagCategories[grepl('^DN431.*' , diagnosis) , leftOut := TRUE]
  ##DN44: torsio testis, classified as other: 
  diagCategories[grepl('^DN44.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN45: inflammation of testicle and coiled tube, likely infectious, left out:
  diagCategories[grepl('^DN45.*' , diagnosis) , leftOut := TRUE]
  ##DN46: male sterility, classified as other:
  diagCategories[grepl('^DN46.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN479: diseases of the foreskin, classified as other:
  diagCategories[grepl('^DN47.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN48 except DN481, DN481D, DN482, DN488D, DN488E, and DN488H: various diseases in penis, classified as other:
  diagCategories[grepl('^DN48.*' , diagnosis) & !grepl('^DN481.*|^DN482.*|^DN488D.*|^DN488E.*|^DN488H.*' , diagnosis), conditionGroupAdditional := "Other"]
  ##DN481 except DN481D: infectious conditions associated with the foreskin, left out:
  diagCategories[grepl('^DN481.*' , diagnosis) & !grepl('^DN481D.*' , diagnosis) , leftOut := TRUE]
  ##DN481D: inflammatory condition, classified as other:
  diagCategories[grepl('^DN481D.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN482, DN488D, DN488E, and DN488H: infectious or traumatic conditions, left out:
  diagCategories[grepl('^DN482.*|^DN488D.*|^DN488E.*|^DN488H.*' , diagnosis) , leftOut := TRUE]
  ##DN49 except DN498M: various infectious or inflammatory conditions in male genitourinary organs, mainly infectious, left out:
  diagCategories[grepl('^DN49.*' , diagnosis) & !grepl('^DN498M.*' , diagnosis) , leftOut := TRUE]
  ##DN498M: microlithiasis testis, classified as other:
  diagCategories[grepl('^DN498M.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN50 except DN501[A-E]: various diseases of male genitalia, classified as other:
  diagCategories[grepl('^DN50.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN501[A-E] hematomas of male genitals, likely as results of trauma, left out:
  diagCategories[grepl('^DN501[A-E].*' , diagnosis) , leftOut := TRUE]
  ##DN51: diseases as a result of other diseases, left out:
  diagCategories[grepl('^DN51.*' , diagnosis) , leftOut := TRUE]
  ##DN60: a number of benign breast conditions, classified as other:
  diagCategories[grepl('^DN60.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN61: non-puerperal inflammation of the breast, likely infectious, left out:
  diagCategories[grepl('^DN61.*' , diagnosis) , leftOut := TRUE]
  ##DN62: large mammae with various causes, classified as other:
  diagCategories[grepl('^DN62.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DN63: unspecified tumor, left out as this is more of a referral diagnosis than a diagnosis of disease:
  diagCategories[grepl('^DN63.*' , diagnosis) , leftOut := TRUE]
  ##DN64: various conditions related to the breast, classified as other:
  diagCategories[grepl('^DN64.*' , diagnosis) , leftOut := TRUE]
  ##DN7[0-7] inflammatory conditions in female pelvis, likely infectious, left out:
  diagCategories[grepl('^DN7[0-7].*' , diagnosis) , leftOut := TRUE]
  ##DN8 and DN9[0-7]: various conditions in female genital organs, classified as other:
  diagCategories[grepl('^DN8.*|^DN9[0-7].*' , diagnosis) &
		 !grepl('^DN859.*|^DN920.*|^DN92[5-6].*|^DN94[0-1].*|^DN94[4-6].*|^DN949.*' , diagnosis) ,
		 conditionGroupAdditional := "Other"]
  ##DN98: complications associated with artificial insemination:
  diagCategories[grepl('^DN98.*' , diagnosis) , leftOut := TRUE]
  ##DN99: conditions as a result of treatment - left out:
  diagCategories[grepl('^DN99.*' , diagnosis) , leftOut := TRUE]
  ##The full chapters for child bearing and perinatal conditions were left out - see arguments for this elsewhere.
  diagCategories[grepl('^DO.*|^DP.*' , diagnosis) , leftOut := TRUE]
  ##The full chapter of Q is congenital abnormal findings - these are all classified as other, as they can by definition not be infectious or caused by accident. Some of these, for example Turner's syndrome, will, also by definition, be very rare among parents, as most women with this syndrome are infertile.
  diagCategories[grepl('DQ.*' , diagnosis) , conditionGroupAdditional := "Other"]
  ##DR consists mainly of symptoms and findings and does thus not constitute diseases - these diagnoses are left out:
  diagCategories[grepl('^DR.*' , diagnosis) , leftOut := TRUE]
  ##DS, DT, DX, and DY  consist of accidents and other trauma - left out:
  diagCategories[grepl('^DS.*|^DT.*|^DX.*|^DY.*' , diagnosis) , leftOut := TRUE]
  ##DZ is not used for classifying diseases but rather circumstances related to treatment, family history or similar. Thus, these are left out as well:
  diagCategories[grepl('^DZ.*' , diagnosis) , leftOut := TRUE]

  ##The categorization has now been completed - all F-diagnoses were checked against the current categorizations, but non-added diagnoses were not added to the other-group to avoid making an already highly diverse group even more so. There were no re-categorizations in this diagnostic chapter.

  ##Cleaned the filter manually for any double-grouping, so this should be obsolete now:
  ## ##If all unspecific diagnoses are visualized, it is seen that a number of those are also categorized as members of a conditionGroup. A categorization as unspecific should always take precedence over a group category - thus:
  ## diagCategories[unspecific == TRUE , conditionGroup := ""]

  ##After running downstream code, it was discovered that some of the additional classification overwrites the original classifications. Checking for this:
  ##View(diagCategories[conditionGroup != "" & conditionGroup != conditionGroupAdditional , .(diagnosis , conditionGroup , conditionGroupAdditional)])
  ##After correcting classification errors based on the view above, the command no longer executes, indicating that there are no "double classifications" anymore - therefore transferring all entries from conditionGroupAdditional to the conditionGroup variable:
  diagCategories[conditionGroup == "" & !is.na(conditionGroupAdditional) , conditionGroup := conditionGroupAdditional]
  ##Looking at the resulting categories:
  diagCategories[ , table(conditionGroup , useNA = "always")]
  diagCategories[ , conditionGroupAdditional := NULL]


  ##There is no obvious way to check the above categories for errors, and categorization has been checked continously, looking at what diagnoses were still not categorized using this command: 
  ##diagCategories[conditionGroup == "" & is.na(leftOut)][1:100 , diagnosis]
  ##Thus, for further error checking, all codes are simply read by me for a sense-check (avoid overlapping categorizations, use sensible coding etc.) 

  ##Defining categories:
  conditionCategory <- c("Circulatory system" , "Endocrine system" , "Pulmonary system and allergy" , "Gastrointestinal system" , "Urogenital system" , "Musculoskeletal system" , "Hematological system" , "Cancers" , "Neurological system" , "Preterm birth and acute caesarian section" , "Mental health conditions" , "Other")
  circulatorySystem <- c("Hypertension" , "Dyslipidemia" , "Ischemic heart disease" , "Atrial fibrillation" , "Heart failure" , "Peripheral artery occlusive disease" , "Stroke")
  endocrineSystem <- c("Diabetes mellitus" , "Thyroid disorder" , "Gout")
  pulmonarySystemAllergy <- c("Chronic pulmonary disease" , "Allergy")
  gastrointestinalSystem <- c("Ulcer/chronic gastritis" , "Chronic liver disease" , "Inflammatory bowel disease" , "Diverticular disease of intestine")
  urogenitalSystem <- c("Chronic kidney disease" , "Prostate disorders")
  musculoskeletalSystem <- c("Connective tissue disorders" , "Osteoporosis" , "Painful condition")
  hematologicalSystem <- c("Anemia") #HIV is excluded here according to the exclusion of infectious diseases
  cancers <- c("Cancer")
  neurologicalSystem <- c("Vision problem" , "Hearing problem" , "Migraine" , "Epilepsy" , "Parkinson's disease" , "Multiple sclerosis" , "Neuropathies")
  pretermCaesarian <- c("Preterm birth" , "Acute caesarian section")
  mentalHealth <- c("Mood, stress-related, or anxiety disorders" , "Alcohol abuse" , "Drug abuse" , "Anorexia/bulimia" , "Bipolar affective disorder" , "Schizophrenia or schizoaffective disorder" , "Dementia" , "Personality disorder")
  other <- "Other"

  ##Assigning conditionCategory:
  ##For some reason, conditionCategory is read by fread as logical, changing that:
  diagCategories[ , conditionCategory := as.character(conditionCategory)]
  atcCategories[ , conditionCategory := as.character(conditionCategory)]

  diagCategories[conditionGroup %in% circulatorySystem , conditionCategory := "Circulatory system"]
  diagCategories[conditionGroup %in% endocrineSystem , conditionCategory := "Endocrine system"]
  diagCategories[conditionGroup %in% pulmonarySystemAllergy , conditionCategory := "Pulmonary system and allergy"]
  diagCategories[conditionGroup %in% gastrointestinalSystem , conditionCategory := "Gastrointestinal system"]
  diagCategories[conditionGroup %in% urogenitalSystem , conditionCategory := "Urogenital system"]
  diagCategories[conditionGroup %in% musculoskeletalSystem , conditionCategory := "Musculoskeletal system"]
  diagCategories[conditionGroup %in% hematologicalSystem , conditionCategory := "Hematological system"]
  diagCategories[conditionGroup %in% cancers , conditionCategory := "Cancers"]
  diagCategories[conditionGroup %in% neurologicalSystem , conditionCategory := "Neurological system"]
  diagCategories[conditionGroup %in% pretermCaesarian , conditionCategory := "Preterm birth and acute caesarian section"]
  diagCategories[conditionGroup %in% mentalHealth , conditionCategory := "Mental health conditions"]
  diagCategories[conditionGroup %in% other , conditionCategory := "Other"]


  atcCategories[conditionGroup %in% circulatorySystem , conditionCategory := "Circulatory system"]
  atcCategories[conditionGroup %in% endocrineSystem , conditionCategory := "Endocrine system"]
  atcCategories[conditionGroup %in% pulmonarySystemAllergy , conditionCategory := "Pulmonary system and allergy"]
  atcCategories[conditionGroup %in% gastrointestinalSystem , conditionCategory := "Gastrointestinal system"]
  atcCategories[conditionGroup %in% urogenitalSystem , conditionCategory := "Urogenital system"]
  atcCategories[conditionGroup %in% musculoskeletalSystem , conditionCategory := "Musculoskeletal system"]
  atcCategories[conditionGroup %in% hematologicalSystem , conditionCategory := "Hematological system"]
  atcCategories[conditionGroup %in% cancers , conditionCategory := "Cancers"]
  atcCategories[conditionGroup %in% neurologicalSystem , conditionCategory := "Neurological system"]
  atcCategories[conditionGroup %in% pretermCaesarian , conditionCategory := "Preterm birth and acute caesarian section"]
  atcCategories[conditionGroup %in% mentalHealth , conditionCategory := "Mental health conditions"]
  atcCategories[conditionGroup %in% other , conditionCategory := "Other"]
  ##All assignments were checked by diagCategories[ is.na(substanceAbuse) == FALSE , View(.SD)], as well as the results from running the entire code.

  ##Saving the full categorizations:
  fwrite(diagCategories , "diagCategoriesFullCategorized.csv")
  fwrite(atcCategories , "atcCategoriesFullCategorized.csv")

  ##Reducing to only those codes that actually gets used in any category:
  atcCategoriesUsed <- atcCategories[conditionGroup != ""]
  fwrite(atcCategoriesUsed , "atcUsed.csv")
  ##Reduction for diagCategories will be done after addition of Charlson coding

#+end_src
** Code for Charlson Index:
This classification is from the repositories of the R-package Heaven, authored by Helene Charlotte Rytgaard et al., see https://rdrr.io/github/tagteam/heaven/ The Charlson function is authored by Christian Torp-Pedersen. The classification used here is tailored to the Danish use of codes, inspired by Quan et al, Am J Epidemiol.2011 173:676-82, DMCG.dk benchmarking consortium and adjustments provided by Peter Ascanius
Jacobsen. 

#+begin_src R :session rsession :results output :exports both
  This classification is from the repositories of the R-package Heaven, authored by Helene Charlotte Rytgaard et al., see https://rdrr.io/github/tagteam/heaven/ The Charlson function is authored by Christian Torp-Pedersen. The classification used here is tailored to the Danish use of codes, inspired by Quan et al, Am J Epidemiol.2011 173:676-82, DMCG.dk benchmarking consortium and adjustments provided by Peter Ascanius
  Jacobsen. 

  ,#+begin_src R :session rsession :results output :exports both
    myocardialInfarctionCharlsonCodes <- c("410" , "DI21" , "DI22")
    ##For all vectors, the same vector is entered twice with a "temp" in the end, and then compared using the following commands:
    ##setdiff(myocardialInfarctionCharlsonCodes , myocardialInfarctionCharlsonCodesTemp)
    ##setdiff(myocardialInfarctionCharlsonCodesTemp , myocardialInfarctionCharlsonCodes)
    heartFailureCharlsonCodes <- c("42709" , "42710" , "42711" , "42719" ,
				   "42899" , "78249" , "DI099" , "DI110" ,
				   "DI130" , "DI132" , "DI255" , "DI425" ,
				   "DI426" , "DI427" , "DI429" , "DI428A" ,
				   "DP290" , "DI43" , "DI50" , "DE105" ,
				   "DE115" , "DE125" , "DE135" , "DE145")  
    ##setdiff(heartFailureCharlsonCodesTemp , heartFailureCharlsonCodes)
    ##setdiff(heartFailureCharlsonCodes , heartFailureCharlsonCodesTemp)
    peripheralVascularDiseaseCharlsonCodes <- c("440" , "441" , "442" ,
						"443" , "444" , "445" ,
						"DI70" , "DI71" , "DI72" ,
						"DI731" , "DI738" ,
						"DI739" , "DI77" ,
						"DI790" , "DI792" ,
						"DK551" , "DK558" ,
						"DK559" , "DZ958" ,
						"DZ959")
    ##setdiff(peripheralVascularDiseaseCodesTemp , peripheralVascularDiseaseCodes)
    ##setdiff(peripheralVascularDiseaseCodes , peripheralVascularDiseaseCodesTemp)
    cerebrovascularDiseaseCharlsonCodes <- c(paste0("43" , 0:8) ,
					     paste0("DI6" , 0:9) , "DG45" ,
					     "DG46" , "DH340")
    ##setdiff(cerebrovascularDiseaseCharlsonCodes , cerebrovascularDiseaseCharlsonCodesTemp)
    ##setdiff(cerebrovascularDiseaseCharlsonCodesTemp , cerebrovascularDiseaseCharlsonCodes)
    dementiaCharlsonCodes <- c("290" , paste0("DF0" , 0:3) ,
			       "DG30" , "DF051" , "DG311")
    ##setdiff(dementiaCharlsonCodes , dementiaCharlsonCodesTemp)
    ##setdiff(dementiaCharlsonCodesTemp , dementiaCharlsonCodes)
    chronicPulmonaryDiseaseCharlsonCodes <- c(paste0("51" , 5:8) ,
					      paste0("49" , 0:3) ,
					      paste0("DJ4" , 0:7) ,
					      paste0("DJ6" , 0:7) ,
					      "DJ684" , "DI278" ,
					      "DI279" , "DJ84" ,
					      "DJ701" , "DJ703" ,
					      "DJ920" , "DJ953" ,
					      "DJ961" , "DJ982" ,
					      "DJ983")
    ##setdiff(chronicPulmonaryDiseaseCharlsonCodes , chronicPulmonaryDiseaseCharlsonCodesTemp)
    ##setdiff(chronicPulmonaryDiseaseCharlsonCodesTemp , chronicPulmonaryDiseaseCharlsonCodes)
    rheumaticDiseaseCharlsonCodes <- c("712" , "716" , "734" , "446" ,
				       "13599" , "DM05" , "DM06" ,
				       "DM08" , "DM09" , "DM30" ,
				       "DM31" , "DM32" , "DM33" ,
				       "DM34" , "DM35" , "DM36")
    ## setdiff(rheumaticDiseaseCharlsonCodes , rheumaticDiseaseCharlsonCodesTemp)
    ## setdiff(rheumaticDiseaseCharlsonCodesTemp , rheumaticDiseaseCharlsonCodes)
    pepticUlcerDiseaseCharlsonCodes <- c("53091" , "53098" , paste0("53" , 1:4) , "DK25" , "DK26" , "DK27" , "DK28" , "DK221")
    ## setdiff(pepticUlcerDiseaseCharlsonCodes , pepticUlcerDiseaseCharlsonCodesTemp)
    ## setdiff(pepticUlcerDiseaseCharlsonCodesTemp , pepticUlcerDiseaseCharlsonCodes)
    mildLiverDiseaseCharlsonCodes <- c("571" , "57301" , "57304" , "DB18" , "DK700" , "DK701" , "DK702" , "DK709" , "DK703" , "DK713" , "DK714" , "DK715" , "DK717" , "DK73" , "DK74" , "DK760" , "DK762" , "DK763" , "DK764" , "DK769" , "DZ944")
    ## setdiff(mildLiverDiseaseCharlsonCodes , mildLiverDiseaseCharlsonCodesTemp)
    ## setdiff(mildLiverDiseaseCharlsonCodesTemp , mildLiverDiseaseCharlsonCodes)
    severeLiverDiseaseCharlsonCodes <- c("07000" , "07002" , "07004" , "07006" , "07008" , "57300" , "45601" , "45602" , "45603" , "45604" , "45605" , "45606" , "45607" , "45608" , "45609" , "DB150" , "DB160" , "DB162" , "DB190" , "DI850" , "DI859" , "DI864" , "DI982" , "DK704" , "DK711" , "DK721" , "DK729" , "DK765" , "DK766" , "DK767")
    ## setdiff(severeLiverDiseaseCharlsonCodes , severeLiverDiseaseCharlsonCodesTemp)
    ## setdiff(severeLiverDiseaseCharlsonCodesTemp , severeLiverDiseaseCharlsonCodes)
    diabetesWithoutComplicationsCharlsonCodes <- c("24900" , "24906" , "24907" , "24909" , "25000" , "25006" , "25007" , "25009" , "DE100" , "DE101" , "DE108" , "DE109" , "DE110" , "DE111" , "DE119" , "DE120" , "DE121" , "DE129" , "DE130" , "DE131" , "DE139" , "DE140" , "DE141" , "DE149")
    ## setdiff(diabetesWithoutComplicationsCharlsonCodes , diabetesWithoutComplicationsCharlsonCodesTemp)
    ## setdiff(diabetesWithoutComplicationsCharlsonCodesTemp , diabetesWithoutComplicationsCharlsonCodes)
    diabetesWithComplicationsCharlsonCodes <- c(paste0("2490" , 1:5) , "24908" , paste0("2500" , 1:5) , "25008" , paste0("DE10" , 2:7) , paste0("DE11" , 2:8) , paste0("DE12" , 2:8) , paste0("DE13" , 2:8) , paste0("DE14" , 2:8))
    ## setdiff(diabetesWithComplicationsCharlsonCodes , diabetesWithComplicationsCharlsonCodesTemp)
    ## setdiff(diabetesWithComplicationsCharlsonCodesTemp , diabetesWithComplicationsCharlsonCodes)
    hemiplegiaParaplegiaCharlsonCodes <- c("344" , paste0("DG83" , 0:4) , "DG81" , "DG82" , "DG041" , "DG114" , "DG801" , "DG802" , "DG839")
    ## setdiff(hemiplegiaParaplegiaCharlsonCodes , hemiplegiaParaplegiaCharlsonCodesTemp)
    ## setdiff(hemiplegiaParaplegiaCharlsonCodesTemp , hemiplegiaParaplegiaCharlsonCodes)
    renalDiseaseCharlsonCodes <- c("403" , "404" , paste0("58" , 0:4) , "59009" , "59319" , paste0("7531" , 0:9) , "792" , paste0("DN03" , 2:7) , paste0("DN05" , 2:7) , "DZ490" , "DZ491" , "DZ492" , "DN18" , "DN19" , "DI120" , "DI131" , "DI132" , "DN250" , "DZ940" , "DZ992" , "DN26")
    ## setdiff(renalDiseaseCharlsonCodes , renalDiseaseCharlsonCodesTemp)
    ## setdiff(renalDiseaseCharlsonCodesTemp , renalDiseaseCharlsonCodes)
    anyMalignancyCharlsonCodes <- c(paste0("1" , 40:72) , paste0(174:194) , "27559" , paste0("DC" , 0:3) , paste0("DC4" , 0:9) , "DC5" , "DC6" , paste0("DC7" , 0:6) , "DC86" , "DC97")
    ## setdiff(anyMalignancyCharlsonCodes , anyMalignancyCharlsonCodesTemp)
    ## setdiff(anyMalignancyCharlsonCodesTemp , anyMalignancyCharlsonCodes)
    metastaticSolidTumorCharlsonCodes <- c(paste0("19" , 5:9) , paste0("DC" , 77:80))
    ## setdiff(metastaticSolidTumorCharlsonCodes , metastaticSolidTumorCharlsonCodesTemp)
    ## setdiff(metastaticSolidTumorCharlsonCodesTemp , metastaticSolidTumorCharlsonCodes)
    aidsHivCharlsonCodes <- c("07983" , "DB20" , "DB21" , "DB22" , "DB23" , "DB24")
    ## setdiff(aidsHivCharlsonCodes , aidsHivCharlsonCodesTemp)
    ## setdiff(aidsHivCharlsonCodesTemp , aidsHivCharlsonCodes)
    leukemiaCharlsonCodes <- c(paste0("20" , 4:7) , paste0("DC9" , 1:5))
    ## setdiff(leukemiaCharlsonCodesTemp , leukemiaCharlsonCodes)
    ## setdiff(leukemiaCharlsonCodes , leukemiaCharlsonCodesTemp)
    lymphomaCharlsonCodes <- c(paste0("20" , 0:3) , "27559" , paste0("DC8" , 1:5) , "DC88" , "DC90" , "DC96")
    ## setdiff(lymphomaCharlsonCodes , lymphomaCharlsonCodesTemp)
    ## setdiff(lymphomaCharlsonCodesTemp , lymphomaCharlsonCodes)
  ,#+end_src
 
#+end_src
 
** Code for Charlson Index categorization:
#+begin_src R :session rsession :results output :exports both
  diagCategories <- fread("diagCategoriesFullCategorized.csv")
  charlsonCodesList <- ls(pattern = '.*CharlsonCodes$') 
  for (i in charlsonCodesList) {
      eval(parse(text = paste0("diagCategories[grepl(\'^" , get(i) , ".*\' , diagnosis) , " , strsplit(i , "Codes") , " := 1]")))
  }
  fwrite(diagCategories , "diagCategoriesFullCategorizedCharlson.csv")

  ##For checking the created categories:
  ## for (i in charlsonCodesList) {
  ##     eval(parse(text = paste0("print(diagCategories[ , table(" , i , " , useNA = 'always')])")))
  ## }
#+end_src
** Code for inter-parental violence - manual creation
| ICD 10 Diagnosis                               |
|------------------------------------------------|
| *Specific, standalone codes*                   |
| DT741B                                         |
| DY070                                          |
| EUD1                                           |
|                                                |
| *Codes useful in conjuction with police codes* |
| *Sexual violence*                              |
| DT742                                          |
| DY05                                           |
| DY059                                          |
| ZZ9601                                         |
| BVAA64                                         |
| BVAA64A                                        |
| EUVG1                                          |
| EUVG10                                         |
| EUVG11                                         |
| EUVG18                                         |
| EUVG19                                         |
|                                                |
| *Physical violence*                            |
| DX85                                           |
| DX859                                          |
| DX86                                           |
| DX869                                          |
| DX87                                           |
| DX879                                          |
| DX88                                           |
| DX889                                          |
| DX89                                           |
| DX899                                          |
| DX90                                           |
| DX909                                          |
| DX91                                           |
| DX919                                          |
| DX92                                           |
| DX929                                          |
| DX93                                           |
| DX939                                          |
| DX94                                           |
| DX949                                          |
| DX95                                           |
| DX959                                          |
| DX96                                           |
| DX969                                          |
| DX97                                           |
| DX979                                          |
| DX98                                           |
| DX989                                          |
| DX99                                           |
| DX999                                          |
| DY00                                           |
| DY009                                          |
| DY01                                           |
| DY019                                          |
| DY02                                           |
| DY029                                          |
| DY03                                           |
| DY039                                          |
| DY04                                           |
| DY049                                          |
| DY08                                           |
| DY089                                          |
| DY09                                           |
| DY099                                          |
| BVAA63                                         |
| ALCC03                                         |
| DT748                                          |
| EUVA                                           |
| EUVA0                                          |
| EUVA00                                         |
| EUVA01                                         |
| EUVA02                                         |
| EUVA07                                         |
| EUVA08                                         |
| EUVA09                                         |
| EUVA1                                          |
| EUVA10                                         |
| EUVA11                                         |
| EUVA12                                         |
| EUVA13                                         |
| EUVA14                                         |
| EUVA15                                         |
| EUVA17                                         |
| EUVA18                                         |
| EUVA19                                         |
| EUVA2                                          |
| EUVA20                                         |
| EUVA21                                         |
| EUVA22                                         |
| EUVA23                                         |
| EUVA27                                         |
| EUVA28                                         |
| EUVA29                                         |
| EUVB                                           |
| EUVB0                                          |
| EUVB00                                         |
| EUVB01                                         |
| EUVB02                                         |
| EUVB04                                         |
| EUVB08                                         |
| EUVB09                                         |
| EUVC                                           |
| EUVC0                                          |
| EUVC03                                         |
| EUVC9                                          |
| EUVC98                                         |
| EUVC99                                         |
| EUVD                                           |
| EUVD0                                          |
| EUVD03                                         |
| EUVD08                                         |
| EUVD09                                         |
| EUVE                                           |
| EUVE0                                          |
| EUVE00                                         |
| EUVE01                                         |
| EUVE02                                         |
| EUVE03                                         |
| EUVE08                                         |
| EUVE09                                         |
| EUVG                                           |
| EUVG0                                          |
| EUVG00                                         |
| EUVG01                                         |
| EUVG02                                         |
| EUVG08                                         |
| EUVG09                                         |
| EUVJ                                           |
| EUVJ0                                          |
| EUVJ01                                         |
| EUVJ08                                         |
| EUVJ09                                         |
| EUVZ                                           |
| EUVZ9                                          |
| EUVZ98                                         |
| EUVZ99                                         |
| EUN3                                           |
|                                                |
| *Psychic violence*                             |
| DT743                                          |
|                                                |
| *Unspecific maltreatment*                      |
| EUVG                                           |
|                                                |
| *Violence in ICD 8*                            |
| E9600                                          |
| E9609                                          |
| E9610                                          |
| E9619                                          |
| E9620                                          |
| E9629                                          |
| E9630                                          |
| E9639                                          |
| E9640                                          |
| E9649                                          |
| E9650                                          |
| E9659                                          |
| E9660                                          |
| E9669                                          |
| E9670                                          |
| E9679                                          |
| E9680                                          |
| E9689                                          |
| E9690                                          |
| E9699                                          |
|------------------------------------------------|

Also use kontaars == 3 in conjunction with police codes.

The table was entered twice, then compared by going through the
parallel results of org-table-transpose-table-at-point. 

BE AWARE: the table was altered after entry after detecting some missing codes during error checks - will have to be "translated" after export. 

For export of full list: 

| ICD10Diagnosis |
|----------------|
| DT741B         |
| DY070          |
| EUD1           |
| DT742          |
| DY05           |
| DY059          |
| ZZ9601         |
| BVAA64         |
| BVAA64A        |
| EUVG1          |
| EUVG10         |
| EUVG11         |
| EUVG18         |
| EUVG19         |
| DX85           |
| DX859          |
| DX86           |
| DX869          |
| DX87           |
| DX879          |
| DX88           |
| DX889          |
| DX89           |
| DX899          |
| DX90           |
| DX909          |
| DX91           |
| DX919          |
| DX92           |
| DX929          |
| DX93           |
| DX939          |
| DX94           |
| DX949          |
| DX95           |
| DX959          |
| DX96           |
| DX969          |
| DX97           |
| DX979          |
| DX98           |
| DX989          |
| DX99           |
| DX999          |
| DY00           |
| DY009          |
| DY01           |
| DY019          |
| DY02           |
| DY029          |
| DY03           |
| DY039          |
| DY04           |
| DY049          |
| DY08           |
| DY089          |
| DY09           |
| DY099          |
| BVAA63         |
| ALCC03         |
| DT748          |
| EUVA           |
| EUVA0          |
| EUVA00         |
| EUVA01         |
| EUVA02         |
| EUVA07         |
| EUVA08         |
| EUVA09         |
| EUVA1          |
| EUVA10         |
| EUVA11         |
| EUVA12         |
| EUVA13         |
| EUVA14         |
| EUVA15         |
| EUVA17         |
| EUVA18         |
| EUVA19         |
| EUVA2          |
| EUVA20         |
| EUVA21         |
| EUVA22         |
| EUVA23         |
| EUVA27         |
| EUVA28         |
| EUVA29         |
| EUVB           |
| EUVB0          |
| EUVB00         |
| EUVB01         |
| EUVB02         |
| EUVB04         |
| EUVB08         |
| EUVB09         |
| EUVC           |
| EUVC0          |
| EUVC03         |
| EUVC9          |
| EUVC98         |
| EUVC99         |
| EUVD           |
| EUVD0          |
| EUVD03         |
| EUVD08         |
| EUVD09         |
| EUVE           |
| EUVE0          |
| EUVE00         |
| EUVE01         |
| EUVE02         |
| EUVE03         |
| EUVE08         |
| EUVE09         |
| EUVG           |
| EUVG0          |
| EUVG00         |
| EUVG01         |
| EUVG02         |
| EUVG08         |
| EUVG09         |
| EUVJ           |
| EUVJ0          |
| EUVJ01         |
| EUVJ08         |
| EUVJ09         |
| EUVZ           |
| EUVZ9          |
| EUVZ98         |
| EUVZ99         |
| EUN3           |
| DT743          |
| EUVG           |
| E9600          |
| E9609          |
| E9610          |
| E9619          |
| E9620          |
| E9629          |
| E9630          |
| E9639          |
| E9640          |
| E9649          |
| E9650          |
| E9659          |
| E9660          |
| E9669          |
| E9670          |
| E9679          |
| E9680          |
| E9689          |
| E9690          |
| E9699          |

Exported as: intimatePartner.csv

For export of list of diagnoses indicating interparental violence
with certainty:
 
| ICD10IPVCertain |
|-----------------|
| DT741B          |
| DY070           |
| EUD1            |

Exported as: ICDIPVCertain.csv

| ICDIPVPartial |
|---------------|
| DT742         |
| DY05          |
| DY059         |
| ZZ9601        |
| BVAA64        |
| BVAA64A       |
| EUVG1         |
| EUVG10        |
| EUVG11        |
| EUVG18        |
| EUVG19        |
| DX85          |
| DX859         |
| DX86          |
| DX869         |
| DX87          |
| DX879         |
| DX88          |
| DX889         |
| DX89          |
| DX899         |
| DX90          |
| DX909         |
| DX91          |
| DX919         |
| DX92          |
| DX929         |
| DX93          |
| DX939         |
| DX94          |
| DX949         |
| DX95          |
| DX959         |
| DX96          |
| DX969         |
| DX97          |
| DX979         |
| DX98          |
| DX989         |
| DX99          |
| DX999         |
| DY00          |
| DY009         |
| DY01          |
| DY019         |
| DY02          |
| DY029         |
| DY03          |
| DY039         |
| DY04          |
| DY049         |
| DY08          |
| DY089         |
| DY09          |
| DY099         |
| BVAA63        |
| ALCC03        |
| DT748         |
| EUVA          |
| EUVA0         |
| EUVA00        |
| EUVA01        |
| EUVA02        |
| EUVA07        |
| EUVA08        |
| EUVA09        |
| EUVA1         |
| EUVA10        |
| EUVA11        |
| EUVA12        |
| EUVA13        |
| EUVA14        |
| EUVA15        |
| EUVA17        |
| EUVA18        |
| EUVA19        |
| EUVA2         |
| EUVA20        |
| EUVA21        |
| EUVA22        |
| EUVA23        |
| EUVA27        |
| EUVA28        |
| EUVA29        |
| EUVB          |
| EUVB0         |
| EUVB00        |
| EUVB01        |
| EUVB02        |
| EUVB04        |
| EUVB08        |
| EUVB09        |
| EUVC          |
| EUVC0         |
| EUVC03        |
| EUVC9         |
| EUVC98        |
| EUVC99        |
| EUVD          |
| EUVD0         |
| EUVD03        |
| EUVD08        |
| EUVD09        |
| EUVE          |
| EUVE0         |
| EUVE00        |
| EUVE01        |
| EUVE02        |
| EUVE03        |
| EUVE08        |
| EUVE09        |
| EUVG          |
| EUVG0         |
| EUVG00        |
| EUVG01        |
| EUVG02        |
| EUVG08        |
| EUVG09        |
| EUVJ          |
| EUVJ0         |
| EUVJ01        |
| EUVJ08        |
| EUVJ09        |
| EUVZ          |
| EUVZ9         |
| EUVZ98        |
| EUVZ99        |
| EUN3          |
| DT743         |
| EUVG          |
| E9600         |
| E9609         |
| E9610         |
| E9619         |
| E9620         |
| E9629         |
| E9630         |
| E9639         |
| E9640         |
| E9649         |
| E9650         |
| E9659         |
| E9660         |
| E9669         |
| E9670         |
| E9679         |
| E9680         |
| E9689         |
| E9690         |
| E9699         |

Exported as: ICDIPVPartial.csv

** Additional co-variates and categories categorization
#+begin_src R :session rsession :results output :exports both
  ##To enable reducing data with merging instead of regular expressions (which is severely time consuming), more additional variables using health events is defined here: 
  diagCategories <- fread("diagCategoriesFullCategorizedCharlson.csv")
  ##For some reason, alcoholAbuse and substanceAbuse is read as a logical - changing to numbers if it exists at this point: 
  if ("alcoholAbuse" %in% names(diagCategories)) {
      diagCategories[ , alcoholAbuse := as.numeric(alcoholAbuse)]
  }
  if ("substanceAbuse" %in% names(diagCategories)) {
      diagCategories[ , substanceAbuse := as.numeric(substanceAbuse)]
  }


  ##Coding conditionGroup for preterm birth and acute caesarian section:
  diagCategories[grepl('^DO601.*|^DO603.*|^DO609.*' , diagnosis) , conditionGroup := "Preterm birth"]
  diagCategories[grepl('^DO842A.*|^KMCA10A.*|^KMCA10E.*|^NZTB10.*' , diagnosis) , conditionGroup := "Acute caesarian section"]
  pretermCaesarian <- c("Preterm birth" , "Acute caesarian section")
  diagCategories[conditionGroup %in% pretermCaesarian , conditionCategory := "Preterm birth and acute caesarian section"]

  ##Defining covariates alcohol and substance abuse - crime registries were supposed to be used, but they do not contain any reference of when the crime was committed. As the judicial system in Denmark is sometimes heavily delayed, the classification in time would be somewhat unreliable. 
  diagCategories[grepl('^DF10[1-9].*|^DT510.*|^DT519.*|^DK852.*|^DK860.*|^DE244.*|^DG312.*|^DG621.*|^DG721.*|^DI426.*|^DK292.*|^DO354.*|^DP043.*|^DQ860.*|^DY906.*|^DY907.*|^DY908.*|^DY912.*|^DY913.*|^DZ502.*|^DZ714.*|^DZ721.*|^DK70.*|^DX65.*|^DY15.*' , diagnosis) , alcoholAbuse := 1]##This was inspired by unpublished, earlier work by the first author and Ahacic K, Kennison RF, Kreholt I. Alcohol abstinence, non-hasardous use a decade after alcohol-related hospitalization: registry data linked to population-based representative postal surveys." BMC Public Health. 2014
  ##healthMergeTotal[ , table(alcoholAbuse)]
  ##Inspected, categorizes as expected

  diagCategories[grepl('^DF1[1-6].*|^DF1[8-9].*|^DT436.*|^DT438.*|^DO355.*|^DR782.*|^DR783.*|^DR784.*|^DZ715.*|^DZ722.*|^DT40.*' , diagnosis) , substanceAbuse := 1]##Inspired as alcohol, mentioned above.
  ##healthMergeTotal[ , table(substanceAbuse)]
  ##Inspected, categorizes as expected
  ##Excluding all observations that has not been marked in the processes above:
  ##To avoid errors, all the Charlson categories are added by the code that has been commented out below:
  ## temp <- strsplit(charlsonCodesList , "Codes")
  ## temp <- paste0(temp , " == 1" , " | " , collapse = "")
  diagCategories <- diagCategories[conditionGroup != "" |
				       unspecific == TRUE |
				       myocardialInfarctionCharlson == 1 |
				       aidsHivCharlson == 1 |
				       anyMalignancyCharlson == 1 |
				       leukemiaCharlson == 1 |
				       lymphomaCharlson == 1 |
				       cerebrovascularDiseaseCharlson == 1 |
				       chronicPulmonaryDiseaseCharlson == 1 |
				       dementiaCharlson == 1 |
				       diabetesWithComplicationsCharlson == 1 |
				       diabetesWithoutComplicationsCharlson == 1 |
				       heartFailureCharlson == 1 |
				       hemiplegiaParaplegiaCharlson == 1 |
				       metastaticSolidTumorCharlson == 1 |
				       mildLiverDiseaseCharlson == 1 |
				       myocardialInfarctionCharlson == 1 |
				       pepticUlcerDiseaseCharlson == 1 |
				       peripheralVascularDiseaseCharlson == 1 |
				       renalDiseaseCharlson == 1 |
				       rheumaticDiseaseCharlson == 1 |
				       severeLiverDiseaseCharlson == 1 |
				       alcoholAbuse == 1 |
				       substanceAbuse == 1]
  fwrite(diagCategories , "diagUsed.csv")

  ## Subsequent export of diagUsed:

  diagUsed <- fread("diagUsed.csv")
  temp <- grep('.*Charlson' , names(diagUsed) , value = TRUE)
  diagUsed[ , c(temp) := NULL]
  diagUsed[ , c("diagError" , "GESTATIONSALDER_DAGE" , "D_FODTDTODato" , "substanceAbuse" , "pregnancy" , "D_FODTDTO" , "D_TERMINDato" , "D_TERMIN" , "alcoholAbuse") := NULL]
  diagUsed[conditionCategory != "" & leftOut == TRUE , leftOut := NA]
  diagUsed[unspecific == TRUE & leftOut == TRUE , leftOut := NA]
  diagUsed <- diagUsed[conditionCategory != "" | unspecific == TRUE | leftOut == TRUE]
  fwrite(diagUsed , "diagUsedExport.csv")

#+end_src
** Code for parishes - manual creation

This table was entered manually, then exported back to an external
computer where it was compared to the original using LibreCalc and a
code to mark any discrepancies between columns, correcting faulty
entries. 

| Parish | ParishGrp |
|--------+-----------|
|   7598 |      7644 |
|   7599 |      7644 |
|   7600 |      7644 |
|   7601 |      7644 |
|   7602 |      7644 |
|   7603 |      7644 |
|   7604 |      7644 |
|   7606 |      7644 |
|   7644 |      7644 |
|   7645 |      7644 |
|   8294 |      8300 |
|   8295 |      8300 |
|   8296 |      8300 |
|   8297 |      8300 |
|   8298 |      8300 |
|   8299 |      8300 |
|   8300 |      8300 |
|   8302 |      8300 |
|   8345 |      8300 |
|   8390 |      8300 |
|   7622 |      7622 |
|   7623 |      7622 |
|   7626 |      7622 |
|   7627 |      7622 |
|   7640 |      7622 |
|   7641 |      7622 |
|   7667 |      7622 |
|   7668 |      7622 |
|   9250 |      7622 |
|   7231 |      7234 |
|   7232 |      7234 |
|   7234 |      7234 |
|   7320 |      7321 |
|   7321 |      7321 |
|   7322 |      7321 |
|   7323 |      7321 |
|   7324 |      7321 |
|   7325 |      7321 |
|   7326 |      7321 |
|   7327 |      7321 |
|   7350 |      7234 |
|   7352 |      7234 |
|   7353 |      7234 |
|   7354 |      7234 |
|   7385 |      7234 |
|   7628 |      7630 |
|   7629 |      7630 |
|   7630 |      7630 |
|   7631 |      7630 |
|   7632 |      7630 |
|   7633 |      7630 |
|   7673 |      7630 |
|   8154 |      8514 |
|   8232 |      8235 |
|   8234 |      8235 |
|   8235 |      8235 |
|   8236 |      8235 |
|   8237 |      8235 |
|   8238 |      8235 |
|   8240 |      8235 |
|   8241 |      8235 |
|   8512 |      8514 |
|   8514 |      8514 |
|   8515 |      8514 |
|   8552 |      8574 |
|   8554 |      8574 |
|   8555 |      8574 |
|   8574 |      8574 |
|   8579 |      8574 |
|   8580 |      8574 |
|   8626 |      8514 |
|   8628 |      8514 |
|   8632 |      8514 |
|   8633 |      8514 |
|   8642 |      8642 |
|   8643 |      8642 |
|   8645 |      8642 |
|   8647 |      8642 |
|   8662 |      9198 |
|   8663 |      9198 |
|   8683 |      9198 |
|   8685 |      9198 |
|   8686 |      9198 |
|   8689 |      9198 |
|   8690 |      9198 |
|   8696 |      8701 |
|   8697 |      8701 |
|   8698 |      8701 |
|   8699 |      8701 |
|   8700 |      8701 |
|   8701 |      8701 |
|   8702 |      8701 |
|   8715 |      8642 |
|   8723 |      8642 |
|   8725 |      8642 |
|   8735 |      8642 |
|   8827 |      8847 |
|   8830 |      8574 |
|   8831 |      8574 |
|   8847 |      8847 |
|   8850 |      8847 |
|   8862 |      8847 |
|   8863 |      8847 |
|   8864 |      8847 |
|   8865 |      8847 |
|   8866 |      8847 |
|   9042 |      9062 |
|   9049 |      9062 |
|   9050 |      9062 |
|   9052 |      9062 |
|   9053 |      9062 |
|   9054 |      9062 |
|   9055 |      9062 |
|   9062 |      9062 |
|   9198 |      9198 |
|   9236 |      8701 |
|   9248 |      7630 |
|   7373 |      7373 |
|   7374 |      7373 |
|   7462 |      7373 |
|   7463 |      7373 |
|   7464 |      7373 |
|   7465 |      7373 |
|   7520 |      7373 |
|   7583 |      7611 |
|   7584 |      7611 |
|   7586 |      7611 |
|   7587 |      7611 |
|   7590 |      7611 |
|   7609 |      7611 |
|   7611 |      7611 |
|   7634 |      7665 |
|   7635 |      7665 |
|   7649 |      7665 |
|   7650 |      7665 |
|   7663 |      7665 |
|   7664 |      7665 |
|   7665 |      7665 |
|   7802 |      7811 |
|   7807 |      7811 |
|   7808 |      7811 |
|   7810 |      7811 |
|   7811 |      7811 |
|   7813 |      7811 |
|   7842 |      7811 |
|   8149 |      8204 |
|   8185 |      8204 |
|   8186 |      8204 |
|   8204 |      8204 |
|   8205 |      8204 |
|   8206 |      8204 |
|   8315 |      8204 |
|   8349 |      8349 |
|   8351 |      8349 |
|   8354 |      8349 |
|   8355 |      8349 |
|   8359 |      8349 |
|   8360 |      8349 |
|   8361 |      8349 |
|   8405 |      8472 |
|   8408 |      8472 |
|   8409 |      8472 |
|   8469 |      8472 |
|   8472 |      8472 |
|   8474 |      8472 |
|   8475 |      8472 |
|   8538 |      8538 |
|   8539 |      8538 |
|   8542 |      8538 |
|   8543 |      8538 |
|   8544 |      8538 |
|   8545 |      8538 |
|   8553 |      8538 |
|   8648 |      8648 |
|   8649 |      8648 |
|   8651 |      8648 |
|   8652 |      8648 |
|   8653 |      8648 |
|   8654 |      8648 |
|   8668 |      8681 |
|   8669 |      8681 |
|   8670 |      8681 |
|   8671 |      8681 |
|   8673 |      8681 |
|   8674 |      8681 |
|   8681 |      8681 |
|   8691 |      8648 |
|   7694 |      7708 |
|   7702 |      7745 |
|   7703 |      7745 |
|   7704 |      7745 |
|   7705 |      7745 |
|   7706 |      7708 |
|   7707 |      7708 |
|   7708 |      7708 |
|   7742 |      7708 |
|   7743 |      7708 |
|   7744 |      7745 |
|   7745 |      7745 |
|   7804 |      7804 |
|   7805 |      7804 |
|   7806 |      7804 |
|   7809 |      7804 |
|   7815 |      7804 |
|   7816 |      7804 |
|   7849 |      7855 |
|   7851 |      7855 |
|   7852 |      7855 |
|   7853 |      7855 |
|   7854 |      7855 |
|   7855 |      7855 |
|   7857 |      7857 |
|   7858 |      7857 |
|   7859 |      7857 |
|   7860 |      7857 |
|   7861 |      7857 |
|   7862 |      7857 |
|   7980 |      7981 |
|   7981 |      7981 |
|   8042 |      8094 |
|   8045 |      8094 |
|   8060 |      8139 |
|   8088 |      8094 |
|   8094 |      8094 |
|   8095 |      8094 |
|   8099 |      8094 |
|   8133 |      8156 |
|   8134 |      8156 |
|   8139 |      8139 |
|   8140 |      8139 |
|   8142 |      8139 |
|   8156 |      8156 |
|   8157 |      8156 |
|   8158 |      8156 |
|   8167 |      8173 |
|   8168 |      8173 |
|   8169 |      8173 |
|   8172 |      8173 |
|   8173 |      8173 |
|   8175 |      8173 |
|   8187 |      8156 |
|   8253 |      8253 |
|   8255 |      8253 |
|   8256 |      8253 |
|   8257 |      8253 |
|   8258 |      8253 |
|   8259 |      8253 |
|   8271 |      8281 |
|   8272 |      8281 |
|   8274 |      8281 |
|   8276 |      8281 |
|   8281 |      8281 |
|   8287 |      8288 |
|   8288 |      8288 |
|   8353 |      8281 |
|   8492 |      8139 |
|   8493 |      8139 |
|   8517 |      8288 |
|   8518 |      8288 |
|   8520 |      8288 |
|   8541 |      8585 |
|   8583 |      8585 |
|   8584 |      8585 |
|   8585 |      8585 |
|   8586 |      8585 |
|   8587 |      8585 |
|   8672 |      8676 |
|   8675 |      8676 |
|   8676 |      8676 |
|   8677 |      8676 |
|   8678 |      8676 |
|   8679 |      8676 |
|   8703 |      8703 |
|   8704 |      8703 |
|   8705 |      8703 |
|   8706 |      8703 |
|   8707 |      8703 |
|   8708 |      8703 |
|   8726 |      8728 |
|   8727 |      8728 |
|   8728 |      8728 |
|   8729 |      8728 |
|   8730 |      8728 |
|   8887 |      8887 |
|   8889 |      8887 |
|   8890 |      8887 |
|   8891 |      8887 |
|   9034 |      8887 |
|   9035 |      8887 |
|   9095 |      8288 |
|   9127 |      8728 |
|   9210 |      7981 |
|   9281 |      7981 |
|   9282 |      7981 |
|   9284 |      7981 |
|   7220 |      7220 |
|   7221 |      7220 |
|   7222 |      7220 |
|   7225 |      7220 |
|   7254 |      7220 |
|   7305 |      7335 |
|   7307 |      7332 |
|   7312 |      7362 |
|   7317 |      7332 |
|   7318 |      7332 |
|   7330 |      7332 |
|   7332 |      7332 |
|   7333 |      7335 |
|   7335 |      7335 |
|   7336 |      7335 |
|   7337 |      7335 |
|   7340 |      7365 |
|   7343 |      7365 |
|   7344 |      7365 |
|   7357 |      7362 |
|   7358 |      7362 |
|   7361 |      7362 |
|   7362 |      7362 |
|   7365 |      7365 |
|   7366 |      7365 |
|   7387 |      7389 |
|   7388 |      7389 |
|   7389 |      7389 |
|   7390 |      7389 |
|   7391 |      7389 |
|   7492 |      7541 |
|   7524 |      7526 |
|   7525 |      7526 |
|   7526 |      7526 |
|   7529 |      7526 |
|   7536 |      7541 |
|   7541 |      7541 |
|   7545 |      7541 |
|   7546 |      7541 |
|   7550 |      7526 |
|   7592 |      7594 |
|   7593 |      7594 |
|   7594 |      7594 |
|   7595 |      7594 |
|   7597 |      7594 |
|   7619 |      9194 |
|   7620 |      9194 |
|   7654 |      7659 |
|   7657 |      7659 |
|   7658 |      7659 |
|   7659 |      7659 |
|   7660 |      7659 |
|   7671 |      9194 |
|   7674 |      9194 |
|   7697 |      7697 |
|   7698 |      7697 |
|   7709 |      7709 |
|   7710 |      7709 |
|   7711 |      7709 |
|   7712 |      7709 |
|   7713 |      7713 |
|   7715 |      7713 |
|   7716 |      7713 |
|   7717 |      7713 |
|   7718 |      7713 |
|   7747 |      7697 |
|   7750 |      7697 |
|   7765 |      7697 |
|   7843 |      7892 |
|   7845 |      7892 |
|   7850 |      7892 |
|   7889 |      7892 |
|   7892 |      7892 |
|   7914 |      7921 |
|   7921 |      7921 |
|   7931 |      7921 |
|   7935 |      7921 |
|   7937 |      7921 |
|   7950 |      7965 |
|   7951 |      7965 |
|   7955 |      7965 |
|   7965 |      7965 |
|   7972 |      7965 |
|   7975 |      7975 |
|   7982 |      7975 |
|   7985 |      7975 |
|   8023 |      8023 |
|   8024 |      8023 |
|   8029 |      8023 |
|   8030 |      8023 |
|   8068 |      8147 |
|   8072 |      8127 |
|   8074 |      8127 |
|   8126 |      8127 |
|   8127 |      8127 |
|   8131 |      8127 |
|   8135 |      8135 |
|   8136 |      8135 |
|   8141 |      8135 |
|   8143 |      8214 |
|   8144 |      8135 |
|   8147 |      8147 |
|   8148 |      8135 |
|   8152 |      8513 |
|   8153 |      8513 |
|   8188 |      8211 |
|   8191 |      8195 |
|   8192 |      8195 |
|   8193 |      8195 |
|   8194 |      8195 |
|   8195 |      8195 |
|   8207 |      8316 |
|   8209 |      8211 |
|   8210 |      8211 |
|   8211 |      8211 |
|   8212 |      8211 |
|   8214 |      8214 |
|   8216 |      8214 |
|   8217 |      8214 |
|   8224 |      8247 |
|   8225 |      8214 |
|   8226 |      8247 |
|   8227 |      8247 |
|   8228 |      8247 |
|   8229 |      8147 |
|   8230 |      8147 |
|   8247 |      8247 |
|   8248 |      8147 |
|   8260 |      8264 |
|   8261 |      8264 |
|   8262 |      8264 |
|   8263 |      8264 |
|   8264 |      8264 |
|   8277 |      8339 |
|   8278 |      8339 |
|   8279 |      8339 |
|   8283 |      8519 |
|   8284 |      8519 |
|   8285 |      8519 |
|   8286 |      8519 |
|   8289 |      8291 |
|   8290 |      8291 |
|   8291 |      8291 |
|   8292 |      8316 |
|   8316 |      8316 |
|   8317 |      8316 |
|   8339 |      8339 |
|   8342 |      8339 |
|   8356 |      8362 |
|   8357 |      8362 |
|   8358 |      8362 |
|   8362 |      8362 |
|   8363 |      8362 |
|   8391 |      8392 |
|   8392 |      8392 |
|   8396 |      8392 |
|   8398 |      8392 |
|   8399 |      8711 |
|   8400 |      8711 |
|   8406 |      8406 |
|   8411 |      8411 |
|   8412 |      8411 |
|   8413 |      8411 |
|   8415 |      8411 |
|   8431 |      9063 |
|   8432 |      9063 |
|   8434 |      9063 |
|   8468 |      8406 |
|   8470 |      8406 |
|   8471 |      8406 |
|   8473 |      8406 |
|   8484 |      8594 |
|   8485 |      8594 |
|   8495 |      8023 |
|   8497 |      8504 |
|   8501 |      8504 |
|   8502 |      8504 |
|   8503 |      8506 |
|   8504 |      8504 |
|   8506 |      8506 |
|   8508 |      8506 |
|   8509 |      8506 |
|   8510 |      8513 |
|   8511 |      8513 |
|   8513 |      8513 |
|   8519 |      8519 |
|   8521 |      8291 |
|   8524 |      8291 |
|   8525 |      8527 |
|   8526 |      8527 |
|   8527 |      8527 |
|   8529 |      8527 |
|   8536 |      8504 |
|   8546 |      8546 |
|   8547 |      8546 |
|   8548 |      8546 |
|   8551 |      8551 |
|   8568 |      8527 |
|   8569 |      9215 |
|   8570 |      8641 |
|   8575 |      8551 |
|   8576 |      8551 |
|   8577 |      8551 |
|   8578 |      8551 |
|   8581 |      8546 |
|   8582 |      8546 |
|   8594 |      8594 |
|   8597 |      8594 |
|   8599 |      8594 |
|   8624 |      9215 |
|   8625 |      8641 |
|   8627 |      8641 |
|   8634 |      9215 |
|   8637 |      9215 |
|   8639 |      8641 |
|   8641 |      8641 |
|   8655 |      8655 |
|   8656 |      8655 |
|   8657 |      8655 |
|   8658 |      8655 |
|   8659 |      8655 |
|   8664 |      8667 |
|   8665 |      8667 |
|   8666 |      8667 |
|   8667 |      8667 |
|   8680 |      8693 |
|   8682 |      8693 |
|   8684 |      8667 |
|   8693 |      8693 |
|   8694 |      8693 |
|   8695 |      8693 |
|   8710 |      8392 |
|   8711 |      8711 |
|   8712 |      8714 |
|   8713 |      8714 |
|   8714 |      8714 |
|   8716 |      8711 |
|   8717 |      8711 |
|   8718 |      8714 |
|   8719 |      8714 |
|   8731 |      8734 |
|   8733 |      8734 |
|   8734 |      8734 |
|   8736 |      8734 |
|   8737 |      8734 |
|   8739 |      8763 |
|   8740 |      8763 |
|   8741 |      8763 |
|   8754 |      8768 |
|   8756 |      8768 |
|   8760 |      8768 |
|   8763 |      8763 |
|   8764 |      8763 |
|   8768 |      8768 |
|   8779 |      8783 |
|   8780 |      8783 |
|   8781 |      8783 |
|   8782 |      8783 |
|   8783 |      8783 |
|   8856 |      8856 |
|   8857 |      8856 |
|   8859 |      8856 |
|   8860 |      8856 |
|   8861 |      8856 |
|   9063 |      9063 |
|   9065 |      8316 |
|   9168 |      8506 |
|   9194 |      9194 |
|   9215 |      9215 |
|   9221 |      8411 |
|   9231 |      9063 |
|   9254 |      7709 |
|   9275 |      8768 |
|   9283 |      7975 |
|   9285 |      7975 |
|   7223 |      7227 |
|   7226 |      7227 |
|   7227 |      7227 |
|   7229 |      7227 |
|   7246 |      7456 |
|   7247 |      7247 |
|   7249 |      7247 |
|   7257 |      7247 |
|   7279 |      7290 |
|   7280 |      7290 |
|   7290 |      7290 |
|   7291 |      7290 |
|   7310 |      7316 |
|   7311 |      7316 |
|   7314 |      7314 |
|   7315 |      7314 |
|   7316 |      7316 |
|   7319 |      7316 |
|   7355 |      7314 |
|   7356 |      7314 |
|   7371 |      7539 |
|   7372 |      7539 |
|   7375 |      7514 |
|   7376 |      7514 |
|   7382 |      7499 |
|   7456 |      7456 |
|   7457 |      7456 |
|   7460 |      7456 |
|   7486 |      7489 |
|   7487 |      7489 |
|   7488 |      7489 |
|   7489 |      7489 |
|   7493 |      7493 |
|   7494 |      7493 |
|   7499 |      7499 |
|   7512 |      7499 |
|   7513 |      7514 |
|   7514 |      7514 |
|   7532 |      7499 |
|   7538 |      7539 |
|   7539 |      7539 |
|   7549 |      7493 |
|   7551 |      7493 |
|   7565 |      7567 |
|   7566 |      7567 |
|   7567 |      7567 |
|   7568 |      7567 |
|   7575 |      7576 |
|   7576 |      7576 |
|   7580 |      7580 |
|   7581 |      7580 |
|   7582 |      7580 |
|   7585 |      7589 |
|   7589 |      7589 |
|   7591 |      7589 |
|   7608 |      7589 |
|   7612 |      7612 |
|   7614 |      7612 |
|   7615 |      7612 |
|   7616 |      7612 |
|   7617 |      7576 |
|   7618 |      7576 |
|   7651 |      7651 |
|   7652 |      7651 |
|   7653 |      9082 |
|   7655 |      9082 |
|   7656 |      9082 |
|   7661 |      7651 |
|   7662 |      7651 |
|   7701 |      7755 |
|   7725 |      7725 |
|   7726 |      7725 |
|   7727 |      7725 |
|   7735 |      7735 |
|   7737 |      7740 |
|   7738 |      7740 |
|   7739 |      7740 |
|   7740 |      7740 |
|   7751 |      7755 |
|   7752 |      7755 |
|   7755 |      7755 |
|   7758 |      7758 |
|   7759 |      7758 |
|   7760 |      7758 |
|   7761 |      7758 |
|   7770 |      7735 |
|   7771 |      7735 |
|   7773 |      7735 |
|   7824 |      7824 |
|   7825 |      7827 |
|   7827 |      7827 |
|   7828 |      7827 |
|   7838 |      7824 |
|   7839 |      7824 |
|   7840 |      7824 |
|   7873 |      7873 |
|   7874 |      7873 |
|   7875 |      7873 |
|   7876 |      7873 |
|   7907 |      9188 |
|   7908 |      9188 |
|   7946 |      7946 |
|   7947 |      7946 |
|   7961 |      7962 |
|   7962 |      7962 |
|   7963 |      7962 |
|   7989 |      7989 |
|   7990 |      8039 |
|   7991 |      7989 |
|   7996 |      7989 |
|   7997 |      7989 |
|   8013 |      8129 |
|   8014 |      8039 |
|   8039 |      8039 |
|   8040 |      8039 |
|   8043 |      8043 |
|   8046 |      8043 |
|   8055 |      8043 |
|   8056 |      8043 |
|   8059 |      7962 |
|   8061 |      8070 |
|   8064 |      8064 |
|   8070 |      8070 |
|   8075 |      8064 |
|   8076 |      8064 |
|   8077 |      8064 |
|   8081 |      8129 |
|   8084 |      8129 |
|   8089 |      8089 |
|   8090 |      8089 |
|   8091 |      8089 |
|   8092 |      8089 |
|   8129 |      8129 |
|   8137 |      8630 |
|   8138 |      8630 |
|   8165 |      8437 |
|   8189 |      8189 |
|   8190 |      8189 |
|   8196 |      8189 |
|   8197 |      8189 |
|   8280 |      8280 |
|   8293 |      8280 |
|   8337 |      8280 |
|   8338 |      8280 |
|   8420 |      8422 |
|   8421 |      8422 |
|   8422 |      8422 |
|   8423 |      8422 |
|   8436 |      8444 |
|   8437 |      8437 |
|   8438 |      8437 |
|   8439 |      8437 |
|   8442 |      8444 |
|   8443 |      8444 |
|   8444 |      8444 |
|   8481 |      8481 |
|   8486 |      9102 |
|   8487 |      9102 |
|   8489 |      9102 |
|   8494 |      8070 |
|   8498 |      8564 |
|   8507 |      8836 |
|   8537 |      8070 |
|   8549 |      8549 |
|   8550 |      8549 |
|   8556 |      8549 |
|   8557 |      8549 |
|   8558 |      8558 |
|   8560 |      8558 |
|   8561 |      8558 |
|   8562 |      8558 |
|   8563 |      8564 |
|   8564 |      8564 |
|   8565 |      8564 |
|   8566 |      8566 |
|   8567 |      8566 |
|   8571 |      8636 |
|   8590 |      8592 |
|   8591 |      8592 |
|   8592 |      8592 |
|   8595 |      8592 |
|   8604 |      8604 |
|   8605 |      8604 |
|   8608 |      8604 |
|   8609 |      8604 |
|   8616 |      8566 |
|   8629 |      8630 |
|   8630 |      8630 |
|   8635 |      8636 |
|   8636 |      8636 |
|   8638 |      8566 |
|   8640 |      8636 |
|   8660 |      8660 |
|   8661 |      8660 |
|   8751 |      8751 |
|   8752 |      8759 |
|   8753 |      8751 |
|   8758 |      8759 |
|   8759 |      8759 |
|   8761 |      8759 |
|   8767 |      9124 |
|   8770 |      8751 |
|   8772 |      9280 |
|   8773 |      9280 |
|   8774 |      8751 |
|   8775 |      9124 |
|   8776 |      9124 |
|   8784 |      8785 |
|   8785 |      8785 |
|   8786 |      8785 |
|   8788 |      8785 |
|   8793 |      8837 |
|   8795 |      8795 |
|   8806 |      8795 |
|   8807 |      8795 |
|   8811 |      9119 |
|   8820 |      8820 |
|   8822 |      8823 |
|   8823 |      8823 |
|   8824 |      8823 |
|   8825 |      8820 |
|   8826 |      8820 |
|   8829 |      8820 |
|   8832 |      8836 |
|   8833 |      8833 |
|   8834 |      8833 |
|   8836 |      8836 |
|   8837 |      8837 |
|   8838 |      8837 |
|   8843 |      8848 |
|   8844 |      8848 |
|   8845 |      8848 |
|   8848 |      8848 |
|   8853 |      8823 |
|   8878 |      8879 |
|   8879 |      8879 |
|   8880 |      8879 |
|   8882 |      8879 |
|   8948 |      8951 |
|   8950 |      8951 |
|   8951 |      8951 |
|   8952 |      8951 |
|   8959 |      9046 |
|   8966 |      8973 |
|   8967 |      8973 |
|   8973 |      8973 |
|   8983 |      7946 |
|   8984 |      7946 |
|   8986 |      8973 |
|   9031 |      9037 |
|   9032 |      9037 |
|   9033 |      9037 |
|   9036 |      9046 |
|   9037 |      9037 |
|   9046 |      9046 |
|   9048 |      9046 |
|   9082 |      9082 |
|   9102 |      9102 |
|   9119 |      9119 |
|   9120 |      9119 |
|   9124 |      9124 |
|   9129 |      8660 |
|   9170 |      8795 |
|   9188 |      9188 |
|   9201 |      8837 |
|   9203 |      8836 |
|   9204 |      8833 |
|   9207 |      8833 |
|   9209 |      9119 |
|   9228 |      8481 |
|   9229 |      8481 |
|   9230 |      8481 |
|   9235 |      8660 |
|   9245 |      7247 |
|   9249 |      7580 |
|   9255 |      7827 |
|   9257 |      7725 |
|   9276 |      9280 |
|   9280 |      9280 |
|   9286 |      9188 |
|   7161 |      7167 |
|   7163 |      7164 |
|   7164 |      7164 |
|   7165 |      7164 |
|   7167 |      7167 |
|   7168 |      7167 |
|   7172 |      7172 |
|   7174 |      7172 |
|   7176 |      7172 |
|   7180 |      7181 |
|   7181 |      7181 |
|   7182 |      7181 |
|   7205 |      7210 |
|   7210 |      7210 |
|   7212 |      7210 |
|   7215 |      7370 |
|   7217 |      7370 |
|   7224 |      7236 |
|   7233 |      7359 |
|   7236 |      7236 |
|   7237 |      7236 |
|   7238 |      7238 |
|   7239 |      7238 |
|   7248 |      7248 |
|   7250 |      7248 |
|   7251 |      7251 |
|   7252 |      7248 |
|   7253 |      7251 |
|   7271 |      7251 |
|   7328 |      7331 |
|   7329 |      7331 |
|   7331 |      7331 |
|   7338 |      7342 |
|   7339 |      7384 |
|   7341 |      7342 |
|   7342 |      7342 |
|   7346 |      7359 |
|   7351 |      7384 |
|   7359 |      7359 |
|   7367 |      7369 |
|   7368 |      7369 |
|   7369 |      7369 |
|   7370 |      7370 |
|   7377 |      7377 |
|   7378 |      7377 |
|   7380 |      7377 |
|   7384 |      7384 |
|   7405 |      7422 |
|   7406 |      7422 |
|   7422 |      7422 |
|   7433 |      9241 |
|   7435 |      9241 |
|   7471 |      7480 |
|   7474 |      7507 |
|   7476 |      7480 |
|   7477 |      7507 |
|   7480 |      7480 |
|   7490 |      7491 |
|   7491 |      7491 |
|   7495 |      7495 |
|   7496 |      7495 |
|   7498 |      7495 |
|   7507 |      7507 |
|   7508 |      7508 |
|   7509 |      7508 |
|   7517 |      7519 |
|   7518 |      7519 |
|   7519 |      7519 |
|   7521 |      7491 |
|   7528 |      7528 |
|   7531 |      7528 |
|   7542 |      7544 |
|   7543 |      7544 |
|   7544 |      7544 |
|   7547 |      7528 |
|   7558 |      7561 |
|   7561 |      7561 |
|   7562 |      7561 |
|   7570 |      7572 |
|   7572 |      7572 |
|   7573 |      7572 |
|   7605 |      7643 |
|   7643 |      7643 |
|   7646 |      7646 |
|   7647 |      7643 |
|   7666 |      7646 |
|   7669 |      7646 |
|   7683 |      7699 |
|   7685 |      7685 |
|   7687 |      7685 |
|   7691 |      7691 |
|   7692 |      7691 |
|   7693 |      7691 |
|   7699 |      7699 |
|   7700 |      7699 |
|   7719 |      7721 |
|   7721 |      7721 |
|   7723 |      7685 |
|   7729 |      7883 |
|   7730 |      7883 |
|   7731 |      7736 |
|   7732 |      7736 |
|   7734 |      7772 |
|   7736 |      7736 |
|   7753 |      7887 |
|   7756 |      7762 |
|   7757 |      7762 |
|   7762 |      7762 |
|   7772 |      7772 |
|   7792 |      7887 |
|   7794 |      7794 |
|   7800 |      7871 |
|   7812 |      7794 |
|   7814 |      7794 |
|   7818 |      7818 |
|   7820 |      7818 |
|   7822 |      7818 |
|   7831 |      7866 |
|   7834 |      7835 |
|   7835 |      7835 |
|   7837 |      7835 |
|   7848 |      7848 |
|   7866 |      7866 |
|   7871 |      7871 |
|   7872 |      7871 |
|   7878 |      7879 |
|   7879 |      7879 |
|   7881 |      7879 |
|   7883 |      7883 |
|   7887 |      7887 |
|   7888 |      7848 |
|   7890 |      7848 |
|   7896 |      7898 |
|   7898 |      7898 |
|   7918 |      7920 |
|   7920 |      7920 |
|   7923 |      7920 |
|   7930 |      7938 |
|   7936 |      7938 |
|   7938 |      7938 |
|   7939 |      7939 |
|   7944 |      7945 |
|   7945 |      7945 |
|   7948 |      7948 |
|   7949 |      7960 |
|   7952 |      7954 |
|   7953 |      7954 |
|   7954 |      7954 |
|   7956 |      7956 |
|   7957 |      7956 |
|   7958 |      7948 |
|   7959 |      7956 |
|   7960 |      7960 |
|   7968 |      7960 |
|   7973 |      7898 |
|   7979 |      7979 |
|   7988 |      7988 |
|   7992 |      7993 |
|   7993 |      7993 |
|   8001 |      8057 |
|   8002 |      8003 |
|   8003 |      8003 |
|   8004 |      8003 |
|   8006 |      8057 |
|   8007 |      7993 |
|   8011 |      8106 |
|   8015 |      8032 |
|   8016 |      8032 |
|   8025 |      8607 |
|   8027 |      8607 |
|   8032 |      8032 |
|   8033 |      7988 |
|   8034 |      7988 |
|   8036 |      8106 |
|   8050 |      8051 |
|   8051 |      8051 |
|   8057 |      8057 |
|   8093 |      8051 |
|   8096 |      8097 |
|   8097 |      8097 |
|   8098 |      8097 |
|   8106 |      8106 |
|   8111 |      8111 |
|   8112 |      8111 |
|   8113 |      8111 |
|   8159 |      8265 |
|   8160 |      8239 |
|   8161 |      8161 |
|   8162 |      8166 |
|   8166 |      8166 |
|   8170 |      8170 |
|   8171 |      8170 |
|   8174 |      8170 |
|   8176 |      8242 |
|   8177 |      8178 |
|   8178 |      8178 |
|   8179 |      8178 |
|   8202 |      9173 |
|   8203 |      9173 |
|   8220 |      8161 |
|   8222 |      8244 |
|   8223 |      8244 |
|   8233 |      8166 |
|   8239 |      8239 |
|   8242 |      8242 |
|   8244 |      8244 |
|   8254 |      8242 |
|   8265 |      8265 |
|   8268 |      8265 |
|   8270 |      8273 |
|   8273 |      8273 |
|   8275 |      8273 |
|   8304 |      8304 |
|   8305 |      8304 |
|   8308 |      8304 |
|   8309 |      8314 |
|   8310 |      8314 |
|   8314 |      8314 |
|   8318 |      8318 |
|   8323 |      8318 |
|   8328 |      8340 |
|   8332 |      9107 |
|   8340 |      8340 |
|   8341 |      8340 |
|   8343 |      8343 |
|   8344 |      8343 |
|   8346 |      8343 |
|   8386 |      8386 |
|   8388 |      9107 |
|   8394 |      8395 |
|   8395 |      8395 |
|   8397 |      8395 |
|   8404 |      8404 |
|   8416 |      8416 |
|   8417 |      8416 |
|   8425 |      9150 |
|   8428 |      8429 |
|   8429 |      8429 |
|   8433 |      8435 |
|   8435 |      8435 |
|   8441 |      8435 |
|   8446 |      8404 |
|   8448 |      8448 |
|   8449 |      8416 |
|   8457 |      8460 |
|   8460 |      8460 |
|   8461 |      8461 |
|   8462 |      8460 |
|   8463 |      8466 |
|   8464 |      8461 |
|   8466 |      8466 |
|   8467 |      8466 |
|   8482 |      8429 |
|   8483 |      8461 |
|   8488 |      8491 |
|   8490 |      8491 |
|   8491 |      8491 |
|   8523 |      8528 |
|   8528 |      8528 |
|   8530 |      8531 |
|   8531 |      8531 |
|   8532 |      8528 |
|   8533 |      8531 |
|   8534 |      8534 |
|   8593 |      8534 |
|   8607 |      8607 |
|   8618 |      8534 |
|   8644 |      8644 |
|   8646 |      8644 |
|   8720 |      8644 |
|   8743 |      8828 |
|   8755 |      8755 |
|   8757 |      8755 |
|   8771 |      8755 |
|   8787 |      8868 |
|   8796 |      9167 |
|   8801 |      8801 |
|   8808 |      8808 |
|   8810 |      8808 |
|   8821 |      8821 |
|   8828 |      8828 |
|   8835 |      8821 |
|   8839 |      8801 |
|   8842 |      8842 |
|   8849 |      8828 |
|   8851 |      8842 |
|   8852 |      8842 |
|   8867 |      8867 |
|   8868 |      8868 |
|   8874 |      8874 |
|   8875 |      8874 |
|   8876 |      8868 |
|   8892 |      8892 |
|   8893 |      8899 |
|   8894 |      8892 |
|   8896 |      8896 |
|   8899 |      8899 |
|   8901 |      8899 |
|   8910 |      8910 |
|   8911 |      8867 |
|   8912 |      8896 |
|   8913 |      8896 |
|   8914 |      8910 |
|   8915 |      8910 |
|   8921 |      8874 |
|   8925 |      8925 |
|   8928 |      9268 |
|   8929 |      8987 |
|   8932 |      8925 |
|   8935 |      7939 |
|   8936 |      7939 |
|   8945 |      8945 |
|   8954 |      8954 |
|   8955 |      8954 |
|   8958 |      8954 |
|   8963 |      8963 |
|   8964 |      8968 |
|   8968 |      8968 |
|   8970 |      8968 |
|   8972 |      8963 |
|   8974 |      8979 |
|   8978 |      8979 |
|   8979 |      8979 |
|   8981 |      7945 |
|   8982 |      8963 |
|   8987 |      8987 |
|   8995 |      8997 |
|   8997 |      8997 |
|   8998 |      8997 |
|   9015 |      9015 |
|   9018 |      9015 |
|   9030 |      8892 |
|   9040 |      9059 |
|   9043 |      9051 |
|   9044 |      9051 |
|   9051 |      9051 |
|   9058 |      9059 |
|   9059 |      9059 |
|   9107 |      9107 |
|   9114 |      8945 |
|   9123 |      9123 |
|   9125 |      8808 |
|   9137 |      8987 |
|   9150 |      9150 |
|   9156 |      8448 |
|   9159 |      8239 |
|   9167 |      9167 |
|   9172 |      9279 |
|   9173 |      9173 |
|   9193 |      8161 |
|   9205 |      9167 |
|   9208 |      8821 |
|   9211 |      8801 |
|   9220 |      8404 |
|   9223 |      8386 |
|   9224 |      8448 |
|   9225 |      8386 |
|   9232 |      8318 |
|   9234 |      9150 |
|   9241 |      9241 |
|   9244 |      7238 |
|   9247 |      7508 |
|   9251 |      7866 |
|   9256 |      7772 |
|   9258 |      7721 |
|   9260 |      9015 |
|   9262 |      7948 |
|   9264 |      9268 |
|   9265 |      7979 |
|   9266 |      7979 |
|   9267 |      8945 |
|   9268 |      9268 |
|   9269 |      8925 |
|   9273 |      8867 |
|   9278 |      9279 |
|   9279 |      9279 |
|   9288 |      9123 |
|   9289 |      9123 |
|   7124 |      7126 |
|   7126 |      7126 |
|   7150 |      7196 |
|   7158 |      7158 |
|   7177 |      7177 |
|   7178 |      7177 |
|   7184 |      7184 |
|   7185 |      7184 |
|   7196 |      7196 |
|   7198 |      7201 |
|   7201 |      7201 |
|   7208 |      7213 |
|   7209 |      7158 |
|   7213 |      7213 |
|   7219 |      7219 |
|   7230 |      7245 |
|   7245 |      7245 |
|   7255 |      7256 |
|   7256 |      7256 |
|   7258 |      7258 |
|   7259 |      7258 |
|   7260 |      7260 |
|   7263 |      7264 |
|   7264 |      7264 |
|   7269 |      7269 |
|   7270 |      7269 |
|   7273 |      7219 |
|   7278 |      7278 |
|   7281 |      7278 |
|   7286 |      7286 |
|   7287 |      7286 |
|   7288 |      7288 |
|   7289 |      7288 |
|   7294 |      9192 |
|   7295 |      7296 |
|   7296 |      7296 |
|   7300 |      9179 |
|   7304 |      7304 |
|   7309 |      7309 |
|   7313 |      7309 |
|   7334 |      7304 |
|   7381 |      7501 |
|   7393 |      7393 |
|   7394 |      7393 |
|   7401 |      7402 |
|   7402 |      7402 |
|   7403 |      7404 |
|   7404 |      7404 |
|   7410 |      7410 |
|   7411 |      7410 |
|   7412 |      7427 |
|   7419 |      7419 |
|   7420 |      7419 |
|   7423 |      7423 |
|   7424 |      7423 |
|   7427 |      7427 |
|   7429 |      7429 |
|   7430 |      7430 |
|   7440 |      7440 |
|   7445 |      7429 |
|   7453 |      7453 |
|   7454 |      7454 |
|   7458 |      7458 |
|   7459 |      7458 |
|   7461 |      7453 |
|   7466 |      7466 |
|   7472 |      7473 |
|   7473 |      7473 |
|   7475 |      7466 |
|   7479 |      9109 |
|   7483 |      7483 |
|   7485 |      7483 |
|   7500 |      7500 |
|   7501 |      7501 |
|   7502 |      7500 |
|   7503 |      7503 |
|   7504 |      7504 |
|   7505 |      7504 |
|   7506 |      7503 |
|   7523 |      7523 |
|   7527 |      7523 |
|   7530 |      7530 |
|   7533 |      7530 |
|   7534 |      7534 |
|   7535 |      7534 |
|   7554 |      7554 |
|   7555 |      7554 |
|   7556 |      7557 |
|   7557 |      7557 |
|   7559 |      7560 |
|   7560 |      7560 |
|   7563 |      7563 |
|   7564 |      7563 |
|   7579 |      7579 |
|   7588 |      7579 |
|   7607 |      7607 |
|   7610 |      7607 |
|   7639 |      9195 |
|   7679 |      7679 |
|   7680 |      7680 |
|   7681 |      7681 |
|   7682 |      7681 |
|   7684 |      7686 |
|   7686 |      7686 |
|   7688 |      7688 |
|   7696 |      7746 |
|   7720 |      7679 |
|   7722 |      7680 |
|   7746 |      7746 |
|   7748 |      7688 |
|   7749 |      7885 |
|   7754 |      7754 |
|   7763 |      7763 |
|   7764 |      7763 |
|   7768 |      7768 |
|   7769 |      7768 |
|   7786 |      7786 |
|   7789 |      7795 |
|   7793 |      7754 |
|   7795 |      7795 |
|   7803 |      7821 |
|   7821 |      7821 |
|   7829 |      7829 |
|   7830 |      7829 |
|   7832 |      7832 |
|   7833 |      9075 |
|   7841 |      7832 |
|   7863 |      7864 |
|   7864 |      7864 |
|   7869 |      7870 |
|   7870 |      7870 |
|   7880 |      7884 |
|   7884 |      7884 |
|   7885 |      7885 |
|   7899 |      7899 |
|   7900 |      7900 |
|   7901 |      7899 |
|   7903 |      7903 |
|   7910 |      7922 |
|   7922 |      7922 |
|   7924 |      7926 |
|   7926 |      7926 |
|   7940 |      7940 |
|   7942 |      7942 |
|   7943 |      7942 |
|   7964 |      7964 |
|   7970 |      7964 |
|   7976 |      7977 |
|   7977 |      7977 |
|   7978 |      8000 |
|   7984 |      7986 |
|   7986 |      7986 |
|   7987 |      7903 |
|   7994 |      7994 |
|   7995 |      7994 |
|   7999 |      7999 |
|   8000 |      8000 |
|   8005 |      7999 |
|   8021 |      8031 |
|   8026 |      8026 |
|   8028 |      8026 |
|   8031 |      8031 |
|   8035 |      8035 |
|   8037 |      8037 |
|   8038 |      8037 |
|   8041 |      8035 |
|   8044 |      8044 |
|   8047 |      8054 |
|   8049 |      8044 |
|   8054 |      8054 |
|   8058 |      7900 |
|   8065 |      8069 |
|   8066 |      8066 |
|   8069 |      8069 |
|   8078 |      8078 |
|   8079 |      8066 |
|   8080 |      8082 |
|   8082 |      8082 |
|   8083 |      8078 |
|   8086 |      9183 |
|   8123 |      8123 |
|   8145 |      8215 |
|   8150 |      8199 |
|   8151 |      8155 |
|   8155 |      8155 |
|   8180 |      8219 |
|   8199 |      8199 |
|   8208 |      8516 |
|   8215 |      8215 |
|   8218 |      8218 |
|   8219 |      8219 |
|   8221 |      8218 |
|   8266 |      8266 |
|   8267 |      8266 |
|   8301 |      8301 |
|   8303 |      8303 |
|   8311 |      9217 |
|   8313 |      9184 |
|   8319 |      8319 |
|   8324 |      8324 |
|   8325 |      8325 |
|   8326 |      8325 |
|   8329 |      8329 |
|   8331 |      8329 |
|   8334 |      8334 |
|   8336 |      8301 |
|   8347 |      8324 |
|   8350 |      8350 |
|   8352 |      8350 |
|   8371 |      8371 |
|   8382 |      8382 |
|   8383 |      8383 |
|   8384 |      8383 |
|   8389 |      8319 |
|   8401 |      8401 |
|   8403 |      8414 |
|   8407 |      8407 |
|   8410 |      8407 |
|   8414 |      8414 |
|   8418 |      8418 |
|   8419 |      8418 |
|   8426 |      8401 |
|   8445 |      9226 |
|   8447 |      8447 |
|   8450 |      8382 |
|   8452 |      8447 |
|   8499 |      8499 |
|   8500 |      8500 |
|   8505 |      8500 |
|   8516 |      8516 |
|   8522 |      8904 |
|   8535 |      8602 |
|   8540 |      8540 |
|   8559 |      8499 |
|   8573 |      8573 |
|   8588 |      8540 |
|   8589 |      8573 |
|   8600 |      8601 |
|   8601 |      8601 |
|   8602 |      8602 |
|   8603 |      8603 |
|   8610 |      8611 |
|   8611 |      8611 |
|   8617 |      8619 |
|   8619 |      8619 |
|   8621 |      9214 |
|   8722 |      8722 |
|   8724 |      8722 |
|   8738 |      8872 |
|   8742 |      8742 |
|   8744 |      8742 |
|   8745 |      8746 |
|   8746 |      8746 |
|   8747 |      8747 |
|   8748 |      8747 |
|   8766 |      8766 |
|   8777 |      8777 |
|   8778 |      8777 |
|   8805 |      8805 |
|   8812 |      8812 |
|   8817 |      8817 |
|   8818 |      8817 |
|   8841 |      8841 |
|   8846 |      8841 |
|   8854 |      8854 |
|   8855 |      8854 |
|   8869 |      8870 |
|   8870 |      8870 |
|   8872 |      8872 |
|   8877 |      8877 |
|   8881 |      8877 |
|   8897 |      8927 |
|   8898 |      9153 |
|   8902 |      8903 |
|   8903 |      8903 |
|   8904 |      8904 |
|   8909 |      8909 |
|   8916 |      8917 |
|   8917 |      8917 |
|   8918 |      8918 |
|   8919 |      8909 |
|   8920 |      8918 |
|   8923 |      8923 |
|   8924 |      8923 |
|   8927 |      8927 |
|   8930 |      8930 |
|   8933 |      8934 |
|   8934 |      8934 |
|   8937 |      8937 |
|   8938 |      8937 |
|   8941 |      7940 |
|   8944 |      8944 |
|   8947 |      8930 |
|   8953 |      8977 |
|   8956 |      8956 |
|   8957 |      8980 |
|   8965 |      8965 |
|   8971 |      8965 |
|   8977 |      8977 |
|   8980 |      8980 |
|   8990 |      8990 |
|   8991 |      8990 |
|   8993 |      8993 |
|   8994 |      8993 |
|   9000 |      9003 |
|   9001 |      9001 |
|   9002 |      9001 |
|   9003 |      9003 |
|   9004 |      9004 |
|   9005 |      9004 |
|   9007 |      9008 |
|   9008 |      9008 |
|   9009 |      9009 |
|   9011 |      9011 |
|   9013 |      9013 |
|   9016 |      8956 |
|   9017 |      9011 |
|   9021 |      9009 |
|   9022 |      9022 |
|   9023 |      9023 |
|   9024 |      9025 |
|   9025 |      9025 |
|   9026 |      9022 |
|   9027 |      9027 |
|   9028 |      9027 |
|   9041 |      9047 |
|   9047 |      9047 |
|   9056 |      9056 |
|   9057 |      9056 |
|   9060 |      9013 |
|   9075 |      9075 |
|   9109 |      9109 |
|   9141 |      8805 |
|   9147 |      8123 |
|   9153 |      9153 |
|   9179 |      9179 |
|   9183 |      9183 |
|   9184 |      9184 |
|   9192 |      9192 |
|   9195 |      9195 |
|   9196 |      9291 |
|   9212 |      8812 |
|   9213 |      8603 |
|   9214 |      9214 |
|   9216 |      8303 |
|   9217 |      9217 |
|   9226 |      9226 |
|   9237 |      8371 |
|   9238 |      8334 |
|   9240 |      7440 |
|   9242 |      7454 |
|   9243 |      7430 |
|   9246 |      7260 |
|   9253 |      7786 |
|   9259 |      9023 |
|   9270 |      8944 |
|   9277 |      8766 |
|   9291 |      9291 |
|--------+-----------|

#+begin_src R :session rsession :results output :exports both
#+end_src
** Code for police codes - manual creation
The codes are entered manually twice, exported as csv-files by M-x
org-table-export and compared in R to find errors. 


| All codes of interest |
|-----------------------|
|        *Sexual abuse* |
|               1110505 |
|               1110510 |
|               1110515 |
|               1110516 |
|               1110520 |
|               1110521 |
|               1110525 |
|               1110526 |
|               1110530 |
|               1110531 |
|               1110535 |
|               1110536 |
|               1110540 |
|               1110545 |
|               1120504 |
|               1120505 |
|               1120506 |
|               1120510 |
|               1120511 |
|               1120515 |
|               1120516 |
|               1120519 |
|               1120520 |
|               1120521 |
|               1120525 |
|               1120526 |
|               1120530 |
|               1120531 |
|               1130505 |
|               1130510 |
|               1130515 |
|               1131505 |
|               1131510 |
|               1140505 |
|               1140507 |
|               1140510 |
|               1140515 |
|               1140520 |
|               1140525 |
|               1140530 |
|               1140535 |
|               1140540 |
|               1140545 |
|               1140550 |
|               1140555 |
|               1140560 |
|               1140565 |
|               1141505 |
|               1141510 |
|               1141515 |
|               1145505 |
|               1145510 |
|               1145515 |
|               1145520 |
|               1145525 |
|               1145530 |
|               1145535 |
|               1145540 |
|               1145545 |
|               1145550 |
|               1145555 |
|               1145560 |
|               1145565 |
|               1145570 |
|               1145575 |
|               1150505 |
|               1150510 |
|               1150515 |
|               1160505 |
|               1160510 |
|               1160515 |
|               1160520 |
|               1160525 |
|               1160530 |
|               1172005 |
|               1172010 |
|               1174005 |
|               1174010 |
|               1176005 |
|               1176010 |
|               1176205 |
|               1176605 |
|               1176610 |
|               1176805 |
|               1180505 |
|               1180506 |
|               1180540 |
|               1180541 |
|               1180542 |
|               1180543 |
|               1180544 |
|               1180545 |
|               1180546 |
|               1180547 |
|               1180550 |
|               1180551 |
|                       |
|   *Physical violence* |
|               1230505 |
|               1230705 |
|               1240505 |
|               1252505 |
|               1255305 |
|               1255705 |
|               1255710 |
|               1258305 |
|               1258705 |
|               1260505 |
|               1270305 |
|               1270505 |
|               1270705 |
|               1280305 |
|               1280505 |
|               1280510 |
|               1280705 |
|               1286515 |
|               1289505 |
|               1289705 |
|               1289710 |
|                       |
|    *Psychic violence* |
|               1250505 |
|               1292505 |
|               1292515 |
|               1176405 |
|               1176410 |
|               1366505 |
|               1485510 |
|               1485515 |
|               1485705 |
|               1485710 |
|               1485715 |
|               1485720 |
|               1485725 |
|               1485735 |
|               1485740 |
|                       |
|             *Neglect* |
|               1455520 |
|-----------------------|

| Codes for physical abuse, when directed towards anyone less than 18 years old |
|-------------------------------------------------------------------------------|
|                                                                       1230505 |
|                                                                       1230705 |
|                                                                       1240505 |
|                                                                       1252505 |
|                                                                       1255305 |
|                                                                       1255705 |
|                                                                       1255710 |
|                                                                       1258305 |
|                                                                       1258705 |
|                                                                       1260505 |
|                                                                       1270305 |
|                                                                       1270505 |
|                                                                       1270705 |
|                                                                       1280305 |
|                                                                       1280505 |
|                                                                       1280510 |
|                                                                       1280705 |
|                                                                       1286515 |
|                                                                       1289505 |
|                                                                       1289705 |
|                                                                       1289710 |
|-------------------------------------------------------------------------------|

| Codes for intimate partner violence |
|-------------------------------------|
|                      *Sexual abuse* |
|                             1120504 |
|                             1120505 |
|                             1120506 |
|                             1120510 |
|                             1120511 |
|                             1120515 |
|                             1120516 |
|                             1120519 |
|                             1120520 |
|                             1120521 |
|                             1120525 |
|                             1120526 |
|                             1120530 |
|                             1120531 |
|                             1140505 |
|                             1140507 |
|                             1140510 |
|                             1140515 |
|                             1140525 |
|                             1140530 |
|                             1140535 |
|                             1140540 |
|                             1140545 |
|                             1140550 |
|                             1145510 |
|                             1145515 |
|                             1145525 |
|                             1145535 |
|                             1145545 |
|                             1160510 |
|                             1160515 |
|                             1160520 |
|                             1172005 |
|                             1172010 |
|                             1174005 |
|                             1174010 |
|                             1176005 |
|                             1176010 |
|                             1176205 |
|                             1176605 |
|                             1176610 |
|                             1176805 |
|                             1180505 |
|                             1180506 |
|                                     |
|                 *Physical violence* |
|                             1230505 |
|                             1240505 |
|                             1252505 |
|                             1255305 |
|                             1255705 |
|                             1255710 |
|                             1258305 |
|                             1258705 |
|                             1260505 |
|                             1270305 |
|                             1270505 |
|                             1270705 |
|                             1280305 |
|                             1280505 |
|                             1280510 |
|                             1280705 |
|                             1286515 |
|                             1289505 |
|                             1289705 |
|                             1289710 |
|                                     |
|                  *Psychic violence* |
|                             1250505 |
|                             1292505 |
|                             1292515 |
|                             1176405 |
|                             1176410 |
|                             1366505 |
|                             1485510 |
|                             1485515 |
|                             1485705 |
|                             1485710 |
|                             1485715 |
|                             1485720 |
|                             1485725 |
|                             1485735 |
|                             1485740 |
|-------------------------------------|

| Codes for lethal abuse |
|------------------------|
|                1230505 |
|                1230705 |
|                1258705 |
|------------------------|

Physical abuse, for export: 

| physicalAbusePolice |
|---------------------|
|             1230505 |
|             1230705 |
|             1240505 |
|             1252505 |
|             1255305 |
|             1255705 |
|             1255710 |
|             1258305 |
|             1258705 |
|             1260505 |
|             1270305 |
|             1270505 |
|             1270705 |
|             1280305 |
|             1280505 |
|             1280510 |
|             1280705 |
|             1286515 |
|             1289505 |
|             1289705 |
|             1289710 |
|---------------------|

Interparental violence (IPV) for export:

| policeIPVPartial |
|------------------|
|          1120504 |
|          1120505 |
|          1120506 |
|          1120510 |
|          1120511 |
|          1120515 |
|          1120516 |
|          1120519 |
|          1120520 |
|          1120521 |
|          1120525 |
|          1120526 |
|          1120530 |
|          1120531 |
|          1140505 |
|          1140507 |
|          1140510 |
|          1140515 |
|          1140525 |
|          1140530 |
|          1140535 |
|          1140540 |
|          1140545 |
|          1140550 |
|          1145510 |
|          1145515 |
|          1145525 |
|          1145535 |
|          1145545 |
|          1160510 |
|          1160515 |
|          1160520 |
|          1172005 |
|          1172010 |
|          1174005 |
|          1174010 |
|          1176005 |
|          1176010 |
|          1176205 |
|          1176605 |
|          1176610 |
|          1176805 |
|          1180505 |
|          1180506 |
|          1230505 |
|          1240505 |
|          1252505 |
|          1255305 |
|          1255705 |
|          1255710 |
|          1258305 |
|          1258705 |
|          1260505 |
|          1270305 |
|          1270505 |
|          1270705 |
|          1280305 |
|          1280505 |
|          1280510 |
|          1280705 |
|          1286515 |
|          1289505 |
|          1289705 |
|          1289710 |
|          1250505 |
|          1292505 |
|          1292515 |
|          1176405 |
|          1176410 |
|          1366505 |
|          1485510 |
|          1485515 |
|          1485705 |
|          1485710 |
|          1485715 |
|          1485720 |
|          1485725 |
|          1485735 |
|          1485740 |
|------------------|

For export: 
| policeLethal |
|--------------|
|      1230505 |
|      1230705 |
|      1258705 |
|--------------|

#+begin_src R :session rsession :results output :exports both
  ##This codeblock only needs to be run during the validation of a new list to check for differences between two lists after entering data twice
  ## policeUseful <- fread("tempPoliceCodes1.csv")
  ## comp1 <- policeUseful[ , Code]
  ## temp <- fread("tempPoliceCodes2.csv")
  ## comp2 <- temp[ , Code]
  ## setdiff(comp1 , comp2)
  ## setdiff(comp2 , comp1)
#+end_src
** Code for health codes related to maltreatment - manual creation

| ICD10Diagnosis             |
|----------------------------|
| *Neglect*                  |
| DT740                      |
| DY06                       |
| DY060                      |
| DY061                      |
| DY062                      |
| DY068                      |
| DY069                      |
| EUVK00                     |
| EUVK08                     |
| EUVK                       |
| EUVK0                      |
| EUVK09                     |
| DZ620                      |
| DZ624                      |
|                            |
| *Physical abuse*           |
| DT741                      |
| DX85                       |
| DX859                      |
| DX86                       |
| DX869                      |
| DX87                       |
| DX879                      |
| DX88                       |
| DX889                      |
| DX89                       |
| DX899                      |
| DX90                       |
| DX909                      |
| DX91                       |
| DX919                      |
| DX92                       |
| DX929                      |
| DX93                       |
| DX939                      |
| DX94                       |
| DX949                      |
| DX95                       |
| DX959                      |
| DX96                       |
| DX969                      |
| DX97                       |
| DX979                      |
| DX98                       |
| DX989                      |
| DX99                       |
| DX999                      |
| DY00                       |
| DY009                      |
| DY01                       |
| DY019                      |
| DY02                       |
| DY029                      |
| DY03                       |
| DY039                      |
| DY04                       |
| DY049                      |
| DY871                      |
| DZ616                      |
| EUVA                       |
| EUVA0                      |
| EUVA00                     |
| EUVA01                     |
| EUVA02                     |
| EUVA07                     |
| EUVA08                     |
| EUVA09                     |
| EUVA1                      |
| EUVA10                     |
| EUVA11                     |
| EUVA12                     |
| EUVA13                     |
| EUVA14                     |
| EUVA15                     |
| EUVA17                     |
| EUVA18                     |
| EUVA19                     |
| EUVA2                      |
| EUVA20                     |
| EUVA21                     |
| EUVA22                     |
| EUVA23                     |
| EUVA27                     |
| EUVA28                     |
| EUVA29                     |
| EUVB                       |
| EUVB0                      |
| EUVB00                     |
| EUVB01                     |
| EUVB02                     |
| EUVB04                     |
| EUVB08                     |
| EUVB09                     |
| EUVC                       |
| EUVC0                      |
| EUVC03                     |
| EUVC9                      |
| EUVC98                     |
| EUVC99                     |
| EUVD                       |
| EUVD0                      |
| EUVD03                     |
| EUVD08                     |
| EUVD09                     |
| EUVE                       |
| EUVE0                      |
| EUVE00                     |
| EUVE01                     |
| EUVE02                     |
| EUVE03                     |
| EUVE08                     |
| EUVE09                     |
| EUVG0                      |
| EUVG00                     |
| EUVG01                     |
| EUVG02                     |
| EUVG08                     |
| EUVG09                     |
| EUVJ                       |
| EUVJ0                      |
| EUVJ01                     |
| EUVJ08                     |
| EUVJ09                     |
| EUVZ                       |
| EUVZ9                      |
| EUVZ98                     |
| EUVZ99                     |
| EUN3                       |
|                            |
| *Sexual abuse*             |
| DT742                      |
| DY05                       |
| DY059                      |
| EUVG1                      |
| EUVG10                     |
| EUVG11                     |
| EUVG18                     |
| EUVG19                     |
| DZ614                      |
| DZ615                      |
|                            |
| *Psychological abuse*      |
| DT743                      |
|                            |
| *Munchausen by Proxy*      |
| DT748A                     |
|                            |
| *Unspecified maltreatment* |
| DT749                      |
| DY07                       |
| DY070                      |
| DY071                      |
| DY072                      |
| DY073                      |
| DY078                      |
| DY079                      |
| DY08                       |
| DY089                      |
| DY09                       |
| DY099                      |
| EUVK01                     |
| EUVG                       |
|----------------------------|

For export:
| ICD10Diagnosis |
|----------------|
| DT740          |
| DY06           |
| DY060          |
| DY061          |
| DY062          |
| DY068          |
| DY069          |
| EUVK00         |
| EUVK08         |
| EUVK           |
| EUVK0          |
| EUVK09         |
| DZ620          |
| DZ624          |
| DT741          |
| DX85           |
| DX859          |
| DX86           |
| DX869          |
| DX87           |
| DX879          |
| DX88           |
| DX889          |
| DX89           |
| DX899          |
| DX90           |
| DX909          |
| DX91           |
| DX919          |
| DX92           |
| DX929          |
| DX93           |
| DX939          |
| DX94           |
| DX949          |
| DX95           |
| DX959          |
| DX96           |
| DX969          |
| DX97           |
| DX979          |
| DX98           |
| DX989          |
| DX99           |
| DX999          |
| DY00           |
| DY009          |
| DY01           |
| DY019          |
| DY02           |
| DY029          |
| DY03           |
| DY039          |
| DY04           |
| DY049          |
| DY871          |
| DZ616          |
| EUVA           |
| EUVA0          |
| EUVA00         |
| EUVA01         |
| EUVA02         |
| EUVA07         |
| EUVA08         |
| EUVA09         |
| EUVA1          |
| EUVA10         |
| EUVA11         |
| EUVA12         |
| EUVA13         |
| EUVA14         |
| EUVA15         |
| EUVA17         |
| EUVA18         |
| EUVA19         |
| EUVA2          |
| EUVA20         |
| EUVA21         |
| EUVA22         |
| EUVA23         |
| EUVA27         |
| EUVA28         |
| EUVA29         |
| EUVB           |
| EUVB0          |
| EUVB00         |
| EUVB01         |
| EUVB02         |
| EUVB04         |
| EUVB08         |
| EUVB09         |
| EUVC           |
| EUVC0          |
| EUVC03         |
| EUVC9          |
| EUVC98         |
| EUVC99         |
| EUVD           |
| EUVD0          |
| EUVD03         |
| EUVD08         |
| EUVD09         |
| EUVE           |
| EUVE0          |
| EUVE00         |
| EUVE01         |
| EUVE02         |
| EUVE03         |
| EUVE08         |
| EUVE09         |
| EUVG0          |
| EUVG00         |
| EUVG01         |
| EUVG02         |
| EUVG08         |
| EUVG09         |
| EUVJ           |
| EUVJ0          |
| EUVJ01         |
| EUVJ08         |
| EUVJ09         |
| EUVZ           |
| EUVZ9          |
| EUVZ98         |
| EUVZ99         |
| EUN3           |
| DT742          |
| DY05           |
| DY059          |
| EUVG1          |
| EUVG10         |
| EUVG11         |
| EUVG18         |
| EUVG19         |
| DZ614          |
| DZ615          |
| DT743          |
| DT748A         |
| DT749          |
| DY07           |
| DY070          |
| DY071          |
| DY072          |
| DY073          |
| DY078          |
| DY079          |
| DY08           |
| DY089          |
| DY09           |
| DY099          |
| EUVK01         |
| EUVG           |
|----------------|

Exported as: healthMaltreatment.csv

Also remember c_kontaars == 3
Adult parents indicating childhood abuse during therapy are not
counted here - this is to avoid conditioning on the future, as I
assume committing abuse as an adult might influence recall of abuse.  

#+begin_src R :session rsession :results output :exports both
  ##This codeblock only needs to be run during the validation of a new list to check for differences between two lists after entering data twice
  ## healthMaltreatment <- fread("healthMaltreatment.csv")
  ## tempHealthMaltreatment <- fread("healthMaltreatment1.csv")
  ## all.equal(healthMaltreatment , tempHealthMaltreatment)
  ## ##As some strings were not equal, both datasets were combined in a table and exported (using org-table-transpose-table-at-point):
  ## tempCompareHealthMaltreatment <- fread("healthMaltreatmentCompare.csv")
  ## tempCompareHealthMaltreatment
  ## tempCompareHealthMaltreatment[ICD10Diagnosis != ICD10Diagnosis2 , notEqual := TRUE] 
#+end_src

Adding a section on ICD 8: 

| ICD8Diagnosis |
|---------------|
| E9600         |
| E9609         |
| E9610         |
| E9619         |
| E9620         |
| E9629         |
| E9630         |
| E9639         |
| E9640         |
| E9649         |
| E9650         |
| E9659         |
| E9660         |
| E9669         |
| E9670         |
| E9679         |
| E9680         |
| E9689         |
| E9690         |
| E9699         |
|---------------|

For export of physical abuse:

| *physicalAbuse* |
|-----------------|
| DT741           |
| DX85            |
| DX859           |
| DX86            |
| DX869           |
| DX87            |
| DX879           |
| DX88            |
| DX889           |
| DX89            |
| DX899           |
| DX90            |
| DX909           |
| DX91            |
| DX919           |
| DX92            |
| DX929           |
| DX93            |
| DX939           |
| DX94            |
| DX949           |
| DX95            |
| DX959           |
| DX96            |
| DX969           |
| DX97            |
| DX979           |
| DX98            |
| DX989           |
| DX99            |
| DX999           |
| DY00            |
| DY009           |
| DY01            |
| DY019           |
| DY02            |
| DY029           |
| DY03            |
| DY039           |
| DY04            |
| DY049           |
| DY871           |
| DZ616           |
| EUVA            |
| EUVA0           |
| EUVA00          |
| EUVA01          |
| EUVA02          |
| EUVA07          |
| EUVA08          |
| EUVA09          |
| EUVA1           |
| EUVA10          |
| EUVA11          |
| EUVA12          |
| EUVA13          |
| EUVA14          |
| EUVA15          |
| EUVA17          |
| EUVA18          |
| EUVA19          |
| EUVA2           |
| EUVA20          |
| EUVA21          |
| EUVA22          |
| EUVA23          |
| EUVA27          |
| EUVA28          |
| EUVA29          |
| EUVB            |
| EUVB0           |
| EUVB00          |
| EUVB01          |
| EUVB02          |
| EUVB04          |
| EUVB08          |
| EUVB09          |
| EUVC            |
| EUVC0           |
| EUVC03          |
| EUVC9           |
| EUVC98          |
| EUVC99          |
| EUVD            |
| EUVD0           |
| EUVD03          |
| EUVD08          |
| EUVD09          |
| EUVE            |
| EUVE0           |
| EUVE00          |
| EUVE01          |
| EUVE02          |
| EUVE03          |
| EUVE08          |
| EUVE09          |
| EUVG0           |
| EUVG00          |
| EUVG01          |
| EUVG02          |
| EUVG08          |
| EUVG09          |
| EUVJ            |
| EUVJ0           |
| EUVJ01          |
| EUVJ08          |
| EUVJ09          |
| EUVZ            |
| EUVZ9           |
| EUVZ98          |
| EUVZ99          |
| EUN3            |
|-----------------|


The table was entered twice and then compared using the command org-table-transpose-table-at-point.

** Code for price purchasing power - manual creation
Source: PRIS8, Statistics Denmark

| Year | Value |
|------+-------|
| 1990 |  4251 |
| 1991 |  4353 |
| 1992 |  4445 |
| 1993 |  4500 |
| 1994 |  4590 |
| 1995 |  4686 |
| 1996 |  4785 |
| 1997 |  4890 |
| 1998 |  4980 |
| 1999 |  5104 |
| 2000 |  5253 |
| 2001 |  5377 |
| 2002 |  5507 |
| 2003 |  5622 |
| 2004 |  5687 |
| 2005 |  5790 |
| 2006 |  5900 |
| 2007 |  6001 |
| 2008 |  6205 |
| 2009 |  6287 |
| 2010 |  6432 |
| 2011 |  6609 |
| 2012 |  6768 |
| 2013 |  6821 |
| 2014 |  6860 |
| 2015 |  6891 |
| 2016 |  6909 |
| 2017 |  6988 |
| 2018 |  7045 |
|------+-------|

#+begin_src R :session rsession :results output :exports both
  ##This codeblock only needs to be run during the validation of a new list to check for differences between two lists after entering data twice
  ## purchasingPower <- fread("purchasingPower.csv")
  ## tempPurchasingPower <- fread("purchasingPower1.csv")
  ## all.equal(purchasingPower , tempPurchasingPower)
#+end_src

** Code for mean equivalent disposable income - manual creation
Numbers from IFOR32, Statistics Denmark

| Year | EquivalentIncome |
|------+------------------|
| 1990 |            97856 |
| 1991 |           101831 |
| 1992 |           104950 |
| 1993 |           107399 |
| 1994 |           114589 |
| 1995 |           118698 |
| 1996 |           122295 |
| 1997 |           125938 |
| 1998 |           131121 |
| 1999 |           135022 |
| 2000 |           139554 |
| 2001 |           144273 |
| 2002 |           150513 |
| 2003 |           154880 |
| 2004 |           163447 |
| 2005 |           168260 |
| 2006 |           173475 |
| 2007 |           177868 |
| 2008 |           182478 |
| 2009 |           186859 |
| 2010 |           198711 |
| 2011 |           202048 |
| 2012 |           205633 |
| 2013 |           209384 |
| 2014 |           214412 |
| 2015 |           217580 |
| 2016 |           221437 |
| 2017 |           226804 |
| 2018 |           233247 |
|------+------------------|

#+begin_src R :session rsession :results output :exports both
  ##This codeblock only needs to be run during the validation of a new list to check for differences between two lists after entering data twice
  ## equivalentIncome <- fread("equivalentIncome.csv")
  ## tempEquivalentIncome <- fread("equivalentIncome1.csv")
  ## all.equal(equivalentIncome , tempEquivalentIncome)
#+end_src

** Code for educational levels - formatted from Statistics Denmark pre-coding
This code was taken from a SAS-script and modified with regular
expressions into this table:

| Code | Level | Description               |
|------+-------+---------------------------|
| 0000 |    90 | Not elsewhere classified  |
| 0001 |    10 | Primary                   |
| 0002 |    90 | Not elsewhere classified  |
| 0141 |    50 | Short cycle tertiary      |
| 0144 |    50 | Short cycle tertiary      |
| 0145 |    50 | Short cycle tertiary      |
| 0146 |    50 | Short cycle tertiary      |
| 0148 |    50 | Short cycle tertiary      |
| 0150 |    60 | Bachelor or equivalent    |
| 0151 |    60 | Bachelor or equivalent    |
| 0152 |    60 | Bachelor or equivalent    |
| 0153 |    60 | Bachelor or equivalent    |
| 0154 |    60 | Bachelor or equivalent    |
| 0155 |    60 | Bachelor or equivalent    |
| 0156 |    60 | Bachelor or equivalent    |
| 0159 |    60 | Bachelor or equivalent    |
| 0161 |    60 | Bachelor or equivalent    |
| 0162 |    60 | Bachelor or equivalent    |
| 0163 |    60 | Bachelor or equivalent    |
| 0164 |    60 | Bachelor or equivalent    |
| 0165 |    60 | Bachelor or equivalent    |
| 0167 |    60 | Bachelor or equivalent    |
| 0170 |    70 | Master or equivalent      |
| 0171 |    70 | Master or equivalent      |
| 0172 |    70 | Master or equivalent      |
| 0173 |    70 | Master or equivalent      |
| 0174 |    70 | Master or equivalent      |
| 0175 |    70 | Master or equivalent      |
| 0176 |    70 | Master or equivalent      |
| 0177 |    70 | Master or equivalent      |
| 0179 |    70 | Master or equivalent      |
| 0200 |    10 | Primary                   |
| 0205 |    20 | Lower secondary           |
| 0210 |    20 | Lower secondary           |
| 0215 |    30 | Upper secondary           |
| 0220 |    30 | Upper secondary           |
| 0239 |    30 | Upper secondary           |
| 0253 |    30 | Upper secondary           |
| 0254 |    30 | Upper secondary           |
| 0255 |    30 | Upper secondary           |
| 0258 |    30 | Upper secondary           |
| 0260 |    30 | Upper secondary           |
| 0275 |    30 | Upper secondary           |
| 0280 |    30 | Upper secondary           |
| 0285 |    30 | Upper secondary           |
| 0290 |    30 | Upper secondary           |
| 0300 |    30 | Upper secondary           |
| 0320 |    30 | Upper secondary           |
| 0339 |    30 | Upper secondary           |
| 0353 |    30 | Upper secondary           |
| 0354 |    30 | Upper secondary           |
| 0355 |    30 | Upper secondary           |
| 0358 |    30 | Upper secondary           |
| 0360 |    30 | Upper secondary           |
| 0375 |    30 | Upper secondary           |
| 0380 |    30 | Upper secondary           |
| 0385 |    30 | Upper secondary           |
| 0390 |    30 | Upper secondary           |
| 0400 |    50 | Short cycle tertiary      |
| 0425 |    50 | Short cycle tertiary      |
| 0430 |    50 | Short cycle tertiary      |
| 0439 |    50 | Short cycle tertiary      |
| 0459 |    50 | Short cycle tertiary      |
| 0475 |    50 | Short cycle tertiary      |
| 0480 |    50 | Short cycle tertiary      |
| 0485 |    50 | Short cycle tertiary      |
| 0490 |    50 | Short cycle tertiary      |
| 0495 |    50 | Short cycle tertiary      |
| 0500 |    60 | Bachelor or equivalent    |
| 0520 |    60 | Bachelor or equivalent    |
| 0525 |    60 | Bachelor or equivalent    |
| 0530 |    60 | Bachelor or equivalent    |
| 0539 |    60 | Bachelor or equivalent    |
| 0545 |    60 | Bachelor or equivalent    |
| 0559 |    60 | Bachelor or equivalent    |
| 0575 |    60 | Bachelor or equivalent    |
| 0580 |    60 | Bachelor or equivalent    |
| 0585 |    60 | Bachelor or equivalent    |
| 0590 |    60 | Bachelor or equivalent    |
| 0595 |    60 | Bachelor or equivalent    |
| 0600 |    70 | Master or equivalent      |
| 0620 |    70 | Master or equivalent      |
| 0625 |    70 | Master or equivalent      |
| 0630 |    70 | Master or equivalent      |
| 0639 |    70 | Master or equivalent      |
| 0645 |    70 | Master or equivalent      |
| 0659 |    70 | Master or equivalent      |
| 0675 |    70 | Master or equivalent      |
| 0680 |    70 | Master or equivalent      |
| 0690 |    70 | Master or equivalent      |
| 0695 |    70 | Master or equivalent      |
| 0700 |    60 | Bachelor or equivalent    |
| 0702 |    60 | Bachelor or equivalent    |
| 0703 |    60 | Bachelor or equivalent    |
| 0704 |    60 | Bachelor or equivalent    |
| 0705 |    60 | Bachelor or equivalent    |
| 0706 |    60 | Bachelor or equivalent    |
| 0707 |    60 | Bachelor or equivalent    |
| 0708 |    60 | Bachelor or equivalent    |
| 0709 |    60 | Bachelor or equivalent    |
| 0720 |    80 | Doctoral or equivalent    |
| 0721 |    80 | Doctoral or equivalent    |
| 0722 |    80 | Doctoral or equivalent    |
| 0723 |    80 | Doctoral or equivalent    |
| 0724 |    80 | Doctoral or equivalent    |
| 0725 |    80 | Doctoral or equivalent    |
| 0726 |    80 | Doctoral or equivalent    |
| 0728 |    80 | Doctoral or equivalent    |
| 0729 |    80 | Doctoral or equivalent    |
| 0800 |    50 | Short cycle tertiary      |
| 0802 |    60 | Bachelor or equivalent    |
| 0803 |    50 | Short cycle tertiary      |
| 0805 |    30 | Upper secondary           |
| 0806 |    50 | Short cycle tertiary      |
| 0807 |    50 | Short cycle tertiary      |
| 0810 |    60 | Bachelor or equivalent    |
| 0811 |    50 | Short cycle tertiary      |
| 0812 |    30 | Upper secondary           |
| 0815 |    60 | Bachelor or equivalent    |
| 0816 |    50 | Short cycle tertiary      |
| 0820 |    30 | Upper secondary           |
| 0825 |    30 | Upper secondary           |
| 0835 |    50 | Short cycle tertiary      |
| 0840 |    60 | Bachelor or equivalent    |
| 0845 |    30 | Upper secondary           |
| 0850 |    30 | Upper secondary           |
| 0990 |    70 | Master or equivalent      |
| 1006 |    10 | Primary                   |
| 1007 |    20 | Lower secondary           |
| 1008 |    20 | Lower secondary           |
| 1009 |    20 | Lower secondary           |
| 1010 |    20 | Lower secondary           |
| 1011 |    20 | Lower secondary           |
| 1021 |    20 | Lower secondary           |
| 1022 |    20 | Lower secondary           |
| 1023 |    20 | Lower secondary           |
| 1031 |    30 | Upper secondary           |
| 1032 |    30 | Upper secondary           |
| 1040 |    30 | Upper secondary           |
| 1041 |    30 | Upper secondary           |
| 1042 |    30 | Upper secondary           |
| 1049 |    30 | Upper secondary           |
| 1051 |    30 | Upper secondary           |
| 1052 |    30 | Upper secondary           |
| 1061 |    30 | Upper secondary           |
| 1062 |    30 | Upper secondary           |
| 1064 |    30 | Upper secondary           |
| 1069 |    30 | Upper secondary           |
| 1070 |    30 | Upper secondary           |
| 1071 |    30 | Upper secondary           |
| 1072 |    30 | Upper secondary           |
| 1073 |    30 | Upper secondary           |
| 1080 |    30 | Upper secondary           |
| 1081 |    30 | Upper secondary           |
| 1082 |    30 | Upper secondary           |
| 1083 |    30 | Upper secondary           |
| 1084 |    30 | Upper secondary           |
| 1090 |    90 | Not elsewhere classified  |
| 1095 |    90 | Not elsewhere classified  |
| 1097 |    30 | Upper secondary           |
| 1098 |    30 | Upper secondary           |
| 1099 |    90 | Not elsewhere classified  |
| 1100 |    10 | Primary                   |
| 1101 |    10 | Primary                   |
| 1102 |    10 | Primary                   |
| 1103 |    10 | Primary                   |
| 1104 |    10 | Primary                   |
| 1105 |    10 | Primary                   |
| 1106 |    10 | Primary                   |
| 1107 |    20 | Lower secondary           |
| 1108 |    20 | Lower secondary           |
| 1109 |    20 | Lower secondary           |
| 1110 |    20 | Lower secondary           |
| 1111 |    20 | Lower secondary           |
| 1120 |    10 | Primary                   |
| 1121 |    20 | Lower secondary           |
| 1122 |    20 | Lower secondary           |
| 1123 |    20 | Lower secondary           |
| 1140 |    30 | Upper secondary           |
| 1141 |    30 | Upper secondary           |
| 1142 |    30 | Upper secondary           |
| 1143 |    30 | Upper secondary           |
| 1144 |    30 | Upper secondary           |
| 1145 |    30 | Upper secondary           |
| 1146 |    30 | Upper secondary           |
| 1149 |    30 | Upper secondary           |
| 1151 |    30 | Upper secondary           |
| 1152 |    30 | Upper secondary           |
| 1153 |    30 | Upper secondary           |
| 1154 |    30 | Upper secondary           |
| 1155 |    30 | Upper secondary           |
| 1161 |    30 | Upper secondary           |
| 1162 |    30 | Upper secondary           |
| 1163 |    30 | Upper secondary           |
| 1164 |    30 | Upper secondary           |
| 1165 |    30 | Upper secondary           |
| 1169 |    30 | Upper secondary           |
| 1171 |    30 | Upper secondary           |
| 1172 |    30 | Upper secondary           |
| 1173 |    30 | Upper secondary           |
| 1174 |    30 | Upper secondary           |
| 1175 |    30 | Upper secondary           |
| 1179 |    30 | Upper secondary           |
| 1181 |    30 | Upper secondary           |
| 1182 |    30 | Upper secondary           |
| 1183 |    30 | Upper secondary           |
| 1184 |    30 | Upper secondary           |
| 1185 |    30 | Upper secondary           |
| 1189 |    30 | Upper secondary           |
| 1190 |    30 | Upper secondary           |
| 1195 |    30 | Upper secondary           |
| 1196 |    30 | Upper secondary           |
| 1197 |    30 | Upper secondary           |
| 1198 |    30 | Upper secondary           |
| 1199 |    30 | Upper secondary           |
| 1206 |    10 | Primary                   |
| 1207 |    20 | Lower secondary           |
| 1208 |    20 | Lower secondary           |
| 1209 |    20 | Lower secondary           |
| 1210 |    20 | Lower secondary           |
| 1301 |    20 | Lower secondary           |
| 1302 |    20 | Lower secondary           |
| 1303 |    20 | Lower secondary           |
| 1304 |    30 | Upper secondary           |
| 1305 |    20 | Lower secondary           |
| 1351 |    20 | Lower secondary           |
| 1352 |    20 | Lower secondary           |
| 1353 |    20 | Lower secondary           |
| 1354 |    20 | Lower secondary           |
| 1355 |    20 | Lower secondary           |
| 1356 |    20 | Lower secondary           |
| 1357 |    20 | Lower secondary           |
| 1359 |    20 | Lower secondary           |
| 1365 |    30 | Upper secondary           |
| 1410 |    20 | Lower secondary           |
| 1423 |    20 | Lower secondary           |
| 1509 |    20 | Lower secondary           |
| 1510 |    20 | Lower secondary           |
| 1511 |    30 | Upper secondary           |
| 1522 |    20 | Lower secondary           |
| 1523 |    20 | Lower secondary           |
| 1531 |    30 | Upper secondary           |
| 1532 |    30 | Upper secondary           |
| 1533 |    30 | Upper secondary           |
| 1535 |    30 | Upper secondary           |
| 1536 |    30 | Upper secondary           |
| 1537 |    30 | Upper secondary           |
| 1539 |    30 | Upper secondary           |
| 1540 |    30 | Upper secondary           |
| 1541 |    30 | Upper secondary           |
| 1542 |    30 | Upper secondary           |
| 1543 |    30 | Upper secondary           |
| 1549 |    30 | Upper secondary           |
| 1551 |    30 | Upper secondary           |
| 1552 |    30 | Upper secondary           |
| 1553 |    30 | Upper secondary           |
| 1555 |    30 | Upper secondary           |
| 1559 |    30 | Upper secondary           |
| 1561 |    30 | Upper secondary           |
| 1562 |    30 | Upper secondary           |
| 1563 |    30 | Upper secondary           |
| 1565 |    30 | Upper secondary           |
| 1569 |    30 | Upper secondary           |
| 1650 |    30 | Upper secondary           |
| 1651 |    30 | Upper secondary           |
| 1652 |    30 | Upper secondary           |
| 1671 |    30 | Upper secondary           |
| 1672 |    30 | Upper secondary           |
| 1673 |    30 | Upper secondary           |
| 1679 |    30 | Upper secondary           |
| 1681 |    30 | Upper secondary           |
| 1682 |    30 | Upper secondary           |
| 1683 |    30 | Upper secondary           |
| 1689 |    30 | Upper secondary           |
| 1721 |    20 | Lower secondary           |
| 1722 |    20 | Lower secondary           |
| 1723 |    20 | Lower secondary           |
| 1879 |    30 | Upper secondary           |
| 1881 |    30 | Upper secondary           |
| 1882 |    30 | Upper secondary           |
| 1883 |    30 | Upper secondary           |
| 1889 |    30 | Upper secondary           |
| 1891 |    30 | Upper secondary           |
| 1892 |    30 | Upper secondary           |
| 1893 |    30 | Upper secondary           |
| 1896 |    30 | Upper secondary           |
| 1897 |    30 | Upper secondary           |
| 1898 |    30 | Upper secondary           |
| 1899 |    30 | Upper secondary           |
| 1901 |    20 | Lower secondary           |
| 1984 |    05 | Early childhood education |
| 1985 |    05 | Early childhood education |
| 2003 |    30 | Upper secondary           |
| 2005 |    30 | Upper secondary           |
| 2007 |    30 | Upper secondary           |
| 2008 |    30 | Upper secondary           |
| 2009 |    30 | Upper secondary           |
| 2010 |    30 | Upper secondary           |
| 2015 |    30 | Upper secondary           |
| 2016 |    30 | Upper secondary           |
| 2017 |    30 | Upper secondary           |
| 2018 |    30 | Upper secondary           |
| 2019 |    30 | Upper secondary           |
| 2021 |    30 | Upper secondary           |
| 2022 |    30 | Upper secondary           |
| 2027 |    30 | Upper secondary           |
| 2028 |    30 | Upper secondary           |
| 2029 |    60 | Bachelor or equivalent    |
| 2401 |    20 | Lower secondary           |
| 2411 |    20 | Lower secondary           |
| 2413 |    20 | Lower secondary           |
| 2414 |    50 | Short cycle tertiary      |
| 2415 |    20 | Lower secondary           |
| 2417 |    20 | Lower secondary           |
| 2419 |    30 | Upper secondary           |
| 2421 |    20 | Lower secondary           |
| 2425 |    30 | Upper secondary           |
| 2428 |    20 | Lower secondary           |
| 2431 |    20 | Lower secondary           |
| 2432 |    20 | Lower secondary           |
| 2441 |    20 | Lower secondary           |
| 2442 |    20 | Lower secondary           |
| 2443 |    20 | Lower secondary           |
| 2444 |    20 | Lower secondary           |
| 2445 |    20 | Lower secondary           |
| 2446 |    20 | Lower secondary           |
| 2447 |    20 | Lower secondary           |
| 2459 |    30 | Upper secondary           |
| 2460 |    30 | Upper secondary           |
| 2461 |    30 | Upper secondary           |
| 2462 |    30 | Upper secondary           |
| 2463 |    50 | Short cycle tertiary      |
| 2464 |    50 | Short cycle tertiary      |
| 2465 |    50 | Short cycle tertiary      |
| 2466 |    50 | Short cycle tertiary      |
| 2467 |    50 | Short cycle tertiary      |
| 2468 |    50 | Short cycle tertiary      |
| 2469 |    30 | Upper secondary           |
| 2470 |    30 | Upper secondary           |
| 2471 |    30 | Upper secondary           |
| 2472 |    20 | Lower secondary           |
| 2473 |    30 | Upper secondary           |
| 2475 |    50 | Short cycle tertiary      |
| 2476 |    30 | Upper secondary           |
| 2477 |    30 | Upper secondary           |
| 2478 |    30 | Upper secondary           |
| 2479 |    30 | Upper secondary           |
| 2480 |    30 | Upper secondary           |
| 2481 |    30 | Upper secondary           |
| 2483 |    30 | Upper secondary           |
| 2484 |    30 | Upper secondary           |
| 2485 |    30 | Upper secondary           |
| 2486 |    30 | Upper secondary           |
| 2487 |    30 | Upper secondary           |
| 2488 |    30 | Upper secondary           |
| 2489 |    30 | Upper secondary           |
| 2490 |    30 | Upper secondary           |
| 2491 |    30 | Upper secondary           |
| 2492 |    30 | Upper secondary           |
| 2493 |    30 | Upper secondary           |
| 2494 |    30 | Upper secondary           |
| 2495 |    30 | Upper secondary           |
| 2508 |    20 | Lower secondary           |
| 2509 |    20 | Lower secondary           |
| 2510 |    20 | Lower secondary           |
| 2511 |    20 | Lower secondary           |
| 2530 |    30 | Upper secondary           |
| 2900 |    30 | Upper secondary           |
| 2901 |    30 | Upper secondary           |
| 2902 |    30 | Upper secondary           |
| 2903 |    30 | Upper secondary           |
| 2904 |    30 | Upper secondary           |
| 2905 |    30 | Upper secondary           |
| 2906 |    30 | Upper secondary           |
| 2907 |    30 | Upper secondary           |
| 2908 |    30 | Upper secondary           |
| 2909 |    30 | Upper secondary           |
| 2910 |    30 | Upper secondary           |
| 2911 |    30 | Upper secondary           |
| 2912 |    30 | Upper secondary           |
| 2913 |    30 | Upper secondary           |
| 2914 |    30 | Upper secondary           |
| 2915 |    30 | Upper secondary           |
| 2916 |    30 | Upper secondary           |
| 2917 |    30 | Upper secondary           |
| 2918 |    30 | Upper secondary           |
| 2919 |    30 | Upper secondary           |
| 2920 |    30 | Upper secondary           |
| 2921 |    30 | Upper secondary           |
| 2922 |    30 | Upper secondary           |
| 2923 |    30 | Upper secondary           |
| 2924 |    30 | Upper secondary           |
| 2925 |    30 | Upper secondary           |
| 2926 |    30 | Upper secondary           |
| 2950 |    30 | Upper secondary           |
| 2951 |    30 | Upper secondary           |
| 2952 |    30 | Upper secondary           |
| 2953 |    30 | Upper secondary           |
| 2954 |    30 | Upper secondary           |
| 2955 |    30 | Upper secondary           |
| 2956 |    30 | Upper secondary           |
| 2957 |    30 | Upper secondary           |
| 2958 |    30 | Upper secondary           |
| 2959 |    30 | Upper secondary           |
| 2960 |    30 | Upper secondary           |
| 2961 |    30 | Upper secondary           |
| 2969 |    30 | Upper secondary           |
| 2970 |    30 | Upper secondary           |
| 2971 |    30 | Upper secondary           |
| 2972 |    30 | Upper secondary           |
| 2973 |    30 | Upper secondary           |
| 2974 |    30 | Upper secondary           |
| 2975 |    30 | Upper secondary           |
| 2976 |    30 | Upper secondary           |
| 2977 |    30 | Upper secondary           |
| 2978 |    30 | Upper secondary           |
| 2979 |    30 | Upper secondary           |
| 2980 |    30 | Upper secondary           |
| 2981 |    30 | Upper secondary           |
| 2982 |    30 | Upper secondary           |
| 2983 |    30 | Upper secondary           |
| 2984 |    30 | Upper secondary           |
| 2985 |    30 | Upper secondary           |
| 2986 |    30 | Upper secondary           |
| 2990 |    30 | Upper secondary           |
| 2991 |    30 | Upper secondary           |
| 2992 |    30 | Upper secondary           |
| 3000 |    70 | Master or equivalent      |
| 3001 |    70 | Master or equivalent      |
| 3002 |    70 | Master or equivalent      |
| 3003 |    70 | Master or equivalent      |
| 3004 |    70 | Master or equivalent      |
| 3005 |    70 | Master or equivalent      |
| 3006 |    60 | Bachelor or equivalent    |
| 3007 |    60 | Bachelor or equivalent    |
| 3008 |    60 | Bachelor or equivalent    |
| 3009 |    60 | Bachelor or equivalent    |
| 3010 |    60 | Bachelor or equivalent    |
| 3011 |    60 | Bachelor or equivalent    |
| 3012 |    60 | Bachelor or equivalent    |
| 3013 |    60 | Bachelor or equivalent    |
| 3014 |    60 | Bachelor or equivalent    |
| 3015 |    60 | Bachelor or equivalent    |
| 3016 |    60 | Bachelor or equivalent    |
| 3017 |    60 | Bachelor or equivalent    |
| 3018 |    60 | Bachelor or equivalent    |
| 3019 |    60 | Bachelor or equivalent    |
| 3020 |    70 | Master or equivalent      |
| 3021 |    70 | Master or equivalent      |
| 3022 |    60 | Bachelor or equivalent    |
| 3023 |    60 | Bachelor or equivalent    |
| 3024 |    70 | Master or equivalent      |
| 3025 |    60 | Bachelor or equivalent    |
| 3026 |    60 | Bachelor or equivalent    |
| 3027 |    60 | Bachelor or equivalent    |
| 3028 |    70 | Master or equivalent      |
| 3029 |    70 | Master or equivalent      |
| 3030 |    70 | Master or equivalent      |
| 3031 |    70 | Master or equivalent      |
| 3032 |    60 | Bachelor or equivalent    |
| 3033 |    70 | Master or equivalent      |
| 3034 |    60 | Bachelor or equivalent    |
| 3035 |    70 | Master or equivalent      |
| 3036 |    60 | Bachelor or equivalent    |
| 3037 |    60 | Bachelor or equivalent    |
| 3038 |    60 | Bachelor or equivalent    |
| 3039 |    60 | Bachelor or equivalent    |
| 3040 |    70 | Master or equivalent      |
| 3041 |    60 | Bachelor or equivalent    |
| 3042 |    70 | Master or equivalent      |
| 3043 |    60 | Bachelor or equivalent    |
| 3044 |    30 | Upper secondary           |
| 3045 |    60 | Bachelor or equivalent    |
| 3046 |    70 | Master or equivalent      |
| 3047 |    70 | Master or equivalent      |
| 3048 |    70 | Master or equivalent      |
| 3049 |    70 | Master or equivalent      |
| 3050 |    70 | Master or equivalent      |
| 3051 |    70 | Master or equivalent      |
| 3052 |    70 | Master or equivalent      |
| 3053 |    60 | Bachelor or equivalent    |
| 3054 |    70 | Master or equivalent      |
| 3055 |    60 | Bachelor or equivalent    |
| 3056 |    60 | Bachelor or equivalent    |
| 3057 |    70 | Master or equivalent      |
| 3058 |    70 | Master or equivalent      |
| 3059 |    70 | Master or equivalent      |
| 3060 |    70 | Master or equivalent      |
| 3061 |    70 | Master or equivalent      |
| 3062 |    60 | Bachelor or equivalent    |
| 3063 |    70 | Master or equivalent      |
| 3064 |    60 | Bachelor or equivalent    |
| 3065 |    60 | Bachelor or equivalent    |
| 3066 |    60 | Bachelor or equivalent    |
| 3067 |    70 | Master or equivalent      |
| 3068 |    60 | Bachelor or equivalent    |
| 3069 |    70 | Master or equivalent      |
| 3070 |    70 | Master or equivalent      |
| 3071 |    60 | Bachelor or equivalent    |
| 3072 |    60 | Bachelor or equivalent    |
| 3073 |    60 | Bachelor or equivalent    |
| 3074 |    60 | Bachelor or equivalent    |
| 3075 |    70 | Master or equivalent      |
| 3076 |    70 | Master or equivalent      |
| 3077 |    70 | Master or equivalent      |
| 3078 |    70 | Master or equivalent      |
| 3079 |    70 | Master or equivalent      |
| 3080 |    60 | Bachelor or equivalent    |
| 3081 |    70 | Master or equivalent      |
| 3082 |    70 | Master or equivalent      |
| 3083 |    60 | Bachelor or equivalent    |
| 3084 |    60 | Bachelor or equivalent    |
| 3085 |    70 | Master or equivalent      |
| 3086 |    70 | Master or equivalent      |
| 3087 |    60 | Bachelor or equivalent    |
| 3088 |    60 | Bachelor or equivalent    |
| 3089 |    60 | Bachelor or equivalent    |
| 3090 |    60 | Bachelor or equivalent    |
| 3091 |    70 | Master or equivalent      |
| 3092 |    70 | Master or equivalent      |
| 3093 |    70 | Master or equivalent      |
| 3094 |    60 | Bachelor or equivalent    |
| 3095 |    70 | Master or equivalent      |
| 3096 |    70 | Master or equivalent      |
| 3097 |    60 | Bachelor or equivalent    |
| 3098 |    70 | Master or equivalent      |
| 3099 |    70 | Master or equivalent      |
| 3100 |    60 | Bachelor or equivalent    |
| 3101 |    70 | Master or equivalent      |
| 3102 |    70 | Master or equivalent      |
| 3103 |    70 | Master or equivalent      |
| 3104 |    70 | Master or equivalent      |
| 3105 |    60 | Bachelor or equivalent    |
| 3106 |    70 | Master or equivalent      |
| 3107 |    70 | Master or equivalent      |
| 3108 |    70 | Master or equivalent      |
| 3109 |    70 | Master or equivalent      |
| 3110 |    70 | Master or equivalent      |
| 3111 |    70 | Master or equivalent      |
| 3112 |    70 | Master or equivalent      |
| 3113 |    70 | Master or equivalent      |
| 3114 |    70 | Master or equivalent      |
| 3115 |    70 | Master or equivalent      |
| 3116 |    60 | Bachelor or equivalent    |
| 3117 |    70 | Master or equivalent      |
| 3118 |    70 | Master or equivalent      |
| 3119 |    70 | Master or equivalent      |
| 3120 |    70 | Master or equivalent      |
| 3121 |    60 | Bachelor or equivalent    |
| 3122 |    60 | Bachelor or equivalent    |
| 3123 |    70 | Master or equivalent      |
| 3124 |    60 | Bachelor or equivalent    |
| 3125 |    70 | Master or equivalent      |
| 3126 |    70 | Master or equivalent      |
| 3127 |    70 | Master or equivalent      |
| 3128 |    70 | Master or equivalent      |
| 3129 |    70 | Master or equivalent      |
| 3130 |    70 | Master or equivalent      |
| 3131 |    70 | Master or equivalent      |
| 3132 |    70 | Master or equivalent      |
| 3133 |    70 | Master or equivalent      |
| 3134 |    70 | Master or equivalent      |
| 3135 |    30 | Upper secondary           |
| 3136 |    70 | Master or equivalent      |
| 3137 |    70 | Master or equivalent      |
| 3138 |    70 | Master or equivalent      |
| 3139 |    70 | Master or equivalent      |
| 3140 |    70 | Master or equivalent      |
| 3141 |    70 | Master or equivalent      |
| 3142 |    70 | Master or equivalent      |
| 3143 |    70 | Master or equivalent      |
| 3144 |    70 | Master or equivalent      |
| 3145 |    70 | Master or equivalent      |
| 3146 |    70 | Master or equivalent      |
| 3147 |    70 | Master or equivalent      |
| 3148 |    60 | Bachelor or equivalent    |
| 3149 |    70 | Master or equivalent      |
| 3150 |    70 | Master or equivalent      |
| 3151 |    70 | Master or equivalent      |
| 3152 |    70 | Master or equivalent      |
| 3153 |    70 | Master or equivalent      |
| 3154 |    60 | Bachelor or equivalent    |
| 3155 |    70 | Master or equivalent      |
| 3156 |    70 | Master or equivalent      |
| 3157 |    70 | Master or equivalent      |
| 3158 |    70 | Master or equivalent      |
| 3159 |    30 | Upper secondary           |
| 3160 |    70 | Master or equivalent      |
| 3161 |    70 | Master or equivalent      |
| 3162 |    60 | Bachelor or equivalent    |
| 3163 |    70 | Master or equivalent      |
| 3164 |    70 | Master or equivalent      |
| 3165 |    70 | Master or equivalent      |
| 3166 |    60 | Bachelor or equivalent    |
| 3167 |    70 | Master or equivalent      |
| 3168 |    70 | Master or equivalent      |
| 3169 |    70 | Master or equivalent      |
| 3170 |    70 | Master or equivalent      |
| 3171 |    60 | Bachelor or equivalent    |
| 3172 |    60 | Bachelor or equivalent    |
| 3173 |    70 | Master or equivalent      |
| 3174 |    70 | Master or equivalent      |
| 3175 |    30 | Upper secondary           |
| 3176 |    70 | Master or equivalent      |
| 3177 |    60 | Bachelor or equivalent    |
| 3178 |    60 | Bachelor or equivalent    |
| 3179 |    60 | Bachelor or equivalent    |
| 3180 |    60 | Bachelor or equivalent    |
| 3181 |    30 | Upper secondary           |
| 3182 |    60 | Bachelor or equivalent    |
| 3183 |    60 | Bachelor or equivalent    |
| 3184 |    60 | Bachelor or equivalent    |
| 3185 |    60 | Bachelor or equivalent    |
| 3186 |    60 | Bachelor or equivalent    |
| 3187 |    60 | Bachelor or equivalent    |
| 3188 |    60 | Bachelor or equivalent    |
| 3189 |    60 | Bachelor or equivalent    |
| 3190 |    60 | Bachelor or equivalent    |
| 3191 |    60 | Bachelor or equivalent    |
| 3192 |    60 | Bachelor or equivalent    |
| 3193 |    60 | Bachelor or equivalent    |
| 3194 |    60 | Bachelor or equivalent    |
| 3195 |    60 | Bachelor or equivalent    |
| 3196 |    60 | Bachelor or equivalent    |
| 3197 |    60 | Bachelor or equivalent    |
| 3198 |    60 | Bachelor or equivalent    |
| 3199 |    60 | Bachelor or equivalent    |
| 3200 |    60 | Bachelor or equivalent    |
| 3201 |    60 | Bachelor or equivalent    |
| 3202 |    60 | Bachelor or equivalent    |
| 3203 |    60 | Bachelor or equivalent    |
| 3204 |    60 | Bachelor or equivalent    |
| 3205 |    60 | Bachelor or equivalent    |
| 3206 |    60 | Bachelor or equivalent    |
| 3207 |    70 | Master or equivalent      |
| 3208 |    50 | Short cycle tertiary      |
| 3209 |    60 | Bachelor or equivalent    |
| 3210 |    50 | Short cycle tertiary      |
| 3211 |    60 | Bachelor or equivalent    |
| 3212 |    60 | Bachelor or equivalent    |
| 3213 |    70 | Master or equivalent      |
| 3214 |    70 | Master or equivalent      |
| 3215 |    70 | Master or equivalent      |
| 3216 |    70 | Master or equivalent      |
| 3217 |    60 | Bachelor or equivalent    |
| 3219 |    60 | Bachelor or equivalent    |
| 3220 |    60 | Bachelor or equivalent    |
| 3221 |    60 | Bachelor or equivalent    |
| 3222 |    70 | Master or equivalent      |
| 3223 |    60 | Bachelor or equivalent    |
| 3224 |    70 | Master or equivalent      |
| 3225 |    30 | Upper secondary           |
| 3226 |    30 | Upper secondary           |
| 3227 |    30 | Upper secondary           |
| 3228 |    30 | Upper secondary           |
| 3229 |    30 | Upper secondary           |
| 3230 |    60 | Bachelor or equivalent    |
| 3231 |    30 | Upper secondary           |
| 3232 |    30 | Upper secondary           |
| 3233 |    30 | Upper secondary           |
| 3234 |    30 | Upper secondary           |
| 3235 |    30 | Upper secondary           |
| 3236 |    30 | Upper secondary           |
| 3237 |    30 | Upper secondary           |
| 3238 |    30 | Upper secondary           |
| 3239 |    30 | Upper secondary           |
| 3240 |    30 | Upper secondary           |
| 3241 |    30 | Upper secondary           |
| 3242 |    30 | Upper secondary           |
| 3243 |    30 | Upper secondary           |
| 3244 |    30 | Upper secondary           |
| 3245 |    30 | Upper secondary           |
| 3246 |    30 | Upper secondary           |
| 3247 |    30 | Upper secondary           |
| 3248 |    30 | Upper secondary           |
| 3249 |    30 | Upper secondary           |
| 3250 |    30 | Upper secondary           |
| 3251 |    30 | Upper secondary           |
| 3252 |    30 | Upper secondary           |
| 3253 |    30 | Upper secondary           |
| 3254 |    30 | Upper secondary           |
| 3255 |    30 | Upper secondary           |
| 3256 |    30 | Upper secondary           |
| 3257 |    30 | Upper secondary           |
| 3258 |    30 | Upper secondary           |
| 3259 |    30 | Upper secondary           |
| 3260 |    30 | Upper secondary           |
| 3261 |    60 | Bachelor or equivalent    |
| 3262 |    30 | Upper secondary           |
| 3263 |    30 | Upper secondary           |
| 3264 |    30 | Upper secondary           |
| 3265 |    30 | Upper secondary           |
| 3266 |    30 | Upper secondary           |
| 3267 |    30 | Upper secondary           |
| 3268 |    30 | Upper secondary           |
| 3269 |    30 | Upper secondary           |
| 3270 |    30 | Upper secondary           |
| 3271 |    30 | Upper secondary           |
| 3272 |    60 | Bachelor or equivalent    |
| 3273 |    70 | Master or equivalent      |
| 3274 |    60 | Bachelor or equivalent    |
| 3275 |    30 | Upper secondary           |
| 3276 |    60 | Bachelor or equivalent    |
| 3277 |    60 | Bachelor or equivalent    |
| 3278 |    60 | Bachelor or equivalent    |
| 3279 |    60 | Bachelor or equivalent    |
| 3280 |    60 | Bachelor or equivalent    |
| 3281 |    30 | Upper secondary           |
| 3282 |    60 | Bachelor or equivalent    |
| 3283 |    60 | Bachelor or equivalent    |
| 3284 |    60 | Bachelor or equivalent    |
| 3285 |    30 | Upper secondary           |
| 3286 |    60 | Bachelor or equivalent    |
| 3287 |    30 | Upper secondary           |
| 3288 |    60 | Bachelor or equivalent    |
| 3289 |    60 | Bachelor or equivalent    |
| 3290 |    60 | Bachelor or equivalent    |
| 3291 |    30 | Upper secondary           |
| 3292 |    30 | Upper secondary           |
| 3293 |    30 | Upper secondary           |
| 3294 |    30 | Upper secondary           |
| 3295 |    30 | Upper secondary           |
| 3296 |    30 | Upper secondary           |
| 3297 |    30 | Upper secondary           |
| 3298 |    30 | Upper secondary           |
| 3299 |    30 | Upper secondary           |
| 3300 |    30 | Upper secondary           |
| 3301 |    30 | Upper secondary           |
| 3302 |    30 | Upper secondary           |
| 3303 |    30 | Upper secondary           |
| 3304 |    60 | Bachelor or equivalent    |
| 3305 |    50 | Short cycle tertiary      |
| 3306 |    50 | Short cycle tertiary      |
| 3307 |    70 | Master or equivalent      |
| 3308 |    70 | Master or equivalent      |
| 3309 |    70 | Master or equivalent      |
| 3310 |    70 | Master or equivalent      |
| 3311 |    70 | Master or equivalent      |
| 3312 |    70 | Master or equivalent      |
| 3313 |    70 | Master or equivalent      |
| 3314 |    70 | Master or equivalent      |
| 3315 |    70 | Master or equivalent      |
| 3316 |    60 | Bachelor or equivalent    |
| 3317 |    70 | Master or equivalent      |
| 3318 |    70 | Master or equivalent      |
| 3319 |    20 | Lower secondary           |
| 3320 |    50 | Short cycle tertiary      |
| 3321 |    60 | Bachelor or equivalent    |
| 3322 |    60 | Bachelor or equivalent    |
| 3323 |    30 | Upper secondary           |
| 3324 |    30 | Upper secondary           |
| 3325 |    30 | Upper secondary           |
| 3326 |    70 | Master or equivalent      |
| 3327 |    60 | Bachelor or equivalent    |
| 3329 |    60 | Bachelor or equivalent    |
| 3330 |    70 | Master or equivalent      |
| 3331 |    70 | Master or equivalent      |
| 3332 |    70 | Master or equivalent      |
| 3333 |    60 | Bachelor or equivalent    |
| 3334 |    70 | Master or equivalent      |
| 3335 |    60 | Bachelor or equivalent    |
| 3336 |    70 | Master or equivalent      |
| 3337 |    70 | Master or equivalent      |
| 3339 |    60 | Bachelor or equivalent    |
| 3340 |    70 | Master or equivalent      |
| 3341 |    70 | Master or equivalent      |
| 3342 |    60 | Bachelor or equivalent    |
| 3343 |    60 | Bachelor or equivalent    |
| 3344 |    70 | Master or equivalent      |
| 3345 |    70 | Master or equivalent      |
| 3346 |    60 | Bachelor or equivalent    |
| 3347 |    70 | Master or equivalent      |
| 3348 |    70 | Master or equivalent      |
| 3349 |    70 | Master or equivalent      |
| 3350 |    50 | Short cycle tertiary      |
| 3351 |    50 | Short cycle tertiary      |
| 3352 |    50 | Short cycle tertiary      |
| 3353 |    60 | Bachelor or equivalent    |
| 3354 |    70 | Master or equivalent      |
| 3355 |    60 | Bachelor or equivalent    |
| 3356 |    60 | Bachelor or equivalent    |
| 3357 |    60 | Bachelor or equivalent    |
| 3358 |    60 | Bachelor or equivalent    |
| 3359 |    60 | Bachelor or equivalent    |
| 3360 |    60 | Bachelor or equivalent    |
| 3361 |    60 | Bachelor or equivalent    |
| 3362 |    60 | Bachelor or equivalent    |
| 3363 |    70 | Master or equivalent      |
| 3364 |    30 | Upper secondary           |
| 3365 |    30 | Upper secondary           |
| 3366 |    70 | Master or equivalent      |
| 3367 |    70 | Master or equivalent      |
| 3368 |    60 | Bachelor or equivalent    |
| 3369 |    60 | Bachelor or equivalent    |
| 3370 |    60 | Bachelor or equivalent    |
| 3371 |    60 | Bachelor or equivalent    |
| 3372 |    70 | Master or equivalent      |
| 3373 |    60 | Bachelor or equivalent    |
| 3374 |    70 | Master or equivalent      |
| 3401 |    30 | Upper secondary           |
| 3402 |    30 | Upper secondary           |
| 3403 |    30 | Upper secondary           |
| 3404 |    30 | Upper secondary           |
| 3535 |    70 | Master or equivalent      |
| 3597 |    30 | Upper secondary           |
| 3598 |    30 | Upper secondary           |
| 3599 |    30 | Upper secondary           |
| 3600 |    30 | Upper secondary           |
| 3601 |    30 | Upper secondary           |
| 3602 |    30 | Upper secondary           |
| 3603 |    30 | Upper secondary           |
| 3604 |    30 | Upper secondary           |
| 3605 |    30 | Upper secondary           |
| 3606 |    30 | Upper secondary           |
| 3607 |    30 | Upper secondary           |
| 3608 |    30 | Upper secondary           |
| 3609 |    30 | Upper secondary           |
| 3610 |    30 | Upper secondary           |
| 3611 |    30 | Upper secondary           |
| 3612 |    30 | Upper secondary           |
| 3613 |    30 | Upper secondary           |
| 3614 |    30 | Upper secondary           |
| 3615 |    30 | Upper secondary           |
| 3616 |    30 | Upper secondary           |
| 3617 |    30 | Upper secondary           |
| 3618 |    30 | Upper secondary           |
| 3619 |    30 | Upper secondary           |
| 3620 |    30 | Upper secondary           |
| 3621 |    30 | Upper secondary           |
| 3622 |    30 | Upper secondary           |
| 3623 |    30 | Upper secondary           |
| 3624 |    30 | Upper secondary           |
| 3625 |    30 | Upper secondary           |
| 3626 |    30 | Upper secondary           |
| 3627 |    30 | Upper secondary           |
| 3628 |    30 | Upper secondary           |
| 3629 |    30 | Upper secondary           |
| 3630 |    30 | Upper secondary           |
| 3631 |    30 | Upper secondary           |
| 3632 |    30 | Upper secondary           |
| 3633 |    30 | Upper secondary           |
| 3634 |    30 | Upper secondary           |
| 3635 |    30 | Upper secondary           |
| 3636 |    30 | Upper secondary           |
| 3637 |    30 | Upper secondary           |
| 3638 |    30 | Upper secondary           |
| 3639 |    30 | Upper secondary           |
| 3640 |    30 | Upper secondary           |
| 3641 |    30 | Upper secondary           |
| 3642 |    30 | Upper secondary           |
| 3643 |    30 | Upper secondary           |
| 3644 |    30 | Upper secondary           |
| 3645 |    30 | Upper secondary           |
| 3646 |    30 | Upper secondary           |
| 3647 |    30 | Upper secondary           |
| 3648 |    30 | Upper secondary           |
| 3649 |    30 | Upper secondary           |
| 3650 |    30 | Upper secondary           |
| 3651 |    30 | Upper secondary           |
| 3652 |    30 | Upper secondary           |
| 3653 |    30 | Upper secondary           |
| 3654 |    30 | Upper secondary           |
| 3655 |    30 | Upper secondary           |
| 3656 |    30 | Upper secondary           |
| 3657 |    30 | Upper secondary           |
| 3658 |    30 | Upper secondary           |
| 3659 |    30 | Upper secondary           |
| 3660 |    30 | Upper secondary           |
| 3661 |    30 | Upper secondary           |
| 3662 |    30 | Upper secondary           |
| 3663 |    30 | Upper secondary           |
| 3664 |    30 | Upper secondary           |
| 3665 |    30 | Upper secondary           |
| 3666 |    30 | Upper secondary           |
| 3667 |    30 | Upper secondary           |
| 3668 |    30 | Upper secondary           |
| 3669 |    30 | Upper secondary           |
| 3670 |    30 | Upper secondary           |
| 3671 |    30 | Upper secondary           |
| 3672 |    30 | Upper secondary           |
| 3673 |    30 | Upper secondary           |
| 3674 |    30 | Upper secondary           |
| 3675 |    30 | Upper secondary           |
| 3676 |    30 | Upper secondary           |
| 3677 |    30 | Upper secondary           |
| 3678 |    30 | Upper secondary           |
| 3679 |    30 | Upper secondary           |
| 3680 |    30 | Upper secondary           |
| 3681 |    30 | Upper secondary           |
| 3682 |    30 | Upper secondary           |
| 3683 |    30 | Upper secondary           |
| 3684 |    30 | Upper secondary           |
| 3685 |    30 | Upper secondary           |
| 3686 |    30 | Upper secondary           |
| 3687 |    30 | Upper secondary           |
| 3688 |    30 | Upper secondary           |
| 3689 |    30 | Upper secondary           |
| 3690 |    30 | Upper secondary           |
| 3691 |    30 | Upper secondary           |
| 3692 |    30 | Upper secondary           |
| 3693 |    30 | Upper secondary           |
| 3694 |    30 | Upper secondary           |
| 3695 |    30 | Upper secondary           |
| 3696 |    30 | Upper secondary           |
| 3697 |    30 | Upper secondary           |
| 3698 |    30 | Upper secondary           |
| 3699 |    30 | Upper secondary           |
| 3700 |    30 | Upper secondary           |
| 3701 |    30 | Upper secondary           |
| 3702 |    30 | Upper secondary           |
| 3703 |    30 | Upper secondary           |
| 3704 |    30 | Upper secondary           |
| 3705 |    30 | Upper secondary           |
| 3706 |    30 | Upper secondary           |
| 3707 |    30 | Upper secondary           |
| 3708 |    30 | Upper secondary           |
| 3709 |    30 | Upper secondary           |
| 3710 |    30 | Upper secondary           |
| 3711 |    30 | Upper secondary           |
| 3712 |    30 | Upper secondary           |
| 3713 |    30 | Upper secondary           |
| 3714 |    30 | Upper secondary           |
| 3715 |    30 | Upper secondary           |
| 3716 |    30 | Upper secondary           |
| 3717 |    30 | Upper secondary           |
| 3718 |    30 | Upper secondary           |
| 3719 |    30 | Upper secondary           |
| 3720 |    30 | Upper secondary           |
| 3721 |    30 | Upper secondary           |
| 3722 |    30 | Upper secondary           |
| 3723 |    30 | Upper secondary           |
| 3724 |    30 | Upper secondary           |
| 3725 |    30 | Upper secondary           |
| 3726 |    30 | Upper secondary           |
| 3727 |    30 | Upper secondary           |
| 3728 |    30 | Upper secondary           |
| 3729 |    30 | Upper secondary           |
| 3730 |    30 | Upper secondary           |
| 3731 |    30 | Upper secondary           |
| 3732 |    30 | Upper secondary           |
| 3733 |    30 | Upper secondary           |
| 3734 |    30 | Upper secondary           |
| 3735 |    30 | Upper secondary           |
| 3736 |    30 | Upper secondary           |
| 3737 |    30 | Upper secondary           |
| 3738 |    30 | Upper secondary           |
| 3739 |    30 | Upper secondary           |
| 3740 |    30 | Upper secondary           |
| 3741 |    30 | Upper secondary           |
| 3742 |    30 | Upper secondary           |
| 3743 |    30 | Upper secondary           |
| 3744 |    50 | Short cycle tertiary      |
| 3745 |    50 | Short cycle tertiary      |
| 3746 |    50 | Short cycle tertiary      |
| 3747 |    50 | Short cycle tertiary      |
| 3748 |    50 | Short cycle tertiary      |
| 3749 |    30 | Upper secondary           |
| 3750 |    50 | Short cycle tertiary      |
| 3751 |    30 | Upper secondary           |
| 3752 |    50 | Short cycle tertiary      |
| 3753 |    30 | Upper secondary           |
| 3754 |    30 | Upper secondary           |
| 3755 |    60 | Bachelor or equivalent    |
| 3756 |    30 | Upper secondary           |
| 3757 |    30 | Upper secondary           |
| 3758 |    30 | Upper secondary           |
| 3759 |    30 | Upper secondary           |
| 3760 |    50 | Short cycle tertiary      |
| 3761 |    30 | Upper secondary           |
| 3762 |    30 | Upper secondary           |
| 3763 |    30 | Upper secondary           |
| 3764 |    30 | Upper secondary           |
| 3765 |    50 | Short cycle tertiary      |
| 3766 |    30 | Upper secondary           |
| 3767 |    30 | Upper secondary           |
| 3768 |    30 | Upper secondary           |
| 3769 |    30 | Upper secondary           |
| 3770 |    60 | Bachelor or equivalent    |
| 3771 |    30 | Upper secondary           |
| 3772 |    30 | Upper secondary           |
| 3773 |    30 | Upper secondary           |
| 3774 |    30 | Upper secondary           |
| 3775 |    50 | Short cycle tertiary      |
| 3776 |    30 | Upper secondary           |
| 3777 |    30 | Upper secondary           |
| 3778 |    30 | Upper secondary           |
| 3779 |    30 | Upper secondary           |
| 3780 |    30 | Upper secondary           |
| 3781 |    30 | Upper secondary           |
| 3782 |    30 | Upper secondary           |
| 3783 |    30 | Upper secondary           |
| 3784 |    30 | Upper secondary           |
| 3785 |    30 | Upper secondary           |
| 3786 |    30 | Upper secondary           |
| 3787 |    30 | Upper secondary           |
| 3788 |    30 | Upper secondary           |
| 3789 |    30 | Upper secondary           |
| 3790 |    30 | Upper secondary           |
| 3791 |    30 | Upper secondary           |
| 3792 |    30 | Upper secondary           |
| 3793 |    30 | Upper secondary           |
| 3794 |    30 | Upper secondary           |
| 3795 |    30 | Upper secondary           |
| 3796 |    30 | Upper secondary           |
| 3797 |    30 | Upper secondary           |
| 3798 |    30 | Upper secondary           |
| 3799 |    30 | Upper secondary           |
| 3800 |    50 | Short cycle tertiary      |
| 3801 |    50 | Short cycle tertiary      |
| 3802 |    50 | Short cycle tertiary      |
| 3803 |    50 | Short cycle tertiary      |
| 3804 |    50 | Short cycle tertiary      |
| 3805 |    30 | Upper secondary           |
| 3806 |    50 | Short cycle tertiary      |
| 3807 |    50 | Short cycle tertiary      |
| 3808 |    30 | Upper secondary           |
| 3809 |    50 | Short cycle tertiary      |
| 3810 |    70 | Master or equivalent      |
| 3811 |    50 | Short cycle tertiary      |
| 3812 |    50 | Short cycle tertiary      |
| 3813 |    50 | Short cycle tertiary      |
| 3814 |    50 | Short cycle tertiary      |
| 3815 |    50 | Short cycle tertiary      |
| 3816 |    50 | Short cycle tertiary      |
| 3817 |    50 | Short cycle tertiary      |
| 3818 |    50 | Short cycle tertiary      |
| 3819 |    50 | Short cycle tertiary      |
| 3820 |    50 | Short cycle tertiary      |
| 3821 |    50 | Short cycle tertiary      |
| 3822 |    50 | Short cycle tertiary      |
| 3823 |    50 | Short cycle tertiary      |
| 3824 |    50 | Short cycle tertiary      |
| 3825 |    50 | Short cycle tertiary      |
| 3826 |    50 | Short cycle tertiary      |
| 3827 |    50 | Short cycle tertiary      |
| 3828 |    50 | Short cycle tertiary      |
| 3829 |    50 | Short cycle tertiary      |
| 3830 |    50 | Short cycle tertiary      |
| 3831 |    50 | Short cycle tertiary      |
| 3832 |    50 | Short cycle tertiary      |
| 3833 |    50 | Short cycle tertiary      |
| 3834 |    50 | Short cycle tertiary      |
| 3835 |    30 | Upper secondary           |
| 3836 |    50 | Short cycle tertiary      |
| 3837 |    50 | Short cycle tertiary      |
| 3838 |    50 | Short cycle tertiary      |
| 3839 |    50 | Short cycle tertiary      |
| 3840 |    50 | Short cycle tertiary      |
| 3841 |    50 | Short cycle tertiary      |
| 3842 |    50 | Short cycle tertiary      |
| 3843 |    50 | Short cycle tertiary      |
| 3844 |    50 | Short cycle tertiary      |
| 3845 |    50 | Short cycle tertiary      |
| 3846 |    50 | Short cycle tertiary      |
| 3847 |    50 | Short cycle tertiary      |
| 3848 |    50 | Short cycle tertiary      |
| 3849 |    50 | Short cycle tertiary      |
| 3850 |    50 | Short cycle tertiary      |
| 3851 |    50 | Short cycle tertiary      |
| 3852 |    50 | Short cycle tertiary      |
| 3853 |    50 | Short cycle tertiary      |
| 3854 |    50 | Short cycle tertiary      |
| 3855 |    50 | Short cycle tertiary      |
| 3856 |    50 | Short cycle tertiary      |
| 3857 |    50 | Short cycle tertiary      |
| 3858 |    50 | Short cycle tertiary      |
| 3859 |    50 | Short cycle tertiary      |
| 3860 |    50 | Short cycle tertiary      |
| 3861 |    50 | Short cycle tertiary      |
| 3862 |    50 | Short cycle tertiary      |
| 3863 |    50 | Short cycle tertiary      |
| 3864 |    50 | Short cycle tertiary      |
| 3865 |    50 | Short cycle tertiary      |
| 3866 |    50 | Short cycle tertiary      |
| 3867 |    50 | Short cycle tertiary      |
| 3868 |    30 | Upper secondary           |
| 3869 |    30 | Upper secondary           |
| 3870 |    30 | Upper secondary           |
| 3871 |    30 | Upper secondary           |
| 3872 |    50 | Short cycle tertiary      |
| 3873 |    30 | Upper secondary           |
| 3874 |    30 | Upper secondary           |
| 3875 |    50 | Short cycle tertiary      |
| 3876 |    50 | Short cycle tertiary      |
| 3880 |    30 | Upper secondary           |
| 3881 |    30 | Upper secondary           |
| 3882 |    30 | Upper secondary           |
| 3883 |    30 | Upper secondary           |
| 3884 |    30 | Upper secondary           |
| 3885 |    30 | Upper secondary           |
| 3886 |    30 | Upper secondary           |
| 3887 |    30 | Upper secondary           |
| 3910 |    30 | Upper secondary           |
| 3915 |    30 | Upper secondary           |
| 3920 |    30 | Upper secondary           |
| 3925 |    30 | Upper secondary           |
| 3930 |    30 | Upper secondary           |
| 3935 |    30 | Upper secondary           |
| 3939 |    30 | Upper secondary           |
| 3940 |    30 | Upper secondary           |
| 3941 |    30 | Upper secondary           |
| 3942 |    20 | Lower secondary           |
| 3943 |    60 | Bachelor or equivalent    |
| 3945 |    50 | Short cycle tertiary      |
| 3950 |    50 | Short cycle tertiary      |
| 3955 |    20 | Lower secondary           |
| 3960 |    30 | Upper secondary           |
| 3961 |    30 | Upper secondary           |
| 3965 |    30 | Upper secondary           |
| 3970 |    50 | Short cycle tertiary      |
| 3971 |    50 | Short cycle tertiary      |
| 3972 |    50 | Short cycle tertiary      |
| 4000 |    50 | Short cycle tertiary      |
| 4001 |    30 | Upper secondary           |
| 4002 |    30 | Upper secondary           |
| 4003 |    30 | Upper secondary           |
| 4004 |    30 | Upper secondary           |
| 4005 |    50 | Short cycle tertiary      |
| 4006 |    50 | Short cycle tertiary      |
| 4007 |    50 | Short cycle tertiary      |
| 4008 |    30 | Upper secondary           |
| 4009 |    50 | Short cycle tertiary      |
| 4010 |    30 | Upper secondary           |
| 4011 |    50 | Short cycle tertiary      |
| 4012 |    50 | Short cycle tertiary      |
| 4013 |    50 | Short cycle tertiary      |
| 4014 |    50 | Short cycle tertiary      |
| 4015 |    50 | Short cycle tertiary      |
| 4017 |    50 | Short cycle tertiary      |
| 4018 |    50 | Short cycle tertiary      |
| 4019 |    50 | Short cycle tertiary      |
| 4020 |    50 | Short cycle tertiary      |
| 4021 |    50 | Short cycle tertiary      |
| 4022 |    50 | Short cycle tertiary      |
| 4023 |    50 | Short cycle tertiary      |
| 4024 |    50 | Short cycle tertiary      |
| 4025 |    50 | Short cycle tertiary      |
| 4026 |    50 | Short cycle tertiary      |
| 4027 |    50 | Short cycle tertiary      |
| 4028 |    50 | Short cycle tertiary      |
| 4029 |    50 | Short cycle tertiary      |
| 4030 |    50 | Short cycle tertiary      |
| 4032 |    60 | Bachelor or equivalent    |
| 4033 |    60 | Bachelor or equivalent    |
| 4034 |    60 | Bachelor or equivalent    |
| 4035 |    60 | Bachelor or equivalent    |
| 4036 |    50 | Short cycle tertiary      |
| 4037 |    50 | Short cycle tertiary      |
| 4038 |    30 | Upper secondary           |
| 4039 |    30 | Upper secondary           |
| 4040 |    60 | Bachelor or equivalent    |
| 4041 |    60 | Bachelor or equivalent    |
| 4044 |    30 | Upper secondary           |
| 4045 |    30 | Upper secondary           |
| 4048 |    60 | Bachelor or equivalent    |
| 4049 |    50 | Short cycle tertiary      |
| 4050 |    50 | Short cycle tertiary      |
| 4051 |    30 | Upper secondary           |
| 4052 |    50 | Short cycle tertiary      |
| 4053 |    30 | Upper secondary           |
| 4054 |    50 | Short cycle tertiary      |
| 4055 |    60 | Bachelor or equivalent    |
| 4056 |    30 | Upper secondary           |
| 4057 |    30 | Upper secondary           |
| 4058 |    30 | Upper secondary           |
| 4059 |    30 | Upper secondary           |
| 4060 |    50 | Short cycle tertiary      |
| 4061 |    60 | Bachelor or equivalent    |
| 4062 |    50 | Short cycle tertiary      |
| 4063 |    50 | Short cycle tertiary      |
| 4064 |    50 | Short cycle tertiary      |
| 4065 |    50 | Short cycle tertiary      |
| 4066 |    50 | Short cycle tertiary      |
| 4067 |    50 | Short cycle tertiary      |
| 4068 |    50 | Short cycle tertiary      |
| 4069 |    50 | Short cycle tertiary      |
| 4070 |    60 | Bachelor or equivalent    |
| 4071 |    60 | Bachelor or equivalent    |
| 4072 |    60 | Bachelor or equivalent    |
| 4073 |    60 | Bachelor or equivalent    |
| 4074 |    60 | Bachelor or equivalent    |
| 4075 |    50 | Short cycle tertiary      |
| 4076 |    60 | Bachelor or equivalent    |
| 4077 |    60 | Bachelor or equivalent    |
| 4078 |    60 | Bachelor or equivalent    |
| 4079 |    60 | Bachelor or equivalent    |
| 4080 |    30 | Upper secondary           |
| 4081 |    50 | Short cycle tertiary      |
| 4082 |    60 | Bachelor or equivalent    |
| 4083 |    60 | Bachelor or equivalent    |
| 4084 |    60 | Bachelor or equivalent    |
| 4085 |    60 | Bachelor or equivalent    |
| 4086 |    60 | Bachelor or equivalent    |
| 4087 |    60 | Bachelor or equivalent    |
| 4088 |    60 | Bachelor or equivalent    |
| 4089 |    50 | Short cycle tertiary      |
| 4090 |    50 | Short cycle tertiary      |
| 4091 |    50 | Short cycle tertiary      |
| 4092 |    50 | Short cycle tertiary      |
| 4093 |    60 | Bachelor or equivalent    |
| 4094 |    30 | Upper secondary           |
| 4096 |    50 | Short cycle tertiary      |
| 4097 |    50 | Short cycle tertiary      |
| 4098 |    30 | Upper secondary           |
| 4099 |    50 | Short cycle tertiary      |
| 4100 |    30 | Upper secondary           |
| 4101 |    30 | Upper secondary           |
| 4103 |    30 | Upper secondary           |
| 4108 |    30 | Upper secondary           |
| 4117 |    30 | Upper secondary           |
| 4118 |    30 | Upper secondary           |
| 4119 |    30 | Upper secondary           |
| 4120 |    30 | Upper secondary           |
| 4121 |    30 | Upper secondary           |
| 4122 |    30 | Upper secondary           |
| 4123 |    30 | Upper secondary           |
| 4124 |    30 | Upper secondary           |
| 4125 |    30 | Upper secondary           |
| 4126 |    30 | Upper secondary           |
| 4127 |    30 | Upper secondary           |
| 4128 |    30 | Upper secondary           |
| 4129 |    30 | Upper secondary           |
| 4134 |    50 | Short cycle tertiary      |
| 4135 |    30 | Upper secondary           |
| 4140 |    30 | Upper secondary           |
| 4141 |    30 | Upper secondary           |
| 4142 |    30 | Upper secondary           |
| 4143 |    30 | Upper secondary           |
| 4166 |    30 | Upper secondary           |
| 4168 |    30 | Upper secondary           |
| 4188 |    30 | Upper secondary           |
| 4189 |    30 | Upper secondary           |
| 4193 |    30 | Upper secondary           |
| 4194 |    30 | Upper secondary           |
| 4195 |    30 | Upper secondary           |
| 4196 |    30 | Upper secondary           |
| 4197 |    30 | Upper secondary           |
| 4198 |    30 | Upper secondary           |
| 4199 |    30 | Upper secondary           |
| 4200 |    30 | Upper secondary           |
| 4201 |    30 | Upper secondary           |
| 4202 |    30 | Upper secondary           |
| 4203 |    30 | Upper secondary           |
| 4204 |    30 | Upper secondary           |
| 4205 |    30 | Upper secondary           |
| 4206 |    30 | Upper secondary           |
| 4207 |    30 | Upper secondary           |
| 4208 |    70 | Master or equivalent      |
| 4211 |    30 | Upper secondary           |
| 4212 |    30 | Upper secondary           |
| 4213 |    30 | Upper secondary           |
| 4214 |    30 | Upper secondary           |
| 4215 |    30 | Upper secondary           |
| 4216 |    30 | Upper secondary           |
| 4217 |    30 | Upper secondary           |
| 4218 |    30 | Upper secondary           |
| 4219 |    30 | Upper secondary           |
| 4220 |    30 | Upper secondary           |
| 4221 |    30 | Upper secondary           |
| 4222 |    30 | Upper secondary           |
| 4223 |    30 | Upper secondary           |
| 4224 |    30 | Upper secondary           |
| 4225 |    30 | Upper secondary           |
| 4226 |    30 | Upper secondary           |
| 4227 |    30 | Upper secondary           |
| 4228 |    30 | Upper secondary           |
| 4229 |    30 | Upper secondary           |
| 4230 |    30 | Upper secondary           |
| 4231 |    30 | Upper secondary           |
| 4232 |    30 | Upper secondary           |
| 4233 |    30 | Upper secondary           |
| 4234 |    30 | Upper secondary           |
| 4235 |    30 | Upper secondary           |
| 4236 |    30 | Upper secondary           |
| 4237 |    30 | Upper secondary           |
| 4238 |    30 | Upper secondary           |
| 4239 |    30 | Upper secondary           |
| 4240 |    30 | Upper secondary           |
| 4241 |    30 | Upper secondary           |
| 4242 |    30 | Upper secondary           |
| 4243 |    30 | Upper secondary           |
| 4244 |    30 | Upper secondary           |
| 4245 |    30 | Upper secondary           |
| 4246 |    30 | Upper secondary           |
| 4247 |    30 | Upper secondary           |
| 4248 |    30 | Upper secondary           |
| 4249 |    30 | Upper secondary           |
| 4250 |    30 | Upper secondary           |
| 4251 |    30 | Upper secondary           |
| 4252 |    30 | Upper secondary           |
| 4253 |    30 | Upper secondary           |
| 4254 |    30 | Upper secondary           |
| 4255 |    30 | Upper secondary           |
| 4256 |    30 | Upper secondary           |
| 4257 |    30 | Upper secondary           |
| 4258 |    30 | Upper secondary           |
| 4259 |    30 | Upper secondary           |
| 4260 |    30 | Upper secondary           |
| 4261 |    30 | Upper secondary           |
| 4262 |    30 | Upper secondary           |
| 4263 |    30 | Upper secondary           |
| 4264 |    30 | Upper secondary           |
| 4265 |    30 | Upper secondary           |
| 4266 |    30 | Upper secondary           |
| 4267 |    30 | Upper secondary           |
| 4268 |    30 | Upper secondary           |
| 4269 |    30 | Upper secondary           |
| 4270 |    30 | Upper secondary           |
| 4271 |    30 | Upper secondary           |
| 4272 |    30 | Upper secondary           |
| 4273 |    30 | Upper secondary           |
| 4274 |    30 | Upper secondary           |
| 4275 |    30 | Upper secondary           |
| 4276 |    30 | Upper secondary           |
| 4277 |    30 | Upper secondary           |
| 4278 |    30 | Upper secondary           |
| 4279 |    30 | Upper secondary           |
| 4280 |    30 | Upper secondary           |
| 4281 |    30 | Upper secondary           |
| 4282 |    30 | Upper secondary           |
| 4283 |    30 | Upper secondary           |
| 4284 |    30 | Upper secondary           |
| 4285 |    30 | Upper secondary           |
| 4286 |    30 | Upper secondary           |
| 4287 |    30 | Upper secondary           |
| 4288 |    30 | Upper secondary           |
| 4289 |    30 | Upper secondary           |
| 4290 |    30 | Upper secondary           |
| 4291 |    30 | Upper secondary           |
| 4292 |    30 | Upper secondary           |
| 4293 |    30 | Upper secondary           |
| 4294 |    30 | Upper secondary           |
| 4295 |    30 | Upper secondary           |
| 4296 |    30 | Upper secondary           |
| 4297 |    30 | Upper secondary           |
| 4298 |    30 | Upper secondary           |
| 4299 |    30 | Upper secondary           |
| 4300 |    30 | Upper secondary           |
| 4301 |    30 | Upper secondary           |
| 4302 |    30 | Upper secondary           |
| 4303 |    30 | Upper secondary           |
| 4304 |    30 | Upper secondary           |
| 4305 |    30 | Upper secondary           |
| 4306 |    30 | Upper secondary           |
| 4307 |    30 | Upper secondary           |
| 4308 |    30 | Upper secondary           |
| 4309 |    30 | Upper secondary           |
| 4310 |    30 | Upper secondary           |
| 4311 |    30 | Upper secondary           |
| 4312 |    30 | Upper secondary           |
| 4313 |    30 | Upper secondary           |
| 4314 |    30 | Upper secondary           |
| 4315 |    30 | Upper secondary           |
| 4316 |    30 | Upper secondary           |
| 4317 |    30 | Upper secondary           |
| 4318 |    30 | Upper secondary           |
| 4319 |    30 | Upper secondary           |
| 4320 |    30 | Upper secondary           |
| 4321 |    30 | Upper secondary           |
| 4322 |    30 | Upper secondary           |
| 4323 |    30 | Upper secondary           |
| 4324 |    30 | Upper secondary           |
| 4325 |    30 | Upper secondary           |
| 4326 |    30 | Upper secondary           |
| 4327 |    30 | Upper secondary           |
| 4328 |    30 | Upper secondary           |
| 4329 |    30 | Upper secondary           |
| 4330 |    30 | Upper secondary           |
| 4331 |    30 | Upper secondary           |
| 4332 |    30 | Upper secondary           |
| 4333 |    30 | Upper secondary           |
| 4334 |    30 | Upper secondary           |
| 4335 |    30 | Upper secondary           |
| 4336 |    30 | Upper secondary           |
| 4337 |    30 | Upper secondary           |
| 4338 |    30 | Upper secondary           |
| 4339 |    30 | Upper secondary           |
| 4340 |    30 | Upper secondary           |
| 4341 |    30 | Upper secondary           |
| 4342 |    30 | Upper secondary           |
| 4343 |    30 | Upper secondary           |
| 4344 |    30 | Upper secondary           |
| 4345 |    30 | Upper secondary           |
| 4346 |    30 | Upper secondary           |
| 4347 |    30 | Upper secondary           |
| 4348 |    30 | Upper secondary           |
| 4349 |    30 | Upper secondary           |
| 4350 |    30 | Upper secondary           |
| 4351 |    30 | Upper secondary           |
| 4352 |    30 | Upper secondary           |
| 4353 |    30 | Upper secondary           |
| 4354 |    30 | Upper secondary           |
| 4355 |    30 | Upper secondary           |
| 4356 |    30 | Upper secondary           |
| 4357 |    30 | Upper secondary           |
| 4358 |    30 | Upper secondary           |
| 4359 |    30 | Upper secondary           |
| 4360 |    30 | Upper secondary           |
| 4361 |    30 | Upper secondary           |
| 4362 |    30 | Upper secondary           |
| 4363 |    30 | Upper secondary           |
| 4364 |    30 | Upper secondary           |
| 4365 |    30 | Upper secondary           |
| 4366 |    30 | Upper secondary           |
| 4367 |    30 | Upper secondary           |
| 4368 |    30 | Upper secondary           |
| 4369 |    30 | Upper secondary           |
| 4370 |    30 | Upper secondary           |
| 4371 |    30 | Upper secondary           |
| 4372 |    30 | Upper secondary           |
| 4373 |    30 | Upper secondary           |
| 4374 |    30 | Upper secondary           |
| 4375 |    30 | Upper secondary           |
| 4376 |    30 | Upper secondary           |
| 4377 |    30 | Upper secondary           |
| 4378 |    30 | Upper secondary           |
| 4379 |    30 | Upper secondary           |
| 4380 |    30 | Upper secondary           |
| 4381 |    30 | Upper secondary           |
| 4382 |    30 | Upper secondary           |
| 4383 |    30 | Upper secondary           |
| 4384 |    30 | Upper secondary           |
| 4385 |    30 | Upper secondary           |
| 4386 |    30 | Upper secondary           |
| 4387 |    30 | Upper secondary           |
| 4388 |    30 | Upper secondary           |
| 4389 |    30 | Upper secondary           |
| 4390 |    30 | Upper secondary           |
| 4391 |    30 | Upper secondary           |
| 4392 |    30 | Upper secondary           |
| 4393 |    30 | Upper secondary           |
| 4394 |    30 | Upper secondary           |
| 4395 |    30 | Upper secondary           |
| 4396 |    30 | Upper secondary           |
| 4397 |    30 | Upper secondary           |
| 4398 |    30 | Upper secondary           |
| 4399 |    30 | Upper secondary           |
| 4400 |    30 | Upper secondary           |
| 4401 |    30 | Upper secondary           |
| 4402 |    30 | Upper secondary           |
| 4403 |    30 | Upper secondary           |
| 4404 |    30 | Upper secondary           |
| 4405 |    30 | Upper secondary           |
| 4406 |    30 | Upper secondary           |
| 4407 |    30 | Upper secondary           |
| 4410 |    30 | Upper secondary           |
| 4411 |    30 | Upper secondary           |
| 4412 |    30 | Upper secondary           |
| 4413 |    30 | Upper secondary           |
| 4414 |    30 | Upper secondary           |
| 4415 |    30 | Upper secondary           |
| 4416 |    30 | Upper secondary           |
| 4417 |    30 | Upper secondary           |
| 4418 |    30 | Upper secondary           |
| 4419 |    30 | Upper secondary           |
| 4420 |    30 | Upper secondary           |
| 4421 |    30 | Upper secondary           |
| 4422 |    30 | Upper secondary           |
| 4423 |    30 | Upper secondary           |
| 4424 |    30 | Upper secondary           |
| 4425 |    30 | Upper secondary           |
| 4426 |    30 | Upper secondary           |
| 4427 |    30 | Upper secondary           |
| 4428 |    30 | Upper secondary           |
| 4429 |    30 | Upper secondary           |
| 4430 |    30 | Upper secondary           |
| 4431 |    30 | Upper secondary           |
| 4432 |    30 | Upper secondary           |
| 4433 |    30 | Upper secondary           |
| 4434 |    30 | Upper secondary           |
| 4435 |    30 | Upper secondary           |
| 4436 |    30 | Upper secondary           |
| 4437 |    30 | Upper secondary           |
| 4438 |    30 | Upper secondary           |
| 4439 |    30 | Upper secondary           |
| 4440 |    30 | Upper secondary           |
| 4441 |    30 | Upper secondary           |
| 4442 |    30 | Upper secondary           |
| 4443 |    30 | Upper secondary           |
| 4444 |    30 | Upper secondary           |
| 4445 |    30 | Upper secondary           |
| 4446 |    30 | Upper secondary           |
| 4447 |    30 | Upper secondary           |
| 4448 |    30 | Upper secondary           |
| 4449 |    30 | Upper secondary           |
| 4450 |    60 | Bachelor or equivalent    |
| 4451 |    30 | Upper secondary           |
| 4452 |    30 | Upper secondary           |
| 4453 |    30 | Upper secondary           |
| 4454 |    30 | Upper secondary           |
| 4455 |    30 | Upper secondary           |
| 4456 |    30 | Upper secondary           |
| 4457 |    30 | Upper secondary           |
| 4458 |    30 | Upper secondary           |
| 4459 |    30 | Upper secondary           |
| 4460 |    30 | Upper secondary           |
| 4461 |    30 | Upper secondary           |
| 4462 |    30 | Upper secondary           |
| 4463 |    30 | Upper secondary           |
| 4464 |    30 | Upper secondary           |
| 4465 |    30 | Upper secondary           |
| 4466 |    30 | Upper secondary           |
| 4467 |    30 | Upper secondary           |
| 4468 |    30 | Upper secondary           |
| 4469 |    30 | Upper secondary           |
| 4470 |    30 | Upper secondary           |
| 4471 |    30 | Upper secondary           |
| 4472 |    30 | Upper secondary           |
| 4473 |    30 | Upper secondary           |
| 4474 |    60 | Bachelor or equivalent    |
| 4475 |    30 | Upper secondary           |
| 4476 |    30 | Upper secondary           |
| 4477 |    30 | Upper secondary           |
| 4478 |    30 | Upper secondary           |
| 4479 |    30 | Upper secondary           |
| 4480 |    30 | Upper secondary           |
| 4481 |    30 | Upper secondary           |
| 4482 |    30 | Upper secondary           |
| 4483 |    30 | Upper secondary           |
| 4484 |    30 | Upper secondary           |
| 4485 |    30 | Upper secondary           |
| 4486 |    30 | Upper secondary           |
| 4487 |    30 | Upper secondary           |
| 4488 |    30 | Upper secondary           |
| 4489 |    30 | Upper secondary           |
| 4490 |    30 | Upper secondary           |
| 4491 |    30 | Upper secondary           |
| 4492 |    30 | Upper secondary           |
| 4493 |    30 | Upper secondary           |
| 4494 |    30 | Upper secondary           |
| 4495 |    30 | Upper secondary           |
| 4496 |    30 | Upper secondary           |
| 4497 |    30 | Upper secondary           |
| 4498 |    30 | Upper secondary           |
| 4499 |    30 | Upper secondary           |
| 4500 |    30 | Upper secondary           |
| 4501 |    30 | Upper secondary           |
| 4502 |    30 | Upper secondary           |
| 4503 |    30 | Upper secondary           |
| 4504 |    30 | Upper secondary           |
| 4505 |    30 | Upper secondary           |
| 4506 |    30 | Upper secondary           |
| 4507 |    30 | Upper secondary           |
| 4508 |    30 | Upper secondary           |
| 4509 |    30 | Upper secondary           |
| 4510 |    30 | Upper secondary           |
| 4511 |    30 | Upper secondary           |
| 4512 |    30 | Upper secondary           |
| 4513 |    30 | Upper secondary           |
| 4514 |    30 | Upper secondary           |
| 4515 |    30 | Upper secondary           |
| 4516 |    30 | Upper secondary           |
| 4517 |    30 | Upper secondary           |
| 4518 |    30 | Upper secondary           |
| 4519 |    30 | Upper secondary           |
| 4520 |    30 | Upper secondary           |
| 4521 |    30 | Upper secondary           |
| 4522 |    30 | Upper secondary           |
| 4523 |    30 | Upper secondary           |
| 4524 |    30 | Upper secondary           |
| 4525 |    30 | Upper secondary           |
| 4526 |    30 | Upper secondary           |
| 4527 |    30 | Upper secondary           |
| 4528 |    30 | Upper secondary           |
| 4529 |    30 | Upper secondary           |
| 4530 |    30 | Upper secondary           |
| 4531 |    30 | Upper secondary           |
| 4532 |    30 | Upper secondary           |
| 4533 |    30 | Upper secondary           |
| 4534 |    30 | Upper secondary           |
| 4535 |    30 | Upper secondary           |
| 4536 |    30 | Upper secondary           |
| 4537 |    30 | Upper secondary           |
| 4538 |    30 | Upper secondary           |
| 4539 |    30 | Upper secondary           |
| 4540 |    30 | Upper secondary           |
| 4541 |    30 | Upper secondary           |
| 4542 |    30 | Upper secondary           |
| 4543 |    30 | Upper secondary           |
| 4544 |    30 | Upper secondary           |
| 4545 |    30 | Upper secondary           |
| 4546 |    30 | Upper secondary           |
| 4547 |    30 | Upper secondary           |
| 4548 |    30 | Upper secondary           |
| 4549 |    30 | Upper secondary           |
| 4550 |    30 | Upper secondary           |
| 4551 |    30 | Upper secondary           |
| 4552 |    30 | Upper secondary           |
| 4553 |    30 | Upper secondary           |
| 4554 |    30 | Upper secondary           |
| 4555 |    30 | Upper secondary           |
| 4556 |    30 | Upper secondary           |
| 4557 |    30 | Upper secondary           |
| 4558 |    30 | Upper secondary           |
| 4559 |    30 | Upper secondary           |
| 4560 |    30 | Upper secondary           |
| 4561 |    30 | Upper secondary           |
| 4562 |    50 | Short cycle tertiary      |
| 4563 |    30 | Upper secondary           |
| 4564 |    30 | Upper secondary           |
| 4565 |    30 | Upper secondary           |
| 4566 |    30 | Upper secondary           |
| 4567 |    30 | Upper secondary           |
| 4568 |    30 | Upper secondary           |
| 4569 |    30 | Upper secondary           |
| 4570 |    30 | Upper secondary           |
| 4571 |    30 | Upper secondary           |
| 4572 |    30 | Upper secondary           |
| 4573 |    30 | Upper secondary           |
| 4574 |    30 | Upper secondary           |
| 4575 |    30 | Upper secondary           |
| 4576 |    30 | Upper secondary           |
| 4577 |    30 | Upper secondary           |
| 4578 |    30 | Upper secondary           |
| 4579 |    30 | Upper secondary           |
| 4580 |    30 | Upper secondary           |
| 4581 |    30 | Upper secondary           |
| 4582 |    30 | Upper secondary           |
| 4600 |    30 | Upper secondary           |
| 4601 |    30 | Upper secondary           |
| 4602 |    30 | Upper secondary           |
| 4603 |    30 | Upper secondary           |
| 4604 |    30 | Upper secondary           |
| 4605 |    30 | Upper secondary           |
| 4606 |    30 | Upper secondary           |
| 4607 |    30 | Upper secondary           |
| 4608 |    30 | Upper secondary           |
| 4609 |    30 | Upper secondary           |
| 4610 |    30 | Upper secondary           |
| 4611 |    30 | Upper secondary           |
| 4612 |    30 | Upper secondary           |
| 4613 |    30 | Upper secondary           |
| 4614 |    30 | Upper secondary           |
| 4615 |    30 | Upper secondary           |
| 4616 |    30 | Upper secondary           |
| 4617 |    30 | Upper secondary           |
| 4618 |    30 | Upper secondary           |
| 4619 |    30 | Upper secondary           |
| 4620 |    30 | Upper secondary           |
| 4621 |    30 | Upper secondary           |
| 4622 |    30 | Upper secondary           |
| 4623 |    30 | Upper secondary           |
| 4624 |    30 | Upper secondary           |
| 4625 |    30 | Upper secondary           |
| 4626 |    30 | Upper secondary           |
| 4627 |    30 | Upper secondary           |
| 4628 |    30 | Upper secondary           |
| 4629 |    30 | Upper secondary           |
| 4630 |    30 | Upper secondary           |
| 4631 |    30 | Upper secondary           |
| 4632 |    30 | Upper secondary           |
| 4633 |    30 | Upper secondary           |
| 4634 |    30 | Upper secondary           |
| 4635 |    30 | Upper secondary           |
| 4636 |    30 | Upper secondary           |
| 4637 |    30 | Upper secondary           |
| 4638 |    30 | Upper secondary           |
| 4639 |    30 | Upper secondary           |
| 4640 |    30 | Upper secondary           |
| 4641 |    30 | Upper secondary           |
| 4642 |    30 | Upper secondary           |
| 4643 |    30 | Upper secondary           |
| 4644 |    30 | Upper secondary           |
| 4645 |    30 | Upper secondary           |
| 4646 |    30 | Upper secondary           |
| 4647 |    30 | Upper secondary           |
| 4648 |    30 | Upper secondary           |
| 4649 |    30 | Upper secondary           |
| 4650 |    30 | Upper secondary           |
| 4651 |    30 | Upper secondary           |
| 4652 |    30 | Upper secondary           |
| 4653 |    30 | Upper secondary           |
| 4654 |    30 | Upper secondary           |
| 4655 |    30 | Upper secondary           |
| 4656 |    30 | Upper secondary           |
| 4657 |    30 | Upper secondary           |
| 4658 |    30 | Upper secondary           |
| 4659 |    30 | Upper secondary           |
| 4660 |    30 | Upper secondary           |
| 4661 |    30 | Upper secondary           |
| 4662 |    30 | Upper secondary           |
| 4663 |    30 | Upper secondary           |
| 4664 |    30 | Upper secondary           |
| 4665 |    30 | Upper secondary           |
| 4666 |    30 | Upper secondary           |
| 4667 |    30 | Upper secondary           |
| 4668 |    30 | Upper secondary           |
| 4669 |    30 | Upper secondary           |
| 4670 |    30 | Upper secondary           |
| 4671 |    30 | Upper secondary           |
| 4672 |    30 | Upper secondary           |
| 4673 |    30 | Upper secondary           |
| 4674 |    30 | Upper secondary           |
| 4675 |    30 | Upper secondary           |
| 4676 |    30 | Upper secondary           |
| 4677 |    30 | Upper secondary           |
| 4678 |    30 | Upper secondary           |
| 4679 |    30 | Upper secondary           |
| 4680 |    30 | Upper secondary           |
| 4681 |    30 | Upper secondary           |
| 4682 |    30 | Upper secondary           |
| 4683 |    30 | Upper secondary           |
| 4684 |    30 | Upper secondary           |
| 4685 |    30 | Upper secondary           |
| 4686 |    30 | Upper secondary           |
| 4687 |    30 | Upper secondary           |
| 4688 |    30 | Upper secondary           |
| 4689 |    30 | Upper secondary           |
| 4690 |    30 | Upper secondary           |
| 4691 |    30 | Upper secondary           |
| 4692 |    30 | Upper secondary           |
| 4693 |    30 | Upper secondary           |
| 4694 |    30 | Upper secondary           |
| 4695 |    30 | Upper secondary           |
| 4696 |    30 | Upper secondary           |
| 4697 |    30 | Upper secondary           |
| 4698 |    30 | Upper secondary           |
| 4699 |    30 | Upper secondary           |
| 4700 |    30 | Upper secondary           |
| 4701 |    30 | Upper secondary           |
| 4702 |    30 | Upper secondary           |
| 4703 |    30 | Upper secondary           |
| 4704 |    30 | Upper secondary           |
| 4705 |    30 | Upper secondary           |
| 4706 |    30 | Upper secondary           |
| 4707 |    30 | Upper secondary           |
| 4708 |    30 | Upper secondary           |
| 4709 |    30 | Upper secondary           |
| 4710 |    30 | Upper secondary           |
| 4711 |    30 | Upper secondary           |
| 4712 |    30 | Upper secondary           |
| 4713 |    30 | Upper secondary           |
| 4714 |    30 | Upper secondary           |
| 4715 |    30 | Upper secondary           |
| 4716 |    30 | Upper secondary           |
| 4717 |    30 | Upper secondary           |
| 4718 |    30 | Upper secondary           |
| 4719 |    30 | Upper secondary           |
| 4720 |    30 | Upper secondary           |
| 4721 |    30 | Upper secondary           |
| 4722 |    30 | Upper secondary           |
| 4723 |    30 | Upper secondary           |
| 4724 |    30 | Upper secondary           |
| 4725 |    20 | Lower secondary           |
| 4726 |    30 | Upper secondary           |
| 4727 |    30 | Upper secondary           |
| 4728 |    30 | Upper secondary           |
| 4729 |    30 | Upper secondary           |
| 4730 |    30 | Upper secondary           |
| 4731 |    30 | Upper secondary           |
| 4732 |    30 | Upper secondary           |
| 4733 |    30 | Upper secondary           |
| 4734 |    30 | Upper secondary           |
| 4735 |    30 | Upper secondary           |
| 4736 |    30 | Upper secondary           |
| 4737 |    30 | Upper secondary           |
| 4738 |    30 | Upper secondary           |
| 4739 |    30 | Upper secondary           |
| 4740 |    30 | Upper secondary           |
| 4750 |    30 | Upper secondary           |
| 4754 |    30 | Upper secondary           |
| 4755 |    30 | Upper secondary           |
| 4756 |    30 | Upper secondary           |
| 4757 |    30 | Upper secondary           |
| 4758 |    30 | Upper secondary           |
| 4759 |    30 | Upper secondary           |
| 4760 |    30 | Upper secondary           |
| 4762 |    30 | Upper secondary           |
| 4764 |    20 | Lower secondary           |
| 4765 |    20 | Lower secondary           |
| 4766 |    20 | Lower secondary           |
| 4767 |    20 | Lower secondary           |
| 4780 |    30 | Upper secondary           |
| 4781 |    30 | Upper secondary           |
| 4782 |    30 | Upper secondary           |
| 4783 |    30 | Upper secondary           |
| 4784 |    30 | Upper secondary           |
| 4785 |    30 | Upper secondary           |
| 4786 |    30 | Upper secondary           |
| 4787 |    30 | Upper secondary           |
| 4788 |    30 | Upper secondary           |
| 4789 |    30 | Upper secondary           |
| 4790 |    30 | Upper secondary           |
| 4791 |    30 | Upper secondary           |
| 4792 |    30 | Upper secondary           |
| 4800 |    70 | Master or equivalent      |
| 4801 |    60 | Bachelor or equivalent    |
| 4850 |    30 | Upper secondary           |
| 4851 |    30 | Upper secondary           |
| 4853 |    30 | Upper secondary           |
| 4854 |    30 | Upper secondary           |
| 4855 |    30 | Upper secondary           |
| 4856 |    30 | Upper secondary           |
| 4858 |    30 | Upper secondary           |
| 4859 |    30 | Upper secondary           |
| 4860 |    30 | Upper secondary           |
| 4861 |    30 | Upper secondary           |
| 4864 |    30 | Upper secondary           |
| 4865 |    30 | Upper secondary           |
| 4866 |    30 | Upper secondary           |
| 4867 |    30 | Upper secondary           |
| 4868 |    30 | Upper secondary           |
| 4869 |    30 | Upper secondary           |
| 4870 |    30 | Upper secondary           |
| 4871 |    30 | Upper secondary           |
| 4874 |    30 | Upper secondary           |
| 4875 |    30 | Upper secondary           |
| 4876 |    30 | Upper secondary           |
| 4877 |    30 | Upper secondary           |
| 4878 |    30 | Upper secondary           |
| 4879 |    30 | Upper secondary           |
| 4880 |    30 | Upper secondary           |
| 4881 |    30 | Upper secondary           |
| 4882 |    30 | Upper secondary           |
| 4901 |    30 | Upper secondary           |
| 4902 |    30 | Upper secondary           |
| 4903 |    30 | Upper secondary           |
| 4904 |    30 | Upper secondary           |
| 4905 |    30 | Upper secondary           |
| 4906 |    30 | Upper secondary           |
| 4907 |    30 | Upper secondary           |
| 4908 |    30 | Upper secondary           |
| 4909 |    30 | Upper secondary           |
| 4910 |    30 | Upper secondary           |
| 4911 |    30 | Upper secondary           |
| 4912 |    30 | Upper secondary           |
| 4913 |    30 | Upper secondary           |
| 4914 |    30 | Upper secondary           |
| 4915 |    30 | Upper secondary           |
| 4916 |    30 | Upper secondary           |
| 4917 |    30 | Upper secondary           |
| 4918 |    30 | Upper secondary           |
| 4919 |    30 | Upper secondary           |
| 4920 |    30 | Upper secondary           |
| 4921 |    30 | Upper secondary           |
| 4922 |    30 | Upper secondary           |
| 4923 |    30 | Upper secondary           |
| 4924 |    30 | Upper secondary           |
| 4925 |    30 | Upper secondary           |
| 4926 |    30 | Upper secondary           |
| 4927 |    30 | Upper secondary           |
| 4928 |    30 | Upper secondary           |
| 4929 |    30 | Upper secondary           |
| 4930 |    30 | Upper secondary           |
| 4931 |    30 | Upper secondary           |
| 4932 |    30 | Upper secondary           |
| 4933 |    30 | Upper secondary           |
| 4934 |    30 | Upper secondary           |
| 4937 |    30 | Upper secondary           |
| 4938 |    30 | Upper secondary           |
| 4939 |    30 | Upper secondary           |
| 4940 |    30 | Upper secondary           |
| 4941 |    30 | Upper secondary           |
| 4942 |    30 | Upper secondary           |
| 4943 |    30 | Upper secondary           |
| 4944 |    30 | Upper secondary           |
| 4945 |    30 | Upper secondary           |
| 4946 |    30 | Upper secondary           |
| 4947 |    30 | Upper secondary           |
| 4948 |    30 | Upper secondary           |
| 4949 |    30 | Upper secondary           |
| 4951 |    30 | Upper secondary           |
| 4952 |    30 | Upper secondary           |
| 4953 |    30 | Upper secondary           |
| 4954 |    30 | Upper secondary           |
| 4955 |    30 | Upper secondary           |
| 4956 |    30 | Upper secondary           |
| 4957 |    30 | Upper secondary           |
| 4958 |    30 | Upper secondary           |
| 4959 |    30 | Upper secondary           |
| 4960 |    30 | Upper secondary           |
| 4961 |    30 | Upper secondary           |
| 4962 |    30 | Upper secondary           |
| 4963 |    30 | Upper secondary           |
| 4964 |    30 | Upper secondary           |
| 4965 |    30 | Upper secondary           |
| 4966 |    30 | Upper secondary           |
| 4967 |    30 | Upper secondary           |
| 4968 |    30 | Upper secondary           |
| 4969 |    30 | Upper secondary           |
| 4970 |    30 | Upper secondary           |
| 4971 |    30 | Upper secondary           |
| 4977 |    30 | Upper secondary           |
| 4978 |    30 | Upper secondary           |
| 4979 |    30 | Upper secondary           |
| 4980 |    30 | Upper secondary           |
| 4981 |    30 | Upper secondary           |
| 4982 |    30 | Upper secondary           |
| 4983 |    30 | Upper secondary           |
| 4984 |    30 | Upper secondary           |
| 4985 |    30 | Upper secondary           |
| 4986 |    30 | Upper secondary           |
| 4987 |    30 | Upper secondary           |
| 4988 |    30 | Upper secondary           |
| 4989 |    30 | Upper secondary           |
| 4990 |    30 | Upper secondary           |
| 4991 |    30 | Upper secondary           |
| 4992 |    30 | Upper secondary           |
| 4994 |    30 | Upper secondary           |
| 4995 |    30 | Upper secondary           |
| 4996 |    30 | Upper secondary           |
| 4997 |    30 | Upper secondary           |
| 4998 |    30 | Upper secondary           |
| 4999 |    50 | Short cycle tertiary      |
| 5000 |    50 | Short cycle tertiary      |
| 5001 |    50 | Short cycle tertiary      |
| 5003 |    50 | Short cycle tertiary      |
| 5004 |    50 | Short cycle tertiary      |
| 5005 |    50 | Short cycle tertiary      |
| 5006 |    50 | Short cycle tertiary      |
| 5007 |    50 | Short cycle tertiary      |
| 5008 |    50 | Short cycle tertiary      |
| 5009 |    50 | Short cycle tertiary      |
| 5015 |    20 | Lower secondary           |
| 5016 |    20 | Lower secondary           |
| 5017 |    50 | Short cycle tertiary      |
| 5018 |    20 | Lower secondary           |
| 5019 |    20 | Lower secondary           |
| 5020 |    50 | Short cycle tertiary      |
| 5021 |    50 | Short cycle tertiary      |
| 5022 |    70 | Master or equivalent      |
| 5023 |    70 | Master or equivalent      |
| 5024 |    70 | Master or equivalent      |
| 5025 |    50 | Short cycle tertiary      |
| 5028 |    30 | Upper secondary           |
| 5029 |    30 | Upper secondary           |
| 5031 |    50 | Short cycle tertiary      |
| 5032 |    30 | Upper secondary           |
| 5033 |    50 | Short cycle tertiary      |
| 5034 |    50 | Short cycle tertiary      |
| 5035 |    50 | Short cycle tertiary      |
| 5036 |    50 | Short cycle tertiary      |
| 5037 |    50 | Short cycle tertiary      |
| 5038 |    50 | Short cycle tertiary      |
| 5039 |    50 | Short cycle tertiary      |
| 5040 |    50 | Short cycle tertiary      |
| 5041 |    50 | Short cycle tertiary      |
| 5042 |    50 | Short cycle tertiary      |
| 5043 |    50 | Short cycle tertiary      |
| 5044 |    20 | Lower secondary           |
| 5045 |    50 | Short cycle tertiary      |
| 5046 |    60 | Bachelor or equivalent    |
| 5047 |    60 | Bachelor or equivalent    |
| 5048 |    20 | Lower secondary           |
| 5049 |    20 | Lower secondary           |
| 5051 |    20 | Lower secondary           |
| 5052 |    20 | Lower secondary           |
| 5053 |    20 | Lower secondary           |
| 5054 |    20 | Lower secondary           |
| 5055 |    60 | Bachelor or equivalent    |
| 5056 |    70 | Master or equivalent      |
| 5057 |    70 | Master or equivalent      |
| 5058 |    70 | Master or equivalent      |
| 5059 |    70 | Master or equivalent      |
| 5060 |    60 | Bachelor or equivalent    |
| 5061 |    50 | Short cycle tertiary      |
| 5062 |    70 | Master or equivalent      |
| 5063 |    70 | Master or equivalent      |
| 5064 |    70 | Master or equivalent      |
| 5065 |    50 | Short cycle tertiary      |
| 5066 |    50 | Short cycle tertiary      |
| 5067 |    50 | Short cycle tertiary      |
| 5068 |    50 | Short cycle tertiary      |
| 5069 |    50 | Short cycle tertiary      |
| 5070 |    50 | Short cycle tertiary      |
| 5071 |    50 | Short cycle tertiary      |
| 5072 |    50 | Short cycle tertiary      |
| 5073 |    50 | Short cycle tertiary      |
| 5074 |    50 | Short cycle tertiary      |
| 5075 |    60 | Bachelor or equivalent    |
| 5076 |    50 | Short cycle tertiary      |
| 5077 |    50 | Short cycle tertiary      |
| 5078 |    50 | Short cycle tertiary      |
| 5079 |    50 | Short cycle tertiary      |
| 5080 |    30 | Upper secondary           |
| 5081 |    30 | Upper secondary           |
| 5082 |    50 | Short cycle tertiary      |
| 5083 |    50 | Short cycle tertiary      |
| 5084 |    50 | Short cycle tertiary      |
| 5085 |    50 | Short cycle tertiary      |
| 5086 |    50 | Short cycle tertiary      |
| 5087 |    50 | Short cycle tertiary      |
| 5088 |    30 | Upper secondary           |
| 5090 |    30 | Upper secondary           |
| 5091 |    20 | Lower secondary           |
| 5092 |    30 | Upper secondary           |
| 5093 |    50 | Short cycle tertiary      |
| 5094 |    50 | Short cycle tertiary      |
| 5095 |    50 | Short cycle tertiary      |
| 5096 |    50 | Short cycle tertiary      |
| 5097 |    30 | Upper secondary           |
| 5098 |    30 | Upper secondary           |
| 5099 |    50 | Short cycle tertiary      |
| 5100 |    50 | Short cycle tertiary      |
| 5101 |    70 | Master or equivalent      |
| 5102 |    70 | Master or equivalent      |
| 5103 |    70 | Master or equivalent      |
| 5104 |    70 | Master or equivalent      |
| 5105 |    70 | Master or equivalent      |
| 5106 |    70 | Master or equivalent      |
| 5107 |    70 | Master or equivalent      |
| 5108 |    70 | Master or equivalent      |
| 5109 |    70 | Master or equivalent      |
| 5110 |    50 | Short cycle tertiary      |
| 5111 |    60 | Bachelor or equivalent    |
| 5112 |    60 | Bachelor or equivalent    |
| 5113 |    60 | Bachelor or equivalent    |
| 5114 |    60 | Bachelor or equivalent    |
| 5115 |    60 | Bachelor or equivalent    |
| 5116 |    60 | Bachelor or equivalent    |
| 5117 |    60 | Bachelor or equivalent    |
| 5118 |    60 | Bachelor or equivalent    |
| 5119 |    60 | Bachelor or equivalent    |
| 5120 |    60 | Bachelor or equivalent    |
| 5121 |    50 | Short cycle tertiary      |
| 5122 |    50 | Short cycle tertiary      |
| 5123 |    50 | Short cycle tertiary      |
| 5124 |    50 | Short cycle tertiary      |
| 5125 |    50 | Short cycle tertiary      |
| 5126 |    30 | Upper secondary           |
| 5127 |    60 | Bachelor or equivalent    |
| 5128 |    60 | Bachelor or equivalent    |
| 5129 |    50 | Short cycle tertiary      |
| 5130 |    50 | Short cycle tertiary      |
| 5131 |    50 | Short cycle tertiary      |
| 5132 |    50 | Short cycle tertiary      |
| 5133 |    50 | Short cycle tertiary      |
| 5134 |    50 | Short cycle tertiary      |
| 5135 |    50 | Short cycle tertiary      |
| 5136 |    50 | Short cycle tertiary      |
| 5137 |    50 | Short cycle tertiary      |
| 5138 |    60 | Bachelor or equivalent    |
| 5139 |    50 | Short cycle tertiary      |
| 5140 |    50 | Short cycle tertiary      |
| 5141 |    50 | Short cycle tertiary      |
| 5142 |    30 | Upper secondary           |
| 5143 |    50 | Short cycle tertiary      |
| 5144 |    30 | Upper secondary           |
| 5145 |    30 | Upper secondary           |
| 5146 |    30 | Upper secondary           |
| 5147 |    30 | Upper secondary           |
| 5148 |    30 | Upper secondary           |
| 5149 |    30 | Upper secondary           |
| 5150 |    50 | Short cycle tertiary      |
| 5151 |    60 | Bachelor or equivalent    |
| 5152 |    30 | Upper secondary           |
| 5153 |    60 | Bachelor or equivalent    |
| 5154 |    60 | Bachelor or equivalent    |
| 5155 |    30 | Upper secondary           |
| 5156 |    50 | Short cycle tertiary      |
| 5157 |    60 | Bachelor or equivalent    |
| 5158 |    60 | Bachelor or equivalent    |
| 5159 |    60 | Bachelor or equivalent    |
| 5160 |    60 | Bachelor or equivalent    |
| 5161 |    60 | Bachelor or equivalent    |
| 5162 |    50 | Short cycle tertiary      |
| 5163 |    50 | Short cycle tertiary      |
| 5164 |    50 | Short cycle tertiary      |
| 5165 |    60 | Bachelor or equivalent    |
| 5166 |    60 | Bachelor or equivalent    |
| 5167 |    60 | Bachelor or equivalent    |
| 5168 |    60 | Bachelor or equivalent    |
| 5169 |    60 | Bachelor or equivalent    |
| 5170 |    60 | Bachelor or equivalent    |
| 5171 |    60 | Bachelor or equivalent    |
| 5172 |    60 | Bachelor or equivalent    |
| 5173 |    60 | Bachelor or equivalent    |
| 5174 |    50 | Short cycle tertiary      |
| 5175 |    60 | Bachelor or equivalent    |
| 5176 |    60 | Bachelor or equivalent    |
| 5177 |    50 | Short cycle tertiary      |
| 5178 |    60 | Bachelor or equivalent    |
| 5179 |    60 | Bachelor or equivalent    |
| 5180 |    70 | Master or equivalent      |
| 5181 |    60 | Bachelor or equivalent    |
| 5182 |    30 | Upper secondary           |
| 5183 |    30 | Upper secondary           |
| 5184 |    50 | Short cycle tertiary      |
| 5185 |    30 | Upper secondary           |
| 5186 |    30 | Upper secondary           |
| 5187 |    60 | Bachelor or equivalent    |
| 5188 |    60 | Bachelor or equivalent    |
| 5189 |    60 | Bachelor or equivalent    |
| 5190 |    60 | Bachelor or equivalent    |
| 5191 |    60 | Bachelor or equivalent    |
| 5192 |    60 | Bachelor or equivalent    |
| 5193 |    60 | Bachelor or equivalent    |
| 5194 |    60 | Bachelor or equivalent    |
| 5195 |    50 | Short cycle tertiary      |
| 5196 |    50 | Short cycle tertiary      |
| 5197 |    50 | Short cycle tertiary      |
| 5198 |    50 | Short cycle tertiary      |
| 5199 |    50 | Short cycle tertiary      |
| 5200 |    30 | Upper secondary           |
| 5201 |    30 | Upper secondary           |
| 5202 |    30 | Upper secondary           |
| 5203 |    50 | Short cycle tertiary      |
| 5204 |    70 | Master or equivalent      |
| 5205 |    30 | Upper secondary           |
| 5206 |    30 | Upper secondary           |
| 5207 |    30 | Upper secondary           |
| 5208 |    30 | Upper secondary           |
| 5209 |    30 | Upper secondary           |
| 5210 |    60 | Bachelor or equivalent    |
| 5211 |    60 | Bachelor or equivalent    |
| 5212 |    70 | Master or equivalent      |
| 5213 |    70 | Master or equivalent      |
| 5214 |    70 | Master or equivalent      |
| 5215 |    30 | Upper secondary           |
| 5216 |    70 | Master or equivalent      |
| 5217 |    70 | Master or equivalent      |
| 5218 |    70 | Master or equivalent      |
| 5219 |    70 | Master or equivalent      |
| 5220 |    50 | Short cycle tertiary      |
| 5221 |    60 | Bachelor or equivalent    |
| 5222 |    60 | Bachelor or equivalent    |
| 5223 |    60 | Bachelor or equivalent    |
| 5224 |    60 | Bachelor or equivalent    |
| 5225 |    60 | Bachelor or equivalent    |
| 5226 |    60 | Bachelor or equivalent    |
| 5227 |    60 | Bachelor or equivalent    |
| 5228 |    60 | Bachelor or equivalent    |
| 5229 |    60 | Bachelor or equivalent    |
| 5230 |    30 | Upper secondary           |
| 5231 |    50 | Short cycle tertiary      |
| 5232 |    50 | Short cycle tertiary      |
| 5233 |    50 | Short cycle tertiary      |
| 5234 |    50 | Short cycle tertiary      |
| 5235 |    50 | Short cycle tertiary      |
| 5236 |    70 | Master or equivalent      |
| 5237 |    70 | Master or equivalent      |
| 5238 |    50 | Short cycle tertiary      |
| 5239 |    70 | Master or equivalent      |
| 5240 |    70 | Master or equivalent      |
| 5241 |    70 | Master or equivalent      |
| 5242 |    70 | Master or equivalent      |
| 5243 |    70 | Master or equivalent      |
| 5244 |    70 | Master or equivalent      |
| 5245 |    70 | Master or equivalent      |
| 5246 |    60 | Bachelor or equivalent    |
| 5247 |    60 | Bachelor or equivalent    |
| 5248 |    60 | Bachelor or equivalent    |
| 5249 |    70 | Master or equivalent      |
| 5250 |    60 | Bachelor or equivalent    |
| 5251 |    60 | Bachelor or equivalent    |
| 5252 |    60 | Bachelor or equivalent    |
| 5253 |    60 | Bachelor or equivalent    |
| 5254 |    60 | Bachelor or equivalent    |
| 5255 |    60 | Bachelor or equivalent    |
| 5256 |    60 | Bachelor or equivalent    |
| 5257 |    60 | Bachelor or equivalent    |
| 5258 |    60 | Bachelor or equivalent    |
| 5259 |    60 | Bachelor or equivalent    |
| 5260 |    50 | Short cycle tertiary      |
| 5265 |    70 | Master or equivalent      |
| 5266 |    60 | Bachelor or equivalent    |
| 5267 |    60 | Bachelor or equivalent    |
| 5268 |    60 | Bachelor or equivalent    |
| 5269 |    60 | Bachelor or equivalent    |
| 5270 |    60 | Bachelor or equivalent    |
| 5271 |    70 | Master or equivalent      |
| 5272 |    70 | Master or equivalent      |
| 5273 |    70 | Master or equivalent      |
| 5274 |    70 | Master or equivalent      |
| 5275 |    60 | Bachelor or equivalent    |
| 5276 |    60 | Bachelor or equivalent    |
| 5277 |    60 | Bachelor or equivalent    |
| 5278 |    60 | Bachelor or equivalent    |
| 5279 |    60 | Bachelor or equivalent    |
| 5280 |    60 | Bachelor or equivalent    |
| 5281 |    60 | Bachelor or equivalent    |
| 5282 |    60 | Bachelor or equivalent    |
| 5283 |    60 | Bachelor or equivalent    |
| 5284 |    60 | Bachelor or equivalent    |
| 5285 |    70 | Master or equivalent      |
| 5286 |    70 | Master or equivalent      |
| 5295 |    50 | Short cycle tertiary      |
| 5298 |    30 | Upper secondary           |
| 5299 |    30 | Upper secondary           |
| 5300 |    60 | Bachelor or equivalent    |
| 5301 |    60 | Bachelor or equivalent    |
| 5302 |    60 | Bachelor or equivalent    |
| 5303 |    60 | Bachelor or equivalent    |
| 5304 |    60 | Bachelor or equivalent    |
| 5305 |    60 | Bachelor or equivalent    |
| 5306 |    60 | Bachelor or equivalent    |
| 5307 |    60 | Bachelor or equivalent    |
| 5308 |    60 | Bachelor or equivalent    |
| 5309 |    60 | Bachelor or equivalent    |
| 5310 |    60 | Bachelor or equivalent    |
| 5311 |    60 | Bachelor or equivalent    |
| 5312 |    60 | Bachelor or equivalent    |
| 5313 |    60 | Bachelor or equivalent    |
| 5314 |    60 | Bachelor or equivalent    |
| 5315 |    60 | Bachelor or equivalent    |
| 5316 |    60 | Bachelor or equivalent    |
| 5317 |    60 | Bachelor or equivalent    |
| 5318 |    60 | Bachelor or equivalent    |
| 5319 |    60 | Bachelor or equivalent    |
| 5320 |    60 | Bachelor or equivalent    |
| 5321 |    60 | Bachelor or equivalent    |
| 5322 |    60 | Bachelor or equivalent    |
| 5323 |    60 | Bachelor or equivalent    |
| 5324 |    60 | Bachelor or equivalent    |
| 5325 |    60 | Bachelor or equivalent    |
| 5326 |    60 | Bachelor or equivalent    |
| 5327 |    60 | Bachelor or equivalent    |
| 5328 |    60 | Bachelor or equivalent    |
| 5329 |    60 | Bachelor or equivalent    |
| 5330 |    60 | Bachelor or equivalent    |
| 5331 |    60 | Bachelor or equivalent    |
| 5332 |    60 | Bachelor or equivalent    |
| 5333 |    60 | Bachelor or equivalent    |
| 5334 |    60 | Bachelor or equivalent    |
| 5335 |    60 | Bachelor or equivalent    |
| 5336 |    60 | Bachelor or equivalent    |
| 5337 |    60 | Bachelor or equivalent    |
| 5338 |    60 | Bachelor or equivalent    |
| 5339 |    60 | Bachelor or equivalent    |
| 5340 |    60 | Bachelor or equivalent    |
| 5341 |    60 | Bachelor or equivalent    |
| 5342 |    60 | Bachelor or equivalent    |
| 5343 |    60 | Bachelor or equivalent    |
| 5344 |    60 | Bachelor or equivalent    |
| 5345 |    60 | Bachelor or equivalent    |
| 5346 |    60 | Bachelor or equivalent    |
| 5347 |    60 | Bachelor or equivalent    |
| 5349 |    60 | Bachelor or equivalent    |
| 5350 |    60 | Bachelor or equivalent    |
| 5351 |    60 | Bachelor or equivalent    |
| 5352 |    60 | Bachelor or equivalent    |
| 5353 |    60 | Bachelor or equivalent    |
| 5354 |    60 | Bachelor or equivalent    |
| 5355 |    60 | Bachelor or equivalent    |
| 5356 |    60 | Bachelor or equivalent    |
| 5357 |    60 | Bachelor or equivalent    |
| 5358 |    60 | Bachelor or equivalent    |
| 5359 |    60 | Bachelor or equivalent    |
| 5360 |    70 | Master or equivalent      |
| 5361 |    70 | Master or equivalent      |
| 5362 |    70 | Master or equivalent      |
| 5363 |    70 | Master or equivalent      |
| 5364 |    70 | Master or equivalent      |
| 5365 |    70 | Master or equivalent      |
| 5366 |    70 | Master or equivalent      |
| 5367 |    70 | Master or equivalent      |
| 5368 |    70 | Master or equivalent      |
| 5369 |    70 | Master or equivalent      |
| 5370 |    70 | Master or equivalent      |
| 5371 |    70 | Master or equivalent      |
| 5372 |    70 | Master or equivalent      |
| 5373 |    70 | Master or equivalent      |
| 5374 |    70 | Master or equivalent      |
| 5375 |    70 | Master or equivalent      |
| 5376 |    70 | Master or equivalent      |
| 5377 |    70 | Master or equivalent      |
| 5378 |    70 | Master or equivalent      |
| 5379 |    70 | Master or equivalent      |
| 5380 |    70 | Master or equivalent      |
| 5381 |    70 | Master or equivalent      |
| 5382 |    70 | Master or equivalent      |
| 5383 |    70 | Master or equivalent      |
| 5384 |    70 | Master or equivalent      |
| 5385 |    70 | Master or equivalent      |
| 5386 |    70 | Master or equivalent      |
| 5387 |    70 | Master or equivalent      |
| 5388 |    70 | Master or equivalent      |
| 5389 |    70 | Master or equivalent      |
| 5390 |    70 | Master or equivalent      |
| 5391 |    70 | Master or equivalent      |
| 5392 |    70 | Master or equivalent      |
| 5393 |    70 | Master or equivalent      |
| 5394 |    70 | Master or equivalent      |
| 5395 |    70 | Master or equivalent      |
| 5396 |    70 | Master or equivalent      |
| 5397 |    70 | Master or equivalent      |
| 5398 |    70 | Master or equivalent      |
| 5399 |    80 | Doctoral or equivalent    |
| 5400 |    70 | Master or equivalent      |
| 5401 |    70 | Master or equivalent      |
| 5402 |    70 | Master or equivalent      |
| 5403 |    70 | Master or equivalent      |
| 5404 |    70 | Master or equivalent      |
| 5406 |    70 | Master or equivalent      |
| 5408 |    70 | Master or equivalent      |
| 5409 |    70 | Master or equivalent      |
| 5410 |    70 | Master or equivalent      |
| 5412 |    70 | Master or equivalent      |
| 5413 |    70 | Master or equivalent      |
| 5414 |    70 | Master or equivalent      |
| 5415 |    70 | Master or equivalent      |
| 5416 |    80 | Doctoral or equivalent    |
| 5417 |    80 | Doctoral or equivalent    |
| 5419 |    70 | Master or equivalent      |
| 5420 |    70 | Master or equivalent      |
| 5421 |    70 | Master or equivalent      |
| 5422 |    70 | Master or equivalent      |
| 5423 |    70 | Master or equivalent      |
| 5424 |    60 | Bachelor or equivalent    |
| 5425 |    70 | Master or equivalent      |
| 5426 |    60 | Bachelor or equivalent    |
| 5427 |    80 | Doctoral or equivalent    |
| 5428 |    70 | Master or equivalent      |
| 5429 |    60 | Bachelor or equivalent    |
| 5430 |    70 | Master or equivalent      |
| 5431 |    60 | Bachelor or equivalent    |
| 5432 |    50 | Short cycle tertiary      |
| 5433 |    70 | Master or equivalent      |
| 5434 |    60 | Bachelor or equivalent    |
| 5435 |    80 | Doctoral or equivalent    |
| 5436 |    60 | Bachelor or equivalent    |
| 5437 |    60 | Bachelor or equivalent    |
| 5438 |    60 | Bachelor or equivalent    |
| 5439 |    60 | Bachelor or equivalent    |
| 5440 |    60 | Bachelor or equivalent    |
| 5441 |    60 | Bachelor or equivalent    |
| 5442 |    60 | Bachelor or equivalent    |
| 5443 |    30 | Upper secondary           |
| 5444 |    60 | Bachelor or equivalent    |
| 5445 |    60 | Bachelor or equivalent    |
| 5446 |    60 | Bachelor or equivalent    |
| 5447 |    60 | Bachelor or equivalent    |
| 5448 |    70 | Master or equivalent      |
| 5449 |    70 | Master or equivalent      |
| 5450 |    60 | Bachelor or equivalent    |
| 5451 |    60 | Bachelor or equivalent    |
| 5452 |    70 | Master or equivalent      |
| 5453 |    70 | Master or equivalent      |
| 5454 |    70 | Master or equivalent      |
| 5455 |    70 | Master or equivalent      |
| 5456 |    60 | Bachelor or equivalent    |
| 5457 |    60 | Bachelor or equivalent    |
| 5458 |    60 | Bachelor or equivalent    |
| 5459 |    60 | Bachelor or equivalent    |
| 5460 |    60 | Bachelor or equivalent    |
| 5461 |    60 | Bachelor or equivalent    |
| 5462 |    60 | Bachelor or equivalent    |
| 5463 |    60 | Bachelor or equivalent    |
| 5464 |    80 | Doctoral or equivalent    |
| 5465 |    70 | Master or equivalent      |
| 5467 |    60 | Bachelor or equivalent    |
| 5468 |    70 | Master or equivalent      |
| 5469 |    60 | Bachelor or equivalent    |
| 5470 |    70 | Master or equivalent      |
| 5471 |    60 | Bachelor or equivalent    |
| 5472 |    60 | Bachelor or equivalent    |
| 5473 |    60 | Bachelor or equivalent    |
| 5474 |    70 | Master or equivalent      |
| 5475 |    60 | Bachelor or equivalent    |
| 5476 |    60 | Bachelor or equivalent    |
| 5477 |    60 | Bachelor or equivalent    |
| 5478 |    60 | Bachelor or equivalent    |
| 5479 |    60 | Bachelor or equivalent    |
| 5480 |    80 | Doctoral or equivalent    |
| 5481 |    60 | Bachelor or equivalent    |
| 5482 |    60 | Bachelor or equivalent    |
| 5483 |    60 | Bachelor or equivalent    |
| 5484 |    60 | Bachelor or equivalent    |
| 5485 |    60 | Bachelor or equivalent    |
| 5486 |    60 | Bachelor or equivalent    |
| 5487 |    60 | Bachelor or equivalent    |
| 5488 |    60 | Bachelor or equivalent    |
| 5489 |    60 | Bachelor or equivalent    |
| 5490 |    60 | Bachelor or equivalent    |
| 5491 |    60 | Bachelor or equivalent    |
| 5492 |    60 | Bachelor or equivalent    |
| 5493 |    50 | Short cycle tertiary      |
| 5494 |    60 | Bachelor or equivalent    |
| 5495 |    50 | Short cycle tertiary      |
| 5496 |    50 | Short cycle tertiary      |
| 5497 |    60 | Bachelor or equivalent    |
| 5498 |    60 | Bachelor or equivalent    |
| 5499 |    60 | Bachelor or equivalent    |
| 5500 |    60 | Bachelor or equivalent    |
| 5501 |    60 | Bachelor or equivalent    |
| 5502 |    60 | Bachelor or equivalent    |
| 5504 |    60 | Bachelor or equivalent    |
| 5508 |    60 | Bachelor or equivalent    |
| 5509 |    60 | Bachelor or equivalent    |
| 5511 |    60 | Bachelor or equivalent    |
| 5512 |    60 | Bachelor or equivalent    |
| 5513 |    60 | Bachelor or equivalent    |
| 5514 |    60 | Bachelor or equivalent    |
| 5515 |    60 | Bachelor or equivalent    |
| 5516 |    60 | Bachelor or equivalent    |
| 5517 |    60 | Bachelor or equivalent    |
| 5518 |    60 | Bachelor or equivalent    |
| 5519 |    60 | Bachelor or equivalent    |
| 5520 |    60 | Bachelor or equivalent    |
| 5521 |    60 | Bachelor or equivalent    |
| 5522 |    60 | Bachelor or equivalent    |
| 5523 |    60 | Bachelor or equivalent    |
| 5524 |    60 | Bachelor or equivalent    |
| 5525 |    60 | Bachelor or equivalent    |
| 5526 |    60 | Bachelor or equivalent    |
| 5527 |    60 | Bachelor or equivalent    |
| 5528 |    60 | Bachelor or equivalent    |
| 5529 |    60 | Bachelor or equivalent    |
| 5530 |    60 | Bachelor or equivalent    |
| 5531 |    60 | Bachelor or equivalent    |
| 5532 |    70 | Master or equivalent      |
| 5533 |    70 | Master or equivalent      |
| 5534 |    70 | Master or equivalent      |
| 5535 |    70 | Master or equivalent      |
| 5536 |    70 | Master or equivalent      |
| 5537 |    70 | Master or equivalent      |
| 5541 |    60 | Bachelor or equivalent    |
| 5542 |    60 | Bachelor or equivalent    |
| 5543 |    60 | Bachelor or equivalent    |
| 5545 |    60 | Bachelor or equivalent    |
| 5546 |    60 | Bachelor or equivalent    |
| 5547 |    60 | Bachelor or equivalent    |
| 5550 |    60 | Bachelor or equivalent    |
| 5551 |    60 | Bachelor or equivalent    |
| 5552 |    60 | Bachelor or equivalent    |
| 5553 |    60 | Bachelor or equivalent    |
| 5555 |    60 | Bachelor or equivalent    |
| 5556 |    60 | Bachelor or equivalent    |
| 5557 |    60 | Bachelor or equivalent    |
| 5561 |    60 | Bachelor or equivalent    |
| 5562 |    60 | Bachelor or equivalent    |
| 5563 |    60 | Bachelor or equivalent    |
| 5564 |    60 | Bachelor or equivalent    |
| 5565 |    60 | Bachelor or equivalent    |
| 5566 |    60 | Bachelor or equivalent    |
| 5569 |    60 | Bachelor or equivalent    |
| 5571 |    70 | Master or equivalent      |
| 5572 |    70 | Master or equivalent      |
| 5575 |    60 | Bachelor or equivalent    |
| 5576 |    70 | Master or equivalent      |
| 5577 |    70 | Master or equivalent      |
| 5578 |    70 | Master or equivalent      |
| 5579 |    60 | Bachelor or equivalent    |
| 5580 |    80 | Doctoral or equivalent    |
| 5581 |    60 | Bachelor or equivalent    |
| 5582 |    60 | Bachelor or equivalent    |
| 5583 |    60 | Bachelor or equivalent    |
| 5586 |    60 | Bachelor or equivalent    |
| 5587 |    60 | Bachelor or equivalent    |
| 5589 |    70 | Master or equivalent      |
| 5590 |    70 | Master or equivalent      |
| 5591 |    70 | Master or equivalent      |
| 5592 |    70 | Master or equivalent      |
| 5593 |    70 | Master or equivalent      |
| 5594 |    70 | Master or equivalent      |
| 5595 |    70 | Master or equivalent      |
| 5596 |    70 | Master or equivalent      |
| 5597 |    70 | Master or equivalent      |
| 5598 |    70 | Master or equivalent      |
| 5599 |    70 | Master or equivalent      |
| 5600 |    60 | Bachelor or equivalent    |
| 5602 |    60 | Bachelor or equivalent    |
| 5603 |    60 | Bachelor or equivalent    |
| 5606 |    60 | Bachelor or equivalent    |
| 5607 |    60 | Bachelor or equivalent    |
| 5608 |    70 | Master or equivalent      |
| 5609 |    70 | Master or equivalent      |
| 5611 |    80 | Doctoral or equivalent    |
| 5615 |    80 | Doctoral or equivalent    |
| 5616 |    70 | Master or equivalent      |
| 5618 |    80 | Doctoral or equivalent    |
| 5619 |    80 | Doctoral or equivalent    |
| 5620 |    80 | Doctoral or equivalent    |
| 5621 |    70 | Master or equivalent      |
| 5622 |    70 | Master or equivalent      |
| 5623 |    70 | Master or equivalent      |
| 5624 |    70 | Master or equivalent      |
| 5630 |    50 | Short cycle tertiary      |
| 5631 |    50 | Short cycle tertiary      |
| 5632 |    50 | Short cycle tertiary      |
| 5633 |    50 | Short cycle tertiary      |
| 5635 |    50 | Short cycle tertiary      |
| 5636 |    50 | Short cycle tertiary      |
| 5637 |    50 | Short cycle tertiary      |
| 5651 |    60 | Bachelor or equivalent    |
| 5652 |    70 | Master or equivalent      |
| 5653 |    70 | Master or equivalent      |
| 5654 |    60 | Bachelor or equivalent    |
| 5656 |    60 | Bachelor or equivalent    |
| 5657 |    70 | Master or equivalent      |
| 5658 |    70 | Master or equivalent      |
| 5661 |    60 | Bachelor or equivalent    |
| 5662 |    70 | Master or equivalent      |
| 5663 |    60 | Bachelor or equivalent    |
| 5666 |    60 | Bachelor or equivalent    |
| 5667 |    70 | Master or equivalent      |
| 5670 |    60 | Bachelor or equivalent    |
| 5671 |    60 | Bachelor or equivalent    |
| 5672 |    60 | Bachelor or equivalent    |
| 5673 |    60 | Bachelor or equivalent    |
| 5674 |    60 | Bachelor or equivalent    |
| 5675 |    60 | Bachelor or equivalent    |
| 5676 |    60 | Bachelor or equivalent    |
| 5677 |    60 | Bachelor or equivalent    |
| 5678 |    60 | Bachelor or equivalent    |
| 5679 |    60 | Bachelor or equivalent    |
| 5680 |    70 | Master or equivalent      |
| 5681 |    60 | Bachelor or equivalent    |
| 5682 |    60 | Bachelor or equivalent    |
| 5683 |    60 | Bachelor or equivalent    |
| 5684 |    60 | Bachelor or equivalent    |
| 5685 |    60 | Bachelor or equivalent    |
| 5686 |    60 | Bachelor or equivalent    |
| 5687 |    60 | Bachelor or equivalent    |
| 5688 |    60 | Bachelor or equivalent    |
| 5689 |    60 | Bachelor or equivalent    |
| 5690 |    60 | Bachelor or equivalent    |
| 5691 |    60 | Bachelor or equivalent    |
| 5692 |    60 | Bachelor or equivalent    |
| 5693 |    60 | Bachelor or equivalent    |
| 5694 |    60 | Bachelor or equivalent    |
| 5695 |    60 | Bachelor or equivalent    |
| 5696 |    60 | Bachelor or equivalent    |
| 5697 |    60 | Bachelor or equivalent    |
| 5698 |    60 | Bachelor or equivalent    |
| 5700 |    60 | Bachelor or equivalent    |
| 5701 |    60 | Bachelor or equivalent    |
| 5702 |    60 | Bachelor or equivalent    |
| 5703 |    70 | Master or equivalent      |
| 5704 |    60 | Bachelor or equivalent    |
| 5705 |    80 | Doctoral or equivalent    |
| 5706 |    60 | Bachelor or equivalent    |
| 5707 |    60 | Bachelor or equivalent    |
| 5708 |    70 | Master or equivalent      |
| 5709 |    60 | Bachelor or equivalent    |
| 5710 |    60 | Bachelor or equivalent    |
| 5711 |    60 | Bachelor or equivalent    |
| 5712 |    60 | Bachelor or equivalent    |
| 5713 |    60 | Bachelor or equivalent    |
| 5714 |    60 | Bachelor or equivalent    |
| 5715 |    60 | Bachelor or equivalent    |
| 5716 |    60 | Bachelor or equivalent    |
| 5717 |    70 | Master or equivalent      |
| 5718 |    60 | Bachelor or equivalent    |
| 5719 |    60 | Bachelor or equivalent    |
| 5720 |    60 | Bachelor or equivalent    |
| 5721 |    60 | Bachelor or equivalent    |
| 5722 |    60 | Bachelor or equivalent    |
| 5723 |    60 | Bachelor or equivalent    |
| 5724 |    60 | Bachelor or equivalent    |
| 5725 |    60 | Bachelor or equivalent    |
| 5726 |    60 | Bachelor or equivalent    |
| 5727 |    60 | Bachelor or equivalent    |
| 5728 |    60 | Bachelor or equivalent    |
| 5729 |    60 | Bachelor or equivalent    |
| 5730 |    60 | Bachelor or equivalent    |
| 5731 |    60 | Bachelor or equivalent    |
| 5732 |    60 | Bachelor or equivalent    |
| 5733 |    60 | Bachelor or equivalent    |
| 5734 |    60 | Bachelor or equivalent    |
| 5735 |    60 | Bachelor or equivalent    |
| 5736 |    60 | Bachelor or equivalent    |
| 5737 |    70 | Master or equivalent      |
| 5738 |    70 | Master or equivalent      |
| 5739 |    70 | Master or equivalent      |
| 5740 |    70 | Master or equivalent      |
| 5741 |    70 | Master or equivalent      |
| 5742 |    70 | Master or equivalent      |
| 5743 |    70 | Master or equivalent      |
| 5744 |    70 | Master or equivalent      |
| 5745 |    80 | Doctoral or equivalent    |
| 5746 |    60 | Bachelor or equivalent    |
| 5747 |    60 | Bachelor or equivalent    |
| 5748 |    60 | Bachelor or equivalent    |
| 5749 |    60 | Bachelor or equivalent    |
| 5750 |    70 | Master or equivalent      |
| 5751 |    70 | Master or equivalent      |
| 5752 |    70 | Master or equivalent      |
| 5753 |    70 | Master or equivalent      |
| 5754 |    70 | Master or equivalent      |
| 5755 |    60 | Bachelor or equivalent    |
| 5756 |    70 | Master or equivalent      |
| 5757 |    70 | Master or equivalent      |
| 5758 |    70 | Master or equivalent      |
| 5759 |    70 | Master or equivalent      |
| 5761 |    70 | Master or equivalent      |
| 5762 |    70 | Master or equivalent      |
| 5763 |    70 | Master or equivalent      |
| 5764 |    60 | Bachelor or equivalent    |
| 5766 |    60 | Bachelor or equivalent    |
| 5767 |    60 | Bachelor or equivalent    |
| 5768 |    60 | Bachelor or equivalent    |
| 5769 |    60 | Bachelor or equivalent    |
| 5770 |    70 | Master or equivalent      |
| 5771 |    70 | Master or equivalent      |
| 5772 |    70 | Master or equivalent      |
| 5773 |    70 | Master or equivalent      |
| 5774 |    70 | Master or equivalent      |
| 5776 |    60 | Bachelor or equivalent    |
| 5777 |    60 | Bachelor or equivalent    |
| 5778 |    60 | Bachelor or equivalent    |
| 5779 |    70 | Master or equivalent      |
| 5780 |    60 | Bachelor or equivalent    |
| 5781 |    60 | Bachelor or equivalent    |
| 5782 |    70 | Master or equivalent      |
| 5783 |    60 | Bachelor or equivalent    |
| 5784 |    70 | Master or equivalent      |
| 5785 |    70 | Master or equivalent      |
| 5786 |    70 | Master or equivalent      |
| 5787 |    70 | Master or equivalent      |
| 5788 |    70 | Master or equivalent      |
| 5789 |    70 | Master or equivalent      |
| 5790 |    60 | Bachelor or equivalent    |
| 5791 |    60 | Bachelor or equivalent    |
| 5792 |    70 | Master or equivalent      |
| 5793 |    70 | Master or equivalent      |
| 5794 |    70 | Master or equivalent      |
| 5795 |    70 | Master or equivalent      |
| 5796 |    70 | Master or equivalent      |
| 5797 |    60 | Bachelor or equivalent    |
| 5798 |    70 | Master or equivalent      |
| 5799 |    60 | Bachelor or equivalent    |
| 5801 |    60 | Bachelor or equivalent    |
| 5802 |    60 | Bachelor or equivalent    |
| 5803 |    60 | Bachelor or equivalent    |
| 5804 |    60 | Bachelor or equivalent    |
| 5805 |    60 | Bachelor or equivalent    |
| 5806 |    60 | Bachelor or equivalent    |
| 5807 |    60 | Bachelor or equivalent    |
| 5808 |    60 | Bachelor or equivalent    |
| 5809 |    70 | Master or equivalent      |
| 5810 |    70 | Master or equivalent      |
| 5811 |    70 | Master or equivalent      |
| 5812 |    70 | Master or equivalent      |
| 5813 |    60 | Bachelor or equivalent    |
| 5814 |    60 | Bachelor or equivalent    |
| 5816 |    60 | Bachelor or equivalent    |
| 5817 |    60 | Bachelor or equivalent    |
| 5818 |    60 | Bachelor or equivalent    |
| 5819 |    60 | Bachelor or equivalent    |
| 5820 |    70 | Master or equivalent      |
| 5821 |    70 | Master or equivalent      |
| 5822 |    70 | Master or equivalent      |
| 5823 |    70 | Master or equivalent      |
| 5824 |    70 | Master or equivalent      |
| 5825 |    70 | Master or equivalent      |
| 5826 |    60 | Bachelor or equivalent    |
| 5827 |    60 | Bachelor or equivalent    |
| 5828 |    60 | Bachelor or equivalent    |
| 5829 |    60 | Bachelor or equivalent    |
| 5830 |    50 | Short cycle tertiary      |
| 5831 |    60 | Bachelor or equivalent    |
| 5832 |    70 | Master or equivalent      |
| 5833 |    60 | Bachelor or equivalent    |
| 5834 |    60 | Bachelor or equivalent    |
| 5836 |    60 | Bachelor or equivalent    |
| 5837 |    60 | Bachelor or equivalent    |
| 5838 |    60 | Bachelor or equivalent    |
| 5839 |    80 | Doctoral or equivalent    |
| 5840 |    70 | Master or equivalent      |
| 5841 |    70 | Master or equivalent      |
| 5842 |    70 | Master or equivalent      |
| 5843 |    70 | Master or equivalent      |
| 5844 |    70 | Master or equivalent      |
| 5846 |    60 | Bachelor or equivalent    |
| 5847 |    60 | Bachelor or equivalent    |
| 5848 |    60 | Bachelor or equivalent    |
| 5849 |    60 | Bachelor or equivalent    |
| 5850 |    60 | Bachelor or equivalent    |
| 5851 |    60 | Bachelor or equivalent    |
| 5852 |    60 | Bachelor or equivalent    |
| 5855 |    60 | Bachelor or equivalent    |
| 5856 |    60 | Bachelor or equivalent    |
| 5857 |    60 | Bachelor or equivalent    |
| 5858 |    70 | Master or equivalent      |
| 5859 |    60 | Bachelor or equivalent    |
| 5860 |    60 | Bachelor or equivalent    |
| 5865 |    60 | Bachelor or equivalent    |
| 5866 |    60 | Bachelor or equivalent    |
| 5867 |    60 | Bachelor or equivalent    |
| 5868 |    60 | Bachelor or equivalent    |
| 5869 |    60 | Bachelor or equivalent    |
| 5870 |    60 | Bachelor or equivalent    |
| 5871 |    60 | Bachelor or equivalent    |
| 5872 |    60 | Bachelor or equivalent    |
| 5873 |    60 | Bachelor or equivalent    |
| 5874 |    30 | Upper secondary           |
| 5875 |    70 | Master or equivalent      |
| 5876 |    30 | Upper secondary           |
| 5877 |    70 | Master or equivalent      |
| 5878 |    30 | Upper secondary           |
| 5879 |    30 | Upper secondary           |
| 5880 |    70 | Master or equivalent      |
| 5885 |    70 | Master or equivalent      |
| 5886 |    70 | Master or equivalent      |
| 5889 |    70 | Master or equivalent      |
| 5890 |    70 | Master or equivalent      |
| 5895 |    50 | Short cycle tertiary      |
| 5897 |    70 | Master or equivalent      |
| 5898 |    70 | Master or equivalent      |
| 5899 |    60 | Bachelor or equivalent    |
| 5900 |    70 | Master or equivalent      |
| 5901 |    70 | Master or equivalent      |
| 5902 |    70 | Master or equivalent      |
| 5903 |    70 | Master or equivalent      |
| 5904 |    50 | Short cycle tertiary      |
| 5905 |    60 | Bachelor or equivalent    |
| 5906 |    70 | Master or equivalent      |
| 5907 |    60 | Bachelor or equivalent    |
| 5908 |    60 | Bachelor or equivalent    |
| 5909 |    70 | Master or equivalent      |
| 5911 |    60 | Bachelor or equivalent    |
| 5912 |    60 | Bachelor or equivalent    |
| 5913 |    70 | Master or equivalent      |
| 5914 |    60 | Bachelor or equivalent    |
| 5915 |    60 | Bachelor or equivalent    |
| 5916 |    70 | Master or equivalent      |
| 5917 |    70 | Master or equivalent      |
| 5918 |    70 | Master or equivalent      |
| 5919 |    80 | Doctoral or equivalent    |
| 5921 |    60 | Bachelor or equivalent    |
| 5922 |    70 | Master or equivalent      |
| 5923 |    60 | Bachelor or equivalent    |
| 5924 |    70 | Master or equivalent      |
| 5925 |    70 | Master or equivalent      |
| 5926 |    70 | Master or equivalent      |
| 5927 |    60 | Bachelor or equivalent    |
| 5928 |    60 | Bachelor or equivalent    |
| 5929 |    70 | Master or equivalent      |
| 5931 |    60 | Bachelor or equivalent    |
| 5932 |    60 | Bachelor or equivalent    |
| 5933 |    60 | Bachelor or equivalent    |
| 5934 |    60 | Bachelor or equivalent    |
| 5935 |    60 | Bachelor or equivalent    |
| 5936 |    60 | Bachelor or equivalent    |
| 5937 |    60 | Bachelor or equivalent    |
| 5938 |    60 | Bachelor or equivalent    |
| 5939 |    60 | Bachelor or equivalent    |
| 5940 |    60 | Bachelor or equivalent    |
| 5941 |    60 | Bachelor or equivalent    |
| 5942 |    60 | Bachelor or equivalent    |
| 5943 |    60 | Bachelor or equivalent    |
| 5944 |    60 | Bachelor or equivalent    |
| 5945 |    60 | Bachelor or equivalent    |
| 5946 |    60 | Bachelor or equivalent    |
| 5947 |    60 | Bachelor or equivalent    |
| 5948 |    60 | Bachelor or equivalent    |
| 5949 |    60 | Bachelor or equivalent    |
| 5950 |    60 | Bachelor or equivalent    |
| 5951 |    60 | Bachelor or equivalent    |
| 5952 |    60 | Bachelor or equivalent    |
| 5953 |    60 | Bachelor or equivalent    |
| 5954 |    60 | Bachelor or equivalent    |
| 5955 |    60 | Bachelor or equivalent    |
| 5956 |    60 | Bachelor or equivalent    |
| 5957 |    60 | Bachelor or equivalent    |
| 5958 |    60 | Bachelor or equivalent    |
| 5959 |    60 | Bachelor or equivalent    |
| 5960 |    60 | Bachelor or equivalent    |
| 5961 |    60 | Bachelor or equivalent    |
| 5962 |    70 | Master or equivalent      |
| 5963 |    70 | Master or equivalent      |
| 5964 |    70 | Master or equivalent      |
| 5965 |    70 | Master or equivalent      |
| 5966 |    70 | Master or equivalent      |
| 5967 |    70 | Master or equivalent      |
| 5968 |    70 | Master or equivalent      |
| 5969 |    70 | Master or equivalent      |
| 5970 |    60 | Bachelor or equivalent    |
| 5971 |    60 | Bachelor or equivalent    |
| 5972 |    60 | Bachelor or equivalent    |
| 5973 |    60 | Bachelor or equivalent    |
| 5974 |    60 | Bachelor or equivalent    |
| 5975 |    60 | Bachelor or equivalent    |
| 5976 |    60 | Bachelor or equivalent    |
| 5977 |    60 | Bachelor or equivalent    |
| 5978 |    60 | Bachelor or equivalent    |
| 5979 |    60 | Bachelor or equivalent    |
| 5980 |    60 | Bachelor or equivalent    |
| 5981 |    60 | Bachelor or equivalent    |
| 5982 |    60 | Bachelor or equivalent    |
| 5983 |    60 | Bachelor or equivalent    |
| 5984 |    60 | Bachelor or equivalent    |
| 5985 |    60 | Bachelor or equivalent    |
| 5986 |    60 | Bachelor or equivalent    |
| 5987 |    60 | Bachelor or equivalent    |
| 5988 |    60 | Bachelor or equivalent    |
| 5989 |    60 | Bachelor or equivalent    |
| 5990 |    60 | Bachelor or equivalent    |
| 5991 |    60 | Bachelor or equivalent    |
| 5992 |    60 | Bachelor or equivalent    |
| 5993 |    60 | Bachelor or equivalent    |
| 5994 |    60 | Bachelor or equivalent    |
| 5995 |    60 | Bachelor or equivalent    |
| 5996 |    70 | Master or equivalent      |
| 6000 |    70 | Master or equivalent      |
| 6001 |    60 | Bachelor or equivalent    |
| 6002 |    60 | Bachelor or equivalent    |
| 6003 |    60 | Bachelor or equivalent    |
| 6004 |    60 | Bachelor or equivalent    |
| 6005 |    60 | Bachelor or equivalent    |
| 6006 |    60 | Bachelor or equivalent    |
| 6007 |    60 | Bachelor or equivalent    |
| 6008 |    60 | Bachelor or equivalent    |
| 6011 |    70 | Master or equivalent      |
| 6012 |    70 | Master or equivalent      |
| 6013 |    70 | Master or equivalent      |
| 6014 |    70 | Master or equivalent      |
| 6015 |    70 | Master or equivalent      |
| 6016 |    70 | Master or equivalent      |
| 6017 |    60 | Bachelor or equivalent    |
| 6018 |    60 | Bachelor or equivalent    |
| 6020 |    50 | Short cycle tertiary      |
| 6021 |    50 | Short cycle tertiary      |
| 6022 |    30 | Upper secondary           |
| 6023 |    30 | Upper secondary           |
| 6024 |    30 | Upper secondary           |
| 6025 |    30 | Upper secondary           |
| 6026 |    50 | Short cycle tertiary      |
| 6027 |    60 | Bachelor or equivalent    |
| 6029 |    70 | Master or equivalent      |
| 6030 |    60 | Bachelor or equivalent    |
| 6031 |    70 | Master or equivalent      |
| 6040 |    60 | Bachelor or equivalent    |
| 6045 |    60 | Bachelor or equivalent    |
| 6046 |    60 | Bachelor or equivalent    |
| 6047 |    60 | Bachelor or equivalent    |
| 6048 |    60 | Bachelor or equivalent    |
| 6050 |    60 | Bachelor or equivalent    |
| 6051 |    60 | Bachelor or equivalent    |
| 6055 |    70 | Master or equivalent      |
| 6062 |    70 | Master or equivalent      |
| 6064 |    70 | Master or equivalent      |
| 6065 |    70 | Master or equivalent      |
| 6071 |    70 | Master or equivalent      |
| 6076 |    70 | Master or equivalent      |
| 6077 |    70 | Master or equivalent      |
| 6081 |    70 | Master or equivalent      |
| 6082 |    70 | Master or equivalent      |
| 6083 |    60 | Bachelor or equivalent    |
| 6084 |    60 | Bachelor or equivalent    |
| 6086 |    70 | Master or equivalent      |
| 6087 |    70 | Master or equivalent      |
| 6100 |    70 | Master or equivalent      |
| 6101 |    60 | Bachelor or equivalent    |
| 6102 |    60 | Bachelor or equivalent    |
| 6103 |    60 | Bachelor or equivalent    |
| 6104 |    70 | Master or equivalent      |
| 6105 |    70 | Master or equivalent      |
| 6106 |    70 | Master or equivalent      |
| 6107 |    60 | Bachelor or equivalent    |
| 6108 |    60 | Bachelor or equivalent    |
| 6109 |    60 | Bachelor or equivalent    |
| 6110 |    60 | Bachelor or equivalent    |
| 6111 |    70 | Master or equivalent      |
| 6112 |    70 | Master or equivalent      |
| 6113 |    70 | Master or equivalent      |
| 6114 |    70 | Master or equivalent      |
| 6115 |    60 | Bachelor or equivalent    |
| 6116 |    60 | Bachelor or equivalent    |
| 6117 |    60 | Bachelor or equivalent    |
| 6118 |    60 | Bachelor or equivalent    |
| 6119 |    70 | Master or equivalent      |
| 6120 |    70 | Master or equivalent      |
| 6121 |    70 | Master or equivalent      |
| 6125 |    70 | Master or equivalent      |
| 6126 |    70 | Master or equivalent      |
| 6127 |    70 | Master or equivalent      |
| 6128 |    70 | Master or equivalent      |
| 6129 |    70 | Master or equivalent      |
| 6130 |    70 | Master or equivalent      |
| 6131 |    70 | Master or equivalent      |
| 6132 |    70 | Master or equivalent      |
| 6133 |    70 | Master or equivalent      |
| 6134 |    70 | Master or equivalent      |
| 6135 |    70 | Master or equivalent      |
| 6136 |    70 | Master or equivalent      |
| 6137 |    70 | Master or equivalent      |
| 6138 |    70 | Master or equivalent      |
| 6139 |    70 | Master or equivalent      |
| 6140 |    70 | Master or equivalent      |
| 6141 |    70 | Master or equivalent      |
| 6142 |    70 | Master or equivalent      |
| 6143 |    70 | Master or equivalent      |
| 6144 |    70 | Master or equivalent      |
| 6145 |    70 | Master or equivalent      |
| 6146 |    70 | Master or equivalent      |
| 6147 |    70 | Master or equivalent      |
| 6148 |    70 | Master or equivalent      |
| 6149 |    70 | Master or equivalent      |
| 6150 |    70 | Master or equivalent      |
| 6151 |    60 | Bachelor or equivalent    |
| 6152 |    60 | Bachelor or equivalent    |
| 6153 |    70 | Master or equivalent      |
| 6154 |    60 | Bachelor or equivalent    |
| 6155 |    60 | Bachelor or equivalent    |
| 6156 |    60 | Bachelor or equivalent    |
| 6157 |    60 | Bachelor or equivalent    |
| 6158 |    70 | Master or equivalent      |
| 6159 |    70 | Master or equivalent      |
| 6161 |    60 | Bachelor or equivalent    |
| 6162 |    60 | Bachelor or equivalent    |
| 6163 |    60 | Bachelor or equivalent    |
| 6164 |    60 | Bachelor or equivalent    |
| 6165 |    60 | Bachelor or equivalent    |
| 6166 |    60 | Bachelor or equivalent    |
| 6167 |    70 | Master or equivalent      |
| 6168 |    70 | Master or equivalent      |
| 6169 |    70 | Master or equivalent      |
| 6170 |    70 | Master or equivalent      |
| 6171 |    70 | Master or equivalent      |
| 6172 |    70 | Master or equivalent      |
| 6173 |    70 | Master or equivalent      |
| 6174 |    70 | Master or equivalent      |
| 6175 |    70 | Master or equivalent      |
| 6176 |    70 | Master or equivalent      |
| 6177 |    70 | Master or equivalent      |
| 6178 |    70 | Master or equivalent      |
| 6179 |    70 | Master or equivalent      |
| 6181 |    70 | Master or equivalent      |
| 6182 |    70 | Master or equivalent      |
| 6183 |    70 | Master or equivalent      |
| 6184 |    70 | Master or equivalent      |
| 6185 |    70 | Master or equivalent      |
| 6186 |    70 | Master or equivalent      |
| 6187 |    70 | Master or equivalent      |
| 6188 |    70 | Master or equivalent      |
| 6189 |    70 | Master or equivalent      |
| 6200 |    70 | Master or equivalent      |
| 6235 |    70 | Master or equivalent      |
| 6242 |    60 | Bachelor or equivalent    |
| 6243 |    70 | Master or equivalent      |
| 6244 |    70 | Master or equivalent      |
| 6245 |    70 | Master or equivalent      |
| 6246 |    70 | Master or equivalent      |
| 6247 |    70 | Master or equivalent      |
| 6260 |    70 | Master or equivalent      |
| 6261 |    70 | Master or equivalent      |
| 6262 |    70 | Master or equivalent      |
| 6263 |    70 | Master or equivalent      |
| 6264 |    70 | Master or equivalent      |
| 6265 |    70 | Master or equivalent      |
| 6266 |    70 | Master or equivalent      |
| 6267 |    70 | Master or equivalent      |
| 6268 |    70 | Master or equivalent      |
| 6269 |    70 | Master or equivalent      |
| 6270 |    70 | Master or equivalent      |
| 6271 |    70 | Master or equivalent      |
| 6282 |    70 | Master or equivalent      |
| 6285 |    70 | Master or equivalent      |
| 6296 |    70 | Master or equivalent      |
| 6297 |    70 | Master or equivalent      |
| 6298 |    60 | Bachelor or equivalent    |
| 6299 |    60 | Bachelor or equivalent    |
| 6301 |    70 | Master or equivalent      |
| 6313 |    70 | Master or equivalent      |
| 6321 |    70 | Master or equivalent      |
| 6322 |    70 | Master or equivalent      |
| 6380 |    70 | Master or equivalent      |
| 6381 |    70 | Master or equivalent      |
| 6382 |    70 | Master or equivalent      |
| 6383 |    70 | Master or equivalent      |
| 6384 |    70 | Master or equivalent      |
| 6385 |    70 | Master or equivalent      |
| 6393 |    70 | Master or equivalent      |
| 6394 |    70 | Master or equivalent      |
| 6395 |    70 | Master or equivalent      |
| 6396 |    70 | Master or equivalent      |
| 6397 |    70 | Master or equivalent      |
| 6398 |    70 | Master or equivalent      |
| 6399 |    70 | Master or equivalent      |
| 6401 |    70 | Master or equivalent      |
| 6402 |    70 | Master or equivalent      |
| 6403 |    60 | Bachelor or equivalent    |
| 6404 |    60 | Bachelor or equivalent    |
| 6405 |    60 | Bachelor or equivalent    |
| 6406 |    60 | Bachelor or equivalent    |
| 6407 |    70 | Master or equivalent      |
| 6408 |    70 | Master or equivalent      |
| 6409 |    70 | Master or equivalent      |
| 6410 |    70 | Master or equivalent      |
| 6413 |    70 | Master or equivalent      |
| 6414 |    70 | Master or equivalent      |
| 6415 |    70 | Master or equivalent      |
| 6416 |    70 | Master or equivalent      |
| 6417 |    70 | Master or equivalent      |
| 6418 |    70 | Master or equivalent      |
| 6419 |    70 | Master or equivalent      |
| 6420 |    70 | Master or equivalent      |
| 6421 |    70 | Master or equivalent      |
| 6424 |    70 | Master or equivalent      |
| 6425 |    70 | Master or equivalent      |
| 6426 |    70 | Master or equivalent      |
| 6427 |    70 | Master or equivalent      |
| 6428 |    70 | Master or equivalent      |
| 6452 |    70 | Master or equivalent      |
| 6454 |    70 | Master or equivalent      |
| 6455 |    70 | Master or equivalent      |
| 6456 |    70 | Master or equivalent      |
| 6457 |    70 | Master or equivalent      |
| 6458 |    70 | Master or equivalent      |
| 6459 |    70 | Master or equivalent      |
| 6461 |    70 | Master or equivalent      |
| 6462 |    70 | Master or equivalent      |
| 6463 |    60 | Bachelor or equivalent    |
| 6464 |    70 | Master or equivalent      |
| 6490 |    70 | Master or equivalent      |
| 6491 |    70 | Master or equivalent      |
| 6492 |    70 | Master or equivalent      |
| 6493 |    70 | Master or equivalent      |
| 6494 |    70 | Master or equivalent      |
| 6495 |    60 | Bachelor or equivalent    |
| 6496 |    60 | Bachelor or equivalent    |
| 6497 |    60 | Bachelor or equivalent    |
| 6500 |    60 | Bachelor or equivalent    |
| 6501 |    70 | Master or equivalent      |
| 6502 |    60 | Bachelor or equivalent    |
| 6503 |    70 | Master or equivalent      |
| 6504 |    60 | Bachelor or equivalent    |
| 6505 |    60 | Bachelor or equivalent    |
| 6506 |    60 | Bachelor or equivalent    |
| 6507 |    60 | Bachelor or equivalent    |
| 6508 |    60 | Bachelor or equivalent    |
| 6509 |    60 | Bachelor or equivalent    |
| 6510 |    60 | Bachelor or equivalent    |
| 6511 |    70 | Master or equivalent      |
| 6512 |    60 | Bachelor or equivalent    |
| 6513 |    70 | Master or equivalent      |
| 6514 |    70 | Master or equivalent      |
| 6515 |    70 | Master or equivalent      |
| 6516 |    60 | Bachelor or equivalent    |
| 6517 |    70 | Master or equivalent      |
| 6518 |    60 | Bachelor or equivalent    |
| 6519 |    70 | Master or equivalent      |
| 6520 |    60 | Bachelor or equivalent    |
| 6521 |    70 | Master or equivalent      |
| 6522 |    60 | Bachelor or equivalent    |
| 6523 |    70 | Master or equivalent      |
| 6524 |    60 | Bachelor or equivalent    |
| 6525 |    70 | Master or equivalent      |
| 6526 |    60 | Bachelor or equivalent    |
| 6527 |    70 | Master or equivalent      |
| 6528 |    60 | Bachelor or equivalent    |
| 6529 |    70 | Master or equivalent      |
| 6530 |    60 | Bachelor or equivalent    |
| 6531 |    70 | Master or equivalent      |
| 6532 |    60 | Bachelor or equivalent    |
| 6533 |    70 | Master or equivalent      |
| 6534 |    60 | Bachelor or equivalent    |
| 6535 |    70 | Master or equivalent      |
| 6536 |    60 | Bachelor or equivalent    |
| 6537 |    70 | Master or equivalent      |
| 6538 |    60 | Bachelor or equivalent    |
| 6539 |    70 | Master or equivalent      |
| 6540 |    60 | Bachelor or equivalent    |
| 6541 |    70 | Master or equivalent      |
| 6542 |    60 | Bachelor or equivalent    |
| 6543 |    70 | Master or equivalent      |
| 6544 |    60 | Bachelor or equivalent    |
| 6545 |    70 | Master or equivalent      |
| 6546 |    60 | Bachelor or equivalent    |
| 6547 |    70 | Master or equivalent      |
| 6548 |    60 | Bachelor or equivalent    |
| 6549 |    70 | Master or equivalent      |
| 6550 |    60 | Bachelor or equivalent    |
| 6551 |    70 | Master or equivalent      |
| 6552 |    60 | Bachelor or equivalent    |
| 6553 |    70 | Master or equivalent      |
| 6554 |    60 | Bachelor or equivalent    |
| 6555 |    60 | Bachelor or equivalent    |
| 6556 |    60 | Bachelor or equivalent    |
| 6557 |    70 | Master or equivalent      |
| 6558 |    60 | Bachelor or equivalent    |
| 6559 |    60 | Bachelor or equivalent    |
| 6560 |    60 | Bachelor or equivalent    |
| 6561 |    60 | Bachelor or equivalent    |
| 6562 |    60 | Bachelor or equivalent    |
| 6563 |    70 | Master or equivalent      |
| 6564 |    60 | Bachelor or equivalent    |
| 6565 |    70 | Master or equivalent      |
| 6566 |    60 | Bachelor or equivalent    |
| 6567 |    70 | Master or equivalent      |
| 6568 |    60 | Bachelor or equivalent    |
| 6569 |    70 | Master or equivalent      |
| 6570 |    60 | Bachelor or equivalent    |
| 6571 |    70 | Master or equivalent      |
| 6572 |    70 | Master or equivalent      |
| 6573 |    70 | Master or equivalent      |
| 6574 |    60 | Bachelor or equivalent    |
| 6575 |    70 | Master or equivalent      |
| 6576 |    60 | Bachelor or equivalent    |
| 6577 |    70 | Master or equivalent      |
| 6578 |    60 | Bachelor or equivalent    |
| 6579 |    70 | Master or equivalent      |
| 6580 |    60 | Bachelor or equivalent    |
| 6581 |    70 | Master or equivalent      |
| 6582 |    60 | Bachelor or equivalent    |
| 6583 |    70 | Master or equivalent      |
| 6584 |    60 | Bachelor or equivalent    |
| 6585 |    70 | Master or equivalent      |
| 6586 |    60 | Bachelor or equivalent    |
| 6587 |    70 | Master or equivalent      |
| 6588 |    60 | Bachelor or equivalent    |
| 6589 |    70 | Master or equivalent      |
| 6590 |    60 | Bachelor or equivalent    |
| 6591 |    70 | Master or equivalent      |
| 6592 |    60 | Bachelor or equivalent    |
| 6593 |    70 | Master or equivalent      |
| 6594 |    60 | Bachelor or equivalent    |
| 6595 |    70 | Master or equivalent      |
| 6596 |    60 | Bachelor or equivalent    |
| 6597 |    70 | Master or equivalent      |
| 6598 |    60 | Bachelor or equivalent    |
| 6599 |    70 | Master or equivalent      |
| 6600 |    60 | Bachelor or equivalent    |
| 6601 |    70 | Master or equivalent      |
| 6602 |    60 | Bachelor or equivalent    |
| 6603 |    70 | Master or equivalent      |
| 6604 |    60 | Bachelor or equivalent    |
| 6605 |    70 | Master or equivalent      |
| 6606 |    60 | Bachelor or equivalent    |
| 6607 |    70 | Master or equivalent      |
| 6608 |    60 | Bachelor or equivalent    |
| 6609 |    70 | Master or equivalent      |
| 6610 |    60 | Bachelor or equivalent    |
| 6611 |    70 | Master or equivalent      |
| 6612 |    60 | Bachelor or equivalent    |
| 6613 |    70 | Master or equivalent      |
| 6614 |    60 | Bachelor or equivalent    |
| 6615 |    70 | Master or equivalent      |
| 6616 |    60 | Bachelor or equivalent    |
| 6617 |    70 | Master or equivalent      |
| 6618 |    60 | Bachelor or equivalent    |
| 6619 |    70 | Master or equivalent      |
| 6620 |    60 | Bachelor or equivalent    |
| 6621 |    70 | Master or equivalent      |
| 6622 |    60 | Bachelor or equivalent    |
| 6623 |    70 | Master or equivalent      |
| 6625 |    70 | Master or equivalent      |
| 6627 |    70 | Master or equivalent      |
| 6629 |    70 | Master or equivalent      |
| 6631 |    70 | Master or equivalent      |
| 6632 |    60 | Bachelor or equivalent    |
| 6633 |    70 | Master or equivalent      |
| 6634 |    60 | Bachelor or equivalent    |
| 6635 |    60 | Bachelor or equivalent    |
| 6636 |    60 | Bachelor or equivalent    |
| 6637 |    70 | Master or equivalent      |
| 6638 |    60 | Bachelor or equivalent    |
| 6639 |    70 | Master or equivalent      |
| 6640 |    60 | Bachelor or equivalent    |
| 6641 |    70 | Master or equivalent      |
| 6642 |    60 | Bachelor or equivalent    |
| 6643 |    70 | Master or equivalent      |
| 6644 |    60 | Bachelor or equivalent    |
| 6645 |    70 | Master or equivalent      |
| 6646 |    60 | Bachelor or equivalent    |
| 6647 |    70 | Master or equivalent      |
| 6649 |    70 | Master or equivalent      |
| 6650 |    60 | Bachelor or equivalent    |
| 6651 |    70 | Master or equivalent      |
| 6652 |    60 | Bachelor or equivalent    |
| 6653 |    70 | Master or equivalent      |
| 6655 |    70 | Master or equivalent      |
| 6657 |    70 | Master or equivalent      |
| 6659 |    70 | Master or equivalent      |
| 6661 |    70 | Master or equivalent      |
| 6665 |    60 | Bachelor or equivalent    |
| 6666 |    60 | Bachelor or equivalent    |
| 6667 |    70 | Master or equivalent      |
| 6668 |    60 | Bachelor or equivalent    |
| 6669 |    70 | Master or equivalent      |
| 6670 |    60 | Bachelor or equivalent    |
| 6671 |    70 | Master or equivalent      |
| 6672 |    60 | Bachelor or equivalent    |
| 6673 |    60 | Bachelor or equivalent    |
| 6674 |    60 | Bachelor or equivalent    |
| 6675 |    60 | Bachelor or equivalent    |
| 6676 |    60 | Bachelor or equivalent    |
| 6677 |    70 | Master or equivalent      |
| 6679 |    60 | Bachelor or equivalent    |
| 6680 |    60 | Bachelor or equivalent    |
| 6681 |    60 | Bachelor or equivalent    |
| 6682 |    60 | Bachelor or equivalent    |
| 6683 |    60 | Bachelor or equivalent    |
| 6684 |    60 | Bachelor or equivalent    |
| 6685 |    60 | Bachelor or equivalent    |
| 6686 |    60 | Bachelor or equivalent    |
| 6687 |    60 | Bachelor or equivalent    |
| 6688 |    60 | Bachelor or equivalent    |
| 6689 |    60 | Bachelor or equivalent    |
| 6690 |    60 | Bachelor or equivalent    |
| 6691 |    60 | Bachelor or equivalent    |
| 6692 |    60 | Bachelor or equivalent    |
| 6693 |    60 | Bachelor or equivalent    |
| 6694 |    60 | Bachelor or equivalent    |
| 6695 |    60 | Bachelor or equivalent    |
| 6696 |    60 | Bachelor or equivalent    |
| 6697 |    60 | Bachelor or equivalent    |
| 6698 |    60 | Bachelor or equivalent    |
| 6700 |    70 | Master or equivalent      |
| 6701 |    70 | Master or equivalent      |
| 6702 |    70 | Master or equivalent      |
| 6703 |    70 | Master or equivalent      |
| 6704 |    70 | Master or equivalent      |
| 6705 |    70 | Master or equivalent      |
| 6706 |    70 | Master or equivalent      |
| 6707 |    70 | Master or equivalent      |
| 6708 |    70 | Master or equivalent      |
| 6709 |    70 | Master or equivalent      |
| 6710 |    70 | Master or equivalent      |
| 6711 |    70 | Master or equivalent      |
| 6712 |    70 | Master or equivalent      |
| 6713 |    70 | Master or equivalent      |
| 6714 |    70 | Master or equivalent      |
| 6715 |    70 | Master or equivalent      |
| 6716 |    70 | Master or equivalent      |
| 6717 |    70 | Master or equivalent      |
| 6718 |    70 | Master or equivalent      |
| 6719 |    70 | Master or equivalent      |
| 6720 |    70 | Master or equivalent      |
| 6721 |    70 | Master or equivalent      |
| 6722 |    70 | Master or equivalent      |
| 6723 |    70 | Master or equivalent      |
| 6724 |    70 | Master or equivalent      |
| 6725 |    70 | Master or equivalent      |
| 6726 |    70 | Master or equivalent      |
| 6727 |    70 | Master or equivalent      |
| 6729 |    70 | Master or equivalent      |
| 6730 |    70 | Master or equivalent      |
| 6731 |    70 | Master or equivalent      |
| 6732 |    70 | Master or equivalent      |
| 6733 |    70 | Master or equivalent      |
| 6734 |    70 | Master or equivalent      |
| 6735 |    70 | Master or equivalent      |
| 6737 |    70 | Master or equivalent      |
| 6738 |    70 | Master or equivalent      |
| 6739 |    70 | Master or equivalent      |
| 6740 |    70 | Master or equivalent      |
| 6741 |    70 | Master or equivalent      |
| 6742 |    70 | Master or equivalent      |
| 6743 |    70 | Master or equivalent      |
| 6744 |    70 | Master or equivalent      |
| 6745 |    70 | Master or equivalent      |
| 6746 |    70 | Master or equivalent      |
| 6747 |    70 | Master or equivalent      |
| 6749 |    70 | Master or equivalent      |
| 6750 |    70 | Master or equivalent      |
| 6751 |    70 | Master or equivalent      |
| 6753 |    70 | Master or equivalent      |
| 6754 |    70 | Master or equivalent      |
| 6757 |    70 | Master or equivalent      |
| 6758 |    70 | Master or equivalent      |
| 6760 |    70 | Master or equivalent      |
| 6762 |    70 | Master or equivalent      |
| 6763 |    70 | Master or equivalent      |
| 6765 |    70 | Master or equivalent      |
| 6766 |    70 | Master or equivalent      |
| 6767 |    70 | Master or equivalent      |
| 6768 |    70 | Master or equivalent      |
| 6769 |    70 | Master or equivalent      |
| 6771 |    70 | Master or equivalent      |
| 6773 |    70 | Master or equivalent      |
| 6774 |    70 | Master or equivalent      |
| 6775 |    70 | Master or equivalent      |
| 6777 |    70 | Master or equivalent      |
| 6778 |    70 | Master or equivalent      |
| 6779 |    70 | Master or equivalent      |
| 6781 |    70 | Master or equivalent      |
| 6782 |    70 | Master or equivalent      |
| 6783 |    70 | Master or equivalent      |
| 6785 |    70 | Master or equivalent      |
| 6786 |    70 | Master or equivalent      |
| 6787 |    70 | Master or equivalent      |
| 6789 |    70 | Master or equivalent      |
| 6790 |    70 | Master or equivalent      |
| 6791 |    70 | Master or equivalent      |
| 6793 |    70 | Master or equivalent      |
| 6795 |    70 | Master or equivalent      |
| 6797 |    70 | Master or equivalent      |
| 6800 |    70 | Master or equivalent      |
| 6801 |    70 | Master or equivalent      |
| 6802 |    70 | Master or equivalent      |
| 6803 |    70 | Master or equivalent      |
| 6804 |    70 | Master or equivalent      |
| 6805 |    70 | Master or equivalent      |
| 6806 |    70 | Master or equivalent      |
| 6807 |    70 | Master or equivalent      |
| 6808 |    70 | Master or equivalent      |
| 6809 |    70 | Master or equivalent      |
| 6810 |    60 | Bachelor or equivalent    |
| 6811 |    70 | Master or equivalent      |
| 6813 |    70 | Master or equivalent      |
| 6814 |    70 | Master or equivalent      |
| 6815 |    70 | Master or equivalent      |
| 6816 |    70 | Master or equivalent      |
| 6817 |    70 | Master or equivalent      |
| 6818 |    70 | Master or equivalent      |
| 6819 |    70 | Master or equivalent      |
| 6820 |    70 | Master or equivalent      |
| 6821 |    70 | Master or equivalent      |
| 6822 |    70 | Master or equivalent      |
| 6823 |    70 | Master or equivalent      |
| 6824 |    70 | Master or equivalent      |
| 6825 |    70 | Master or equivalent      |
| 6827 |    70 | Master or equivalent      |
| 6829 |    70 | Master or equivalent      |
| 6831 |    70 | Master or equivalent      |
| 6832 |    70 | Master or equivalent      |
| 6833 |    70 | Master or equivalent      |
| 6836 |    70 | Master or equivalent      |
| 6837 |    70 | Master or equivalent      |
| 6838 |    70 | Master or equivalent      |
| 6839 |    70 | Master or equivalent      |
| 6840 |    70 | Master or equivalent      |
| 6841 |    70 | Master or equivalent      |
| 6842 |    70 | Master or equivalent      |
| 6843 |    70 | Master or equivalent      |
| 6845 |    70 | Master or equivalent      |
| 6846 |    70 | Master or equivalent      |
| 6847 |    70 | Master or equivalent      |
| 6849 |    70 | Master or equivalent      |
| 6851 |    70 | Master or equivalent      |
| 6853 |    70 | Master or equivalent      |
| 6855 |    70 | Master or equivalent      |
| 6857 |    70 | Master or equivalent      |
| 6859 |    70 | Master or equivalent      |
| 6860 |    70 | Master or equivalent      |
| 6861 |    70 | Master or equivalent      |
| 6862 |    70 | Master or equivalent      |
| 6863 |    70 | Master or equivalent      |
| 6864 |    70 | Master or equivalent      |
| 6865 |    70 | Master or equivalent      |
| 6867 |    70 | Master or equivalent      |
| 6868 |    70 | Master or equivalent      |
| 6869 |    70 | Master or equivalent      |
| 6870 |    70 | Master or equivalent      |
| 6871 |    70 | Master or equivalent      |
| 6872 |    70 | Master or equivalent      |
| 6873 |    70 | Master or equivalent      |
| 6874 |    70 | Master or equivalent      |
| 6875 |    70 | Master or equivalent      |
| 6876 |    70 | Master or equivalent      |
| 6877 |    70 | Master or equivalent      |
| 6878 |    70 | Master or equivalent      |
| 6880 |    70 | Master or equivalent      |
| 6881 |    70 | Master or equivalent      |
| 6885 |    70 | Master or equivalent      |
| 6886 |    70 | Master or equivalent      |
| 6887 |    70 | Master or equivalent      |
| 6888 |    70 | Master or equivalent      |
| 6890 |    70 | Master or equivalent      |
| 6891 |    70 | Master or equivalent      |
| 6892 |    70 | Master or equivalent      |
| 6893 |    70 | Master or equivalent      |
| 6894 |    70 | Master or equivalent      |
| 6895 |    70 | Master or equivalent      |
| 6896 |    70 | Master or equivalent      |
| 6897 |    70 | Master or equivalent      |
| 6898 |    70 | Master or equivalent      |
| 6900 |    70 | Master or equivalent      |
| 6901 |    70 | Master or equivalent      |
| 6902 |    70 | Master or equivalent      |
| 6903 |    70 | Master or equivalent      |
| 6904 |    70 | Master or equivalent      |
| 6905 |    70 | Master or equivalent      |
| 6906 |    70 | Master or equivalent      |
| 6908 |    70 | Master or equivalent      |
| 6910 |    70 | Master or equivalent      |
| 6912 |    70 | Master or equivalent      |
| 6913 |    70 | Master or equivalent      |
| 6914 |    70 | Master or equivalent      |
| 6915 |    70 | Master or equivalent      |
| 6920 |    70 | Master or equivalent      |
| 6925 |    70 | Master or equivalent      |
| 6930 |    70 | Master or equivalent      |
| 6940 |    70 | Master or equivalent      |
| 6941 |    70 | Master or equivalent      |
| 6942 |    70 | Master or equivalent      |
| 6987 |    70 | Master or equivalent      |
| 6990 |    70 | Master or equivalent      |
| 6991 |    70 | Master or equivalent      |
| 6992 |    70 | Master or equivalent      |
| 6993 |    70 | Master or equivalent      |
| 7003 |    70 | Master or equivalent      |
| 7004 |    70 | Master or equivalent      |
| 7005 |    70 | Master or equivalent      |
| 7006 |    60 | Bachelor or equivalent    |
| 7007 |    60 | Bachelor or equivalent    |
| 7008 |    60 | Bachelor or equivalent    |
| 7009 |    60 | Bachelor or equivalent    |
| 7011 |    70 | Master or equivalent      |
| 7012 |    70 | Master or equivalent      |
| 7013 |    60 | Bachelor or equivalent    |
| 7014 |    60 | Bachelor or equivalent    |
| 7015 |    60 | Bachelor or equivalent    |
| 7016 |    60 | Bachelor or equivalent    |
| 7017 |    60 | Bachelor or equivalent    |
| 7018 |    60 | Bachelor or equivalent    |
| 7019 |    60 | Bachelor or equivalent    |
| 7020 |    60 | Bachelor or equivalent    |
| 7021 |    70 | Master or equivalent      |
| 7022 |    70 | Master or equivalent      |
| 7023 |    70 | Master or equivalent      |
| 7024 |    70 | Master or equivalent      |
| 7025 |    70 | Master or equivalent      |
| 7026 |    70 | Master or equivalent      |
| 7027 |    70 | Master or equivalent      |
| 7028 |    70 | Master or equivalent      |
| 7030 |    80 | Doctoral or equivalent    |
| 7045 |    70 | Master or equivalent      |
| 7050 |    80 | Doctoral or equivalent    |
| 7061 |    60 | Bachelor or equivalent    |
| 7062 |    60 | Bachelor or equivalent    |
| 7063 |    70 | Master or equivalent      |
| 7065 |    70 | Master or equivalent      |
| 7070 |    80 | Doctoral or equivalent    |
| 7079 |    70 | Master or equivalent      |
| 7081 |    60 | Bachelor or equivalent    |
| 7085 |    70 | Master or equivalent      |
| 7086 |    70 | Master or equivalent      |
| 7090 |    80 | Doctoral or equivalent    |
| 7100 |    60 | Bachelor or equivalent    |
| 7101 |    70 | Master or equivalent      |
| 7102 |    70 | Master or equivalent      |
| 7103 |    60 | Bachelor or equivalent    |
| 7104 |    60 | Bachelor or equivalent    |
| 7105 |    70 | Master or equivalent      |
| 7106 |    70 | Master or equivalent      |
| 7107 |    70 | Master or equivalent      |
| 7108 |    60 | Bachelor or equivalent    |
| 7109 |    60 | Bachelor or equivalent    |
| 7110 |    70 | Master or equivalent      |
| 7111 |    70 | Master or equivalent      |
| 7112 |    70 | Master or equivalent      |
| 7113 |    70 | Master or equivalent      |
| 7114 |    70 | Master or equivalent      |
| 7115 |    70 | Master or equivalent      |
| 7116 |    70 | Master or equivalent      |
| 7117 |    70 | Master or equivalent      |
| 7118 |    70 | Master or equivalent      |
| 7119 |    70 | Master or equivalent      |
| 7120 |    80 | Doctoral or equivalent    |
| 7121 |    60 | Bachelor or equivalent    |
| 7122 |    60 | Bachelor or equivalent    |
| 7123 |    60 | Bachelor or equivalent    |
| 7124 |    60 | Bachelor or equivalent    |
| 7125 |    60 | Bachelor or equivalent    |
| 7126 |    60 | Bachelor or equivalent    |
| 7127 |    60 | Bachelor or equivalent    |
| 7128 |    60 | Bachelor or equivalent    |
| 7129 |    60 | Bachelor or equivalent    |
| 7131 |    60 | Bachelor or equivalent    |
| 7132 |    60 | Bachelor or equivalent    |
| 7133 |    70 | Master or equivalent      |
| 7134 |    60 | Bachelor or equivalent    |
| 7135 |    70 | Master or equivalent      |
| 7136 |    70 | Master or equivalent      |
| 7137 |    60 | Bachelor or equivalent    |
| 7138 |    70 | Master or equivalent      |
| 7139 |    70 | Master or equivalent      |
| 7140 |    80 | Doctoral or equivalent    |
| 7141 |    70 | Master or equivalent      |
| 7142 |    70 | Master or equivalent      |
| 7143 |    70 | Master or equivalent      |
| 7144 |    70 | Master or equivalent      |
| 7145 |    70 | Master or equivalent      |
| 7146 |    70 | Master or equivalent      |
| 7147 |    70 | Master or equivalent      |
| 7148 |    70 | Master or equivalent      |
| 7151 |    70 | Master or equivalent      |
| 7153 |    60 | Bachelor or equivalent    |
| 7155 |    70 | Master or equivalent      |
| 7156 |    60 | Bachelor or equivalent    |
| 7157 |    60 | Bachelor or equivalent    |
| 7158 |    60 | Bachelor or equivalent    |
| 7159 |    60 | Bachelor or equivalent    |
| 7160 |    80 | Doctoral or equivalent    |
| 7161 |    60 | Bachelor or equivalent    |
| 7162 |    60 | Bachelor or equivalent    |
| 7163 |    60 | Bachelor or equivalent    |
| 7164 |    60 | Bachelor or equivalent    |
| 7165 |    60 | Bachelor or equivalent    |
| 7166 |    60 | Bachelor or equivalent    |
| 7167 |    60 | Bachelor or equivalent    |
| 7168 |    60 | Bachelor or equivalent    |
| 7170 |    70 | Master or equivalent      |
| 7172 |    60 | Bachelor or equivalent    |
| 7173 |    70 | Master or equivalent      |
| 7174 |    70 | Master or equivalent      |
| 7175 |    70 | Master or equivalent      |
| 7176 |    60 | Bachelor or equivalent    |
| 7177 |    60 | Bachelor or equivalent    |
| 7178 |    60 | Bachelor or equivalent    |
| 7179 |    60 | Bachelor or equivalent    |
| 7180 |    80 | Doctoral or equivalent    |
| 7181 |    70 | Master or equivalent      |
| 7182 |    60 | Bachelor or equivalent    |
| 7183 |    70 | Master or equivalent      |
| 7184 |    60 | Bachelor or equivalent    |
| 7185 |    70 | Master or equivalent      |
| 7186 |    60 | Bachelor or equivalent    |
| 7187 |    70 | Master or equivalent      |
| 7188 |    70 | Master or equivalent      |
| 7189 |    70 | Master or equivalent      |
| 7190 |    80 | Doctoral or equivalent    |
| 7191 |    60 | Bachelor or equivalent    |
| 7192 |    60 | Bachelor or equivalent    |
| 7193 |    60 | Bachelor or equivalent    |
| 7194 |    60 | Bachelor or equivalent    |
| 7195 |    70 | Master or equivalent      |
| 7196 |    60 | Bachelor or equivalent    |
| 7197 |    60 | Bachelor or equivalent    |
| 7198 |    60 | Bachelor or equivalent    |
| 7199 |    60 | Bachelor or equivalent    |
| 7200 |    80 | Doctoral or equivalent    |
| 7203 |    70 | Master or equivalent      |
| 7207 |    70 | Master or equivalent      |
| 7208 |    60 | Bachelor or equivalent    |
| 7209 |    60 | Bachelor or equivalent    |
| 7210 |    60 | Bachelor or equivalent    |
| 7211 |    60 | Bachelor or equivalent    |
| 7213 |    70 | Master or equivalent      |
| 7215 |    60 | Bachelor or equivalent    |
| 7216 |    70 | Master or equivalent      |
| 7217 |    70 | Master or equivalent      |
| 7218 |    70 | Master or equivalent      |
| 7219 |    70 | Master or equivalent      |
| 7220 |    70 | Master or equivalent      |
| 7223 |    70 | Master or equivalent      |
| 7224 |    70 | Master or equivalent      |
| 7225 |    70 | Master or equivalent      |
| 7226 |    70 | Master or equivalent      |
| 7227 |    70 | Master or equivalent      |
| 7230 |    70 | Master or equivalent      |
| 7231 |    60 | Bachelor or equivalent    |
| 7232 |    70 | Master or equivalent      |
| 7235 |    80 | Doctoral or equivalent    |
| 7236 |    70 | Master or equivalent      |
| 7237 |    70 | Master or equivalent      |
| 7238 |    70 | Master or equivalent      |
| 7239 |    70 | Master or equivalent      |
| 7243 |    70 | Master or equivalent      |
| 7253 |    70 | Master or equivalent      |
| 7263 |    70 | Master or equivalent      |
| 7279 |    70 | Master or equivalent      |
| 7298 |    70 | Master or equivalent      |
| 7303 |    70 | Master or equivalent      |
| 7313 |    70 | Master or equivalent      |
| 7314 |    70 | Master or equivalent      |
| 7321 |    70 | Master or equivalent      |
| 7322 |    60 | Bachelor or equivalent    |
| 7323 |    70 | Master or equivalent      |
| 7324 |    60 | Bachelor or equivalent    |
| 7325 |    60 | Bachelor or equivalent    |
| 7333 |    70 | Master or equivalent      |
| 7335 |    80 | Doctoral or equivalent    |
| 7336 |    70 | Master or equivalent      |
| 7343 |    70 | Master or equivalent      |
| 7344 |    70 | Master or equivalent      |
| 7345 |    70 | Master or equivalent      |
| 7348 |    70 | Master or equivalent      |
| 7353 |    70 | Master or equivalent      |
| 7362 |    70 | Master or equivalent      |
| 7363 |    70 | Master or equivalent      |
| 7364 |    70 | Master or equivalent      |
| 7365 |    80 | Doctoral or equivalent    |
| 7373 |    70 | Master or equivalent      |
| 7383 |    70 | Master or equivalent      |
| 7395 |    70 | Master or equivalent      |
| 7396 |    70 | Master or equivalent      |
| 7397 |    70 | Master or equivalent      |
| 7398 |    70 | Master or equivalent      |
| 7399 |    70 | Master or equivalent      |
| 7400 |    70 | Master or equivalent      |
| 7401 |    70 | Master or equivalent      |
| 7402 |    70 | Master or equivalent      |
| 7403 |    70 | Master or equivalent      |
| 7415 |    60 | Bachelor or equivalent    |
| 7420 |    60 | Bachelor or equivalent    |
| 7423 |    70 | Master or equivalent      |
| 7424 |    70 | Master or equivalent      |
| 7425 |    70 | Master or equivalent      |
| 7426 |    70 | Master or equivalent      |
| 7427 |    70 | Master or equivalent      |
| 7430 |    70 | Master or equivalent      |
| 7438 |    70 | Master or equivalent      |
| 7458 |    70 | Master or equivalent      |
| 7468 |    70 | Master or equivalent      |
| 7478 |    70 | Master or equivalent      |
| 7484 |    70 | Master or equivalent      |
| 7488 |    70 | Master or equivalent      |
| 7489 |    70 | Master or equivalent      |
| 7518 |    70 | Master or equivalent      |
| 7527 |    70 | Master or equivalent      |
| 7537 |    70 | Master or equivalent      |
| 7547 |    70 | Master or equivalent      |
| 7557 |    70 | Master or equivalent      |
| 7567 |    70 | Master or equivalent      |
| 7578 |    70 | Master or equivalent      |
| 7588 |    70 | Master or equivalent      |
| 7598 |    70 | Master or equivalent      |
| 7601 |    70 | Master or equivalent      |
| 7602 |    70 | Master or equivalent      |
| 7607 |    70 | Master or equivalent      |
| 7608 |    70 | Master or equivalent      |
| 7620 |    70 | Master or equivalent      |
| 7621 |    60 | Bachelor or equivalent    |
| 7628 |    70 | Master or equivalent      |
| 7653 |    70 | Master or equivalent      |
| 7667 |    50 | Short cycle tertiary      |
| 7668 |    70 | Master or equivalent      |
| 7673 |    70 | Master or equivalent      |
| 7683 |    70 | Master or equivalent      |
| 7693 |    70 | Master or equivalent      |
| 7723 |    70 | Master or equivalent      |
| 7733 |    70 | Master or equivalent      |
| 7743 |    70 | Master or equivalent      |
| 7745 |    70 | Master or equivalent      |
| 7746 |    70 | Master or equivalent      |
| 7747 |    70 | Master or equivalent      |
| 7748 |    70 | Master or equivalent      |
| 7749 |    70 | Master or equivalent      |
| 7750 |    70 | Master or equivalent      |
| 7751 |    70 | Master or equivalent      |
| 7752 |    70 | Master or equivalent      |
| 7753 |    70 | Master or equivalent      |
| 7754 |    70 | Master or equivalent      |
| 7776 |    70 | Master or equivalent      |
| 7779 |    70 | Master or equivalent      |
| 7802 |    70 | Master or equivalent      |
| 7803 |    60 | Bachelor or equivalent    |
| 7804 |    70 | Master or equivalent      |
| 7813 |    70 | Master or equivalent      |
| 7832 |    70 | Master or equivalent      |
| 7833 |    70 | Master or equivalent      |
| 7841 |    60 | Bachelor or equivalent    |
| 7842 |    70 | Master or equivalent      |
| 7843 |    60 | Bachelor or equivalent    |
| 7844 |    70 | Master or equivalent      |
| 7845 |    60 | Bachelor or equivalent    |
| 7846 |    60 | Bachelor or equivalent    |
| 7847 |    60 | Bachelor or equivalent    |
| 7848 |    60 | Bachelor or equivalent    |
| 7849 |    60 | Bachelor or equivalent    |
| 7850 |    60 | Bachelor or equivalent    |
| 7851 |    60 | Bachelor or equivalent    |
| 7852 |    60 | Bachelor or equivalent    |
| 7853 |    60 | Bachelor or equivalent    |
| 7854 |    60 | Bachelor or equivalent    |
| 7855 |    60 | Bachelor or equivalent    |
| 7856 |    60 | Bachelor or equivalent    |
| 7857 |    60 | Bachelor or equivalent    |
| 7858 |    60 | Bachelor or equivalent    |
| 7859 |    60 | Bachelor or equivalent    |
| 7860 |    60 | Bachelor or equivalent    |
| 7861 |    70 | Master or equivalent      |
| 7862 |    70 | Master or equivalent      |
| 7863 |    70 | Master or equivalent      |
| 7864 |    80 | Doctoral or equivalent    |
| 7865 |    70 | Master or equivalent      |
| 7873 |    70 | Master or equivalent      |
| 7883 |    70 | Master or equivalent      |
| 7887 |    70 | Master or equivalent      |
| 7893 |    70 | Master or equivalent      |
| 7900 |    60 | Bachelor or equivalent    |
| 7901 |    60 | Bachelor or equivalent    |
| 7902 |    60 | Bachelor or equivalent    |
| 7903 |    70 | Master or equivalent      |
| 7904 |    60 | Bachelor or equivalent    |
| 7905 |    60 | Bachelor or equivalent    |
| 7906 |    60 | Bachelor or equivalent    |
| 7907 |    60 | Bachelor or equivalent    |
| 7908 |    60 | Bachelor or equivalent    |
| 7909 |    60 | Bachelor or equivalent    |
| 7910 |    60 | Bachelor or equivalent    |
| 7911 |    60 | Bachelor or equivalent    |
| 7912 |    60 | Bachelor or equivalent    |
| 7913 |    70 | Master or equivalent      |
| 7914 |    60 | Bachelor or equivalent    |
| 7915 |    60 | Bachelor or equivalent    |
| 7916 |    60 | Bachelor or equivalent    |
| 7917 |    60 | Bachelor or equivalent    |
| 7918 |    60 | Bachelor or equivalent    |
| 7919 |    60 | Bachelor or equivalent    |
| 7920 |    60 | Bachelor or equivalent    |
| 7921 |    60 | Bachelor or equivalent    |
| 7922 |    60 | Bachelor or equivalent    |
| 7923 |    60 | Bachelor or equivalent    |
| 7924 |    60 | Bachelor or equivalent    |
| 7925 |    60 | Bachelor or equivalent    |
| 7926 |    60 | Bachelor or equivalent    |
| 7927 |    60 | Bachelor or equivalent    |
| 7928 |    60 | Bachelor or equivalent    |
| 7929 |    60 | Bachelor or equivalent    |
| 7930 |    60 | Bachelor or equivalent    |
| 7931 |    60 | Bachelor or equivalent    |
| 7932 |    60 | Bachelor or equivalent    |
| 7933 |    60 | Bachelor or equivalent    |
| 7934 |    60 | Bachelor or equivalent    |
| 7935 |    60 | Bachelor or equivalent    |
| 7936 |    60 | Bachelor or equivalent    |
| 7937 |    60 | Bachelor or equivalent    |
| 7938 |    60 | Bachelor or equivalent    |
| 7939 |    60 | Bachelor or equivalent    |
| 7940 |    60 | Bachelor or equivalent    |
| 7941 |    70 | Master or equivalent      |
| 7942 |    60 | Bachelor or equivalent    |
| 7943 |    60 | Bachelor or equivalent    |
| 7944 |    60 | Bachelor or equivalent    |
| 7945 |    70 | Master or equivalent      |
| 7946 |    70 | Master or equivalent      |
| 7947 |    70 | Master or equivalent      |
| 7948 |    60 | Bachelor or equivalent    |
| 7949 |    70 | Master or equivalent      |
| 7950 |    70 | Master or equivalent      |
| 7951 |    60 | Bachelor or equivalent    |
| 7952 |    70 | Master or equivalent      |
| 7953 |    60 | Bachelor or equivalent    |
| 7954 |    70 | Master or equivalent      |
| 7955 |    70 | Master or equivalent      |
| 7956 |    70 | Master or equivalent      |
| 7957 |    70 | Master or equivalent      |
| 7958 |    60 | Bachelor or equivalent    |
| 7959 |    70 | Master or equivalent      |
| 7960 |    80 | Doctoral or equivalent    |
| 7961 |    70 | Master or equivalent      |
| 7965 |    80 | Doctoral or equivalent    |
| 7970 |    80 | Doctoral or equivalent    |
| 7971 |    60 | Bachelor or equivalent    |
| 7972 |    60 | Bachelor or equivalent    |
| 7973 |    60 | Bachelor or equivalent    |
| 7995 |    70 | Master or equivalent      |
| 8000 |    80 | Doctoral or equivalent    |
| 8001 |    70 | Master or equivalent      |
| 8002 |    70 | Master or equivalent      |
| 8003 |    70 | Master or equivalent      |
| 8004 |    70 | Master or equivalent      |
| 8005 |    70 | Master or equivalent      |
| 8006 |    70 | Master or equivalent      |
| 8007 |    70 | Master or equivalent      |
| 8008 |    70 | Master or equivalent      |
| 8009 |    70 | Master or equivalent      |
| 8010 |    70 | Master or equivalent      |
| 8011 |    70 | Master or equivalent      |
| 8012 |    70 | Master or equivalent      |
| 8013 |    70 | Master or equivalent      |
| 8014 |    70 | Master or equivalent      |
| 8015 |    70 | Master or equivalent      |
| 8016 |    70 | Master or equivalent      |
| 8017 |    70 | Master or equivalent      |
| 8018 |    70 | Master or equivalent      |
| 8019 |    70 | Master or equivalent      |
| 8020 |    70 | Master or equivalent      |
| 8021 |    60 | Bachelor or equivalent    |
| 8022 |    70 | Master or equivalent      |
| 8023 |    70 | Master or equivalent      |
| 8024 |    70 | Master or equivalent      |
| 8025 |    70 | Master or equivalent      |
| 8026 |    60 | Bachelor or equivalent    |
| 8027 |    70 | Master or equivalent      |
| 8028 |    70 | Master or equivalent      |
| 8029 |    70 | Master or equivalent      |
| 8030 |    70 | Master or equivalent      |
| 8031 |    70 | Master or equivalent      |
| 8032 |    70 | Master or equivalent      |
| 8033 |    70 | Master or equivalent      |
| 8034 |    70 | Master or equivalent      |
| 8035 |    70 | Master or equivalent      |
| 8036 |    70 | Master or equivalent      |
| 8037 |    70 | Master or equivalent      |
| 8038 |    70 | Master or equivalent      |
| 8039 |    60 | Bachelor or equivalent    |
| 8040 |    60 | Bachelor or equivalent    |
| 8041 |    60 | Bachelor or equivalent    |
| 8042 |    60 | Bachelor or equivalent    |
| 8043 |    70 | Master or equivalent      |
| 8044 |    60 | Bachelor or equivalent    |
| 8045 |    60 | Bachelor or equivalent    |
| 8046 |    70 | Master or equivalent      |
| 8047 |    70 | Master or equivalent      |
| 8048 |    70 | Master or equivalent      |
| 8049 |    60 | Bachelor or equivalent    |
| 8050 |    60 | Bachelor or equivalent    |
| 8051 |    70 | Master or equivalent      |
| 8052 |    60 | Bachelor or equivalent    |
| 8053 |    70 | Master or equivalent      |
| 8054 |    70 | Master or equivalent      |
| 8055 |    70 | Master or equivalent      |
| 8056 |    70 | Master or equivalent      |
| 8059 |    60 | Bachelor or equivalent    |
| 8060 |    70 | Master or equivalent      |
| 8073 |    70 | Master or equivalent      |
| 8074 |    70 | Master or equivalent      |
| 8075 |    60 | Bachelor or equivalent    |
| 8076 |    70 | Master or equivalent      |
| 8077 |    70 | Master or equivalent      |
| 8078 |    70 | Master or equivalent      |
| 8079 |    70 | Master or equivalent      |
| 8080 |    70 | Master or equivalent      |
| 8081 |    70 | Master or equivalent      |
| 8082 |    70 | Master or equivalent      |
| 8083 |    70 | Master or equivalent      |
| 8084 |    70 | Master or equivalent      |
| 8085 |    70 | Master or equivalent      |
| 8086 |    70 | Master or equivalent      |
| 8087 |    70 | Master or equivalent      |
| 8088 |    70 | Master or equivalent      |
| 8089 |    70 | Master or equivalent      |
| 8090 |    70 | Master or equivalent      |
| 8091 |    70 | Master or equivalent      |
| 8092 |    70 | Master or equivalent      |
| 8093 |    70 | Master or equivalent      |
| 8094 |    70 | Master or equivalent      |
| 8095 |    70 | Master or equivalent      |
| 8096 |    70 | Master or equivalent      |
| 8097 |    70 | Master or equivalent      |
| 8098 |    70 | Master or equivalent      |
| 8099 |    70 | Master or equivalent      |
| 8100 |    60 | Bachelor or equivalent    |
| 8101 |    60 | Bachelor or equivalent    |
| 8102 |    60 | Bachelor or equivalent    |
| 8103 |    60 | Bachelor or equivalent    |
| 8104 |    60 | Bachelor or equivalent    |
| 8105 |    60 | Bachelor or equivalent    |
| 8106 |    60 | Bachelor or equivalent    |
| 8107 |    60 | Bachelor or equivalent    |
| 8108 |    60 | Bachelor or equivalent    |
| 8109 |    60 | Bachelor or equivalent    |
| 8110 |    60 | Bachelor or equivalent    |
| 8111 |    60 | Bachelor or equivalent    |
| 8112 |    60 | Bachelor or equivalent    |
| 8113 |    60 | Bachelor or equivalent    |
| 8114 |    60 | Bachelor or equivalent    |
| 8116 |    60 | Bachelor or equivalent    |
| 8117 |    70 | Master or equivalent      |
| 8118 |    70 | Master or equivalent      |
| 8119 |    60 | Bachelor or equivalent    |
| 8120 |    60 | Bachelor or equivalent    |
| 8121 |    60 | Bachelor or equivalent    |
| 8122 |    60 | Bachelor or equivalent    |
| 8123 |    60 | Bachelor or equivalent    |
| 8124 |    60 | Bachelor or equivalent    |
| 8125 |    60 | Bachelor or equivalent    |
| 8126 |    60 | Bachelor or equivalent    |
| 8129 |    60 | Bachelor or equivalent    |
| 8130 |    60 | Bachelor or equivalent    |
| 8131 |    70 | Master or equivalent      |
| 8132 |    60 | Bachelor or equivalent    |
| 8133 |    60 | Bachelor or equivalent    |
| 8134 |    60 | Bachelor or equivalent    |
| 8135 |    60 | Bachelor or equivalent    |
| 8136 |    60 | Bachelor or equivalent    |
| 8137 |    60 | Bachelor or equivalent    |
| 8138 |    60 | Bachelor or equivalent    |
| 8139 |    60 | Bachelor or equivalent    |
| 8140 |    60 | Bachelor or equivalent    |
| 8141 |    70 | Master or equivalent      |
| 8142 |    70 | Master or equivalent      |
| 8143 |    70 | Master or equivalent      |
| 8144 |    70 | Master or equivalent      |
| 8145 |    70 | Master or equivalent      |
| 8146 |    70 | Master or equivalent      |
| 8147 |    60 | Bachelor or equivalent    |
| 8148 |    60 | Bachelor or equivalent    |
| 8149 |    60 | Bachelor or equivalent    |
| 8150 |    60 | Bachelor or equivalent    |
| 8151 |    70 | Master or equivalent      |
| 8152 |    60 | Bachelor or equivalent    |
| 8153 |    60 | Bachelor or equivalent    |
| 8154 |    60 | Bachelor or equivalent    |
| 8155 |    60 | Bachelor or equivalent    |
| 8156 |    60 | Bachelor or equivalent    |
| 8157 |    60 | Bachelor or equivalent    |
| 8158 |    60 | Bachelor or equivalent    |
| 8159 |    60 | Bachelor or equivalent    |
| 8161 |    60 | Bachelor or equivalent    |
| 8162 |    60 | Bachelor or equivalent    |
| 8163 |    60 | Bachelor or equivalent    |
| 8164 |    60 | Bachelor or equivalent    |
| 8165 |    70 | Master or equivalent      |
| 8166 |    70 | Master or equivalent      |
| 8167 |    60 | Bachelor or equivalent    |
| 8168 |    60 | Bachelor or equivalent    |
| 8169 |    60 | Bachelor or equivalent    |
| 8171 |    70 | Master or equivalent      |
| 8172 |    60 | Bachelor or equivalent    |
| 8173 |    70 | Master or equivalent      |
| 8174 |    70 | Master or equivalent      |
| 8175 |    70 | Master or equivalent      |
| 8176 |    60 | Bachelor or equivalent    |
| 8177 |    60 | Bachelor or equivalent    |
| 8178 |    60 | Bachelor or equivalent    |
| 8179 |    60 | Bachelor or equivalent    |
| 8180 |    60 | Bachelor or equivalent    |
| 8181 |    70 | Master or equivalent      |
| 8182 |    70 | Master or equivalent      |
| 8183 |    70 | Master or equivalent      |
| 8184 |    70 | Master or equivalent      |
| 8185 |    70 | Master or equivalent      |
| 8186 |    60 | Bachelor or equivalent    |
| 8187 |    60 | Bachelor or equivalent    |
| 8188 |    60 | Bachelor or equivalent    |
| 8189 |    70 | Master or equivalent      |
| 8190 |    60 | Bachelor or equivalent    |
| 8191 |    60 | Bachelor or equivalent    |
| 8192 |    60 | Bachelor or equivalent    |
| 8193 |    60 | Bachelor or equivalent    |
| 8194 |    60 | Bachelor or equivalent    |
| 8195 |    60 | Bachelor or equivalent    |
| 8196 |    60 | Bachelor or equivalent    |
| 8197 |    60 | Bachelor or equivalent    |
| 8200 |    70 | Master or equivalent      |
| 8201 |    70 | Master or equivalent      |
| 8202 |    70 | Master or equivalent      |
| 8203 |    70 | Master or equivalent      |
| 8204 |    70 | Master or equivalent      |
| 8205 |    70 | Master or equivalent      |
| 8206 |    70 | Master or equivalent      |
| 8207 |    70 | Master or equivalent      |
| 8208 |    70 | Master or equivalent      |
| 8209 |    70 | Master or equivalent      |
| 8210 |    70 | Master or equivalent      |
| 8211 |    70 | Master or equivalent      |
| 8212 |    70 | Master or equivalent      |
| 8213 |    70 | Master or equivalent      |
| 8214 |    70 | Master or equivalent      |
| 8215 |    70 | Master or equivalent      |
| 8216 |    70 | Master or equivalent      |
| 8217 |    70 | Master or equivalent      |
| 8218 |    70 | Master or equivalent      |
| 8219 |    70 | Master or equivalent      |
| 8220 |    70 | Master or equivalent      |
| 8221 |    70 | Master or equivalent      |
| 8222 |    70 | Master or equivalent      |
| 8223 |    70 | Master or equivalent      |
| 8224 |    70 | Master or equivalent      |
| 8225 |    70 | Master or equivalent      |
| 8226 |    70 | Master or equivalent      |
| 8227 |    70 | Master or equivalent      |
| 8228 |    70 | Master or equivalent      |
| 8229 |    70 | Master or equivalent      |
| 8231 |    70 | Master or equivalent      |
| 8232 |    70 | Master or equivalent      |
| 8233 |    70 | Master or equivalent      |
| 8234 |    70 | Master or equivalent      |
| 8235 |    70 | Master or equivalent      |
| 8236 |    70 | Master or equivalent      |
| 8237 |    70 | Master or equivalent      |
| 8238 |    70 | Master or equivalent      |
| 8239 |    70 | Master or equivalent      |
| 8240 |    70 | Master or equivalent      |
| 8241 |    70 | Master or equivalent      |
| 8242 |    70 | Master or equivalent      |
| 8243 |    70 | Master or equivalent      |
| 8244 |    70 | Master or equivalent      |
| 8245 |    70 | Master or equivalent      |
| 8246 |    60 | Bachelor or equivalent    |
| 8250 |    70 | Master or equivalent      |
| 8251 |    70 | Master or equivalent      |
| 8252 |    70 | Master or equivalent      |
| 8253 |    60 | Bachelor or equivalent    |
| 8254 |    70 | Master or equivalent      |
| 8255 |    60 | Bachelor or equivalent    |
| 8256 |    70 | Master or equivalent      |
| 8257 |    70 | Master or equivalent      |
| 8258 |    70 | Master or equivalent      |
| 8259 |    70 | Master or equivalent      |
| 8260 |    70 | Master or equivalent      |
| 8261 |    60 | Bachelor or equivalent    |
| 8262 |    70 | Master or equivalent      |
| 8263 |    70 | Master or equivalent      |
| 8265 |    60 | Bachelor or equivalent    |
| 8270 |    70 | Master or equivalent      |
| 8271 |    60 | Bachelor or equivalent    |
| 8272 |    70 | Master or equivalent      |
| 8275 |    70 | Master or equivalent      |
| 8281 |    70 | Master or equivalent      |
| 8282 |    60 | Bachelor or equivalent    |
| 8283 |    70 | Master or equivalent      |
| 8284 |    70 | Master or equivalent      |
| 8285 |    60 | Bachelor or equivalent    |
| 8290 |    60 | Bachelor or equivalent    |
| 8291 |    60 | Bachelor or equivalent    |
| 8292 |    60 | Bachelor or equivalent    |
| 8295 |    70 | Master or equivalent      |
| 8296 |    70 | Master or equivalent      |
| 8300 |    70 | Master or equivalent      |
| 8301 |    80 | Doctoral or equivalent    |
| 8302 |    70 | Master or equivalent      |
| 8303 |    70 | Master or equivalent      |
| 8304 |    70 | Master or equivalent      |
| 8305 |    70 | Master or equivalent      |
| 8306 |    70 | Master or equivalent      |
| 8307 |    70 | Master or equivalent      |
| 8308 |    70 | Master or equivalent      |
| 8309 |    70 | Master or equivalent      |
| 8310 |    70 | Master or equivalent      |
| 8311 |    70 | Master or equivalent      |
| 8312 |    70 | Master or equivalent      |
| 8313 |    70 | Master or equivalent      |
| 8314 |    70 | Master or equivalent      |
| 8315 |    70 | Master or equivalent      |
| 8316 |    70 | Master or equivalent      |
| 8317 |    70 | Master or equivalent      |
| 8318 |    70 | Master or equivalent      |
| 8319 |    70 | Master or equivalent      |
| 8320 |    70 | Master or equivalent      |
| 8321 |    70 | Master or equivalent      |
| 8322 |    70 | Master or equivalent      |
| 8323 |    70 | Master or equivalent      |
| 8324 |    70 | Master or equivalent      |
| 8325 |    70 | Master or equivalent      |
| 8326 |    70 | Master or equivalent      |
| 8327 |    70 | Master or equivalent      |
| 8328 |    70 | Master or equivalent      |
| 8329 |    70 | Master or equivalent      |
| 8330 |    70 | Master or equivalent      |
| 8331 |    70 | Master or equivalent      |
| 8332 |    70 | Master or equivalent      |
| 8333 |    70 | Master or equivalent      |
| 8334 |    70 | Master or equivalent      |
| 8335 |    70 | Master or equivalent      |
| 8336 |    70 | Master or equivalent      |
| 8337 |    70 | Master or equivalent      |
| 8338 |    70 | Master or equivalent      |
| 8339 |    70 | Master or equivalent      |
| 8340 |    70 | Master or equivalent      |
| 8341 |    70 | Master or equivalent      |
| 8342 |    70 | Master or equivalent      |
| 8343 |    70 | Master or equivalent      |
| 8344 |    70 | Master or equivalent      |
| 8345 |    70 | Master or equivalent      |
| 8346 |    70 | Master or equivalent      |
| 8347 |    70 | Master or equivalent      |
| 8348 |    70 | Master or equivalent      |
| 8349 |    70 | Master or equivalent      |
| 8350 |    70 | Master or equivalent      |
| 8351 |    70 | Master or equivalent      |
| 8352 |    70 | Master or equivalent      |
| 8353 |    70 | Master or equivalent      |
| 8354 |    70 | Master or equivalent      |
| 8355 |    70 | Master or equivalent      |
| 8356 |    70 | Master or equivalent      |
| 8357 |    70 | Master or equivalent      |
| 8358 |    70 | Master or equivalent      |
| 8359 |    70 | Master or equivalent      |
| 8360 |    70 | Master or equivalent      |
| 8361 |    70 | Master or equivalent      |
| 8362 |    70 | Master or equivalent      |
| 8363 |    70 | Master or equivalent      |
| 8364 |    70 | Master or equivalent      |
| 8365 |    70 | Master or equivalent      |
| 8366 |    70 | Master or equivalent      |
| 8367 |    70 | Master or equivalent      |
| 8368 |    70 | Master or equivalent      |
| 8369 |    70 | Master or equivalent      |
| 8370 |    70 | Master or equivalent      |
| 8371 |    70 | Master or equivalent      |
| 8372 |    70 | Master or equivalent      |
| 8373 |    70 | Master or equivalent      |
| 8374 |    70 | Master or equivalent      |
| 8375 |    70 | Master or equivalent      |
| 8376 |    70 | Master or equivalent      |
| 8378 |    70 | Master or equivalent      |
| 8379 |    60 | Bachelor or equivalent    |
| 8380 |    70 | Master or equivalent      |
| 8381 |    70 | Master or equivalent      |
| 8382 |    70 | Master or equivalent      |
| 8383 |    70 | Master or equivalent      |
| 8384 |    70 | Master or equivalent      |
| 8385 |    70 | Master or equivalent      |
| 8386 |    70 | Master or equivalent      |
| 8400 |    60 | Bachelor or equivalent    |
| 8401 |    50 | Short cycle tertiary      |
| 8402 |    60 | Bachelor or equivalent    |
| 8403 |    60 | Bachelor or equivalent    |
| 8404 |    60 | Bachelor or equivalent    |
| 8405 |    60 | Bachelor or equivalent    |
| 8406 |    60 | Bachelor or equivalent    |
| 8407 |    60 | Bachelor or equivalent    |
| 8408 |    50 | Short cycle tertiary      |
| 8409 |    60 | Bachelor or equivalent    |
| 8410 |    60 | Bachelor or equivalent    |
| 8411 |    60 | Bachelor or equivalent    |
| 8412 |    60 | Bachelor or equivalent    |
| 8413 |    50 | Short cycle tertiary      |
| 8415 |    70 | Master or equivalent      |
| 8416 |    70 | Master or equivalent      |
| 8420 |    60 | Bachelor or equivalent    |
| 8440 |    60 | Bachelor or equivalent    |
| 8441 |    50 | Short cycle tertiary      |
| 8442 |    50 | Short cycle tertiary      |
| 8443 |    50 | Short cycle tertiary      |
| 8444 |    50 | Short cycle tertiary      |
| 8445 |    60 | Bachelor or equivalent    |
| 8446 |    60 | Bachelor or equivalent    |
| 8447 |    60 | Bachelor or equivalent    |
| 8448 |    60 | Bachelor or equivalent    |
| 8501 |    60 | Bachelor or equivalent    |
| 8502 |    60 | Bachelor or equivalent    |
| 8503 |    60 | Bachelor or equivalent    |
| 8504 |    60 | Bachelor or equivalent    |
| 8505 |    60 | Bachelor or equivalent    |
| 8506 |    60 | Bachelor or equivalent    |
| 8507 |    60 | Bachelor or equivalent    |
| 8508 |    60 | Bachelor or equivalent    |
| 8510 |    60 | Bachelor or equivalent    |
| 8511 |    60 | Bachelor or equivalent    |
| 8517 |    60 | Bachelor or equivalent    |
| 8518 |    60 | Bachelor or equivalent    |
| 8519 |    60 | Bachelor or equivalent    |
| 8520 |    60 | Bachelor or equivalent    |
| 8521 |    60 | Bachelor or equivalent    |
| 8522 |    60 | Bachelor or equivalent    |
| 8523 |    50 | Short cycle tertiary      |
| 8524 |    60 | Bachelor or equivalent    |
| 8525 |    60 | Bachelor or equivalent    |
| 8526 |    60 | Bachelor or equivalent    |
| 8552 |    60 | Bachelor or equivalent    |
| 8553 |    60 | Bachelor or equivalent    |
| 8554 |    60 | Bachelor or equivalent    |
| 8555 |    60 | Bachelor or equivalent    |
| 8556 |    60 | Bachelor or equivalent    |
| 8557 |    60 | Bachelor or equivalent    |
| 8558 |    60 | Bachelor or equivalent    |
| 8559 |    60 | Bachelor or equivalent    |
| 8560 |    60 | Bachelor or equivalent    |
| 8561 |    60 | Bachelor or equivalent    |
| 8562 |    60 | Bachelor or equivalent    |
| 8563 |    60 | Bachelor or equivalent    |
| 8585 |    70 | Master or equivalent      |
| 8586 |    60 | Bachelor or equivalent    |
| 8587 |    70 | Master or equivalent      |
| 8588 |    70 | Master or equivalent      |
| 8599 |    60 | Bachelor or equivalent    |
| 8600 |    60 | Bachelor or equivalent    |
| 8601 |    60 | Bachelor or equivalent    |
| 8602 |    60 | Bachelor or equivalent    |
| 8603 |    60 | Bachelor or equivalent    |
| 8604 |    50 | Short cycle tertiary      |
| 8620 |    60 | Bachelor or equivalent    |
| 8621 |    60 | Bachelor or equivalent    |
| 8622 |    60 | Bachelor or equivalent    |
| 8623 |    60 | Bachelor or equivalent    |
| 8624 |    60 | Bachelor or equivalent    |
| 8625 |    60 | Bachelor or equivalent    |
| 8626 |    60 | Bachelor or equivalent    |
| 8627 |    60 | Bachelor or equivalent    |
| 8628 |    60 | Bachelor or equivalent    |
| 8629 |    60 | Bachelor or equivalent    |
| 8630 |    60 | Bachelor or equivalent    |
| 8631 |    60 | Bachelor or equivalent    |
| 8632 |    60 | Bachelor or equivalent    |
| 8633 |    60 | Bachelor or equivalent    |
| 8634 |    60 | Bachelor or equivalent    |
| 8635 |    60 | Bachelor or equivalent    |
| 8636 |    60 | Bachelor or equivalent    |
| 8637 |    60 | Bachelor or equivalent    |
| 8638 |    60 | Bachelor or equivalent    |
| 8639 |    60 | Bachelor or equivalent    |
| 8655 |    60 | Bachelor or equivalent    |
| 8656 |    60 | Bachelor or equivalent    |
| 8657 |    60 | Bachelor or equivalent    |
| 8658 |    60 | Bachelor or equivalent    |
| 8670 |    60 | Bachelor or equivalent    |
| 8671 |    60 | Bachelor or equivalent    |
| 8672 |    60 | Bachelor or equivalent    |
| 8673 |    60 | Bachelor or equivalent    |
| 8674 |    60 | Bachelor or equivalent    |
| 8750 |    70 | Master or equivalent      |
| 8799 |    70 | Master or equivalent      |
| 8800 |    70 | Master or equivalent      |
| 8801 |    70 | Master or equivalent      |
| 8802 |    70 | Master or equivalent      |
| 8803 |    70 | Master or equivalent      |
| 8804 |    70 | Master or equivalent      |
| 8805 |    70 | Master or equivalent      |
| 8806 |    70 | Master or equivalent      |
| 8807 |    70 | Master or equivalent      |
| 8808 |    70 | Master or equivalent      |
| 8809 |    70 | Master or equivalent      |
| 8810 |    70 | Master or equivalent      |
| 8811 |    70 | Master or equivalent      |
| 8812 |    70 | Master or equivalent      |
| 8813 |    70 | Master or equivalent      |
| 8814 |    70 | Master or equivalent      |
| 8815 |    70 | Master or equivalent      |
| 8816 |    70 | Master or equivalent      |
| 8817 |    70 | Master or equivalent      |
| 8818 |    70 | Master or equivalent      |
| 8819 |    70 | Master or equivalent      |
| 8820 |    70 | Master or equivalent      |
| 8821 |    70 | Master or equivalent      |
| 8822 |    70 | Master or equivalent      |
| 8823 |    70 | Master or equivalent      |
| 8824 |    70 | Master or equivalent      |
| 8825 |    70 | Master or equivalent      |
| 8826 |    70 | Master or equivalent      |
| 8827 |    70 | Master or equivalent      |
| 8828 |    70 | Master or equivalent      |
| 8829 |    70 | Master or equivalent      |
| 8830 |    70 | Master or equivalent      |
| 8831 |    70 | Master or equivalent      |
| 8832 |    70 | Master or equivalent      |
| 8833 |    70 | Master or equivalent      |
| 8834 |    70 | Master or equivalent      |
| 8835 |    70 | Master or equivalent      |
| 8836 |    70 | Master or equivalent      |
| 8837 |    70 | Master or equivalent      |
| 8838 |    70 | Master or equivalent      |
| 8839 |    70 | Master or equivalent      |
| 8840 |    70 | Master or equivalent      |
| 8841 |    70 | Master or equivalent      |
| 8842 |    70 | Master or equivalent      |
| 8843 |    70 | Master or equivalent      |
| 8844 |    70 | Master or equivalent      |
| 8845 |    70 | Master or equivalent      |
| 8846 |    70 | Master or equivalent      |
| 8847 |    70 | Master or equivalent      |
| 8848 |    70 | Master or equivalent      |
| 8849 |    70 | Master or equivalent      |
| 8850 |    70 | Master or equivalent      |
| 8851 |    70 | Master or equivalent      |
| 8852 |    70 | Master or equivalent      |
| 8853 |    70 | Master or equivalent      |
| 8854 |    70 | Master or equivalent      |
| 8855 |    70 | Master or equivalent      |
| 8856 |    70 | Master or equivalent      |
| 8857 |    70 | Master or equivalent      |
| 8858 |    70 | Master or equivalent      |
| 8859 |    70 | Master or equivalent      |
| 8860 |    70 | Master or equivalent      |
| 8861 |    70 | Master or equivalent      |
| 8862 |    70 | Master or equivalent      |
| 8863 |    70 | Master or equivalent      |
| 8864 |    70 | Master or equivalent      |
| 8865 |    70 | Master or equivalent      |
| 8866 |    70 | Master or equivalent      |
| 8867 |    70 | Master or equivalent      |
| 8868 |    70 | Master or equivalent      |
| 8869 |    70 | Master or equivalent      |
| 8870 |    70 | Master or equivalent      |
| 8871 |    70 | Master or equivalent      |
| 8872 |    70 | Master or equivalent      |
| 8873 |    70 | Master or equivalent      |
| 8874 |    70 | Master or equivalent      |
| 8875 |    70 | Master or equivalent      |
| 8876 |    70 | Master or equivalent      |
| 8877 |    70 | Master or equivalent      |
| 8878 |    70 | Master or equivalent      |
| 8879 |    70 | Master or equivalent      |
| 8880 |    70 | Master or equivalent      |
| 8881 |    70 | Master or equivalent      |
| 8882 |    70 | Master or equivalent      |
| 8883 |    70 | Master or equivalent      |
| 8884 |    70 | Master or equivalent      |
| 8885 |    70 | Master or equivalent      |
| 8886 |    70 | Master or equivalent      |
| 8887 |    70 | Master or equivalent      |
| 8888 |    70 | Master or equivalent      |
| 8889 |    70 | Master or equivalent      |
| 8890 |    70 | Master or equivalent      |
| 8891 |    70 | Master or equivalent      |
| 8892 |    70 | Master or equivalent      |
| 8893 |    70 | Master or equivalent      |
| 8894 |    70 | Master or equivalent      |
| 8895 |    70 | Master or equivalent      |
| 8896 |    70 | Master or equivalent      |
| 8897 |    70 | Master or equivalent      |
| 8898 |    70 | Master or equivalent      |
| 8899 |    70 | Master or equivalent      |
| 8900 |    70 | Master or equivalent      |
| 8901 |    70 | Master or equivalent      |
| 8902 |    70 | Master or equivalent      |
| 8903 |    70 | Master or equivalent      |
| 8904 |    70 | Master or equivalent      |
| 8905 |    70 | Master or equivalent      |
| 8906 |    70 | Master or equivalent      |
| 8907 |    70 | Master or equivalent      |
| 8908 |    70 | Master or equivalent      |
| 8909 |    70 | Master or equivalent      |
| 8910 |    70 | Master or equivalent      |
| 8911 |    70 | Master or equivalent      |
| 8912 |    70 | Master or equivalent      |
| 8913 |    70 | Master or equivalent      |
| 8914 |    70 | Master or equivalent      |
| 8915 |    70 | Master or equivalent      |
| 8916 |    70 | Master or equivalent      |
| 8917 |    70 | Master or equivalent      |
| 8918 |    70 | Master or equivalent      |
| 8919 |    70 | Master or equivalent      |
| 8920 |    70 | Master or equivalent      |
| 8921 |    70 | Master or equivalent      |
| 8922 |    70 | Master or equivalent      |
| 8923 |    70 | Master or equivalent      |
| 8924 |    70 | Master or equivalent      |
| 8925 |    70 | Master or equivalent      |
| 8926 |    70 | Master or equivalent      |
| 8927 |    70 | Master or equivalent      |
| 8928 |    70 | Master or equivalent      |
| 8929 |    70 | Master or equivalent      |
| 8930 |    70 | Master or equivalent      |
| 8931 |    70 | Master or equivalent      |
| 8932 |    70 | Master or equivalent      |
| 8933 |    70 | Master or equivalent      |
| 8934 |    70 | Master or equivalent      |
| 8935 |    70 | Master or equivalent      |
| 8936 |    70 | Master or equivalent      |
| 8937 |    70 | Master or equivalent      |
| 8938 |    70 | Master or equivalent      |
| 8939 |    70 | Master or equivalent      |
| 8940 |    70 | Master or equivalent      |
| 8941 |    70 | Master or equivalent      |
| 8942 |    70 | Master or equivalent      |
| 8943 |    70 | Master or equivalent      |
| 8944 |    70 | Master or equivalent      |
| 8945 |    70 | Master or equivalent      |
| 8946 |    70 | Master or equivalent      |
| 8947 |    70 | Master or equivalent      |
| 8948 |    70 | Master or equivalent      |
| 8949 |    70 | Master or equivalent      |
| 8950 |    70 | Master or equivalent      |
| 8951 |    70 | Master or equivalent      |
| 8952 |    70 | Master or equivalent      |
| 8953 |    70 | Master or equivalent      |
| 8954 |    70 | Master or equivalent      |
| 8955 |    70 | Master or equivalent      |
| 8956 |    70 | Master or equivalent      |
| 8957 |    70 | Master or equivalent      |
| 8958 |    70 | Master or equivalent      |
| 8959 |    70 | Master or equivalent      |
| 8969 |    70 | Master or equivalent      |
| 8970 |    70 | Master or equivalent      |
| 8971 |    70 | Master or equivalent      |
| 8972 |    70 | Master or equivalent      |
| 8973 |    70 | Master or equivalent      |
| 8974 |    70 | Master or equivalent      |
| 8975 |    70 | Master or equivalent      |
| 8976 |    70 | Master or equivalent      |
| 8977 |    70 | Master or equivalent      |
| 8978 |    70 | Master or equivalent      |
| 8979 |    70 | Master or equivalent      |
| 8980 |    70 | Master or equivalent      |
| 8994 |    70 | Master or equivalent      |
| 8995 |    70 | Master or equivalent      |
| 8996 |    70 | Master or equivalent      |
| 8997 |    70 | Master or equivalent      |
| 8998 |    70 | Master or equivalent      |
| 8999 |    70 | Master or equivalent      |
| 9014 |    30 | Upper secondary           |
| 9015 |    60 | Bachelor or equivalent    |
| 9020 |    60 | Bachelor or equivalent    |
| 9030 |    60 | Bachelor or equivalent    |
| 9034 |    70 | Master or equivalent      |
| 9035 |    70 | Master or equivalent      |
| 9036 |    70 | Master or equivalent      |
| 9037 |    70 | Master or equivalent      |
| 9038 |    70 | Master or equivalent      |
| 9039 |    70 | Master or equivalent      |
| 9040 |    70 | Master or equivalent      |
| 9041 |    70 | Master or equivalent      |
| 9042 |    70 | Master or equivalent      |
| 9043 |    70 | Master or equivalent      |
| 9044 |    70 | Master or equivalent      |
| 9045 |    70 | Master or equivalent      |
| 9046 |    70 | Master or equivalent      |
| 9047 |    70 | Master or equivalent      |
| 9049 |    70 | Master or equivalent      |
| 9050 |    70 | Master or equivalent      |
| 9051 |    70 | Master or equivalent      |
| 9052 |    70 | Master or equivalent      |
| 9053 |    70 | Master or equivalent      |
| 9054 |    70 | Master or equivalent      |
| 9055 |    70 | Master or equivalent      |
| 9056 |    70 | Master or equivalent      |
| 9057 |    70 | Master or equivalent      |
| 9061 |    70 | Master or equivalent      |
| 9062 |    70 | Master or equivalent      |
| 9106 |    30 | Upper secondary           |
| 9121 |    70 | Master or equivalent      |
| 9122 |    70 | Master or equivalent      |
| 9123 |    70 | Master or equivalent      |
| 9124 |    70 | Master or equivalent      |
| 9125 |    70 | Master or equivalent      |
| 9132 |    50 | Short cycle tertiary      |
| 9144 |    50 | Short cycle tertiary      |
| 9167 |    60 | Bachelor or equivalent    |
| 9171 |    80 | Doctoral or equivalent    |
| 9172 |    60 | Bachelor or equivalent    |
| 9173 |    30 | Upper secondary           |
| 9174 |    70 | Master or equivalent      |
| 9175 |    70 | Master or equivalent      |
| 9176 |    60 | Bachelor or equivalent    |
| 9197 |    60 | Bachelor or equivalent    |
| 9203 |    50 | Short cycle tertiary      |
| 9215 |    30 | Upper secondary           |
| 9224 |    60 | Bachelor or equivalent    |
| 9225 |    70 | Master or equivalent      |
| 9258 |    80 | Doctoral or equivalent    |
| 9264 |    70 | Master or equivalent      |
| 9266 |    80 | Doctoral or equivalent    |
| 9267 |    80 | Doctoral or equivalent    |
| 9269 |    80 | Doctoral or equivalent    |
| 9315 |    30 | Upper secondary           |
| 9316 |    30 | Upper secondary           |
| 9317 |    30 | Upper secondary           |
| 9320 |    30 | Upper secondary           |
| 9321 |    30 | Upper secondary           |
| 9322 |    30 | Upper secondary           |
| 9327 |    30 | Upper secondary           |
| 9328 |    30 | Upper secondary           |
| 9329 |    30 | Upper secondary           |
| 9330 |    30 | Upper secondary           |
| 9332 |    30 | Upper secondary           |
| 9333 |    30 | Upper secondary           |
| 9334 |    30 | Upper secondary           |
| 9338 |    30 | Upper secondary           |
| 9339 |    70 | Master or equivalent      |
| 9342 |    30 | Upper secondary           |
| 9369 |    30 | Upper secondary           |
| 9382 |    30 | Upper secondary           |
| 9384 |    30 | Upper secondary           |
| 9385 |    70 | Master or equivalent      |
| 9386 |    30 | Upper secondary           |
| 9390 |    80 | Doctoral or equivalent    |
| 9391 |    70 | Master or equivalent      |
| 9392 |    70 | Master or equivalent      |
| 9393 |    70 | Master or equivalent      |
| 9394 |    70 | Master or equivalent      |
| 9395 |    70 | Master or equivalent      |
| 9396 |    70 | Master or equivalent      |
| 9397 |    70 | Master or equivalent      |
| 9398 |    70 | Master or equivalent      |
| 9399 |    70 | Master or equivalent      |
| 9400 |    70 | Master or equivalent      |
| 9403 |    70 | Master or equivalent      |
| 9404 |    70 | Master or equivalent      |
| 9405 |    70 | Master or equivalent      |
| 9406 |    70 | Master or equivalent      |
| 9407 |    70 | Master or equivalent      |
| 9409 |    70 | Master or equivalent      |
| 9410 |    70 | Master or equivalent      |
| 9412 |    70 | Master or equivalent      |
| 9413 |    70 | Master or equivalent      |
| 9414 |    70 | Master or equivalent      |
| 9416 |    70 | Master or equivalent      |
| 9418 |    70 | Master or equivalent      |
| 9420 |    70 | Master or equivalent      |
| 9422 |    70 | Master or equivalent      |
| 9423 |    70 | Master or equivalent      |
| 9424 |    70 | Master or equivalent      |
| 9429 |    30 | Upper secondary           |
| 9430 |    80 | Doctoral or equivalent    |
| 9431 |    30 | Upper secondary           |
| 9434 |    30 | Upper secondary           |
| 9435 |    30 | Upper secondary           |
| 9440 |    30 | Upper secondary           |
| 9445 |    30 | Upper secondary           |
| 9450 |    80 | Doctoral or equivalent    |
| 9465 |    70 | Master or equivalent      |
| 9467 |    30 | Upper secondary           |
| 9468 |    30 | Upper secondary           |
| 9469 |    70 | Master or equivalent      |
| 9470 |    60 | Bachelor or equivalent    |
| 9471 |    70 | Master or equivalent      |
| 9472 |    70 | Master or equivalent      |
| 9473 |    70 | Master or equivalent      |
| 9474 |    60 | Bachelor or equivalent    |
| 9475 |    70 | Master or equivalent      |
| 9476 |    70 | Master or equivalent      |
| 9477 |    60 | Bachelor or equivalent    |
| 9481 |    70 | Master or equivalent      |
| 9483 |    30 | Upper secondary           |
| 9484 |    30 | Upper secondary           |
| 9485 |    30 | Upper secondary           |
| 9486 |    30 | Upper secondary           |
| 9487 |    70 | Master or equivalent      |
| 9488 |    80 | Doctoral or equivalent    |
| 9490 |    70 | Master or equivalent      |
| 9491 |    70 | Master or equivalent      |
| 9492 |    80 | Doctoral or equivalent    |
| 9493 |    70 | Master or equivalent      |
| 9495 |    60 | Bachelor or equivalent    |
| 9498 |    70 | Master or equivalent      |
| 9500 |    70 | Master or equivalent      |
| 9502 |    80 | Doctoral or equivalent    |
| 9504 |    70 | Master or equivalent      |
| 9505 |    70 | Master or equivalent      |
| 9508 |    70 | Master or equivalent      |
| 9514 |    70 | Master or equivalent      |
| 9515 |    70 | Master or equivalent      |
| 9517 |    30 | Upper secondary           |
| 9518 |    80 | Doctoral or equivalent    |
| 9529 |    50 | Short cycle tertiary      |
| 9531 |    60 | Bachelor or equivalent    |
| 9533 |    50 | Short cycle tertiary      |
| 9534 |    50 | Short cycle tertiary      |
| 9535 |    50 | Short cycle tertiary      |
| 9536 |    50 | Short cycle tertiary      |
| 9537 |    50 | Short cycle tertiary      |
| 9538 |    50 | Short cycle tertiary      |
| 9539 |    50 | Short cycle tertiary      |
| 9540 |    30 | Upper secondary           |
| 9541 |    50 | Short cycle tertiary      |
| 9542 |    50 | Short cycle tertiary      |
| 9556 |    80 | Doctoral or equivalent    |
| 9564 |    30 | Upper secondary           |
| 9569 |    30 | Upper secondary           |
| 9571 |    80 | Doctoral or equivalent    |
| 9572 |    60 | Bachelor or equivalent    |
| 9573 |    30 | Upper secondary           |
| 9574 |    60 | Bachelor or equivalent    |
| 9580 |    60 | Bachelor or equivalent    |
| 9584 |    60 | Bachelor or equivalent    |
| 9585 |    60 | Bachelor or equivalent    |
| 9586 |    60 | Bachelor or equivalent    |
| 9588 |    60 | Bachelor or equivalent    |
| 9589 |    60 | Bachelor or equivalent    |
| 9602 |    20 | Lower secondary           |
| 9603 |    20 | Lower secondary           |
| 9604 |    20 | Lower secondary           |
| 9606 |    20 | Lower secondary           |
| 9607 |    20 | Lower secondary           |
| 9618 |    50 | Short cycle tertiary      |
| 9620 |    60 | Bachelor or equivalent    |
| 9621 |    30 | Upper secondary           |
| 9622 |    30 | Upper secondary           |
| 9623 |    30 | Upper secondary           |
| 9636 |    30 | Upper secondary           |
| 9654 |    30 | Upper secondary           |
| 9655 |    60 | Bachelor or equivalent    |
| 9658 |    60 | Bachelor or equivalent    |
| 9661 |    30 | Upper secondary           |
| 9668 |    70 | Master or equivalent      |
| 9677 |    30 | Upper secondary           |
| 9678 |    30 | Upper secondary           |
| 9679 |    30 | Upper secondary           |
| 9681 |    30 | Upper secondary           |
| 9682 |    30 | Upper secondary           |
| 9683 |    30 | Upper secondary           |
| 9684 |    30 | Upper secondary           |
| 9685 |    30 | Upper secondary           |
| 9686 |    70 | Master or equivalent      |
| 9687 |    60 | Bachelor or equivalent    |
| 9688 |    60 | Bachelor or equivalent    |
| 9689 |    30 | Upper secondary           |
| 9693 |    30 | Upper secondary           |
| 9694 |    30 | Upper secondary           |
| 9695 |    30 | Upper secondary           |
| 9696 |    30 | Upper secondary           |
| 9697 |    30 | Upper secondary           |
| 9698 |    30 | Upper secondary           |
| 9699 |    30 | Upper secondary           |
| 9703 |    30 | Upper secondary           |
| 9704 |    30 | Upper secondary           |
| 9705 |    60 | Bachelor or equivalent    |
| 9706 |    30 | Upper secondary           |
| 9707 |    60 | Bachelor or equivalent    |
| 9708 |    30 | Upper secondary           |
| 9709 |    30 | Upper secondary           |
| 9710 |    30 | Upper secondary           |
| 9711 |    30 | Upper secondary           |
| 9712 |    30 | Upper secondary           |
| 9713 |    30 | Upper secondary           |
| 9714 |    60 | Bachelor or equivalent    |
| 9715 |    30 | Upper secondary           |
| 9716 |    70 | Master or equivalent      |
| 9717 |    70 | Master or equivalent      |
| 9718 |    30 | Upper secondary           |
| 9719 |    30 | Upper secondary           |
| 9720 |    30 | Upper secondary           |
| 9721 |    30 | Upper secondary           |
| 9722 |    30 | Upper secondary           |
| 9723 |    30 | Upper secondary           |
| 9724 |    30 | Upper secondary           |
| 9725 |    30 | Upper secondary           |
| 9726 |    30 | Upper secondary           |
| 9730 |    30 | Upper secondary           |
| 9731 |    30 | Upper secondary           |
| 9732 |    30 | Upper secondary           |
| 9733 |    30 | Upper secondary           |
| 9734 |    30 | Upper secondary           |
| 9735 |    30 | Upper secondary           |
| 9736 |    30 | Upper secondary           |
| 9737 |    30 | Upper secondary           |
| 9738 |    30 | Upper secondary           |
| 9739 |    30 | Upper secondary           |
| 9740 |    30 | Upper secondary           |
| 9741 |    30 | Upper secondary           |
| 9742 |    30 | Upper secondary           |
| 9743 |    30 | Upper secondary           |
| 9744 |    30 | Upper secondary           |
| 9745 |    30 | Upper secondary           |
| 9746 |    30 | Upper secondary           |
| 9747 |    30 | Upper secondary           |
| 9748 |    30 | Upper secondary           |
| 9749 |    30 | Upper secondary           |
| 9750 |    30 | Upper secondary           |
| 9751 |    30 | Upper secondary           |
| 9752 |    30 | Upper secondary           |
| 9753 |    30 | Upper secondary           |
| 9754 |    30 | Upper secondary           |
| 9755 |    30 | Upper secondary           |
| 9756 |    30 | Upper secondary           |
| 9757 |    30 | Upper secondary           |
| 9758 |    30 | Upper secondary           |
| 9759 |    30 | Upper secondary           |
| 9760 |    30 | Upper secondary           |
| 9761 |    30 | Upper secondary           |
| 9762 |    30 | Upper secondary           |
| 9763 |    30 | Upper secondary           |
| 9764 |    30 | Upper secondary           |
| 9765 |    30 | Upper secondary           |
| 9766 |    30 | Upper secondary           |
| 9767 |    30 | Upper secondary           |
| 9768 |    30 | Upper secondary           |
| 9769 |    30 | Upper secondary           |
| 9770 |    30 | Upper secondary           |
| 9771 |    30 | Upper secondary           |
| 9772 |    30 | Upper secondary           |
| 9773 |    30 | Upper secondary           |
| 9774 |    30 | Upper secondary           |
| 9775 |    30 | Upper secondary           |
| 9776 |    30 | Upper secondary           |
| 9777 |    30 | Upper secondary           |
| 9778 |    30 | Upper secondary           |
| 9779 |    30 | Upper secondary           |
| 9780 |    30 | Upper secondary           |
| 9781 |    30 | Upper secondary           |
| 9782 |    30 | Upper secondary           |
| 9783 |    30 | Upper secondary           |
| 9784 |    30 | Upper secondary           |
| 9785 |    30 | Upper secondary           |
| 9786 |    30 | Upper secondary           |
| 9787 |    30 | Upper secondary           |
| 9788 |    30 | Upper secondary           |
| 9800 |    30 | Upper secondary           |
| 9801 |    30 | Upper secondary           |
| 9802 |    30 | Upper secondary           |
| 9803 |    30 | Upper secondary           |
| 9804 |    30 | Upper secondary           |
| 9805 |    30 | Upper secondary           |
| 9806 |    30 | Upper secondary           |
| 9807 |    30 | Upper secondary           |
| 9808 |    30 | Upper secondary           |
| 9809 |    30 | Upper secondary           |
| 9810 |    30 | Upper secondary           |
| 9811 |    30 | Upper secondary           |
| 9812 |    30 | Upper secondary           |
| 9813 |    30 | Upper secondary           |
| 9814 |    30 | Upper secondary           |
| 9815 |    30 | Upper secondary           |
| 9816 |    30 | Upper secondary           |
| 9817 |    30 | Upper secondary           |
| 9818 |    30 | Upper secondary           |
| 9819 |    30 | Upper secondary           |
| 9820 |    30 | Upper secondary           |
| 9821 |    30 | Upper secondary           |
| 9822 |    30 | Upper secondary           |
| 9823 |    30 | Upper secondary           |
| 9824 |    30 | Upper secondary           |
| 9825 |    30 | Upper secondary           |
| 9826 |    30 | Upper secondary           |
| 9827 |    30 | Upper secondary           |
| 9828 |    30 | Upper secondary           |
| 9829 |    30 | Upper secondary           |
| 9830 |    30 | Upper secondary           |
| 9831 |    30 | Upper secondary           |
| 9832 |    30 | Upper secondary           |
| 9833 |    30 | Upper secondary           |
| 9834 |    30 | Upper secondary           |
| 9835 |    30 | Upper secondary           |
| 9836 |    30 | Upper secondary           |
| 9837 |    30 | Upper secondary           |
| 9838 |    30 | Upper secondary           |
| 9839 |    30 | Upper secondary           |
| 9840 |    30 | Upper secondary           |
| 9841 |    30 | Upper secondary           |
| 9842 |    30 | Upper secondary           |
| 9843 |    30 | Upper secondary           |
| 9844 |    30 | Upper secondary           |
| 9845 |    30 | Upper secondary           |
| 9846 |    30 | Upper secondary           |
| 9847 |    30 | Upper secondary           |
| 9848 |    30 | Upper secondary           |
| 9849 |    30 | Upper secondary           |
| 9850 |    30 | Upper secondary           |
| 9851 |    30 | Upper secondary           |
| 9852 |    30 | Upper secondary           |
| 9853 |    30 | Upper secondary           |
| 9854 |    30 | Upper secondary           |
| 9855 |    30 | Upper secondary           |
| 9856 |    30 | Upper secondary           |
| 9857 |    30 | Upper secondary           |
| 9858 |    30 | Upper secondary           |
| 9859 |    30 | Upper secondary           |
| 9860 |    30 | Upper secondary           |
| 9861 |    30 | Upper secondary           |
| 9862 |    30 | Upper secondary           |
| 9863 |    30 | Upper secondary           |
| 9864 |    30 | Upper secondary           |
| 9865 |    30 | Upper secondary           |
| 9866 |    30 | Upper secondary           |
| 9867 |    30 | Upper secondary           |
| 9868 |    30 | Upper secondary           |
| 9869 |    30 | Upper secondary           |
| 9870 |    30 | Upper secondary           |
| 9871 |    30 | Upper secondary           |
| 9872 |    30 | Upper secondary           |
| 9873 |    30 | Upper secondary           |
| 9874 |    30 | Upper secondary           |
| 9875 |    30 | Upper secondary           |
| 9876 |    30 | Upper secondary           |
| 9877 |    30 | Upper secondary           |
| 9878 |    30 | Upper secondary           |
| 9879 |    30 | Upper secondary           |
| 9880 |    30 | Upper secondary           |
| 9881 |    30 | Upper secondary           |
| 9882 |    30 | Upper secondary           |
| 9883 |    30 | Upper secondary           |
| 9884 |    30 | Upper secondary           |
| 9886 |    30 | Upper secondary           |
| 9887 |    30 | Upper secondary           |
| 9888 |    30 | Upper secondary           |
| 9889 |    30 | Upper secondary           |
| 9909 |    30 | Upper secondary           |
| 9910 |    30 | Upper secondary           |
| 9911 |    30 | Upper secondary           |
| 9912 |    30 | Upper secondary           |
| 9913 |    30 | Upper secondary           |
| 9914 |    30 | Upper secondary           |
| 9915 |    30 | Upper secondary           |
| 9916 |    30 | Upper secondary           |
| 9917 |    30 | Upper secondary           |
| 9918 |    30 | Upper secondary           |
| 9919 |    30 | Upper secondary           |
| 9920 |    30 | Upper secondary           |
| 9933 |    30 | Upper secondary           |
| 9999 |    90 | Not elsewhere classified  |
|------+-------+---------------------------|

** Code for creation of dataset, including initial Charlson categorization, and categories of refugees
#+begin_src R :session rsession :results output :exports both
  library(lubridate)
  library(data.table)
  ##This line facilitates testing the code with fewer lines for each dataset, for example 100 or 10000 - the current Inf simply indicates "read it all" for the actual analysis. 
  nrows <- Inf
  setDTthreads(20)

  sink("logCreationDataset.txt" , split = TRUE)

  ##This is a full rewrite of the code to make everything into months to avoid massive computing problems with the previous approach (daily updates of all available variables). Lubridate's floor_date will be used to have everything at the beginning of the month. 

  kategoriRefugee <- c(1 , 47 , 50)
  grundlagRefugee <- c(2 , 273 , 275 , 276 , 277 , 278 , 282)
  forklarRefugee <- c(126 , 156 , 164 , 173 , 175 , 181 , 187 , 209 ,
		      210 , 215 , 227 , 23 , 234 , 24 , 25 , 26 , 28 ,
		      46 , 53 , 62 , 812 , 90)

  ## kategoriRefugee1 <- c(1 , 47 , 50)
  ## grundlagRefugee1 <- c(2 , 273 , 275 , 276 , 277 , 278 , 282)
  ## forklarRefugee1 <- c(126 , 156 , 164 , 173 , 175 , 181 , 187 , 209 , 210 , 215 , 227 , 23 , 234 , 24 , 25 , 26 , 28 , 46 , 53 , 62 , 812 , 90)
  ## setdiff(kategoriRefugee , kategoriRefugee1)
  ## setdiff(grundlagRefugee , grundlagRefugee1)
  ## setdiff(forklarRefugee , forklarRefugee1)
  ##The comparison reveals no differences, validating that the manual creation is consistent with the original.

  myocardialInfarctionCharlsonCodes <- c("410" , "DI21" , "DI22")
  ##For all vectors, the same vector is entered twice with a "temp" in the end, and then compared using the following commands:
  ##setdiff(myocardialInfarctionCharlsonCodes , myocardialInfarctionCharlsonCodesTemp)
  ##setdiff(myocardialInfarctionCharlsonCodesTemp , myocardialInfarctionCharlsonCodes)
  heartFailureCharlsonCodes <- c("42709" , "42710" , "42711" , "42719" ,
				 "42899" , "78249" , "DI099" , "DI110" ,
				 "DI130" , "DI132" , "DI255" , "DI425" ,
				 "DI426" , "DI427" , "DI429" , "DI428A" ,
				 "DP290" , "DI43" , "DI50" , "DE105" ,
				 "DE115" , "DE125" , "DE135" , "DE145")  
  ##setdiff(heartFailureCharlsonCodesTemp , heartFailureCharlsonCodes)
  ##setdiff(heartFailureCharlsonCodes , heartFailureCharlsonCodesTemp)
  peripheralVascularDiseaseCharlsonCodes <- c("440" , "441" , "442" ,
					      "443" , "444" , "445" ,
					      "DI70" , "DI71" , "DI72" ,
					      "DI731" , "DI738" ,
					      "DI739" , "DI77" ,
					      "DI790" , "DI792" ,
					      "DK551" , "DK558" ,
					      "DK559" , "DZ958" ,
					      "DZ959")
  ##setdiff(peripheralVascularDiseaseCodesTemp , peripheralVascularDiseaseCodes)
  ##setdiff(peripheralVascularDiseaseCodes , peripheralVascularDiseaseCodesTemp)
  cerebrovascularDiseaseCharlsonCodes <- c(paste0("43" , 0:8) ,
					   paste0("DI6" , 0:9) , "DG45" ,
					   "DG46" , "DH340")
  ##setdiff(cerebrovascularDiseaseCharlsonCodes , cerebrovascularDiseaseCharlsonCodesTemp)
  ##setdiff(cerebrovascularDiseaseCharlsonCodesTemp , cerebrovascularDiseaseCharlsonCodes)
  dementiaCharlsonCodes <- c("290" , paste0("DF0" , 0:3) ,
			     "DG30" , "DF051" , "DG311")
  ##setdiff(dementiaCharlsonCodes , dementiaCharlsonCodesTemp)
  ##setdiff(dementiaCharlsonCodesTemp , dementiaCharlsonCodes)
  chronicPulmonaryDiseaseCharlsonCodes <- c(paste0("51" , 5:8) ,
					    paste0("49" , 0:3) ,
					    paste0("DJ4" , 0:7) ,
					    paste0("DJ6" , 0:7) ,
					    "DJ684" , "DI278" ,
					    "DI279" , "DJ84" ,
					    "DJ701" , "DJ703" ,
					    "DJ920" , "DJ953" ,
					    "DJ961" , "DJ982" ,
					    "DJ983")
  ##setdiff(chronicPulmonaryDiseaseCharlsonCodes , chronicPulmonaryDiseaseCharlsonCodesTemp)
  ##setdiff(chronicPulmonaryDiseaseCharlsonCodesTemp , chronicPulmonaryDiseaseCharlsonCodes)
  rheumaticDiseaseCharlsonCodes <- c("712" , "716" , "734" , "446" ,
				     "13599" , "DM05" , "DM06" ,
				     "DM08" , "DM09" , "DM30" ,
				     "DM31" , "DM32" , "DM33" ,
				     "DM34" , "DM35" , "DM36")
  ## setdiff(rheumaticDiseaseCharlsonCodes , rheumaticDiseaseCharlsonCodesTemp)
  ## setdiff(rheumaticDiseaseCharlsonCodesTemp , rheumaticDiseaseCharlsonCodes)
  pepticUlcerDiseaseCharlsonCodes <- c("53091" , "53098" , paste0("53" , 1:4) , "DK25" , "DK26" , "DK27" , "DK28" , "DK221")
  ## setdiff(pepticUlcerDiseaseCharlsonCodes , pepticUlcerDiseaseCharlsonCodesTemp)
  ## setdiff(pepticUlcerDiseaseCharlsonCodesTemp , pepticUlcerDiseaseCharlsonCodes)
  mildLiverDiseaseCharlsonCodes <- c("571" , "57301" , "57304" , "DB18" , "DK700" , "DK701" , "DK702" , "DK709" , "DK703" , "DK713" , "DK714" , "DK715" , "DK717" , "DK73" , "DK74" , "DK760" , "DK762" , "DK763" , "DK764" , "DK769" , "DZ944")
  ## setdiff(mildLiverDiseaseCharlsonCodes , mildLiverDiseaseCharlsonCodesTemp)
  ## setdiff(mildLiverDiseaseCharlsonCodesTemp , mildLiverDiseaseCharlsonCodes)
  severeLiverDiseaseCharlsonCodes <- c("07000" , "07002" , "07004" , "07006" , "07008" , "57300" , "45601" , "45602" , "45603" , "45604" , "45605" , "45606" , "45607" , "45608" , "45609" , "DB150" , "DB160" , "DB162" , "DB190" , "DI850" , "DI859" , "DI864" , "DI982" , "DK704" , "DK711" , "DK721" , "DK729" , "DK765" , "DK766" , "DK767")
  ## setdiff(severeLiverDiseaseCharlsonCodes , severeLiverDiseaseCharlsonCodesTemp)
  ## setdiff(severeLiverDiseaseCharlsonCodesTemp , severeLiverDiseaseCharlsonCodes)
  diabetesWithoutComplicationsCharlsonCodes <- c("24900" , "24906" , "24907" , "24909" , "25000" , "25006" , "25007" , "25009" , "DE100" , "DE101" , "DE108" , "DE109" , "DE110" , "DE111" , "DE119" , "DE120" , "DE121" , "DE129" , "DE130" , "DE131" , "DE139" , "DE140" , "DE141" , "DE149")
  ## setdiff(diabetesWithoutComplicationsCharlsonCodes , diabetesWithoutComplicationsCharlsonCodesTemp)
  ## setdiff(diabetesWithoutComplicationsCharlsonCodesTemp , diabetesWithoutComplicationsCharlsonCodes)
  diabetesWithComplicationsCharlsonCodes <- c(paste0("2490" , 1:5) , "24908" , paste0("2500" , 1:5) , "25008" , paste0("DE10" , 2:7) , paste0("DE11" , 2:8) , paste0("DE12" , 2:8) , paste0("DE13" , 2:8) , paste0("DE14" , 2:8))
  ## setdiff(diabetesWithComplicationsCharlsonCodes , diabetesWithComplicationsCharlsonCodesTemp)
  ## setdiff(diabetesWithComplicationsCharlsonCodesTemp , diabetesWithComplicationsCharlsonCodes)
  hemiplegiaParaplegiaCharlsonCodes <- c("344" , paste0("DG83" , 0:4) , "DG81" , "DG82" , "DG041" , "DG114" , "DG801" , "DG802" , "DG839")
  ## setdiff(hemiplegiaParaplegiaCharlsonCodes , hemiplegiaParaplegiaCharlsonCodesTemp)
  ## setdiff(hemiplegiaParaplegiaCharlsonCodesTemp , hemiplegiaParaplegiaCharlsonCodes)
  renalDiseaseCharlsonCodes <- c("403" , "404" , paste0("58" , 0:4) , "59009" , "59319" , paste0("7531" , 0:9) , "792" , paste0("DN03" , 2:7) , paste0("DN05" , 2:7) , "DZ490" , "DZ491" , "DZ492" , "DN18" , "DN19" , "DI120" , "DI131" , "DI132" , "DN250" , "DZ940" , "DZ992" , "DN26")
  ## setdiff(renalDiseaseCharlsonCodes , renalDiseaseCharlsonCodesTemp)
  ## setdiff(renalDiseaseCharlsonCodesTemp , renalDiseaseCharlsonCodes)
  anyMalignancyCharlsonCodes <- c(paste0("1" , 40:72) , paste0(174:194) , "27559" , paste0("DC" , 0:3) , paste0("DC4" , 0:9) , "DC5" , "DC6" , paste0("DC7" , 0:6) , "DC86" , "DC97")
  ## setdiff(anyMalignancyCharlsonCodes , anyMalignancyCharlsonCodesTemp)
  ## setdiff(anyMalignancyCharlsonCodesTemp , anyMalignancyCharlsonCodes)
  metastaticSolidTumorCharlsonCodes <- c(paste0("19" , 5:9) , paste0("DC" , 77:80))
  ## setdiff(metastaticSolidTumorCharlsonCodes , metastaticSolidTumorCharlsonCodesTemp)
  ## setdiff(metastaticSolidTumorCharlsonCodesTemp , metastaticSolidTumorCharlsonCodes)
  aidsHivCharlsonCodes <- c("07983" , "DB20" , "DB21" , "DB22" , "DB23" , "DB24")
  ## setdiff(aidsHivCharlsonCodes , aidsHivCharlsonCodesTemp)
  ## setdiff(aidsHivCharlsonCodesTemp , aidsHivCharlsonCodes)
  leukemiaCharlsonCodes <- c(paste0("20" , 4:7) , paste0("DC9" , 1:5))
  ## setdiff(leukemiaCharlsonCodesTemp , leukemiaCharlsonCodes)
  ## setdiff(leukemiaCharlsonCodes , leukemiaCharlsonCodesTemp)
  lymphomaCharlsonCodes <- c(paste0("20" , 0:3) , "27559" , paste0("DC8" , 1:5) , "DC88" , "DC90" , "DC96")
  ## setdiff(lymphomaCharlsonCodes , lymphomaCharlsonCodesTemp)
  ## setdiff(lymphomaCharlsonCodesTemp , lymphomaCharlsonCodes)



  library(data.table)

  ##LPR
  lprAdm <- fread("lpradm_pop_080621.csv" ,
		  nrows = nrows ,
		  colClasses = c(pnr = "character" ,
				 "recnum" = "character") ,
		  select = c("recnum" , "pnr" , "C_ADIAG" ,
			     "D_INDDTO" ,
			     "C_KONTAARS"))
  lprAdm[ , D_INDDTO := floor_date(as.Date(D_INDDTO , "%m/%d/%Y") , unit = "month")]
  lprDiag <- fread("lprdiag_pop_110621.csv" ,
		   nrows = nrows , drop = c("aar") ,
		   colClasses = ("recnum" = "character"))
  ##There are several types of diagnoses available - only those that can be viewed as describing the patient's condition are listed here:
  diagtypeUseful <- c("A" , "B" , "G" , "C" , "+") #Used later in the code
  ##Only other diagtype is H - for computational speed, H is excluded:
  lprDiag <- lprDiag[!C_DIAGTYPE == "H"] #H means referral diagnosis
  ##C_DIAGMOD is used before 1994. Two categories, "observed for" and  "not present" needs to be removed, as those does not indicate the presence of illness:
  lprDiag <- lprDiag[!C_DIAGMOD == 1 |
		       is.na(C_DIAGMOD)] #Meaning: Observed for
  lprDiag <- lprDiag[!C_DIAGMOD == 2 |
		       is.na(C_DIAGMOD)] #Meaning: Not found
  lprSksOpr <- fread("lprsksopr_pop_080621.csv" ,
		     nrows = nrows ,
		     drop = c("c_oprart" , "c_osgh" , "aar") ,
		     colClasses = ("recnum" = "character"))
  lprSksOpr[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  ##For some reason everything is double quoted - removing those.
  lprSksOpr[ , c_opr := gsub('\"' , '' , c_opr)]
  lprSksOpr[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  lprSksUbe <- fread("lprsksube_pop_110621.csv" ,
		     nrows = nrows ,
		     drop = c("c_oprart" , "c_osgh" , "aar") ,
		     colClasses = ("recnum" = "character"))
  lprSksUbe[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  ##For some reason everything is double quoted - removing those.
  lprSksUbe[ , c_opr := gsub('\"' , '' , c_opr)]
  lprSksUbe[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  ##The dataset has been split into two - loading and combining:
  temp <- fread("lpr_sksube_1999_2004_pop_250621.csv" , nrows = nrows , drop = c("C_OPRART" , "C_OSGH" , "aar") , colClasses = ("recnum" = "character"))
  temp[ , D_ODTO := floor_date(as.Date(D_ODTO) , unit = "month")]
  setnames(x = lprSksUbe , old = c("c_opr" , "c_tilopr" , "d_odto") , new = c("C_OPR" , "C_TILOPR" , "D_ODTO") , skip_absent = TRUE)
  lprSksUbe <- rbindlist(list(lprSksUbe , temp))
  rm(temp)
  lprUlyk <- fread("lprulyk_pop_080621.csv" , nrows = nrows , colClasses = ("recnum" = "character") , drop = c("c_art" , "year"))
  lprUlyk[ , c_tilulyk := gsub('\"' , '' , c_tilulyk)]
  lprUlyk[ , c_ulyk := gsub('\"' , '' , c_ulyk)]
  setkey(lprAdm , recnum)
  setkey(lprDiag , recnum)
  setkey(lprSksOpr , recnum)
  setkey(lprSksUbe , recnum)
  setkey(lprUlyk , recnum)
  ##Merge all the datsets for later merging with the large dataset, and put all diagnoses, procedures etc into one variable:
  lprMergeDiag <- merge(lprAdm , lprDiag , all.x = TRUE)
  ##Visually inspected, merges as expected connecting diagnoses to a pnr
  lprMergeDiag[ , c("C_DIAGMOD" , "C_DIAGTYPE" , "recnum") := NULL]
  ##Clean lines where C_ADIAG and C_DIAG are the same:
  lprMergeDiag[C_ADIAG == C_DIAG , C_DIAG := NA]
  ##Reduce to health events where different variables for diagnoses are pooled:
  lprMergeDiag <- melt(lprMergeDiag , measure.vars = c("C_ADIAG" , "C_DIAG" , "C_TILDIAG") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  lprMergeDiag[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  lprMergeDiag <- lprMergeDiag[!is.na(healthEvent)]
  lprMergeDiag <- lprMergeDiag[healthEvent != ""]
  lprMergeDiag <- lprMergeDiag[!is.na(pnr)]
  lprMergeDiag <- lprMergeDiag[pnr != ""]
  ##Visually inspected, now with one variable for all health events and dates cross-checked with original merged dataset to be the same.
  lprMergeOpr <- merge(lprAdm , lprSksOpr , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  lprMergeOpr[ , recnum := NULL]
  lprMergeOpr <- melt(lprMergeOpr , measure.vars = c("C_ADIAG" , "c_opr" , "c_tilopr") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  lprMergeOpr[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  lprMergeOpr <- lprMergeOpr[!is.na(healthEvent)]
  lprMergeOpr <- lprMergeOpr[healthEvent != ""]
  lprMergeOpr <- lprMergeOpr[!is.na(pnr)]
  lprMergeOpr <- lprMergeOpr[pnr != ""]
  ##Compared with data before merge, dates and ID are preserved correctly for health events.
  lprMergeUbe <- merge(lprAdm , lprSksUbe , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  lprMergeUbe[ , recnum := NULL]
  lprMergeUbe <- melt(lprMergeUbe , measure.vars = c("C_ADIAG" , "C_OPR" , "C_TILOPR") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  lprMergeUbe[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  lprMergeUbe <- lprMergeUbe[!is.na(healthEvent)]
  lprMergeUbe <- lprMergeUbe[healthEvent != ""]
  lprMergeUbe <- lprMergeUbe[!is.na(pnr)]
  lprMergeUbe <- lprMergeUbe[pnr != ""]
  lprMergeUlyk <- merge(lprAdm , lprUlyk , all.x = TRUE)
  ##Visually inspected, merges as expected connecting accidents to a pnr
  lprMergeUlyk[ , recnum := NULL]
  lprMergeUlyk[ , C_ADIAG := NULL]
  lprMergeUlyk <- melt(lprMergeUlyk , measure.vars = c("c_tilulyk" , "c_ulyk") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  lprMergeUlyk[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  lprMergeUlyk <- lprMergeUlyk[!is.na(healthEvent)]
  lprMergeUlyk <- lprMergeUlyk[healthEvent != ""]
  lprMergeUlyk <- lprMergeUlyk[!is.na(pnr)]
  lprMergeUlyk <- lprMergeUlyk[pnr != ""]
  ##Stack all lprAdm-related datasets on top of each other:
  setnames(lprMergeOpr , old = "d_odto" , new = "D_ODTO" , skip_absent = TRUE)
  lprMergeTotal <- rbindlist(list(lprMergeDiag , lprMergeOpr , lprMergeUbe , lprMergeUlyk) , fill = TRUE)
  ##Visually inspected, the N and columns are as expected - pruning for repeated entries:
  lprMergeTotal <- unique(lprMergeTotal)
  ##Freeing up memory:
  rm(lprAdm , lprDiag , lprSksOpr , lprSksUbe , lprUlyk , lprMergeDiag , lprMergeOpr , lprMergeUbe , lprMergeUlyk)
  ##Starting on lprPsyk
  lprPsyk <- fread("psyk_adm_pop_110621.csv" , nrows = nrows , drop = c("c_sex" , "c_sgh" , "d_uddto") , colClasses = c("recnum" = "character" , "pnr" = "character"))
  lprPsyk[ , d_inddto := floor_date(as.Date(d_inddto) , unit = "month")]
  lprPsyk[ , c_adiag := gsub('\"' , '' , c_adiag)]
  lprPsyk[ , c_kontaars := gsub('\"' , '' , c_kontaars)]
  psykDiag <- fread("psykdiag_pop_110621.csv" , nrows = nrows , colClasses = c("recnum" = "character"))
  ##There are several types of diagnoses available - only those that can be viewed as describing the patient's condition are listed here:
  ##Only other diagtype is H - for computational speed, H is excluded:
  psykDiag <- psykDiag[!c_diagtype == "H" | is.na(c_diagtype) == TRUE]
  ##This dataset is also cluttered with "" for some reason:
  psykDiag[ , c_diag := gsub('\"' , '' , c_diag)]
  psykDiag[ , c_diagtype := gsub('\"' , '' , c_diagtype)]
  psykDiag[ , c_tildiag := gsub('\"' , '' , c_tildiag)]
  psykSksOpr <- fread("psyksksopr_pop_110621.csv" , nrows = nrows , colClasses = c("recnum" = "character") , drop = c("c_oprart" , "c_osgh"))
  psykSksOpr[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  ##More ""s - cleaning up:
  psykSksOpr[ , c_opr := gsub('\"' , '' , c_opr)]
  psykSksOpr[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  psykSksUbe <- fread("psyksksube_pop_110621.csv" , nrows = nrows , colClasses = c("recnum" = "character") , drop = c("c_oprart" , "c_osgh"))
  psykSksUbe[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  psykSksUbe[ , c_opr := gsub('\"' , '' , c_opr)]
  psykSksUbe[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  psykUlyk <- fread("psykulyk_pop_110621.csv" , nrows = nrows , colClasses = ("recnum" = "character") , drop = "c_art")
  psykUlyk[ , c_tilulyk := gsub('\"' , '' , c_tilulyk)]
  psykUlyk[ , c_ulyk := gsub('\"' , '' , c_ulyk)]
  setkey(lprPsyk , recnum)
  setkey(psykDiag , recnum)
  setkey(psykSksOpr , recnum)
  setkey(psykSksUbe , recnum)
  setkey(psykUlyk , recnum)
  ##Merge all the datsets for later merging with the large dataset, and put all diagnoses, procedures etc into one variable:
  psykMergeDiag <- merge(lprPsyk , psykDiag , all.x = TRUE)
  ##Visually inspected, merges as expected connecting diagnoses to a pnr
  psykMergeDiag[ , c("c_diagtype" , "recnum") := NULL]
  ##Clean lines where C_ADIAG and C_DIAG are the same:
  psykMergeDiag[c_adiag == c_diag , c_diag := NA]
  ##Reduce to health events where different variables for diagnoses are pooled:
  psykMergeDiag <- melt(psykMergeDiag , measure.vars = c("c_adiag" , "c_diag" , "c_tildiag") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  psykMergeDiag[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  psykMergeDiag <- psykMergeDiag[!is.na(healthEvent)]
  psykMergeDiag <- psykMergeDiag[healthEvent != ""]
  psykMergeDiag <- psykMergeDiag[!is.na(pnr)]
  psykMergeDiag <- psykMergeDiag[pnr != ""]
  ##Visually inspected, now with one variable for all health events.
  psykMergeOpr <- merge(lprPsyk , psykSksOpr , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  psykMergeOpr[ , recnum := NULL]
  psykMergeOpr <- melt(psykMergeOpr , measure.vars = c("c_adiag" , "c_opr" , "c_tilopr") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  psykMergeOpr[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  psykMergeOpr <- psykMergeOpr[!is.na(healthEvent)]
  psykMergeOpr <- psykMergeOpr[healthEvent != ""]
  psykMergeOpr <- psykMergeOpr[!is.na(pnr)]
  psykMergeOpr <- psykMergeOpr[pnr != ""]
  ##Compared with data before merge, dates and ID are preserved correctly for health events.
  psykMergeUbe <- merge(lprPsyk , psykSksUbe , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  psykMergeUbe[ , recnum := NULL]
  psykMergeUbe <- melt(psykMergeUbe , measure.vars = c("c_adiag" , "c_opr" , "c_tilopr") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  psykMergeUbe[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  psykMergeUbe <- psykMergeUbe[!is.na(healthEvent)]
  psykMergeUbe <- psykMergeUbe[healthEvent != ""]
  psykMergeUbe <- psykMergeUbe[!is.na(pnr)]
  psykMergeUbe <- psykMergeUbe[pnr != ""]
  psykMergeUlyk <- merge(lprPsyk , psykUlyk , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  psykMergeUlyk[ , c_adiag := NULL]
  psykMergeUlyk[ , recnum := NULL]
  psykMergeUlyk <- melt(psykMergeUlyk , measure.vars = c("c_tilulyk" , "c_ulyk") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  psykMergeUlyk[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  psykMergeUlyk <- psykMergeUlyk[!is.na(healthEvent)]
  psykMergeUlyk <- psykMergeUlyk[healthEvent != ""]
  psykMergeUlyk <- psykMergeUlyk[!is.na(pnr)]
  psykMergeUlyk <- psykMergeUlyk[pnr != ""]
  ##Stack all lprPsyk-related datasets on top of each other:
  setnames(psykMergeOpr , old = "D_ODTO" , new = "d_odto" , skip_absent = TRUE)
  psykMergeTotal <- rbindlist(list(psykMergeDiag , psykMergeOpr , psykMergeUbe , psykMergeUlyk) , fill = TRUE)
  ##Visually inspected, the N and columns are as expected - pruning for repeated entries:
  psykMergeTotal <- unique(psykMergeTotal)
  ##Freeing up memory:
  rm(lprPsyk , psykDiag , psykSksOpr , psykSksUbe , psykUlyk , psykMergeDiag , psykMergeOpr , psykMergeUbe , psykMergeUlyk)

  ##UAF
  uafAdm <- fread("uaf_adm2018.csv" , nrows = nrows , colClasses = c("RECNUM" = "character" , "PNR" = "character") , drop =c("C_SEX" , "C_SGH" , "C_SPEC" , "D_UDDTO"))
  uafAdm[ , D_INDDTO := floor_date(as.Date(D_INDDTO , "%m/%d/%Y") , unit = "month")]
  uafDiag <- fread("uaf_diag2018.csv" , nrows = nrows , colClasses = ("RECNUM" = "character"))
  uafDiag <- uafDiag[C_DIAGTYPE %in% diagtypeUseful]
  uafDiag[ , C_DIAGTYPE := NULL]
  uafSksOpr <- fread("uaf_sksopr2018.csv" , nrows = nrows , colClasses = ("RECNUM" = "character") , drop = c("C_OPRART" , "C_OSGH"))
  uafSksOpr[ , D_ODTO := floor_date(as.Date(D_ODTO , "%m/%d/%Y") , unit = "month")]
  uafSksUbe <- fread("uaf_sksube2018.csv" , nrows = nrows , colClasses = ("RECNUM" = "character") , drop = c("C_OPRART" , "C_OSGH"))
  uafSksUbe[ , D_ODTO := floor_date(as.Date(D_ODTO , format = "%m/%d/%Y") , unit = "month")]
  uafUlyk <- fread("uaf_ulyk2018.csv" , nrows = nrows , colClasses = ("RECNUM" = "character") , drop = "C_ART")
  setkey(uafAdm , RECNUM)
  setkey(uafDiag , RECNUM)
  setkey(uafSksOpr , RECNUM)
  setkey(uafSksUbe , RECNUM)
  setkey(uafUlyk , RECNUM)
  ##Merge all the datsets for later merging with the large dataset, and put all diagnoses, procedures etc into one variable:
  uafMergeDiag <- merge(uafAdm , uafDiag , all.x = TRUE)
  ##Visually inspected, merges as expected connecting diagnoses to a pnr
  uafMergeDiag[ , RECNUM := NULL]
  ##Clean lines where C_ADIAG and C_DIAG are the same:
  uafMergeDiag[C_ADIAG == C_DIAG , C_DIAG := NA]
  ##Reduce to health events where different variables for diagnoses are pooled:
  uafMergeDiag <- melt(uafMergeDiag , measure.vars = c("C_ADIAG" , "C_DIAG" , "C_TILDIAG") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  uafMergeDiag[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  uafMergeDiag <- uafMergeDiag[!is.na(healthEvent)]
  uafMergeDiag <- uafMergeDiag[healthEvent != ""]
  uafMergeDiag <- uafMergeDiag[!is.na(PNR)]
  uafMergeDiag <- uafMergeDiag[PNR != ""]
  ##Visually inspected, now with one variable for all health events.
  uafMergeOpr <- merge(uafAdm , uafSksOpr , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  uafMergeOpr[ , RECNUM := NULL]
  uafMergeOpr <- melt(uafMergeOpr , measure.vars = c("C_ADIAG" , "C_OPR" , "C_TILOPR") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  uafMergeOpr[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  uafMergeOpr <- uafMergeOpr[!is.na(healthEvent)]
  uafMergeOpr <- uafMergeOpr[healthEvent != ""]
  uafMergeOpr <- uafMergeOpr[!is.na(PNR)]
  uafMergeOpr <- uafMergeOpr[PNR != ""]
  ##Compared with data before merge, dates and ID are preserved correctly for health events.
  uafMergeUbe <- merge(uafAdm , uafSksUbe , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  uafMergeUbe[ , RECNUM := NULL]
  uafMergeUbe <- melt(uafMergeUbe , measure.vars = c("C_ADIAG" , "C_OPR" , "C_TILOPR") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  uafMergeUbe[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  uafMergeUbe <- uafMergeUbe[!is.na(healthEvent)]
  uafMergeUbe <- uafMergeUbe[healthEvent != ""]
  uafMergeUbe <- uafMergeUbe[!is.na(PNR)]
  uafMergeUbe <- uafMergeUbe[PNR != ""]
  uafMergeUlyk <- merge(uafAdm , uafUlyk , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  uafMergeUlyk[ , RECNUM := NULL]
  uafMergeUlyk[ , C_ADIAG := NULL]
  uafMergeUlyk <- melt(uafMergeUlyk , measure.vars = c("C_TILULYK" , "C_ULYK") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  uafMergeUlyk[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  uafMergeUlyk <- uafMergeUlyk[!is.na(healthEvent)]
  uafMergeUlyk <- uafMergeUlyk[healthEvent != ""]
  uafMergeUlyk <- uafMergeUlyk[!is.na(PNR)]
  uafMergeUlyk <- uafMergeUlyk[PNR != ""]
  ##Stack all uaf-related datasets on top of each other:
  uafMergeTotal <- rbindlist(list(uafMergeDiag , uafMergeOpr , uafMergeUbe , uafMergeUlyk) , fill = TRUE)
  ##Visually inspected, the N and columns are as expected - pruning for repeated entries:
  uafMergeTotal <- unique(uafMergeTotal)
  ##Freeing up memory:
  rm(uafAdm , uafDiag , uafSksOpr , uafSksUbe , uafUlyk , uafMergeDiag , uafMergeOpr , uafMergeUbe , uafMergeUlyk)

  ##PRIV
  privAdm <- fread("privadm_pop_110621.csv" , nrows = nrows , colClasses = c("recnum" = "character" , "pnr" = "character") , drop = c("c_sex" , "c_sgh" , "c_spec" , "d_uddto"))
  privAdm[ , c_adiag := gsub('\"' , '' , c_adiag)]
  privAdm[ , c_kontaars := gsub('\"' , '' , c_kontaars)]
  privAdm[ , d_inddto := floor_date(as.Date(d_inddto) , unit = "month")]
  privDiag <- fread("privdiag_pop_110621.csv" , nrows = nrows , drop = "aar" , colClasses = ("recnum" = "character"))
  privDiag <- privDiag[gsub('\"' , '' , c_diagtype) %in% diagtypeUseful]
  privDiag[ , c_diagtype := NULL]
  privDiag[ , c_diag := gsub('\"' , '' , c_diag)]
  privDiag[ , c_tildiag := gsub('\"' , '' , c_tildiag)]
  privSksOpr <- fread("privsksopr_pop_110621.csv" , nrows = nrows , drop = c("c_oprart" , "c_osgh") , colClasses = ("recnum" = "character"))
  privSksOpr[ , c_opr := gsub('\"' , '' , c_opr)]
  privSksOpr[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  privSksOpr[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  privSksUbe <- fread("privsksube_pop_110621.csv" , nrows = nrows , colClasses = ("recnum" = "character") , drop = c("c_oprart" , "c_osgh" , "aar"))
  privSksUbe[ , c_opr := gsub('\"' , '' , c_opr)]
  privSksUbe[ , c_tilopr := gsub('\"' , '' , c_tilopr)]
  privSksUbe[ , d_odto := floor_date(as.Date(d_odto) , unit = "month")]
  setkey(privAdm , recnum)
  setkey(privDiag , recnum)
  setkey(privSksOpr , recnum)
  setkey(privSksUbe , recnum)
  ##Merge all the datsets for later merging with the large dataset, and put all diagnoses, procedures etc into one variable:
  privMergeDiag <- merge(privAdm , privDiag , all.x = TRUE)
  ##Visually inspected, merges as expected connecting diagnoses to a pnr
  privMergeDiag[ , recnum := NULL]
  ##Clean lines where C_ADIAG and C_DIAG are the same:
  privMergeDiag[c_adiag == c_diag , c_diag := NA]
  ##Reduce to health events where different variables for diagnoses are pooled:
  privMergeDiag <- melt(privMergeDiag , measure.vars = c("c_adiag" , "c_diag" , "c_tildiag") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  privMergeDiag[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  privMergeDiag <- privMergeDiag[!is.na(healthEvent)]
  privMergeDiag <- privMergeDiag[healthEvent != ""]
  privMergeDiag <- privMergeDiag[!is.na(pnr)]
  privMergeDiag <- privMergeDiag[pnr != ""]
  ##Visually inspected, now with one variable for all health events.
  privMergeOpr <- merge(privAdm , privSksOpr , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  privMergeOpr[ , recnum := NULL]
  privMergeOpr <- melt(privMergeOpr , measure.vars = c("c_adiag" , "c_opr" , "c_tilopr") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  privMergeOpr[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  privMergeOpr <- privMergeOpr[!is.na(healthEvent)]
  privMergeOpr <- privMergeOpr[healthEvent != ""]
  privMergeOpr <- privMergeOpr[!is.na(pnr)]
  privMergeOpr <- privMergeOpr[pnr != ""]
  privMergeUbe <- merge(privAdm , privSksUbe , all.x = TRUE)
  ##Visually inspected, merges as expected connecting operations and diagnoses to a pnr
  privMergeUbe[ , recnum := NULL]
  privMergeUbe <- melt(privMergeUbe , measure.vars = c("c_adiag" , "c_opr" , "c_tilopr") , value.name = "healthEvent")
  ##Remove the "variable"-variable:
  privMergeUbe[ , variable := NULL]
  ##Prune for meaningless entries with no event or no pnr:
  privMergeUbe <- privMergeUbe[!is.na(healthEvent)]
  privMergeUbe <- privMergeUbe[healthEvent != ""]
  privMergeUbe <- privMergeUbe[!is.na(pnr)]
  privMergeUbe <- privMergeUbe[pnr != ""]
  setnames(privMergeDiag , old = c("PNR" , "C_KONTAARS" , "D_INDDTO") , new = c("pnr" , "c_kontaars" , "d_inddto") , skip_absent = TRUE)
  ##Stack all priv-related datasets on top of each other:
  privMergeTotal <- rbindlist(list(privMergeDiag , privMergeOpr , privMergeUbe) , fill = TRUE)
  ##Visually inspected, the N and columns are as expected - pruning for repeated entries:
  privMergeTotal <- unique(privMergeTotal)
  ##Freeing up memory:
  rm(privAdm , privDiag , privSksOpr , privSksUbe , privMergeDiag , privMergeOpr , privMergeUbe)


  ##Stacking lpr, psyk, uaf and priv on top of each other:
  setnames(uafMergeTotal , old = c("PNR" , "C_KONTAARS" , "D_INDDTO" , "healthEvent" , "D_ODTO") , new = c("pnr" , "c_kontaars" , "d_inddto" , "healthEvent" , "d_odto"))
  setnames(lprMergeTotal , old = c("pnr" , "C_KONTAARS" , "D_INDDTO" , "healthEvent" , "D_ODTO") , new = c("pnr" , "c_kontaars" , "d_inddto" , "healthEvent" , "d_odto"))
  psykMergeTotal[ , c_kontaars := gsub('\"' , '' , c_kontaars)]
  psykMergeTotal[ , c_kontaars := as.integer(c_kontaars)]
  healthMergeTotal <- rbindlist(list(lprMergeTotal , psykMergeTotal , uafMergeTotal , privMergeTotal) , use.names = TRUE)
  healthMergeTotal <- unique(healthMergeTotal)
  ##Looks as expected. Cleaning some memory:
  rm(lprMergeTotal , psykMergeTotal , uafMergeTotal , privMergeTotal)

  ##Writing this file to save some space during each "startup" - this file might be big, check when its done:
  ##Suspending this write - it takes up a lot of space
  ##fwrite(healthMergeTotal , "healthMergeTotal.csv")

  ##As of now, no causes of death will be used for health categories to avoid conditioning on the future (when someone is dead they cannot commit abuse, so abuse committed before the death but because of the disease has been committed because of an un-diagnosed disease).

  ##Importing lmdb data:
  ##If this is too big, I have to load three files at a time and then switch those around for each year.
  lmdbFileList <- paste0("lmdb_" , 1995:2018 , "_pop_250621.csv")
  lmdbList <- lapply(lmdbFileList , fread , nrows = nrows , select = c("pnr" , "eksd" , "atc") , colClasses = c("pnr" = "character" , "atc" = "character"))
  lmdb <- rbindlist(lmdbList)
  lmdb[ , eksd := floor_date(as.Date(eksd , format = "%m/%d/%Y") , unit = "month")]
  ##Inspected visually, pnr, eksd and atc as expected
  rm(lmdbList , lmdbFileList)

  ##As above, attempting to save some time - check file size:
  ##Suspending this write, takes up a lot of space:
  ##fwrite(lmdb , "lmdb.csv")

  ##Again to save space - reducing all lmdb records to those that are actually used:
  lmdbUsed <- fread("atcUsed.csv")
  lmdb <- merge(lmdb , lmdbUsed , by.x = "atc" , by.y = "atc")
  ##Look at this at next run, if it works fine change name to lmdb

  ##Also reducing the number of diagnoses that will have to be imported:
  healthUsed <- fread("diagUsed.csv" , drop = c("pregnancy" , "diagError" , "GESTATIONSALDER_DAGE" , "D_FODTDTO" , "D_TERMIN" , "D_FODTDTODato" , "D_TERMINDato" , "leftOut"))
  healthMergeTotal <- merge(healthMergeTotal , healthUsed , by.x = "healthEvent" , by.y = "diagnosis" , all.x = TRUE)

  ##Marking all diagnoses relevant for maltreatment:
  healthMaltreatment <- fread("healthMaltreatment.csv")
  healthMaltreatment[ , maltreatmentMark := 1]
  healthMergeTotal <- merge(healthMergeTotal , healthMaltreatment , by.x = "healthEvent" , by.y = "ICD10Diagnosis" , all.x = TRUE)
  healthMergeTotal[c_kontaars == 3 , maltreatmentMark := 1]
  healthMaltreatmentICD8 <- fread("healthMaltreatmentICD8.csv")
  healthMaltreatmentICD8[ , maltreatmentMark := 1]
  healthMergeTotal <- merge(healthMergeTotal , healthMaltreatmentICD8 , by.x = "healthEvent" , by.y = "ICD8Diagnosis" , all.x = TRUE)
  healthMergeTotal[maltreatmentMark.x == 1 | maltreatmentMark.y == 1 , maltreatmentMark := 1]
  healthMergeTotal[ , c("maltreatmentMark.x" , "maltreatmentMark.y") := NULL]

  ##Marking all diagnoses relevant for intimate partner violence:
  intimatePartner <- fread("intimatePartner.csv")
  intimatePartner[ , intimatePartnerMark := 1]
  healthMergeTotal <- merge(healthMergeTotal , intimatePartner , by.x = "healthEvent" , by.y = "ICD10Diagnosis" , all.x = TRUE)

  ##As pregnancy-related codes and procedural codes are not loaded during the generation of diagUsed, an extra merge is required to add acute caesarian and diagnostic codes for preterm birth:
  additionalHealthUsed <- data.table(healthEvent =
					 c("DO601" , "DO603" ,
					   "DO609" , "DO842A" ,
					   "KMCA10A" , "KMCA10E" ,
					   "NZTB10" , "NZTB10A" ,
					   "NZTB10B" , "NZTB10C") ,
				     conditionGroup =
					 c("Preterm birth" ,
					   "Preterm birth" ,
					   "Preterm birth" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section" ,
					   "Acute caesarian section"))
  pretermCaesarian <- c("Preterm birth" , "Acute caesarian section")
  additionalHealthUsed[conditionGroup %in% pretermCaesarian , conditionCategory := "Preterm birth and acute caesarian section"]
  healthMergeTotal[additionalHealthUsed ,
		   on = "healthEvent" ,
		   c("conditionGroupAdd" ,
		     "conditionCategoryAdd") :=
		       list(i.conditionGroup ,
			    i.conditionCategory)]
  healthMergeTotal[!is.na(conditionGroupAdd) ,
		   c("conditionGroup" ,
		     "conditionCategory") :=
		       list(conditionGroupAdd ,
			    conditionCategoryAdd)]
  healthMergeTotal[ , c("conditionGroupAdd" ,
			"conditionCategoryAdd") := NULL]

  ##Handling a few special cases for alcohol and substances, also in the O chapter of ICD:
  healthMergeTotal[healthEvent == "DO354" , alcoholAbuse := 1]
  healthMergeTotal[healthEvent == "DO355" , substanceAbuse := 1]

  ##Handling all cases special to aidsHivCharlson:
  healthMergeTotal[healthEvent == "07983" , aidsHivCharlson := 1]
  healthMergeTotal[healthEvent == "DB20" , aidsHivCharlson := 1]
  healthMergeTotal[healthEvent == "DB21" , aidsHivCharlson := 1]
  healthMergeTotal[healthEvent == "DB22" , aidsHivCharlson := 1]
  healthMergeTotal[healthEvent == "DB23" , aidsHivCharlson := 1]
  healthMergeTotal[healthEvent == "DB24" , aidsHivCharlson := 1]

  ##Making two categories for the unspecific diagnoses:
  healthMergeTotal[unspecific == TRUE , c("unspecificEver" , "unspecificTwoYear") := list(1 , 1)]
  healthMergeTotal[ , unspecific := NULL]

  ##Excluding all observations that has not been marked in the processes above:
  ##To avoid errors, all the Charlson categories are added by the code that has been commented out below:
  ## temp <- strsplit(charlsonCodesList , "Codes")
  ## temp <- paste0(temp , " == 1" , " | " , collapse = "")
  healthMergeTotal <- healthMergeTotal[intimatePartnerMark == 1 |
					 maltreatmentMark == 1 |
					 substanceAbuse == 1 |
					 alcoholAbuse == 1 |
					 !is.na(conditionGroup) |
					 unspecificEver == 1 |
					 unspecificTwoYear == 1 |
					 myocardialInfarctionCharlson == 1 |
					 aidsHivCharlson == 1 |
					 anyMalignancyCharlson == 1 |
					 leukemiaCharlson == 1 |
					 lymphomaCharlson == 1 |
					 cerebrovascularDiseaseCharlson == 1 |
					 chronicPulmonaryDiseaseCharlson == 1 |
					 dementiaCharlson == 1 |
					 diabetesWithComplicationsCharlson == 1 |
					 diabetesWithoutComplicationsCharlson == 1 |
					 heartFailureCharlson == 1 |
					 hemiplegiaParaplegiaCharlson == 1 |
					 metastaticSolidTumorCharlson == 1 |
					 mildLiverDiseaseCharlson == 1 |
					 myocardialInfarctionCharlson == 1 |
					 pepticUlcerDiseaseCharlson == 1 |
					 peripheralVascularDiseaseCharlson == 1 |
					 renalDiseaseCharlson == 1 |
					 rheumaticDiseaseCharlson == 1 |
					 severeLiverDiseaseCharlson == 1]

  ##Setting the dates for Charlson:
  ##365.24*5 #result is 1826.2 days, the number of days corresponding to 5 years
  ##Use all the Charlson categories defined:
  charlsonCodesList <- ls(pattern = '.*CharlsonCodes$') 
  for (i in charlsonCodesList) {
    eval(parse(text = paste0("healthMergeTotal[" , strsplit(i , "Codes") , " == 1 , " , strsplit(i , "Codes") , "EndDate" , " := (d_inddto + 1826.2)]")))
  }
  ##This code takes all the diagnoses defined for Charlson, and produces and evaluates a categorization statement for each - the form of the statements has been checked (and can be visualized for inspection) by the following code:
  ## for (i in charlsonCodesList) {
  ##     print(paste0("healthMergeTotal[grepl(\'^" ,
  ##                  get(i) , ".*\' , healthEvent) , " ,
  ##                  strsplit(i , "Codes") , " := 1]"))
  ##     print(paste0("healthMergeTotal[grepl(\'^" , get(i) , ".*\' , healthEvent) , " , strsplit(i , "Codes") , "EndDate" , " := (d_inddto + 1826.2)]"))
  ## }

  ##Setting the scores for Charlson - commented out scores that are unchanged:

  ##healthMergeTotal[myocardialInfarctionCharlson == 1 , myocardialInfarctionCharlson := 1]
  ##For some reason, likely because aidsHivCharlson was empty in diagUsed, it was coerced into a logical - fixing that:
  healthMergeTotal[ , aidsHivCharlson := as.numeric(aidsHivCharlson)]
  healthMergeTotal[aidsHivCharlson == 1 , aidsHivCharlson := 6]
  healthMergeTotal[anyMalignancyCharlson == 1 , anyMalignancyCharlson := 2]
  healthMergeTotal[leukemiaCharlson == 1 , leukemiaCharlson := 2]
  healthMergeTotal[lymphomaCharlson == 1 , lymphomaCharlson := 2]
  ##healthMergeTotal[cerebrovascularDiseaseCharlson == 1 , cerebrovascularDiseaseCharlson := 1]
  ##healthMergeTotal[chronicPulmonaryDiseaseCharlson == 1 , chronicPulmonaryDiseaseCharlson := 1]
  ##healthMergeTotal[dementiaCharlson == 1 , dementiaCharlson := 1]
  healthMergeTotal[diabetesWithComplicationsCharlson == 1 , diabetesWithComplicationsCharlson := 2]
  ##healthMergeTotal[diabetesWithoutComplicationsCharlson == 1 , diabetesWithoutComplicationsCharlson := 1]
  ##healthMergeTotal[heartFailureCharlson == 1 , heartFailureCharlson := 1]
  healthMergeTotal[hemiplegiaParaplegiaCharlson == 1 , hemiplegiaParaplegiaCharlson := 2]
  healthMergeTotal[metastaticSolidTumorCharlson == 1 , metastaticSolidTumorCharlson := 6]
  ##healthMergeTotal[mildLiverDiseaseCharlson == 1 , mildLiverDiseaseCharlson := 1]
  ##healthMergeTotal[myocardialInfarctionCharlson == 1 , myocardialInfarctionCharlson := 1]
  ##healthMergeTotal[pepticUlcerDiseaseCharlson == 1 , pepticUlcerDiseaseCharlson := 1]
  ##healthMergeTotal[peripheralVascularDiseaseCharlson == 1 , peripheralVascularDiseaseCharlson := 1]
  healthMergeTotal[renalDiseaseCharlson == 1 , renalDiseaseCharlson := 2]
  ##healthMergeTotal[rheumaticDiseaseCharlson == 1 , rheumaticDiseaseCharlson := 1]
  healthMergeTotal[severeLiverDiseaseCharlson == 1 , severeLiverDiseaseCharlson := 3]
  ##All assignments of scores were checked against the scores in the Quan-article (see coding of Charlson)

  ##Setting the scores and dates for the groups inspired by Prior:
  healthMergeTotal[conditionGroup == "Hypertension" ,
		   c("hypertensionGroupDiag" , "hypertensionGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Dyslipidemia" ,
		   c("dyslipidemiaGroupDiag" , "dyslipidemiaGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  ##View(healthMergeTotal[dyslipidemiaGroupDiag == 1])
  ##These group variables have been checked with statements similar to the one above, giving the desired results. 
  healthMergeTotal[conditionGroup == "Ischemic heart disease" ,
		   c("ischemicHeartDiseaseGroupDiag" ,
		     "ischemicHeartDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Atrial fibrillation" ,
		   c("atrialFibrillationGroupDiag" ,
		     "atrialFibrillationGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Heart failure" ,
		   c("heartFailureGroupDiag" ,
		     "heartFailureGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Peripheral artery occlusive disease" ,
		   c("peripheralArteryOcclusiveGroupDiag" ,
		     "peripheralArteryOcclusiveGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Stroke" ,
		   c("strokeGroupDiag" , "strokeGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Diabetes mellitus" ,
		   c("diabetesMellitusGroupDiag" ,
		     "diabetesMellitusGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Thyroid disorder" ,
		   c("thyroidDisorderGroupDiag" ,
		     "thyroidDisorderGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  healthMergeTotal[conditionGroup == "Gout" ,
		   c("goutGroupDiag" , "goutGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Chronic pulmonary disease" ,
		   c("chronicPulmonaryDiseaseGroupDiag" ,
		     "chronicPulmonaryDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))] #I choose ever for this group
  healthMergeTotal[conditionGroup == "Allergy" ,
		   c("allergyGroupDiag" , "allergyGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))] #I choose two years for this group
  healthMergeTotal[conditionGroup == "Ulcer/chronic gastritis" ,
		   c("ulcerChronicGastritisGroupDiag" ,
		     "ulcerChronicGastritisGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Chronic liver disease" ,
		   c("chronicLiverDiseaseGroupDiag" ,
		     "chronicLiverDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Inflammatory bowel disease" ,
		   c("inflammatoryBowelDiseaseGroupDiag" ,
		     "inflammatoryBowelDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup ==
		     "Diverticular disease of intestine" ,
		   c("diverticularDiseaseOfIntestineGroupDiag" ,
		     "diverticularDiseaseOfIntestineGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Chronic kidney disease" ,
		   c("chronicKidneyDiseaseGroupDiag" ,
		     "chronicKidneyDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Prostate disorders" ,
		   c("prostateDisordersGroupDiag" ,
		     "prostateDisordersGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Connective tissue disorders" ,
		   c("connectiveTissueDisordersGroupDiag" ,
		     "connectiveTissueDisordersGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Osteoporosis" ,
		   c("osteoporosisGroupDiag" ,
		     "osteoporosisGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  ##Painful condition - is only classified using prescriptions
  healthMergeTotal[conditionGroup == "Anemia" ,
		   c("anemiasGroupDiag" ,
		     "anemiasGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  healthMergeTotal[conditionGroup == "Cancer" ,
		   c("cancerGroupDiag" , "cancerGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("60 months")))]
  healthMergeTotal[conditionGroup == "Vision problem" ,
		   c("visionProblemGroupDiag" ,
		     "visionProblemGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Hearing problem" ,
		   c("hearingProblemGroupDiag" ,
		     "hearingProblemGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Migraine" ,
		   c("migraineGroupDiag" ,
		     "migraineGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  healthMergeTotal[conditionGroup == "Epilepsy" ,
		   c("epilepsyGroupDiag" , "epilepsyGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Parkinson's disease" ,
		   c("parkinsonsDiseaseGroupDiag" ,
		     "parkinsonsDiseaseGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Multiple sclerosis" ,
		   c("multipleSclerosisGroupDiag" ,
		     "multipleSclerosisGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Neuropathies" ,
		   c("neuropathiesGroupDiag" ,
		     "neuropathiesGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  healthMergeTotal[conditionGroup ==
		     "Mood, stress-related, or anxiety disorders" ,
		   c("moodStressrelatedOrAnxietyDisordersGroupDiag" ,
		     "moodStressrelatedOrAnxietyDisordersGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  ##Psychological distress is not coded in my classification
  healthMergeTotal[conditionGroup == "Anorexia/bulimia" ,
		   c("anorexiaBulimiaGroupDiag" ,
		     "anorexiaBulimiaGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("24 months")))]
  healthMergeTotal[conditionGroup == "Bipolar affective disorder" ,
		   c("bipolarAffectiveDisorderGroupDiag" ,
		     "bipolarAffectiveDisorderGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup ==
		     "Schizophrenia or schizoaffective disorder" ,
		   c("schizophreniaOrSchizoaffectiveDisorderGroupDiag" ,
		     "schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Personality disorder" ,
		   c("personalityDisorderGroupDiag" ,
		     "personalityDisorderGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("120 months")))] ##I choose 10 years for this group based on the potential of therapy and changes around the age of 30-40 years
  healthMergeTotal[conditionGroup == "Dementia" ,
		   c("dementiaGroupDiag" , "dementiaGroupDiagEndDate") :=
		     list(1 , as.Date("2019-01-01"))]
  healthMergeTotal[conditionGroup == "Other" ,
		   c("otherGroupDiag" , "otherGroupDiagEndDate") :=
		     list(1 , (d_inddto %m+% period("36 months")))] ##This choice of three years is rather arbitrary in a highly diverse set of diagnoses

  lmdb[conditionGroup == "Dyslipidemia" ,
       c("dyslipidemiaGroupLmdb" , "dyslipidemiaGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Ischemic heart disease" ,
       c("ischemicHeartDiseaseGroupLmdb" ,
	 "ischemicHeartDiseaseGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Diabetes mellitus" ,
       c("diabetesMellitusGroupLmdb" ,
	 "diabetesMellitusGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Thyroid disorder" ,
       c("thyroidDisorderGroupLmdb" ,
	 "thyroidDisorderGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Chronic pulmonary disease" ,
       c("chronicPulmonaryDiseaseGroupLmdb" ,
	 "chronicPulmonaryDiseaseGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Allergy" ,
       c("allergyGroupLmdb" , "allergyGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Osteoporosis" ,
       c("osteoporosisGroupLmdb" ,
	 "osteoporosisGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Painful condition" ,
       c("painfulConditionGroupLmdb" ,
	 "painfulConditionGroupLmdbEndDate") :=
	 list(0.25 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Migraine" ,
       c("migraineGroupLmdb" , "migraineGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Epilepsy" ,
       c("epilepsyGroupLmdb" , "epilepsyGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Bipolar affective disorder" ,
       c("bipolarAffectiveDisorderGroupLmdb" ,
	 "bipolarAffectiveDisorderGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]
  lmdb[conditionGroup == "Dementia" ,
       c("dementiaGroupLmdb" , "dementiaGroupLmdbEndDate") :=
	 list(0.5 , (eksd %m+% period("12 months")))]

  ##Setting dates for additional variables - first adding some categorizations to these variables from other data sources:


  ##Below is additional code to achieve preterm categorization from last menstruation - LPRMFRLF has D_TERMIN, more than three weeks before this would constitute premature birth according to the classification used by Nager. MFR has GESTATIONSALDER_DAGE which would correspond to premature birth with values less than 37*7=259. To use the existing algorithm for classifying disease categories, the data is added to healthMergeTotal:
  mfr <- fread("mfr_pop_070621.csv" , nrows = nrows , colClasses = c("pnr" = "character" , "cpr_fader" = "character" , "cpr_moder" = "character")) #foedselsdato
  mfr <- mfr[!is.na(pnr)]
  mfr <- mfr[pnr != ""]
  mfr[ , foedselsdato := floor_date(as.Date(foedselsdato , format = "%m/%d/%Y") , unit = "month")]
  mfr[GESTATIONSALDER_DAGE < 259 , conditionGroup := "Preterm birth"] ##If gestational age at birth is less than 259 days, that constitutes birth before 37 weeks
  healthMergeTotalAddonMfr <- mfr[conditionGroup == "Preterm birth" , .(cpr_moder , foedselsdato , conditionGroup)]
  setnames(healthMergeTotalAddonMfr , c("cpr_moder" , "foedselsdato") , c("pnr" , "d_inddto"))

  lprmfrlf <- fread("lprmfrlf_pop_070621.csv" , nrows = nrows , colClasses = c("pnr" = "character" , "V_MCPR" = "character" , "V_FCPR" = "character"))
  lprmfrlf[ , D_FODTDTO := as.Date(D_FODTDTO , "%m/%d/%Y")]
  lprmfrlf[ , D_TERMIN := as.Date(D_TERMIN , "%m/%d/%Y")]
  lprmfrlf[(D_TERMIN - D_FODTDTO) > 21 , conditionGroup := "Preterm birth"] ##If birth is more than three weeks prior to estimated 40 weeks gestational age
  healthMergeTotalAddonLprmfrlf <- lprmfrlf[conditionGroup == "Preterm birth" , .(V_MCPR , floor_date(D_FODTDTO , unit = "months") , conditionGroup)]
  setnames(healthMergeTotalAddonLprmfrlf , c("V_MCPR" , "V2") , c("pnr" , "d_inddto"))
  healthMergeTotal <- rbindlist(list(healthMergeTotal , healthMergeTotalAddonMfr , healthMergeTotalAddonLprmfrlf) , fill = TRUE)

  healthMergeTotal[conditionGroup == "Preterm birth" , c("pretermBirthGroupDiag" , "pretermBirthGroupDiagEndDate") := list(1 , as.Date(d_inddto %m+% period("12 months")))] ##Setting end of risk at 1 year - the article describes psychosis within three months
  healthMergeTotal[conditionGroup == "Acute caesarian section" , c("acuteCaesarianSectionGroupDiag" , "acuteCaesarianSectionGroupDiagEndDate") := list(1 , as.Date(d_inddto %m+% period("12 months")))] ##Setting date at 1 year later, rather arbitrarily


  ##Defining covariates alcohol and substance abuse - will not include relevant paragraphs from the crime registries as these have no dates associated:
  healthMergeTotal[alcoholAbuse == 1 , alcoholAbuseEndDate := d_inddto %m+% period("24 months")]
  healthMergeTotal[substanceAbuse == 1 , substanceAbuseEndDate := d_inddto %m+% period("24 months")]

  ##Defining unspecific categories ever and last two years:
  healthMergeTotal[unspecificEver == 1 , unspecificEverEndDate := as.Date("2019-01-01")]
  healthMergeTotal[unspecificTwoYear == 1 , unspecificTwoYearEndDate := d_inddto %m+% period("24 months")]

  ##Marking all parents for adverse events during their childhood
  ##To do this I need a list of parents and their birth dates - this is created in the next code block (but the next code block needs the results from here as well) so I load it here:
  parentalAdversityHealth <- fread("fullPopulationChildrenParents.csv" , nrows = nrows , colClasses = ("parentID" = "character"))
  ##Reduce to pnrs only:
  parentalAdversityHealth <- parentalAdversityHealth[!grepl('.*[A-Z].*' , parentID)]
  parentalAdversityHealth <- parentalAdversityHealth[!is.na(parentID)]
  parentalAdversityHealth <- unique(parentalAdversityHealth)
  parentalAdversityHealth[ , birthDateParent := floor_date(as.Date(birthDateParent) , unit = "month")]
  ##Make a copy for next process:
  parentalAdversityPolice <- copy(parentalAdversityHealth)
  parentalAdversityOutOfHome <- copy(parentalAdversityHealth)
  ##Only keeping observations with a join:
  parentalAdversityHealth <- merge(parentalAdversityHealth , healthMergeTotal[ , .(pnr , d_inddto , healthEvent , c_kontaars)] , by.x = "parentID" , by.y = "pnr" , allow.cartesian = TRUE)
  parentalAdversityHealth[ , d_inddto := floor_date(as.Date(d_inddto) , unit = "month")]
  ##Excluding all observations after parental adulthood:
  parentalAdversityHealth <- parentalAdversityHealth[d_inddto < (birthDateParent + 6575)]
  healthMaltreatment <- fread("healthMaltreatment.csv")
  maltreatmentDiagnoses <- healthMaltreatment[ , ICD10Diagnosis]
  healthMaltreatmentICD8 <- fread("healthMaltreatmentICD8.csv")
  maltreatmentDiagnoses <- c(maltreatmentDiagnoses , healthMaltreatmentICD8[ , ICD8Diagnosis])
  ##If this is really slow, merge on healthEvents instead:
  parentalAdversityHealth <- parentalAdversityHealth[healthEvent %in% maltreatmentDiagnoses | c_kontaars == "3"]
  ##Adding KROF:
  krof <- fread("krof_pop_210621.csv" , nrows = nrows , colClasses = c("ofr_ger7" = "character" , "pnr" = "character" , "journr" = "character") , drop = c("jourger7" , "aar"))
  krof[ , ofr_gerfradt := floor_date(as.Date(ofr_gerfradt , format = "%m/%d/%Y") , unit = "month")]
  ##Removing "s in journr:
  krof[ , journr := gsub('\"' , '' , journr)]
  krof[ , ofr_gerfradt := floor_date(as.Date(ofr_gerfradt , "%m/%d/%Y") , unit = "month")]
  ##Removing those with no pnr:
  krof <- krof[pnr != ""]
  krof <- krof[!is.na(pnr)]
  ##Importing and cleaning police codes that will be used to prune the dataset of non-used codes:
  temp <- fread("policeCodesOfInterest.csv" , col.names = "code" , colClasses = ("code" = "character"))
  temp <- temp[!grepl('\\*.*' , code)]
  temp <- temp[code != ""]
  policeCodesOfInterest <- temp[ , code]
  krof <- krof[ofr_ger7 %in% policeCodesOfInterest]
  krof <- krof[!grepl('.*[A-Z].*' , pnr)]
  ##Keeping only those with a join:
  parentalAdversityPolice <- merge(parentalAdversityPolice , krof , by.x = "parentID" , by.y = "pnr" , allow.cartesian = TRUE)
  parentalAdversityPolice <- parentalAdversityPolice[ofr_gerfradt < (birthDateParent + 6575)]

  ##Merging with BUA to include out-of-home placements:
  bua <- fread("bua_pop_230921.csv" , nrows = nrows , colClasses = ("pnr" = "character") , select = c("pnr" , "pgf" , "SAG_VFRA"))
  bua[ , SAG_VFRA := floor_date(as.Date(SAG_VFRA , format = "%m/%d/%Y") , unit = "month")]
  buaUseful <- c("100" , "110" , "120" , "324")
  bua <- bua[pgf %in% buaUseful]
  parentalAdversityOutOfHome <- merge(parentalAdversityOutOfHome , bua , by.x = "parentID" , by.y = "pnr" , allow.cartesian = TRUE)
  parentalAdversityOutOfHome <- parentalAdversityOutOfHome[SAG_VFRA < (birthDateParent + 6575)]

  ##Creating a list of parental PNRs that has been exposed to abuse:
  parentalAdversityHealth[ , c("birthDateParent" , "d_inddto" , "c_kontaars" , "healthEvent") := NULL]
  parentalAdversityPolice[ , c("birthDateParent" , "ofr_ger7" , "ofr_gerfradt" , "journr") := NULL]
  parentalAdversityOutOfHome[ , c("birthDateParent" , "pgf" , "SAG_VFRA") := NULL]
  parentalAdversity <- rbindlist(list(parentalAdversityPolice , parentalAdversityHealth , parentalAdversityOutOfHome))
  parentalAdversity[ , abuseParent := 1]
  parentalAdversity <- unique(parentalAdversity)
  rm(parentalAdversityPolice , parentalAdversityHealth , parentalAdversityOutOfHome)
  fwrite(parentalAdversity , "parentalAdversity.csv")
  rm(parentalAdversity)

  ##Making a list of children that should be excluded because of prior abuse:
  ##Loading a list of all children in the dataset:
  childAbuseExclusion <- fread("fullPopulationChildren.csv" , colClasses = ("pnr" = "character"))
  ##Loading a list of all abuse-related diagnoses:
  physicalAbuse <- fread("physicalAbuse.csv")
  setnames(physicalAbuse , "*physicalAbuse*" , "physicalAbuseDiag")
  ##Adding ICD8 diagnoses (to allow exclusion of children exposed for physical abuse before inclusion):
  physicalAbuseIcd8 <- fread("physicalAbuseIcd8.csv")
  setnames(physicalAbuseIcd8 , "ICD8Diagnosis" , "physicalAbuseDiag")
  physicalAbuse <- rbindlist(list(physicalAbuse , physicalAbuseIcd8))
  physicalAbuse[ , physicalAbuse := 1]
  healthAbuse <- merge(healthMergeTotal , physicalAbuse , by.x = "healthEvent" , by.y = "physicalAbuseDiag" , all.y = TRUE)
  healthAbuse <- healthAbuse[ , .(pnr , d_inddto , physicalAbuse)]
  healthAbuseTemp <- healthMergeTotal[c_kontaars == 3]
  healthAbuseTemp[ , physicalAbuse := 1]
  healthAbuseTemp <- healthAbuseTemp[ , .(pnr , d_inddto , physicalAbuse)]
  healthAbuse <- rbindlist(list(healthAbuse , healthAbuseTemp))
  healthAbuse <- unique(healthAbuse)
  childAbuseExclusion <- merge(childAbuseExclusion , healthAbuse , by.x = "pnr" , by.y = "pnr") 
  childAbuseExclusion <- childAbuseExclusion[d_inddto < as.Date("1997-01-01")]
  childAbuseExclusion[ , c("birthDate" , "d_inddto") := NULL]
  setnames(childAbuseExclusion , "physicalAbuse" , "childAbuseExclusion")
  fwrite(childAbuseExclusion , "childAbuseExclusion.csv")
  ##Visually inspected, list formatted with pnrs and a variable indicating need of exclusion. 

  ##Loading cause of death registries for classification of outcome:

  dodsaasg <- fread("dodsaasg_pop_110621.csv" ,
		    colClasses = ("pnr" = "character") ,
		    select = c("pnr" , "c_dodtilgrundl_acme" ,
			       "c_dod_1a" , "c_dod_1b" ,
			       "c_dod_1c" , "c_dod_1d" ,
			       "c_dod_21" , "c_dod_22" ,
			       "c_dod_23" , "c_dod_24" ,
			       "c_dod_25" , "c_dod_26" ,
			       "c_dod_27" , "c_dod_28" ,
			       "d_statdato" , "c_dodsmaade"))
  dodsaasg[ , d_statdato := floor_date(as.Date(d_statdato) , unit = "month")]
  ##Removing the "s and adding D to all codes to make them compatible with the codings used elsewhere:
  cols <- grep('dod' , names(dodsaasg) , value = TRUE) 
  dodsaasg[ , (cols) := lapply(.SD , function(x) gsub('\"' , '' , x)) , .SDcols = cols]
  cols <- grep('dod_|dodtil' , names(dodsaasg) , value = TRUE) 
  dodsaasg[ , (cols) := lapply(.SD , function(x) gsub('^' , 'D' , x)) , .SDcols = cols]
  dodsaasg[ , (cols) := lapply(.SD , function(x) gsub('D$' , '' , x)) , .SDcols = cols]
  ##The list of physical abuse diagnoses has been loaded previously:
  physicalAbuseVector <- physicalAbuse[ , physicalAbuseDiag]
  for (i in cols) {
      dodsaasg[get(i) %in% physicalAbuseVector , lethalPhysicalAbuse := 1]
  }
  ##Adding cases from manner of death:
  dodsaasg[c_dodsmaade == 4 , lethalPhysicalAbuse := 1]
  ##Some cases manually inspected, classifies as expected.
  ##As cause of death will only be used for the outcome, throw all others away:
  dodsaasg <- dodsaasg[lethalPhysicalAbuse == 1]

  dodsaars <- fread("dodsaars_pop_180621.csv" ,
		    colClasses = ("pnr" = "character") ,
		    select = c("pnr" , "C_DOD1" ,
			       "C_DOD2" , "C_DOD3" ,
			       "C_DOD4" , "D_DODSDTO" ,
			       "C_DODSMAADE"))
  dodsaars[ , D_DODSDTO := floor_date(as.Date(D_DODSDTO , "%m/%d/%Y") , unit = "month")]
  ##We don't need physical abuse ICD8-codes as codes in ICD8 has to be prior to 1994 - so I will just proceed as above:
  ##Adding D to all codes to make them compatible with the codings used elsewhere:
  cols <- grep('C_' , names(dodsaars) , value = TRUE) 
  dodsaars[D_DODSDTO > as.Date("1994-01-01") , (cols) := lapply(.SD , function(x) gsub('^' , 'D' , x)) , .SDcols = cols]
  dodsaars[D_DODSDTO > as.Date("1994-01-01") , (cols) := lapply(.SD , function(x) gsub('D$' , '' , x)) , .SDcols = cols]
  for (i in cols) {
      dodsaars[get(i) %in% physicalAbuseVector , lethalPhysicalAbuse := 1]
  }
  ##Adding records from manner of death-variable:
  dodsaars[C_DODSMAADE == "D4" & D_DODSDTO > as.Date("1996-12-31") , lethalPhysicalAbuse := 1]
  ##Some cases manually inspected, classifies as expected.
  ##As cause of death will only be used for the outcome, throw all others away:
  dodsaars <- dodsaars[lethalPhysicalAbuse == 1]

  ##Preparing for merge
  dodsaasg <- dodsaasg[ , .(pnr , d_statdato , lethalPhysicalAbuse)]
  dodsaars <- dodsaars[ , .(pnr , D_DODSDTO , lethalPhysicalAbuse)]
  setnames(dodsaars , "D_DODSDTO" , "d_statdato")
  dodAbuse <- rbindlist(list(dodsaasg , dodsaars))
  rm(dodsaasg , dodsaars)

  ##Loading criminal registers for use later:
  kraf <- fread("kraf_pop_210621.csv" , colClasses = c("pnr" = "character" , "journr" = "character") , select = c("journr" , "pnr"))
  kraf <- kraf[pnr != ""]
  kraf <- kraf[!grep('[.*[A-Z].*' , pnr)]

  krin <- fread("krin_pop_020721.csv" , colClasses = c("pnr" = "character" , "journr" = "character") , select = c("journr" , "pnr"))
  krin <- krin[pnr != ""]
  krin <- krin[!grep('[.*[A-Z].*' , pnr)]

  krko <- fread("krko__pop_210621.csv" , colClasses = c("pnr" = "character" , "journr" = "character") , select = c("journr" , "pnr"))
  krko <- krko[pnr != ""]
  krko <- krko[!grep('[.*[A-Z].*' , pnr)]

  krms <- fread("krms_pop_210621.csv" ,
		colClasses = c("pnr" = "character" ,
			       "journr" = "character") ,
		select = c("journr" , "pnr"))
  krms <- krms[pnr != ""]
  krms <- krms[!grep('[.*[A-Z].*' , pnr)]

  ##Loading educational data and formatting it for later use:
  udda <- fread("udda_pop_210621.csv" ,
		nrows = nrows ,
		select = c("pnr" , "hfaudd" ,
			   "HF_VFRA" , "aar") ,
		colClasses = c("pnr" = "character" ,
			       "hfaudd" = "character"))
  udda[ , HF_VFRA := floor_date(as.Date(HF_VFRA , format = "%m/%d/%Y") , unit = "month")]
  ##This is coded above, re-formatted from DSTs coding:
  uddaClassification <- fread("educationClassification.csv" ,
			      colClasses = c("Code" = "character" ,
					     "Level" = "numeric"))
  udda <- merge(udda , uddaClassification ,
		by.x = "hfaudd" ,
		by.y = "Code" , all.x = TRUE)
  udda <- udda[!is.na(Level)]
  udda[ , education := cut(Level ,
			   breaks = c(0 , 10 , 50 , 90) ,
			   labels = c("Primary education" ,
				      "Secondary education" ,
				      "Tertiary education or higher"))]
  setkey(udda , HF_VFRA)


  ##Getting the full population
  setwd("d:/data/Workdata/707544/Population")
  fullPopulation <- fread("population_final.csv" , nrows = nrows , colClasses = (pnr = "character"))
  ##Figuring out which ones are children and at what times
  setwd("d:/data/Workdata/707544/Grunddata")
  ##lprFoedsler <- fread("lprfoedsler_pop_080621.csv" , nrows = nrows) #Does not tie parents and child - only info on parity and length of pregnancy.
  ##lprFoeds <- fread("lprfoeds_pop_080621.csv" , nrows = nrows)
  ftBarn <- fread("ftbarn_pop_070621.csv" , nrows = nrows , colClasses = (pnr = "character")) #FOED_DAG
  ##cpst <- fread("cpst_pop_070621.csv" , nrows = nrows)
  ftBarn <- ftBarn[!is.na(pnr)]
  ftBarn <- ftBarn[pnr != ""]
  bef <- fread("bef_pop_230921.csv" ,
	       nrows = nrows ,
	       select = c("pnr" , "opgikom" , "MOR_ID" ,
			  "FAR_ID" , "BOP_VFRA" , "FOED_DAG" ,
			  "OPR_LAND" , "VAN_VTIL" , "YEAR" ,
			  "kom" , "FM_MARK") ,
	       colClasses = c("pnr" = "character" , "opgikom" = "character" , "MOR_ID" = "character" , "FAR_ID" = "character" , "OPR_LAND" = "character" , "kom" = "character")) 
  bef <- bef[!is.na(pnr)]
  bef <- bef[pnr != ""]
  ##Make everything dates:
  ftBarn[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  ftBarn[ , MOR_VFRA := floor_date(as.Date(MOR_VFRA , format = "%m/%d/%Y") , unit = "month")]
  ftBarn[ , FAR_VFRA := floor_date(as.Date(FAR_VFRA , format = "%m/%d/%Y") , unit = "month")]
  bef[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  bef[ , BOP_VFRA := floor_date(as.Date(BOP_VFRA , format = "%m/%d/%Y") , unit = "month")]
  bef[ , VAN_VTIL := floor_date(as.Date(VAN_VTIL , format = "%m/%d/%Y") , unit = "month")]
  ##Side note on performance - seems I am loading full datasets here, likely not necessary, could be cut down if memory is an issue.

  setkey(fullPopulation , pnr)
  setkey(ftBarn , pnr)
  setkey(bef , pnr)
  setkey(mfr , pnr)

  ##Producing a version of ftBarn without concurrent parents (likely the result of immediate adoption after birth - two parents with the same role "start" at the same time:
  ftBarnMod <- copy(ftBarn)
  ftBarnMod[MOR_VFRA == FOED_DAG & MOR2 != "" , MOR1 := ""]
  ftBarnMod[FAR_VFRA == FOED_DAG & FAR2 != "" , FAR1 := ""]
  ##Merging on birth date information:
  fullPopulation <- merge(fullPopulation , ftBarn[ , .(pnr , FOED_DAG)] , all.x = TRUE)
  fullPopulation <- merge(fullPopulation , bef[ , .(pnr , FOED_DAG)] , all.x = TRUE , suffixes = c("ftBarn" , "bef") , no.dups = TRUE)
  ##bef introduces a number of duplicates - removing those:
  fullPopulation <- unique(fullPopulation)
  fullPopulation <- merge(fullPopulation , mfr[ , .(pnr , foedselsdato)] , all.x = TRUE)
  ##Define for each date who's a child (<18 years old):
  ##Prioritize data from bef over ftBarn over MFR:
  fullPopulation[!is.na(FOED_DAGbef) , birthDate := FOED_DAGbef]
  fullPopulation[!is.na(FOED_DAGftBarn) & is.na(birthDate) , birthDate := FOED_DAGftBarn]
  fullPopulation[!is.na(foedselsdato) & is.na(birthDate) , birthDate := foedselsdato]
  ##Checked by viewing - gives correctly formatted date for all individuals who has a non-missing entry in one of three variables. 
  ##Reducing the dataset to the subjects that are children at some point between 1997 and 2018:
  ##6575 comes from 18*365.24 - if the birth date minus the starting date of the study is less than -6575 this means that the subject was already 18 years old when the study started. All larger numbers means the person was less than 18 at some time during the study.  
  fullPopulation[(birthDate-as.Date("1997-01-01")) > -6575 , child := TRUE]
  fullPopulationChildren <- fullPopulation[child == TRUE , .(pnr , birthDate)]
  ##Writing a list of children to facilitate exclusion if physical abuse took place before the study began:
  fwrite(fullPopulationChildren , "fullPopulationChildren.csv")
  ##Importing the results of that list and removing the children:
  childAbuseExclusion <- fread("childAbuseExclusion.csv" , colClasses =("pnr" = "character"))
  fullPopulationChildren <- merge(fullPopulationChildren , childAbuseExclusion , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
  fullPopulationChildren <- fullPopulationChildren[is.na(childAbuseExclusion)]
  fullPopulationChildren[ , childAbuseExclusion := NULL]
  ##Adding the parents:
  setkey(fullPopulationChildren , pnr)
  setkey(ftBarn , pnr)
  fullPopulationChildren <- merge(x = fullPopulationChildren , y = ftBarnMod[ , .(pnr , MOR1 , MOR2 , FAR1 , FAR2 , MOR_VFRA , FAR_VFRA)] , all.x = TRUE)
  rm(ftBarnMod)
  fullPopulationChildren <- unique(fullPopulationChildren)
  ##Looking for additional parents, that is children with more than two parents during their childhood. I have not yet found any such children, but instead some inconsistensies between ftbarn and bef. Will go with parent 1 and 2 for now. 
  ##fullPopulationChildren <- merge(fullPopulationChildren , bef[ , .(pnr , FAMILIE_ID , MOR_ID , FAR_ID)] , all.x = TRUE)
  ##fullPopulationChildren <- unique(fullPopulationChildren)
  ##Read in family register - I have no variable in BEF that can tell me when a family changes, so I need estimates of when the child had a new parent
  ##fam <- fread("fam_pop_080621.csv" , nrows = nrows , colClasses = (FAMILIE_ID = "character"))
  ##fullPopulationChildren <- merge(fullPopulationChildren , fam , by.x = "FAMILIE_ID" , by.y = "FAMILIE_ID" , all.x = TRUE)

  ##Preparing add-on of additional parents:
  ##Upon inspecting the data structure of ftBarn I conclude that MOR and FAR_VFRA are for the last parent - thus if there is no father or mother 2, the date is usually the same as the birth date, and belongs to parent one. If there is a parent 2, the date is for this person. I will code this (for some reason, when character is the class of a column, all NAs are coded as "") 
  fullPopulationChildren[MOR2 == "" , MOR_VFRA1 := MOR_VFRA]
  fullPopulationChildren[FAR2 == "" , FAR_VFRA1 := FAR_VFRA]
  fullPopulationChildren[MOR2 != "" & !is.na(MOR2) , MOR_VFRA2 := MOR_VFRA]
  fullPopulationChildren[MOR2 != "" & !is.na(MOR2) , MOR_VFRA1 := birthDate]
  fullPopulationChildren[FAR2 != "" & !is.na(FAR2) , FAR_VFRA2 := FAR_VFRA]
  fullPopulationChildren[FAR2 != "" & !is.na(FAR2) , FAR_VFRA1 := birthDate]
  ##Adding these lines as some MOR and FAR1 has been deleted to avoid "double parenting" as a result of early adoption:
  fullPopulationChildren[FAR1 == "" , FAR_VFRA1 := NA]
  fullPopulationChildren[MOR1 == "" , MOR_VFRA1 := NA]
  ##Adding on "new" parents for each year:
  parentNo <- 3
  for (i in 1997:2018) {
    fullPopulationChildren <- merge(fullPopulationChildren , bef[YEAR == i , .(pnr , FAR_ID , MOR_ID , YEAR)] ,
				    by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ##As I do not know when the change in parent occurred, the first of July is assumed:
    fullPopulationChildren[ , (paste0("FAR_VFRA" , parentNo)) :=
			      as.Date(paste0(YEAR , "-07-01"))]
    fullPopulationChildren[ , (paste0("MOR_VFRA" , parentNo)) :=
			      as.Date(paste0(YEAR , "-07-01"))]
    fullPopulationChildren[ , YEAR := NULL]
    setnames(fullPopulationChildren , c("FAR_ID" , "MOR_ID") ,
	     c(paste0("FAR" , parentNo) , paste0("MOR" , parentNo)))
    print(i)
    parentNo <- parentNo + 1
  }
  ##Visually inspected, performs as expected
  ##Remove IDs for parents that are already there - there should be some far4 without deletion, check again:
  for (i in 3:24) {
    for (j in 1:(i-1)) {
      fullPopulationChildren[get(paste0("MOR" , i)) == get(paste0("MOR" , j)) , (paste0("MOR_VFRA" , i)) := NA]
      fullPopulationChildren[get(paste0("MOR" , i)) == get(paste0("MOR" , j)) , (paste0("MOR" , i)) := ""]
      fullPopulationChildren[get(paste0("FAR" , i)) == get(paste0("FAR" , j)) , (paste0("FAR_VFRA" , i)) := NA]
      fullPopulationChildren[get(paste0("FAR" , i)) == get(paste0("FAR" , j)) , (paste0("FAR" , i)) := ""]
    }
  }
  ##Also remove new VFRA for unknown parents - the dataset should present the latest known parent. This holds a risk of connecting children to parents from which they have been removed for adoption or institutionalized - but usually these children should receive new pnrs for parents. If this does not happen, for these very few cases, the last known parent is used. This will be very rare though, as it seems such children simply have a missing value for such parents, and some children in the registries have no parents at all. Determining whether a child actually have any contact with parents with or without parental rights is beyond the capacities of this dataset. 
  for (i in 1:24) {
    fullPopulationChildren[is.na(get(paste0("MOR" , i))) , (paste0("MOR_VFRA" , i)) := NA]
    fullPopulationChildren[is.na(get(paste0("FAR" , i))) , (paste0("FAR_VFRA" , i)) := NA]
    fullPopulationChildren[(get(paste0("MOR" , i))) == "" , (paste0("MOR_VFRA" , i)) := NA]
    fullPopulationChildren[(get(paste0("FAR" , i))) == "" , (paste0("FAR_VFRA" , i)) := NA]
  }


  ##When compared with inspections before loop, it is seen that parents that differs from earlier parents remains, but parents that replicate are deleted.
  ##First some helping variables are declared:
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VFRATemp" , i)) := as.Date(character())]
    fullPopulationChildren[ , (paste0("MOR_VFRATemp" , i)) := as.Date(character())]
  }
  ##Then a loop does the following: for each VFRA it 1: empties the helper variables, 2: defines new helper variables for only those that are larger than itself, 3: use this date as VTIL for a parent. Thus the parent has both a start and an end-date, presuming there is a parent-replacement. Otherwise, the end-date is empty. 
  for (i in 1:24) {
    for (k in 1:24) {
      fullPopulationChildren[ , (paste0("FAR_VFRATemp" , k)) := NA]
      fullPopulationChildren[ , (paste0("MOR_VFRATemp" , k)) := NA]        
    }
    for (j in 1:24) {
      fullPopulationChildren[get(paste0("FAR_VFRA" , i)) <
			       get(paste0("FAR_VFRA" , j)) &
			       !is.na(get(paste0("FAR_VFRA" , j))) ,
			     (paste0("FAR_VFRATemp" , j)) :=
			       get(paste0("FAR_VFRA" , j))]
      fullPopulationChildren[get(paste0("MOR_VFRA" , i)) <
			       get(paste0("MOR_VFRA" , j)) &
			       !is.na(get(paste0("MOR_VFRA" , j))) ,
			     (paste0("MOR_VFRATemp" , j)) :=
			       get(paste0("MOR_VFRA" , j))]               
    }
    fullPopulationChildren[ , (paste0("FAR_VTIL" , i)) := pmin(FAR_VFRATemp1 ,
							       FAR_VFRATemp2 ,
							       FAR_VFRATemp3 ,
							       FAR_VFRATemp4 ,
							       FAR_VFRATemp5 ,
							       FAR_VFRATemp6 ,
							       FAR_VFRATemp7 ,
							       FAR_VFRATemp8 ,
							       FAR_VFRATemp9 ,
							       FAR_VFRATemp10 ,
							       FAR_VFRATemp11 ,
							       FAR_VFRATemp12 ,
							       FAR_VFRATemp13 ,
							       FAR_VFRATemp14 ,
							       FAR_VFRATemp15 ,
							       FAR_VFRATemp16 ,
							       FAR_VFRATemp17 ,
							       FAR_VFRATemp18 ,
							       FAR_VFRATemp19 ,
							       FAR_VFRATemp20 ,
							       FAR_VFRATemp21 ,
							       FAR_VFRATemp22 ,
							       FAR_VFRATemp23 ,
							       FAR_VFRATemp24 , na.rm = TRUE)]
    fullPopulationChildren[ , (paste0("MOR_VTIL" , i)) := pmin(MOR_VFRATemp1 ,
							       MOR_VFRATemp2 ,
							       MOR_VFRATemp3 ,
							       MOR_VFRATemp4 ,
							       MOR_VFRATemp5 ,
							       MOR_VFRATemp6 ,
							       MOR_VFRATemp7 ,
							       MOR_VFRATemp8 ,
							       MOR_VFRATemp9 ,
							       MOR_VFRATemp10 ,
							       MOR_VFRATemp11 ,
							       MOR_VFRATemp12 ,
							       MOR_VFRATemp13 ,
							       MOR_VFRATemp14 ,
							       MOR_VFRATemp15 ,
							       MOR_VFRATemp16 ,
							       MOR_VFRATemp17 ,
							       MOR_VFRATemp18 ,
							       MOR_VFRATemp19 ,
							       MOR_VFRATemp20 ,
							       MOR_VFRATemp21 ,
							       MOR_VFRATemp22 ,
							       MOR_VFRATemp23 ,
							       MOR_VFRATemp24 , na.rm = TRUE)]    
  }
  ##Results visually inspected, performing as described. 
  ##The helper variables are deleted
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VFRATemp" , i)) := NULL]
    fullPopulationChildren[ , (paste0("MOR_VFRATemp" , i)) := NULL]
  }
  ##To avoid a child having two mothers or fathers at a time, the VTIL is subtracted with a single day:
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VTIL" , i)) := (get(paste0("FAR_VTIL" , i)) - 1)]
    fullPopulationChildren[ , (paste0("MOR_VTIL" , i)) := (get(paste0("MOR_VTIL" , i)) - 1)]
  }

  ##Setting up rows and dates for each parent within the current year:
  foraeldreID <- c(paste0("FAR" , 1:24) , paste0("MOR" , 1:24))
  foraeldreFra <- c(paste0("FAR_VFRA" , 1:24) , paste0("MOR_VFRA" , 1:24))
  foraeldreTil <- c(paste0("FAR_VTIL" , 1:24) , paste0("MOR_VTIL" , 1:24))
  fullPopulationChildren <- melt(fullPopulationChildren , measure = list(foraeldreID , foraeldreFra , foraeldreTil) , value.name = c("parentID" , "parenthoodStart" , "parenthoodEnd"))
  fullPopulationChildren[variable %in% c(1:24) , parentRole := "FAR"]
  fullPopulationChildren[variable %in% c(25:48) , parentRole := "MOR"]
  fullPopulationChildren <- fullPopulationChildren[parentID != ""]
  fullPopulationChildren <- fullPopulationChildren[!is.na(parentID)]
  fullPopulationChildren[ , c("MOR_VFRA" , "FAR_VFRA" , "variable") := NULL]
  ##Adding parental birthdays:
  ##Merging FOED_DAG from bef for parents:
  befFoeds <- bef[ , .(pnr , FOED_DAG)]
  befFoeds <- unique(befFoeds)
  fullPopulationChildren <- merge(fullPopulationChildren , befFoeds , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  setnames(fullPopulationChildren , old = "FOED_DAG" , new = "birthDateParentBef")
  rm(befFoeds)
  ##Merging parental FOED_DAG from ftbarn:
  fullPopulationChildren <- merge(fullPopulationChildren , ftBarn[ , .(pnr , FOED_DAG)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  setnames(fullPopulationChildren , old = "FOED_DAG" , new = "birthDateParentFtBarn" , skip_absent = TRUE)
  ##Importing mfr for parental birthdate - this dataset has already been loaded, only using relevant variables:
  fullPopulationChildren <- merge(fullPopulationChildren , mfr[ , .(pnr , foedselsdato)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  ##Prioritize data from bef over ftBarn over MFR and generate birthDateParent: 
  fullPopulationChildren[!is.na(birthDateParentBef) , birthDateParent := birthDateParentBef]
  fullPopulationChildren[!is.na(birthDateParentFtBarn) & is.na(birthDateParent) , birthDateParent := birthDateParentFtBarn]
  fullPopulationChildren[!is.na(foedselsdato) & is.na(birthDateParent) , birthDateParent := foedselsdato]
  fullPopulationChildren[ , c("birthDateParentFtBarn" , "birthDateParentBef" , "foedselsdato") := NULL]
  ##Removing pnrs for single use (with letters in them):
  fullPopulationChildren <- fullPopulationChildren[!grepl('.*[A-Z].*' , pnr)]
  ##Checked and this also removes all parents with single-use pnrs.

  ##Preparing code for outcome - this needs results from fullPopulationChildren:
  ##Inputs from criminal registers:
  krof <- merge(krof , kraf , by.x = "journr" , by.y = "journr" , all.x = TRUE , suffixes = c("Victim" , "PerpetratorKraf"))
  krof <- merge(krof , krin , by.x = "journr" , by.y = "journr" , all.x = TRUE)
  setnames(krof , "pnr" , "pnrPerpetratorKrin")
  krof <- merge(krof , krko , by.x = "journr" , by.y = "journr" , all.x = TRUE)
  setnames(krof , "pnr" , "pnrPerpetratorKrko")
  krof <- merge(krof , krms , by.x = "journr" , by.y = "journr" , all.x = TRUE)
  setnames(krof , "pnr" , "pnrPerpetratorKrms")
  ##All pnrs added, visual inspection shows they are merging according to journr. Switching to long-format:
  krof[ , c("journr") := NULL]
  krof <- melt(krof , id.vars = c("pnrVictim" , "ofr_gerfradt" , "ofr_ger7") , measure.vars = c("pnrPerpetratorKraf" , "pnrPerpetratorKrin" , "pnrPerpetratorKrko" , "pnrPerpetratorKrms"))
  setnames(krof , c("pnrVictim" , "value") , c("pnr" , "pnrPerpetrator"))
  krof[ , variable := NULL]
  ##Making a copy for interparental violence:
  krofIPV <- copy(krof)
  ##Preparing for merge with parents and reducing to children only:
  temp <- unique(fullPopulationChildren , by = c("pnr" , "parentID" , "parenthoodStart" , "birthDate"))
  temp <- temp[ , .(pnr , parentID , parenthoodStart , birthDate)]
  temp[ , parentPerpetrator := 1]
  ##Reducing to children only (only keeping those that merge on pnr on the full list of children in the study) and adding birth date:
  krof <- merge(krof , temp[ , .(pnr , birthDate)] , by.x = "pnr" , by.y = "pnr")
  krof <- unique(krof)
  ##Reducing to incidents during childhood:
  krof <- krof[ofr_gerfradt < (birthDate + 6575)]
  krof <- merge(krof , temp[ , .(pnr , parentID , parenthoodStart , parentPerpetrator)] , by.x = c("pnr" , "pnrPerpetrator") , by.y = c("pnr" , "parentID") , all.x = TRUE)
  ##Removing any marking of parents from something they perpetrated before they became parents:
  krof[parentPerpetrator == 1 & parenthoodStart > ofr_gerfradt , parentPerpetrator := NA]
  krof <- unique(krof)

  ##Preparing datasets for interparental violence: 
  ##Creating subsets of healthMergeTotal for interparental violence:

  ##In this categorization, parents killing each other will not be classified as IPV - this is expected to be preceded by other events or violence, or followed by a change of parental care (the remaning parent will likely be incarcerated). Thus, either the family already has an IPV-status, or the family cease to exist when the event takes place. Also, except for the very few health diagnoses indicating IPV, partial categorization will only be possible from 2001 and forth, as the krof register is necessary for this - this is because krof, the victim register, includes a date for the presumed beginning of the criminal act and thus a date for the presumed beginning of violence.

  ICDIPVCertain <- fread("ICDIPVCertain.csv")
  IPVCertainHealth <- merge(healthMergeTotal , ICDIPVCertain , by.x = "healthEvent" , by.y = "ICD10IPVCertain")
  IPVCertainHealth[ , IPVCertain := 1]
  IPVCertainHealth <- IPVCertainHealth[ , .(pnr , d_inddto , IPVCertain)]

  ICDIPVPartial <- fread("ICDIPVPartial.csv")
  IPVPartialHealth <- merge(healthMergeTotal , ICDIPVPartial , by.x = "healthEvent" , by.y = "ICDIPVPartial")
  IPVPartialHealth <- IPVPartialHealth[ , .(pnr , d_inddto)]
  IPVPartialHealth <- rbindlist(list(IPVPartialHealth ,
				     healthMergeTotal[c_kontaars == "3" ,
						      .(pnr , d_inddto)]) ,
				     use.names = TRUE)
  IPVPartialHealth[ , IPVPartialHealth := 1]
  ##Expanding to one month of dates around d_inddto to facilitate a match with police records of the beginning of the criminal activity:
  NoRowsPartialHealth <- IPVPartialHealth[ , .N]
  IPVPartialHealth <- IPVPartialHealth[ , list(pnr = pnr , IPVPartialHealth = IPVPartialHealth , matchDate = seq(floor_date(d_inddto - 1 , unit = "month") , floor_date((d_inddto %m+% period("1 month")) , unit = "month") , by = "month")) , by = 1:NoRowsPartialHealth]
  IPVPartialHealth[ , NoRowsPartialHealth := NULL]
  ##Only krof will be useful, since this is the only register with a code for the beginning of the criminal act:
  policeIPVPartial <- fread("policeIPVPartial.csv" , colClasses = ("policeIPVPartial"  = "character"))
  krofIPVPartial <- merge(krofIPV , policeIPVPartial , by.x = "ofr_ger7" , by.y = "policeIPVPartial")
  krofIPVPartial[ , c("journr" , "ofr_ger7") := NULL]
  krofIPVPartial[ , IPVPartialPolice := 1]
  krofIPVPartial <- unique(krofIPVPartial)
  ##You are not using for example kraf as there is no variable indicating the beginning of a criminal action such as ofr_gerfradt.

  fullPopulationChildrenParents <- fullPopulationChildren[ , .(parentID , birthDateParent)]
  fullPopulationChildrenParents <- unique(fullPopulationChildrenParents)
  ##Removing parents with non-real pnrs(with letters in them, usually indicating temporary pnrs for the purpose of treatment of acute illness or possibly other temporary administrative action with individuals without a permanent pnr, usually immigrants):
  fullPopulationChildrenParents <- fullPopulationChildrenParents[!grepl('.*[A-Z].*' , parentID)]

  ##fwrite(fullPopulationChildrenParents , "fullPopulationChildrenParents.csv")

  ##Loading registries for censoring
  dod <- fread("dod_pop_110621.csv" , colClasses = ("pnr" = "character"))
  dod[ , doddato := floor_date(as.Date(doddato) , unit = "month")]
  vnds <- fread("vnds_pop_070621.csv" , select = c("pnr" , "indud_kode" , "haend_dato") , colClasses = ("pnr" = "character"))
  vnds[ , haend_dato := floor_date(as.Date(haend_dato) , unit = "month")]
  vnds <- vnds[pnr != ""]
  vnds <- vnds[indud_kode == "U"]
  ##This way of setting up parents only relies on a status of parents performed each year - thus, the date for parent change is unknown. This is set to 1/7 each year, which is an arbitrary choice. However, the number of children with more than two parents is assumed to be limited. 
  ##Doing a dataset for all children in the first year - for each child both parents need an additional dataset with all diagnoses and procedures during the year to read from
  ##Removing datasets no longer necessary at this time:
  rm(mfr , lprmfrlf)

  ##Loading further registries for use in the loop below: 
  ##A number of BEF versions:
  bef <- unique(bef)
  bef[ , BOP_VFRA := floor_date(as.Date(BOP_VFRA , format = "%m/%d/%Y") , unit = "month")]
  ##bef[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  bef[ , VAN_VTIL := floor_date(as.Date(VAN_VTIL , format = "%m/%d/%Y") , unit = "month")]
  ##Merging dates for immigration for children:
  befImmi <- bef[ , .(pnr , VAN_VTIL)]
  befImmi <- unique(befImmi)
  befOrig <- bef[ , .(pnr , OPR_LAND)]
  befOrig <- unique(befOrig)
  befAdr <- bef[ , .(pnr , opgikom , kom , BOP_VFRA)]
  befAdr <- befAdr[!is.na(opgikom)]
  befAdr <- befAdr[opgikom != ""]
  befAdr <- befAdr[!is.na(kom)]
  befAdr <- befAdr[kom != ""]
  setnames(befAdr , "BOP_VFRA" , "BOP_VFRABef")

  ##OPHGIN
  ophginFilesList <- paste0("ophgin" , 1998:2018 , ".csv")
  ophginList <- lapply(ophginFilesList , fread , nrows = nrows , select = c("PNR" , "STATSB" , "KATEGORI" , "GRUNDLAG" , "FORKLAR" , "INDVANDRINGSDATO") , colClasses = c("PNR" = "character"))
  ophgin <- rbindlist(ophginList)
  ophgin[ , INDVANDRINGSDATO := floor_date(as.Date(INDVANDRINGSDATO , format = "%m/%d/%Y") , unit = "month")]
  rm(ophginList , ophginFilesList)
  ##Removing meaningless entries with no pnr:
  ophgin <- ophgin[!is.na(PNR)]
  ophgin <- ophgin[PNR != ""]
  ##Importing OPHG
  ophgFilesList <- paste0("ophg" , 1997:2018 , ".csv")
  ophgList <- lapply(ophgFilesList , fread , nrows = nrows , select = c("PNR" , "KATEGORI" , "GRUNDLAG" , "FORKLAR" , "TILLADELSESDATO") , colClasses = c("PNR" = "character"))
  ophg <- rbindlist(ophgList)
  rm(ophgList , ophgFilesList)
  ##Removing meaningless entries:
  ophg <- ophg[PNR != ""]
  ophg <- ophg[!is.na(PNR)]
  ophg[ , TILLADELSESDATO := as.Date(TILLADELSESDATO , "%m/%d/%Y")]

  ##Importing aekvivadisp_13 from IND:
  indFileList <- c("ind_1991_2000_pop_190621.csv" ,
		   "ind_2001_2010_pop_190621.csv" ,
		   "ind_2011_2017_pop_190621.csv")
  indList <- lapply(indFileList , fread ,
		    nrows = nrows ,
		    select = c("pnr" , "AEKVIVADISP_13" , "aar") ,
		    colClasses = c("pnr" = "character"))
  ind <- rbindlist(indList)
  rm(indFileList , indList)
  ##Adjusting to 2018 currency using purchasing power as index:
  purchasingPower <- fread("purchasingPower.csv")
  ind <- merge(ind , purchasingPower ,
	       by.x = "aar" ,
	       by.y = "Year" ,
	       all.x = TRUE)
  ind[ , AEKVIVADISP_13Adjusted := (AEKVIVADISP_13 * 7045)/Value]
  ind <- ind[pnr != ""]
  ind <- ind[!is.na(pnr)]

  ##Import CPST: commenting this out as it is not being used in the current version of the code:
  ## ##As address information will now be drawn from bef, cpst is reduced to only dates of admission to the country and status, and a number of codes are commented out. 
  ## cpst <- fread("cpst_pop_070621.csv" , nrows = nrows , select = c("pnr" , "status" , "van_vfra" , "van_vtil") , colClasses = c("pnr" = "character" , "status" = "character"))
  ## ##For some reason, R started to read van_vtil as IDate - and correctly so. Commenting out the formatting below: 
  ## ## cpst[van_vtil == "" , van_vtil := NA]
  ## ## cpst[van_vtil == "." , van_vtil := NA]
  ## cpst[ , van_vtil := floor_date(as.Date(van_vtil) , unit = "month")]
  ## cpst[van_vfra == "" , van_vfra := NA]
  ## cpst[van_vfra == "." , van_vfra := NA]
  ## cpst[ , van_vfra := floor_date(as.Date(van_vfra) , unit = "month")]
  ## cpst[ , status := gsub('\"' , '' , status)]
  ## setnames(cpst , old = c("adrdato" , "van_vtil" , "van_vfra") , new = c("adrdatoCpst" , "van_vtilCpst" , "van_vfraCpst") , skip_absent = TRUE)
  ## cpst <- unique(cpst)

  ##Loading SOGN:
  sognFilesList <- c(paste0("sogn" , 2002:2012 , ".csv") , "sogn2014.csv")
  sognList <- lapply(sognFilesList , fread ,
		     nrows = nrows ,
		     select = c("OPGIKOM" , "KOM" , "SOGN") ,
		     colClasses = c("OPGIKOM" = "character" ,
				    "KOM" = "character" ,
				    "SOGN" = "character"))
  ##Preserving the names of the sogn files:
  sognFilesList <- gsub('\\.csv' , '' , sognFilesList)
  names(sognList) <- sognFilesList
  invisible(lapply(sognList ,
		   setnames ,
		   old = c("SOGN" , "OPGIKOM" , "KOM") ,
		   new = c("SOGN" , "opgikomChild" , "komChild") ,
		   skip_absent = TRUE)) ##This name change is contra-intuitive, but accommodates downstream code. 
  ##Getting the sogn data into the current R environment:
  list2env(sognList , globalenv())
  ##Loading the sogn files with sogn in lower case:
  sognFilesList <- c("sogn2013.csv" , "sogn2015.csv" , "sogn2016.csv")
  sognList <- lapply(sognFilesList , fread , nrows = nrows , select = c("OPGIKOM" , "KOM" , "sogn") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "sogn" = "character"))
  ##Harmonizing - making SOGN in capital letters:
  invisible(lapply(sognList , setnames , old = c("sogn" , "OPGIKOM" , "KOM") , new = c("SOGN" , "opgikomChild" , "komChild") , skip_absent = TRUE)) ##This name change is contra-intuitive, but accomodates downstream code. 
  sognFilesList <- gsub('\\.csv' , '' , sognFilesList)
  names(sognList) <- sognFilesList
  list2env(sognList , globalenv())
  rm(sognList , sognFilesList)
  ##Adding sogn for 2017-2018:
  sogn2017 <- fread("dar2017.csv" , select =c("OPGIKOM" , "KOM" , "SOGNEKODE") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "SOGNEKODE" = "character"))
  sogn2018 <- fread("dar2018.csv" , select =c("OPGIKOM" , "KOM" , "SOGNEKODE") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "SOGNEKODE" = "character"))
  setnames(sogn2017 ,
	   c("OPGIKOM" , "KOM" , "SOGNEKODE") ,
	   c("opgikomChild" , "komChild" , "SOGN"))
  setnames(sogn2018 ,
	   c("OPGIKOM" , "KOM" , "SOGNEKODE") ,
	   c("opgikomChild" , "komChild" , "SOGN"))

  ##Only use this block if you have been interrupted in the loop below:
  ## memoryLastYear <- fread("memoryLastYear2015.csv" , colClasses = c("parentID" = "character"))                                              
  ## memoryLastYear[ , d_inddtoParent := as.Date(d_inddtoParent)]                                        
  ## memoryLastYear[ , hypertensionGroupDiag := as.numeric(hypertensionGroupDiag)]                                 
  ## memoryLastYear[ , hypertensionGroupDiagEndDate := as.Date(hypertensionGroupDiagEndDate)]                          
  ## memoryLastYear[ , dyslipidemiaGroupDiag := as.numeric(dyslipidemiaGroupDiag)]                                 
  ## memoryLastYear[ , dyslipidemiaGroupDiagEndDate := as.Date(dyslipidemiaGroupDiagEndDate)]                          
  ## memoryLastYear[ , ischemicHeartDiseaseGroupDiag := as.numeric(ischemicHeartDiseaseGroupDiag)]                         
  ## memoryLastYear[ , ischemicHeartDiseaseGroupDiagEndDate := as.Date(ischemicHeartDiseaseGroupDiagEndDate)]                  
  ## memoryLastYear[ , atrialFibrillationGroupDiag := as.numeric(atrialFibrillationGroupDiag)]                           
  ## memoryLastYear[ , atrialFibrillationGroupDiagEndDate := as.Date(atrialFibrillationGroupDiagEndDate)]                    
  ## memoryLastYear[ , heartFailureGroupDiag := as.numeric(heartFailureGroupDiag)]                                 
  ## memoryLastYear[ , heartFailureGroupDiagEndDate := as.Date(heartFailureGroupDiagEndDate)]                          
  ## memoryLastYear[ , peripheralArteryOcclusiveGroupDiag := as.numeric(peripheralArteryOcclusiveGroupDiag)]                    
  ## memoryLastYear[ , peripheralArteryOcclusiveGroupDiagEndDate := as.Date(peripheralArteryOcclusiveGroupDiagEndDate)]             
  ## memoryLastYear[ , strokeGroupDiag := as.numeric(strokeGroupDiag)]                                       
  ## memoryLastYear[ , strokeGroupDiagEndDate := as.Date(strokeGroupDiagEndDate)]                                
  ## memoryLastYear[ , diabetesMellitusGroupDiag := as.numeric(diabetesMellitusGroupDiag)]                             
  ## memoryLastYear[ , diabetesMellitusGroupDiagEndDate := as.Date(diabetesMellitusGroupDiagEndDate)]                      
  ## memoryLastYear[ , thyroidDisorderGroupDiag := as.numeric(thyroidDisorderGroupDiag)]                              
  ## memoryLastYear[ , thyroidDisorderGroupDiagEndDate := as.Date(thyroidDisorderGroupDiagEndDate)]                       
  ## memoryLastYear[ , goutGroupDiag := as.numeric(goutGroupDiag)]                                         
  ## memoryLastYear[ , goutGroupDiagEndDate := as.Date(goutGroupDiagEndDate)]                                  
  ## memoryLastYear[ , chronicPulmonaryDiseaseGroupDiag := as.numeric(chronicPulmonaryDiseaseGroupDiag)]                      
  ## memoryLastYear[ , chronicPulmonaryDiseaseGroupDiagEndDate := as.Date(chronicPulmonaryDiseaseGroupDiagEndDate)]               
  ## memoryLastYear[ , allergyGroupDiag := as.numeric(allergyGroupDiag)]                                      
  ## memoryLastYear[ , allergyGroupDiagEndDate := as.Date(allergyGroupDiagEndDate)]                               
  ## memoryLastYear[ , ulcerChronicGastritisGroupDiag := as.numeric(ulcerChronicGastritisGroupDiag)]                        
  ## memoryLastYear[ , ulcerChronicGastritisGroupDiagEndDate := as.Date(ulcerChronicGastritisGroupDiagEndDate)]                 
  ## memoryLastYear[ , chronicLiverDiseaseGroupDiag := as.numeric(chronicLiverDiseaseGroupDiag)]                          
  ## memoryLastYear[ , chronicLiverDiseaseGroupDiagEndDate := as.Date(chronicLiverDiseaseGroupDiagEndDate)]                   
  ## memoryLastYear[ , inflammatoryBowelDiseaseGroupDiag := as.numeric(inflammatoryBowelDiseaseGroupDiag)]                     
  ## memoryLastYear[ , inflammatoryBowelDiseaseGroupDiagEndDate := as.Date(inflammatoryBowelDiseaseGroupDiagEndDate)]              
  ## memoryLastYear[ , diverticularDiseaseOfIntestineGroupDiag := as.numeric(diverticularDiseaseOfIntestineGroupDiag)]               
  ## memoryLastYear[ , diverticularDiseaseOfIntestineGroupDiagEndDate := as.Date(diverticularDiseaseOfIntestineGroupDiagEndDate)]        
  ## memoryLastYear[ , chronicKidneyDiseaseGroupDiag := as.numeric(chronicKidneyDiseaseGroupDiag)]                         
  ## memoryLastYear[ , chronicKidneyDiseaseGroupDiagEndDate := as.Date(chronicKidneyDiseaseGroupDiagEndDate)]                  
  ## memoryLastYear[ , prostateDisordersGroupDiag := as.numeric(prostateDisordersGroupDiag)]                            
  ## memoryLastYear[ , prostateDisordersGroupDiagEndDate := as.Date(prostateDisordersGroupDiagEndDate)]                     
  ## memoryLastYear[ , connectiveTissueDisordersGroupDiag := as.numeric(connectiveTissueDisordersGroupDiag)]                    
  ## memoryLastYear[ , connectiveTissueDisordersGroupDiagEndDate := as.Date(connectiveTissueDisordersGroupDiagEndDate)]             
  ## memoryLastYear[ , osteoporosisGroupDiag := as.numeric(osteoporosisGroupDiag)]                                 
  ## memoryLastYear[ , osteoporosisGroupDiagEndDate := as.Date(osteoporosisGroupDiagEndDate)]                          
  ## memoryLastYear[ , anemiasGroupDiag := as.numeric(anemiasGroupDiag)]                                      
  ## memoryLastYear[ , anemiasGroupDiagEndDate := as.Date(anemiasGroupDiagEndDate)]                               
  ## memoryLastYear[ , cancerGroupDiag := as.numeric(cancerGroupDiag)]                                       
  ## memoryLastYear[ , cancerGroupDiagEndDate := as.Date(cancerGroupDiagEndDate)]                                
  ## memoryLastYear[ , visionProblemGroupDiag := as.numeric(visionProblemGroupDiag)]                                
  ## memoryLastYear[ , visionProblemGroupDiagEndDate := as.Date(visionProblemGroupDiagEndDate)]                         
  ## memoryLastYear[ , migraineGroupDiag := as.numeric(migraineGroupDiag)]                                     
  ## memoryLastYear[ , migraineGroupDiagEndDate := as.Date(migraineGroupDiagEndDate)]                              
  ## memoryLastYear[ , epilepsyGroupDiag := as.numeric(epilepsyGroupDiag)]                                     
  ## memoryLastYear[ , epilepsyGroupDiagEndDate := as.Date(epilepsyGroupDiagEndDate)]                              
  ## memoryLastYear[ , parkinsonsDiseaseGroupDiag := as.numeric(parkinsonsDiseaseGroupDiag)]                            
  ## memoryLastYear[ , parkinsonsDiseaseGroupDiagEndDate := as.Date(parkinsonsDiseaseGroupDiagEndDate)]                     
  ## memoryLastYear[ , multipleSclerosisGroupDiag := as.numeric(multipleSclerosisGroupDiag)]                            
  ## memoryLastYear[ , multipleSclerosisGroupDiagEndDate := as.Date(multipleSclerosisGroupDiagEndDate)]                     
  ## memoryLastYear[ , neuropathiesGroupDiag := as.numeric(neuropathiesGroupDiag)]                                 
  ## memoryLastYear[ , neuropathiesGroupDiagEndDate := as.Date(neuropathiesGroupDiagEndDate)]                          
  ## memoryLastYear[ , moodStressrelatedOrAnxietyDisordersGroupDiag := as.numeric(moodStressrelatedOrAnxietyDisordersGroupDiag)]          
  ## memoryLastYear[ , moodStressrelatedOrAnxietyDisordersGroupDiagEndDate := as.Date(moodStressrelatedOrAnxietyDisordersGroupDiagEndDate)]   
  ## memoryLastYear[ , anorexiaBulimiaGroupDiag := as.numeric(anorexiaBulimiaGroupDiag)]                              
  ## memoryLastYear[ , anorexiaBulimiaGroupDiagEndDate := as.Date(anorexiaBulimiaGroupDiagEndDate)]                       
  ## memoryLastYear[ , bipolarAffectiveDisorderGroupDiag := as.numeric(bipolarAffectiveDisorderGroupDiag)]                     
  ## memoryLastYear[ , bipolarAffectiveDisorderGroupDiagEndDate := as.Date(bipolarAffectiveDisorderGroupDiagEndDate)]              
  ## memoryLastYear[ , schizophreniaOrSchizoaffectiveDisorderGroupDiag := as.numeric(schizophreniaOrSchizoaffectiveDisorderGroupDiag)]       
  ## memoryLastYear[ , schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate := as.Date(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate)]
  ## memoryLastYear[ , personalityDisorderGroupDiag := as.numeric(personalityDisorderGroupDiag)]                          
  ## memoryLastYear[ , personalityDisorderGroupDiagEndDate := as.Date(personalityDisorderGroupDiagEndDate)]                   
  ## memoryLastYear[ , dementiaGroupDiag := as.numeric(dementiaGroupDiag)]                                     
  ## memoryLastYear[ , dementiaGroupDiagEndDate := as.Date(dementiaGroupDiagEndDate)]                              
  ## memoryLastYear[ , otherGroupDiag := as.numeric(otherGroupDiag)]                                        
  ## memoryLastYear[ , otherGroupDiagEndDate := as.Date(otherGroupDiagEndDate)]                                 
  ## memoryLastYear[ , pretermBirthGroupDiag := as.numeric(pretermBirthGroupDiag)]                                 
  ## memoryLastYear[ , pretermBirthGroupDiagEndDate := as.Date(pretermBirthGroupDiagEndDate)]                          
  ## memoryLastYear[ , acuteCaesarianSectionGroupDiag := as.numeric(acuteCaesarianSectionGroupDiag)]                        
  ## memoryLastYear[ , acuteCaesarianSectionGroupDiagEndDate := as.Date(acuteCaesarianSectionGroupDiagEndDate)]                 
  ## memoryLastYear[ , alcoholAbuse := as.numeric(alcoholAbuse)]                                          
  ## memoryLastYear[ , alcoholAbuseEndDate := as.Date(alcoholAbuseEndDate)]                                   
  ## memoryLastYear[ , substanceAbuse := as.numeric(substanceAbuse)]                                        
  ## memoryLastYear[ , substanceAbuseEndDate := as.Date(substanceAbuseEndDate)]                                 
  ## memoryLastYear[ , unspecificEver := as.numeric(unspecificEver)]                                        
  ## memoryLastYear[ , unspecificEverEndDate := as.Date(unspecificEverEndDate)]                     

  ## memoryLastYear[ , unspecificTwoYear := as.numeric(unspecificTwoYear)]                                        
  ## memoryLastYear[ , unspecificTwoYearEndDate := as.Date(unspecificTwoYearEndDate)]

  ## memoryLastYear[ , eksd := as.Date(eksd)]                                                  

  ## memoryLastYear[ , dyslipidemiaGroupLmdb := as.numeric(dyslipidemiaGroupLmdb)]                                 
  ## memoryLastYear[ , dyslipidemiaGroupLmdbEndDate := as.Date(dyslipidemiaGroupLmdbEndDate)]                          
  ## memoryLastYear[ , ischemicHeartDiseaseGroupLmdb := as.numeric(ischemicHeartDiseaseGroupLmdb)]                         
  ## memoryLastYear[ , ischemicHeartDiseaseGroupLmdbEndDate := as.Date(ischemicHeartDiseaseGroupLmdbEndDate)]                  
  ## memoryLastYear[ , diabetesMellitusGroupLmdb := as.numeric(diabetesMellitusGroupLmdb)]                             
  ## memoryLastYear[ , diabetesMellitusGroupLmdbEndDate := as.Date(diabetesMellitusGroupLmdbEndDate)]                      
  ## memoryLastYear[ , thyroidDisorderGroupLmdb := as.numeric(thyroidDisorderGroupLmdb)]                              
  ## memoryLastYear[ , thyroidDisorderGroupLmdbEndDate := as.Date(thyroidDisorderGroupLmdbEndDate)]                       
  ## memoryLastYear[ , chronicPulmonaryDiseaseGroupLmdb := as.numeric(chronicPulmonaryDiseaseGroupLmdb)]                      
  ## memoryLastYear[ , chronicPulmonaryDiseaseGroupLmdbEndDate := as.Date(chronicPulmonaryDiseaseGroupLmdbEndDate)]               
  ## memoryLastYear[ , allergyGroupLmdb := as.numeric(allergyGroupLmdb)]                                      
  ## memoryLastYear[ , allergyGroupLmdbEndDate := as.Date(allergyGroupLmdbEndDate)]                               
  ## memoryLastYear[ , osteoporosisGroupLmdb := as.numeric(osteoporosisGroupLmdb)]                                 
  ## memoryLastYear[ , osteoporosisGroupLmdbEndDate := as.Date(osteoporosisGroupLmdbEndDate)]                          
  ## memoryLastYear[ , painfulConditionGroupLmdb := as.numeric(painfulConditionGroupLmdb)]                             
  ## memoryLastYear[ , painfulConditionGroupLmdbEndDate := as.Date(painfulConditionGroupLmdbEndDate)]                      
  ## memoryLastYear[ , migraineGroupLmdb := as.numeric(migraineGroupLmdb)]                                     
  ## memoryLastYear[ , migraineGroupLmdbEndDate := as.Date(migraineGroupLmdbEndDate)]                              
  ## memoryLastYear[ , epilepsyGroupLmdb := as.numeric(epilepsyGroupLmdb)]                                     
  ## memoryLastYear[ , epilepsyGroupLmdbEndDate := as.Date(epilepsyGroupLmdbEndDate)]                              
  ## memoryLastYear[ , bipolarAffectiveDisorderGroupLmdb := as.numeric(bipolarAffectiveDisorderGroupLmdb)]                     
  ## memoryLastYear[ , bipolarAffectiveDisorderGroupLmdbEndDate := as.Date(bipolarAffectiveDisorderGroupLmdbEndDate)]              
  ## memoryLastYear[ , dementiaGroupLmdb := as.numeric(dementiaGroupLmdb)]                                     
  ## memoryLastYear[ , dementiaGroupLmdbEndDate := as.Date(dementiaGroupLmdbEndDate)]         

  ## deathList <- fread("deathList2015.csv" , colClasses = ("pnr" = "character"))
  ## outcomeList <- fread("outcomeList2015.csv" , colClasses = ("pnr" = "character"))
  ## noParentsList <- fread("noParentsList2015.csv" , colClasses = ("pnr" = "character"))
  ## exclusionList <- fread("exclusionList2015.csv" , colClasses = ("pnr" = "character"))

  ## ##Remember if you're repeating the loop:
  ## suppressWarnings(rm(memoryLastYear ,
  ## 		    deathList ,
  ## 		    outcomeList ,
  ## 		    noParentsList ,
  ## 		    exclusionList))
  ##Setting up an exclusion list for emigrated individuals (do not execute if you are restarting a broken loop):
  exclusionList <- data.table(pnr = character())
  ##Freeing up some space before the loop:
  rm(fullPopulation)
  ##Looping over all included years:
  ##This loop takes about two weeks to complete and Statistics Denmark restarts their computers every week - thus, use the code above to start up again and adjust the years in the for-loop below:
  for (k in 1997:2018) {
    firstDate <- as.Date(paste0(k , "-01-01"))
    lastDate <- as.Date(paste0(k , "-12-01"))
    fullPopulationChildrenCurrentYear <- fullPopulationChildren[(birthDate - firstDate) > -6575 & (birthDate - lastDate) <= 0]
    ##Deleting children with outcome in the past:
    if (exists("outcomeList")) {
	outcomeList[ , delete := 1]
	fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear ,
						   outcomeList ,
						   by.x = "pnr" ,
						   by.y = "pnr" ,
						   all.x = TRUE)
	fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
	outcomeList[ , delete := NULL]
	fullPopulationChildrenCurrentYear[ , delete := NULL]
    }
    ##fullPopulationChildrenCurrentYear[ , currentAge := (firstDate - birthDate)/365.24]
    ##All ages less than 18 years on first day of year - or unborn, thus a negative value but not lower than 0.99....
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) <= 0 , studyEntry := firstDate]
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) > 0 , studyEntry := birthDate]
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) <= 0 &
					(birthDate - lastDate) <= -6575 , ageCensoring := birthDate + 6575]
    ##Age censoring visually inspected, staying within the relevant year and corresponding to the 18th year birthday
    ##Implementing censoring for death and emigration:
    ##dod[ , summary(doddato)]
    ##This command showed a reasonable interval for death incidents
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , dod , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , dod , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent"))
    fullPopulationChildrenCurrentYear[ , doddatoChild := floor_date(as.Date(doddatoChild) , unit = "month")]
    fullPopulationChildrenCurrentYear[ , doddatoParent := floor_date(as.Date(doddatoParent) , unit = "month")]
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[doddatoChild >= firstDate | is.na(doddatoChild)]
    fullPopulationChildrenCurrentYear[doddatoChild <= lastDate , deathCensoring := doddatoChild]
    ##The next line may censor some children but that is okay as having a parent is an inclusion criterion (otherwise you cannot have the exposure, and you cannot re-enter after getting new parents(being adopted)). 
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[doddatoParent >= firstDate | is.na(doddatoParent)]
    ##A parental death will not be used for censoring unless this means you have no parents. 
    fullPopulationChildrenCurrentYear[doddatoParent <= lastDate , deathCensoringParent := doddatoParent]
    ##Emigration - anyone dead is assumed not to re-appear in the registries, but anyone emigrated could easily re-emerge later - this would create a strange bias where they have insufficient observation compared to their peers, thus a list is created of all that has emigrated at least once, from whereon they are excluded from the remainder of the study:
    exclusionList[ , delete := 1]
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , exclusionList , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
    exclusionList[ , delete := NULL]
    fullPopulationChildrenCurrentYear[ , delete := NULL]
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , vnds[haend_dato <= lastDate & haend_dato >= firstDate] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear[!is.na(haend_dato) , emigrationCensoring := haend_dato]
    exclusionList <- rbindlist(list(exclusionList , fullPopulationChildrenCurrentYear[!is.na(haend_dato)][ , .(pnr)]))
    exclusionList <- unique(exclusionList)

    ##Also ensure that children dead in earlier datasets are not included again:
    if (exists("deathList")) {
	deathList[ , delete := 1]
	fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , deathList , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
	fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
	deathList[ , delete := NULL]
	fullPopulationChildrenCurrentYear[ , delete := NULL]
    }

    ##Also ensure that children with no parents are not included again (when they get adopted - then they would have a period of time in which they could not experience the exposure):
    if (exists("noParentsList")) {
	noParentsList[ , delete := 1]
	fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , noParentsList , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
	fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
	noParentsList[ , delete := NULL]
	fullPopulationChildrenCurrentYear[ , delete := NULL]
    }

    ##Removing parents that were never parents during 1997 or for which there is no entry:
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[!parenthoodStart > lastDate]
    ##For monitoring:
    print("Just finished censoring")
    print(Sys.time())
    print("Doing some garbage cleaning and printing time afterwards")
    gc()
    print(Sys.time())
    ##Merging health information for the parents onto the dataset (see code for extraction of health information for the code behind this) - going back 5 years to facilitate Charlson scoring:
    setkey(healthMergeTotal , pnr)
    setkey(fullPopulationChildrenCurrentYear , parentID)
    fullPopulationChildrenCurrentYear <-
      merge(x = fullPopulationChildrenCurrentYear ,
	    y = healthMergeTotal[d_inddto >
				   (firstDate - 5*365.24) &
				   d_inddto <
				   (lastDate + 1)] ,
	    by.x = "parentID" ,
	    by.y = "pnr" ,
	    all.x = TRUE ,
	    allow.cartesian = TRUE)
    fullPopulationChildrenCurrentYear <- unique(fullPopulationChildrenCurrentYear)
    ##Merging health information for the children onto the dataset:
    ##This is a many:many join - reducing to one pnr for each child:
    fullPopulationChildrenCurrentYear[ , duplTest := duplicated(pnr)]
    fullPopulationChildrenCurrentYear[duplTest == FALSE , mergePnr := pnr]
    ##To reduce the necessary size of the following merge:
    healthMergeChild <- healthMergeTotal[maltreatmentMark == 1 , .(pnr , maltreatmentMark , d_inddto)]
    healthMergeChild <- unique(healthMergeChild)
    fullPopulationChildrenCurrentYear <-
      merge(x = fullPopulationChildrenCurrentYear ,
	    y = healthMergeChild[d_inddto >
				   (firstDate - 3*365.24) &
				   d_inddto <
				   (lastDate + 1)] ,
	    by.x = "mergePnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE ,
	    suffixes = c("Parent" , "Child") ,
	    allow.cartesian = TRUE)
    fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergePnr") := NULL]
    ##Merges as expected - all info on child and parent health is now in the dataset. 
    ##Merging lmdb onto parents:
    fullPopulationChildrenCurrentYear[ , duplTest := duplicated(parentID) , by = pnr]
    ##If this worked as expected, there should be several instances of the same parental ID that is marked as unique. 
    ##fullPopulationChildrenCurrentYear[1:10000 & duplFullPopulationChildren1997 == FALSE , table(parentID)]
    ##The results of the out-commented command above confirms this - there are several instances of parental IDs counted twice or more as unique, because of the grouping by pnr.  
    fullPopulationChildrenCurrentYear[duplTest == FALSE , mergeParentID := parentID]
    ##During the run of this yearly loop, I have come across code that simply breaks it because of memory - the merge below was coded to include all lmdb-entries with a eksd smaller than lastDate, which is too much in the later years of the dataset. The additional limit on 1.5 years before firstDate is set to be sure to include all prescriptions that might continue into next year, as the maximal endDate for a prescription is one year.
    fullPopulationChildrenCurrentYear <-
	merge(fullPopulationChildrenCurrentYear ,
	      lmdb[eksd <= lastDate &
		   eksd >= (firstDate - (1.1*365.24))] ,
	      by.x = "mergeParentID" ,
	      by.y = "pnr" ,
	      all.x = TRUE ,
	      allow.cartesian = TRUE)
    fullPopulationChildrenCurrentYear <- unique(fullPopulationChildrenCurrentYear)
    fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergeParentID") := NULL]

    ##Merging krof onto the dataset:
    ##Merging onto children: to avoid repetitions of the same data, a unique pnr is created for each pnr, which is then merged upon and subsequently deleted:
    ##Commenting out as this is not used downstream:
    ## fullPopulationChildrenCurrentYear[ , duplTest := duplicated(pnr)]
    ## fullPopulationChildrenCurrentYear[duplTest == FALSE , mergePnr := pnr]
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , krof[ , .(pnr , ofr_gerfradt , ofr_ger7)] , by.x = "mergePnr" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE)
    ## fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergePnr") := NULL]
    ##Visual inspection confirms that multiple records in KROF are now merged once, and the expansion of fullPopulationChildrenCurrentYear is kept to a minimum. 
    ##Merging onto parents: to avoid repetitions of the same data, a unique pnr is created for each pnr, which is then merged upon and subsequently deleted. As several children could have the same parents, this is done grouped by child pnr:
    ##Commenting out as this is not used downstream:
    ## fullPopulationChildrenCurrentYear[ , duplTest := duplicated(parentID) , by = pnr]
    ## ##If this worked as expected, there should be several instances of the same parental ID that is marked as unique. 
    ## ##fullPopulationChildrenCurrentYear[1:10000 & duplTest == FALSE , table(parentID)]
    ## ##The results of the out-commented command above confirms this - there are several instances of parental IDs counted twice or more as unique, because of the grouping by pnr.  
    ## fullPopulationChildrenCurrentYear[duplTest == FALSE , mergeParentID := parentID]
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , krof , by.x = "mergeParentID" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE , suffixes = c("Child" , "Parent"))
    ## fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergeParentID") := NULL]
    ##Dataset visually inspected, merging as intended.
    ##Merging parental FOEDREG_KODE:
    setnames(ftBarn , "pnr" , "parentID")
    fullPopulationChildrenCurrentYear[ftBarn , on = "parentID" , FOEDREG_KODE := i.FOEDREG_KODE]
    setnames(ftBarn , "parentID" , "pnr") 
    ##Merging FAR_FOED_ADOP and MOR_FOED_ADOP to children:
    ##fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , ftBarn[ , .(pnr , FAR_FOED_ADOP , MOR_FOED_ADOP)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ##Merging BEF
    ##bef <- fread("bef_pop_070621.csv" , nrows = nrows , drop = c("FAMILIE_ID" , "MOR_ID" , "FAR_ID" , "efalle" , "civst" , "CIV_VFRA" , "FAMILIE_TYPE" , "FM_MARK" , "generation" , "hustype" , "IE_TYPE" , "koen" , "plads" , "reg") , colClasses = c("pnr" = "character"))
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befImmi , by.x = "pnr" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE)
    ##Merging OPR_LAND for parents:
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befOrig , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("ftBarn" , "bef") , allow.cartesian = TRUE)
    ##Merging OPGIKOM and KOM for children and parents(the last is only to see how many people reside in the family):
    befAdrCurrentYear <- befAdr[BOP_VFRABef <= lastDate]
    befAdrCurrentYear <- unique(befAdrCurrentYear)
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befAdrCurrentYear , by.x = "pnr" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE)
    ##This merge is postponed as it expands the dataset significantly - see at analysisDataset instead:
    ##fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befAdrCurrentYear , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent") , allow.cartesian = TRUE)

    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , ophgin , by.x = "pnr" , by.y = "PNR" , all.x = TRUE)
    ##All merges look as expected. 
    ##Merging to the parents:
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , ophgin , by.x = "parentID" , by.y = "PNR" , all.x = TRUE , suffixes = c("Child" , "Parent"))

    ##Ophg
    ##Merging to the children:
    fullPopulationChildrenCurrentYear <-
	merge(fullPopulationChildrenCurrentYear ,
	      ophg[ ,
		   .(PNR , KATEGORI , GRUNDLAG , FORKLAR)] ,
		   by.x = "pnr" ,
		   by.y = "PNR" ,
		   all.x = TRUE ,
		   allow.cartesian = TRUE)
    ##Merging to the parents:
    fullPopulationChildrenCurrentYear[ , duplTest := duplicated(parentID) , by = pnr]
    fullPopulationChildrenCurrentYear[duplTest == FALSE , mergeParentID := parentID]
    fullPopulationChildrenCurrentYear <-
	merge(fullPopulationChildrenCurrentYear ,
	      ophg[ , .(PNR , KATEGORI , GRUNDLAG , FORKLAR)] ,
	      by.x = "mergeParentID" ,
	      by.y = "PNR" ,
	      all.x = TRUE ,
	      suffixes = c("ChildOPHG" , "ParentOPHG") ,
	      allow.cartesian = TRUE)
    fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergeParentID") := NULL]
    ##For monitoring:
    print("Just finished adding OPHG and OPHGIN")
    print(Sys.time())
    ##Commenting out this code as IND was used instead:
    ## ##Importing famaekvivadisp_13 from faik:
    ## faik <- fread("faik_pop_190621.csv" , nrows = nrows , select = c("FAMILIE_ID" , "famaekvivadisp_13" , "aar") , colClasses = c("FAMILIE_ID" = "character"))
    ## ##I need dates for FAMILIE_ID here - if I can't get them, I might have to rely on fain but it would be better to have actual dates.
    ## ##Merging on currency conversions to 2018-level: 
    ## faik <- merge(faik , purchasingPower , by.x = "aar" , by.y = "Year" , all.x = TRUE)
    ## faik[ , famaekvivadisp_13Adjusted := (famaekvivadisp_13 * 7045)/Value]

    ##Merging IND onto main dataset for children (this is done one year back as ind is a full-year income and using this in the beginning of the current year will condition on the future - thus, instead of using income data from 1997 for 1997, data for 1996, 1995 1nd 1994 are used):
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 1) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE)
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 2) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE ,
	    suffixes = c("Current" , "OneYearBack"))
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 3) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE)
    setnames(fullPopulationChildrenCurrentYear ,
	     "AEKVIVADISP_13Adjusted" ,
	     "AEKVIVADISP_13AdjustedTwoYearsBack")
    ##Computing the mean of the last three years of income:
    fullPopulationChildrenCurrentYear[ ,
				       meanIncome := rowMeans(.SD , na.rm = TRUE) , .SDcols = c("AEKVIVADISP_13AdjustedCurrent" ,
							"AEKVIVADISP_13AdjustedOneYearBack" ,
							"AEKVIVADISP_13AdjustedTwoYearsBack")]
    fullPopulationChildrenCurrentYear[ ,
				       c("AEKVIVADISP_13AdjustedCurrent" ,
					 "AEKVIVADISP_13AdjustedOneYearBack" ,
					 "AEKVIVADISP_13AdjustedTwoYearsBack") := NULL]
    ##Results checked by inspection of the dataset, including the special case of children between 0-1 years old. All children except those 0-1 year old have values if there are any values present for preceding years. Filling in values for the youngest: 
    ##Further calculations on parish after merging of sogn.
    ##There is a special case of children between 0 and 1 years old. These children will be handled by computing the mean of their parents' last year income, and parent is classified as anyone connected to their pnr with a parentID during the current year. Thus, income is merged to the parents as well:
    setnames(ind , "pnr" , "parentID")
    fullPopulationChildrenCurrentYear[ind[aar == (k - 1)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentCurrent :=
					  i.AEKVIVADISP_13Adjusted]
    fullPopulationChildrenCurrentYear[ind[aar == (k - 2)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentOneYearBack :=
					  i.AEKVIVADISP_13Adjusted]
    fullPopulationChildrenCurrentYear[ind[aar == (k - 3)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentTwoYearsBack :=
					  i.AEKVIVADISP_13Adjusted]
    setnames(ind , "parentID" , "pnr")
    fullPopulationChildrenCurrentYear[ ,
				      meanIncomeParentIndividual :=
					  rowMeans(.SD , na.rm = TRUE) ,
				      .SDcols = c("AEKVIVADISP_13AdjustedParentCurrent" ,
						 "AEKVIVADISP_13AdjustedParentOneYearBack" ,
						 "AEKVIVADISP_13AdjustedParentTwoYearsBack")]
    ##Reducing to one line for each parent:
    temp <- unique(fullPopulationChildrenCurrentYear , by = c("pnr" , "parentID"))
    ##Calculating the mean parental income (so this would be the mean income of all parents connected to the child in the year prior to the current one):
    temp[ , meanIncomeParent := mean(meanIncomeParentIndividual , na.rm = TRUE) , by = "pnr"]
    ##Merging this result to the main dataset:
    fullPopulationChildrenCurrentYear[temp , on = "pnr" , meanIncomeParent := i.meanIncomeParent]
    ##Replacing missings among the children with values from their parents:
    fullPopulationChildrenCurrentYear[is.na(meanIncome) , meanIncome := meanIncomeParent]
    ##All steps of calculating meanIncome have been evaluated by manual inspection and performs as expected.
    ##As mentioned above, CPST was abandoned - thus outcommenting this code, that has not been updated for use in a multi-year loop, but is tailored for a single year for test purposes:
    ##Reducing to only those showing the current address - and reducing one year before:
    ## setkey(cpst , pnr , adrdatoCpst)
    ## View(cpst[is.na(adrdatoCpst)][1:10000])
    ## cpst[is.na(adrdatoCpst) , table(van_vtilCpst)]
    ## cpst[is.na(adrdatoCpst) , table(van_vfraCpst)]
    ##From the commands above, one sees that van_vfra and van_vtil is not recorded in a way useful to this study in any records with missing adrdato. There are some van_vtil, but with the most recent dates being in 1978 - this is not relevant for censoring or entering in this study. Thus, lines with adrdato are removed and the dataset is reduced to dates relevant to the current year-1 (status at the first date of the year, as this variable will be derived from a yearly register, and to avoid contidioning on the future):
    ## cpst <- cpst[!is.na(adrdatoCpst)]
    ## cpst1996 <- cpst[adrdatoCpst <= as.Date("1996-12-31")]
    ##Results visually inspected, as expected
    ##Creating an index of the last line for each PNR, when ordered by pnr and adrdatoCpst:
    ## setkey(cpst1996 , pnr , adrdatoCpst)
    ## cpstTemp <- cpst1996[order(pnr , adrdatoCpst) , .I[.N] , by = pnr]
    ## ##Using the index to retrieve the latest date:
    ## cpst1996 <- cpst1996[cpstTemp$V1]
    ## ##Results compared visually to cpst1996 before changes - behaving as expected.
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , cpst1996 , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ## ##Also joining OPGIKOM and KOM for parents to facilitate counting no. of members in the family:
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , cpst1996[ , .(pnr , opgikom , kom , adrdatoCpst)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent"))
    ## rm(cpstTemp , cpst1996)
    ##Dates of immigration has not been utilized in this data draw - this will likely have to be done based on van_vtil and van_vfra, a new set can be constructed using these variables instead of adrdato.

    ##Setting names because of downstream code:
    setnames(fullPopulationChildrenCurrentYear , c("opgikom" , "kom" , "BOP_VFRABef") , c("opgikomChild" , "komChild" , "BOP_VFRABefChild"))

    ##Merging SOGN onto BEF-data
    if (k <=2002) {
	fullPopulationChildrenCurrentYear[sogn2002 ,
					  on = c("opgikomChild" , "komChild") ,
					  SOGN := i.SOGN]
    } else { eval(parse(text = paste0("fullPopulationChildrenCurrentYear[sogn" , k , " , on = c('opgikomChild' , 'komChild') , SOGN := i.SOGN]")))
	for (i in rev(2002:k)[-1]) { ##The strange i-expression is all years up to the current, minus the current year - the idea is to go through all years, with priority to the most adjacent, and add matches as they are found.
	    eval(parse(text = paste0("fullPopulationChildrenCurrentYear[sogn" , i , " , on = c('opgikomChild' , 'komChild') , SOGNTemp := i.SOGN]")))
	    fullPopulationChildrenCurrentYear[is.na(SOGN) , SOGN := SOGNTemp]     
	}
    }
    fullPopulationChildrenCurrentYear[ , SOGNTemp := NULL]
    ##Evaluated, gives an increased number of matches
    ##As mentioned in the article, the address data gives a large number of missings, with no obvious reason for all the missing values. Because of this, I am minimizing the use of address data (in the final study they are only used for the neighborhood variable, trying to locate all participants to a parish). Therefore, outcommenting parts of the code below:  
    ##Merging SOGN onto ADRESSE_ID:
    ##Will outcomment this as we will be using opgikom and kom instead:
    ##Loading befadr:
    ## befadr <- fread("befadr_pop_070621.csv" , nrows = nrows , colClasses = c("opgikom" = "character" , "ADRESSE_ID" = "character" , "kom" = "character"))
    ## befadr[ , ADR_VFRA := floor_date(as.Date(ADR_VFRA , format = "%m/%d/%Y") , unit = "month")]
    ## befadr[ , ADR_RFRA := floor_date(as.Date(ADR_RFRA , format = "%m/%d/%Y") , unit = "month")]
    ## befadr[ , ADR_VTIL := floor_date(as.Date(ADR_VTIL , format = "%m/%d/%Y") , unit = "month")]
    ## ##This merge will only give non-NA values after 2007, as ADR_RFRA and ADR_VFRA mostly specify this date:
    ## ##if (i > 2007) {
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear ,
    ## 	      befadr[ADR_VFRA <= lastDate &
    ## 		     ADR_RFRA <= lastDate &
    ## 		     ADR_VTIL >= firstDate ,
    ## 		     .(opgikom , kom , ADRESSE_ID)] ,
    ## 	      by.x = "ADRESSE_IDChild" ,
    ## 	      by.y = "ADRESSE_ID" ,
    ## 	      all.x = TRUE)
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear ,
    ## 	      befadr[ADR_VFRA <= lastDate &
    ## 		     ADR_RFRA <= lastDate &
    ## 		     ADR_VTIL >= firstDate ,
    ## 		     .(opgikom , kom , ADRESSE_ID)] ,
    ## 	      by.x = "ADRESSE_IDParent" ,
    ## 	      by.y = "ADRESSE_ID" ,
    ## 	      all.x = TRUE , suffixes = c("BefadrChild" , "BefadrParent"))
    ## ##Merging sogn onto bef-data (only after 2007):
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , sogn2008 , by.x = c("opgikomBefadrChild" , "komBefadrChild") , by.y = c("OPGIKOM" , "KOM") , all.x = TRUE)
    ## fullPopulationChildrenCurrentYear[!is.na(SOGN.x) & SOGN.x != "", SOGN := SOGN.x]
    ## fullPopulationChildrenCurrentYear[!is.na(SOGN.y) & SOGN.y != "", SOGN := SOGN.y]
    ## fullPopulationChildrenCurrentYear[ , c("SOGN.x" , "SOGN.y") := NULL]
    ## fullPopulationChildrenCurrentYear[BOP_VFRABefChild > lastDate , SOGN := NA]
    ##}
    ##Introducing grouped SOGN after Carsten Bcker Pedersen:
    parishGroups <- fread("parishGroups.csv" ,
			  colClasses = c("Parish" = "character" ,
					 "ParishGrp" = "character"))
    setnames(parishGroups , "Parish" , "SOGN")
    fullPopulationChildrenCurrentYear[parishGroups , on = "SOGN" , ParishGrp := i.ParishGrp]
    fullPopulationChildrenCurrentYear[!is.na(ParishGrp) , sognGrouped := ParishGrp]
    fullPopulationChildrenCurrentYear[is.na(ParishGrp) , sognGrouped := SOGN]
    ##Computing dataset for parish levels of income:
    parishIncomeCurrentYear <- fullPopulationChildrenCurrentYear[!is.na(sognGrouped) , .(pnr , sognGrouped , meanIncome)]
    parishIncomeCurrentYear <- unique(parishIncomeCurrentYear)
    ##Converting to Euros:
    parishIncomeCurrentYear[ , meanIncomeEuros := meanIncome/7.46038] ##Number from the Central Bank of Denmark - please note Euros were not used until 2002.
    ##Checking that every pnr is only used once in each sogn:
    ## parishIncomeCurrentYear[ , test := duplicated(pnr) , by = SOGN] 
    ## parishIncomeCurrentYear[ , table(test)]
    ##Returns no duplicates. A child can thus contribute in several parishes during a year if this child moves between these parishes. A parish-derived variable is derived from the three-year rolling mean of its inhabitants during the year in this dataset, no matter how long they have lived there.  
    parishIncomeCurrentYear[ , lowerQuantile :=
				   quantile(meanIncomeEuros ,
					    probs = 0.25  ,
					    na.rm = TRUE) ,
			    by = sognGrouped]
    parishIncomeCurrentYear[ , upperQuantile :=
			       quantile(meanIncomeEuros ,
					probs = 0.75  ,
					na.rm = TRUE) ,
			     by = sognGrouped]
    parishIncomeCurrentYear[ , parishQuantileDifference100Euros :=
			       (upperQuantile - lowerQuantile)/100 ,
			     by = sognGrouped]
    ##Visually inspected, provides upper and lower quartiles, and parish differences, as expected. 
    ##Reducing the dataset for subsequent merging:
    parishIncomeCurrentYear[ ,
			     c("pnr" , "meanIncome" ,
			       "meanIncomeEuros" , "lowerQuantile" ,
			       "upperQuantile") := NULL]
    parishIncomeCurrentYear <- unique(parishIncomeCurrentYear)
    ##Using this dataset for merging back to the main dataset:
    fullPopulationChildrenCurrentYear[parishIncomeCurrentYear , on = "sognGrouped" , parishQuantileDifference100Euros := i.parishQuantileDifference100Euros]
    ##Computing income subtracted with the limit for risk of poverty, defined from rolling mean of median income in Denmark and subsequently converted to Euros:
    ##Importing numbers on median income in Denmark, adjusting for purchasing power (taken from Statistics Denmark, table PRIS8) and converting them to a rolling mean: 
    medianIncomeDenmark <- fread("equivalentIncome.csv")
    medianIncomeDenmark <- merge(medianIncomeDenmark , purchasingPower , by.x = "Year" , by.y = "Year" , all.x = TRUE)
    medianIncomeDenmark[ , equivalentIncomeAdjusted := (EquivalentIncome * 7045)/Value]
    medianIncomeDenmark[ , rollingMeanIncomeDenmark := frollmean(equivalentIncomeAdjusted , 3)]
    ##Checked by manual calculation, computes as expected from the two prior and one current year
    ##Multiplied with 0.6 and converted to euros:
    medianIncomeDenmark[ , rollingMeanSixtyPercent := (rollingMeanIncomeDenmark * 0.6)]
    medianIncomeDenmark[ , rollingMeanSixtyPercentEuros := rollingMeanSixtyPercent / 7.46038]
    ##Using 1996 to avoid conditioning on the future:
    fullPopulationChildrenCurrentYear[ ,
				       rollingMeanSixtyPercentEuros :=
					 ..medianIncomeDenmark[Year == (k - 1) ,
							       rollingMeanSixtyPercentEuros]]
    ##Calculating mean income Euros:
    fullPopulationChildrenCurrentYear[ , meanIncomeEuros := meanIncome / 7.46038]
    ##Calculating mean income from rolling mean subtracted by the rolling national mean and reported in hundreds of euros: 
    fullPopulationChildrenCurrentYear[ , incomeVariable :=
					 (meanIncomeEuros -
					    rollingMeanSixtyPercentEuros) / 100]
    ##To do as stated in the pre-registration the difference between upper and lower quartile in parishes should be subtracted with the yearly rate for relative poverty:
    fullPopulationChildrenCurrentYear[ , parishQuantileDifference100EurosMinusRollingMean := parishQuantileDifference100Euros - (rollingMeanSixtyPercentEuros / 100)]
    fullPopulationChildrenCurrentYear[ , c("meanIncomeEuros" , "rollingMeanSixtyPercentEuros") := NULL]

    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[!is.na(pnr)]
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[pnr != ""]
    ##For monitoring:
    print("Just finished adding and calculating economic variables")
    print(Sys.time())
    ##Programming remaining variables - they will be programmed for individual parents and summed in a separate dataset through a number of joins. This dataset should look something like:
    ##pnr , currentMother , currentFather , latestChangeParent(from parenthoodStart) (add on original parent, adoption variable and foster care for each line) and with an entry for each change in status (perhaps use duplicated on the status variable, such as duplicated(charlson) , by = parentID and do a merge on the derived dataset). Make this with a line for each variable update and maybe shrink afterwards. 

    ##Exporting a list of the parents and adding their birth dates for running analyses on their childhood as available - this code is copy-paste from sections of the yearly dataset generated and will only need to be run once:
    ## fullPopulationChildrenTemp <- fullPopulationChildren
    ## fullPopulationChildrenTemp[MOR2 == "" , MOR_VFRA1 := MOR_VFRA]
    ## fullPopulationChildrenTemp[FAR2 == "" , FAR_VFRA1 := FAR_VFRA]
    ## fullPopulationChildrenTemp[MOR2 != "" & !is.na(MOR2) , MOR_VFRA2 := MOR_VFRA]
    ## fullPopulationChildrenTemp[MOR2 != "" & !is.na(MOR2) , MOR_VFRA1 := birthDate]
    ## fullPopulationChildrenTemp[FAR2 != "" & !is.na(FAR2) , FAR_VFRA2 := FAR_VFRA]
    ## fullPopulationChildrenTemp[FAR2 != "" & !is.na(FAR2) , FAR_VFRA1 := birthDate]
    ## foraeldreID <- c("FAR1" , "FAR2" , "MOR1" , "MOR2")
    ## foraeldreFra <- c("FAR_VFRA1" , "FAR_VFRA2" , "MOR_VFRA1" , "MOR_VFRA2")
    ## fullPopulationChildrenParents <- melt(fullPopulationChildrenTemp , measure = list(foraeldreID , foraeldreFra) , value.name = c("parentID" , "parenthoodStart"))
    ## rm(foraeldreID , foraeldreFra)
    ## rm(fullPopulationChildrenTemp)
    ## fullPopulationChildrenParents <- fullPopulationChildrenParents[!is.na(parentID)]
    ## fullPopulationChildrenParents <- fullPopulationChildrenParents[parentID != ""]
    ## fullPopulationChildrenParents[variable == 1 , parentRole := "FAR1"]
    ## fullPopulationChildrenParents[variable == 2 , parentRole := "FAR2"]
    ## fullPopulationChildrenParents[variable == 3 , parentRole := "MOR1"]
    ## fullPopulationChildrenParents[variable == 4 , parentRole := "MOR2"]
    ## fullPopulationChildrenParents[ , c("MOR_VFRA" , "FAR_VFRA" , "variable") := NULL]
    ## fullPopulationChildrenParents <- merge(fullPopulationChildrenParents , ftBarn[ , .(pnr , FOED_DAG)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
    ## setnames(fullPopulationChildrenParents , old = "FOED_DAG" , new = "birthDateParentFtBarn" , skip_absent = TRUE)
    ## befFoeds <- bef[ , .(pnr , FOED_DAG)]
    ## befFoeds <- unique(befFoeds)
    ## fullPopulationChildrenParents <- merge(fullPopulationChildrenParents , befFoeds , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
    ## setnames(fullPopulationChildrenParents , old = "FOED_DAG" , new = "birthDateParentBef")
    ## rm(befFoeds)
    ## ##Importing mfr for parental birthdate - this dataset has already been loaded, only using relevant variables:
    ## fullPopulationChildrenParents <- merge(fullPopulationChildrenParents , mfr[ , .(pnr , foedselsdato)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
    ## ##Prioritize data from bef over ftBarn over MFR and generate birthDateParent: 
    ## fullPopulationChildrenParents[!is.na(birthDateParentBef) , birthDateParent := birthDateParentBef]
    ## fullPopulationChildrenParents[!is.na(birthDateParentFtBarn) & is.na(birthDateParent) , birthDateParent := birthDateParentFtBarn]
    ## fullPopulationChildrenParents[!is.na(foedselsdato) & is.na(birthDateParent) , birthDateParent := foedselsdato]
    ## fullPopulationChildrenParents[ , c("birthDateParentFtBarn" , "birthDateParentBef" , "foedselsdato") := NULL]
    ## fullPopulationChildrenParents[ , c("pnr" , "birthDate") := NULL]
    ## fullPopulationChildrenParents <- unique(fullPopulationChildrenParents)
    ## fwrite(fullPopulationChildrenParents , "fullPopulationChildrenParents.csv")
    ## rm(fullPopulationChildrenParents)

    ##Abuse of parent as a child:
    ##Merging from dataset created in parental childhood adversity codeblock:
    ##Commenting this out as it is re-done in the analysis-dataset:
    ## parentalAdversity <- fread("parentalAdversity.csv" , colClasses = c("parentID" = "character" , "abuseParent" = "integer"))
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , parentalAdversity ,
    ## 				    by.x = "parentID" ,
    ## 				    by.y = "parentID" ,
    ## 				    all.x = TRUE)
    ## fullPopulationChildrenCurrentYear[is.na(abuseParent) , abuseParent := 0]
    ##Visually inspected, merged to parents marked for adversity

    ##Immgration
    danishOrigin <- c(1:4998 , 7001:9599 , 5100:5101)
    unknownOrigin <- c(0 , 4999 , 5001)
    fullPopulationChildrenCurrentYear[!(FOEDREG_KODE %in% danishOrigin) & !is.na(FOEDREG_KODE) , foreignParent := 1]
    fullPopulationChildrenCurrentYear[!(OPR_LAND %in% danishOrigin) & !is.na(OPR_LAND) , foreignParent := 1]
    fullPopulationChildrenCurrentYear[is.na(foreignParent) , foreignParent := 0]
    fullPopulationChildrenCurrentYear[FOEDREG_KODE %in% unknownOrigin , foreignParent := NA]    
    fullPopulationChildrenCurrentYear[OPR_LAND %in% unknownOrigin , foreignParent := NA]
    fullPopulationChildrenCurrentYear[is.na(FOEDREG_KODE) & is.na(OPR_LAND) , foreignParent := NA]
    ##Visually inspected; all parents with codes outside of the danishOrigin range 

    ##Status as refugee
    ##A number of codes are needed - defined above under separate headline
    fullPopulationChildrenCurrentYear[KATEGORIParent %in% kategoriRefugee , needProtection := 1]
    fullPopulationChildrenCurrentYear[GRUNDLAGParent %in% grundlagRefugee , needProtection := 1]
    fullPopulationChildrenCurrentYear[FORKLARParent %in% forklarRefugee , needProtection := 1]
    fullPopulationChildrenCurrentYear[is.na(needProtection) , needProtection := 0]
    ##Visually inspected, categorizing as expected.
    ##Appending health information from last year's run of chronic diseases and covariates with an end date that hasn't expired:
    if (exists("memoryLastYear")) {
      fullPopulationChildrenCurrentYear <-
	rbindlist(list(fullPopulationChildrenCurrentYear ,
		       memoryLastYear) ,
		  use.names = TRUE ,
		  fill = TRUE)
    }


    ##Preserving health info for parents with no new admissions but chronic conditions:
    ##Commenting out this codeblock - in theory, it solves the problem but the execution time is very long - more than 12 hours for the first step, broke the loop after this. 
    ## ##Making a list of categories of disease:
    ## categories <- grep('.*GroupDiag' ,
    ##     	       names(fullPopulationChildrenCurrentYear) ,
    ##     	       value = TRUE)
    ## ##Leaving out one special case that does not categorize disease:
    ## categories<- categories[-1]
    ## ##Adding LMDB-based categories:
    ## categoriesLmdb <- grep('.*GroupLmdb' , names(fullPopulationChildrenCurrentYear) , value = TRUE)
    ## ##conditionGroupLmdb is caught by grep - leaving it out:
    ## categoriesLmdb <- categoriesLmdb[-1]
    ## ##Adding them together:
    ## categories <- c(categories , categoriesLmdb , "alcoholAbuse" , "alcoholAbuseEndDate" , "substanceAbuse" , "substanceAbuseEndDate")
    ## categoriesEndDate <- grep('EndDate' , categories , value = TRUE)
    ## ##For control of how far the loop has come:
    ## print("just before autogenerated code, line 1912")
    ## ##Ranking all enddates to mark the latest - the many commands for this is autogenerated by the outcommented loop below:
    ## ## ##A temp for the loop below:
    ## ## min <- "min"
    ## ## for (i in paste0("fullPopulationChildrenCurrentYear[ , rank" ,
    ## ##                  categoriesEndDate ,
    ## ##                  " := frankv(", categoriesEndDate ,
    ## ##                  " , order = -1 , ties.method = min" ,
    ## ##                  " , na.last = TRUE) , by = parentID]")) {
    ## ##     print(i)
    ## ## }
    ## ##Autogenerated code (after a few seek-and-replace):
    ## fullPopulationChildrenCurrentYear[ , rankhypertensionGroupDiagEndDate := frankv(hypertensionGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdyslipidemiaGroupDiagEndDate := frankv(dyslipidemiaGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankischemicHeartDiseaseGroupDiagEndDate := frankv(ischemicHeartDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankatrialFibrillationGroupDiagEndDate := frankv(atrialFibrillationGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankheartFailureGroupDiagEndDate := frankv(heartFailureGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankperipheralArteryOcclusiveGroupDiagEndDate := frankv(peripheralArteryOcclusiveGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankstrokeGroupDiagEndDate := frankv(strokeGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdiabetesMellitusGroupDiagEndDate := frankv(diabetesMellitusGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankthyroidDisorderGroupDiagEndDate := frankv(thyroidDisorderGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankgoutGroupDiagEndDate := frankv(goutGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankchronicPulmonaryDiseaseGroupDiagEndDate := frankv(chronicPulmonaryDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankallergyGroupDiagEndDate := frankv(allergyGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankulcerChronicGastritisGroupDiagEndDate := frankv(ulcerChronicGastritisGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankchronicLiverDiseaseGroupDiagEndDate := frankv(chronicLiverDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankinflammatoryBowelDiseaseGroupDiagEndDate := frankv(inflammatoryBowelDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdiverticularDiseaseOfIntestineGroupDiagEndDate := frankv(diverticularDiseaseOfIntestineGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankchronicKidneyDiseaseGroupDiagEndDate := frankv(chronicKidneyDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankprostateDisordersGroupDiagEndDate := frankv(prostateDisordersGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankconnectiveTissueDisordersGroupDiagEndDate := frankv(connectiveTissueDisordersGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankosteoporosisGroupDiagEndDate := frankv(osteoporosisGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankanemiasGroupDiagEndDate := frankv(anemiasGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankcancerGroupDiagEndDate := frankv(cancerGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankvisionProblemGroupDiagEndDate := frankv(visionProblemGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankmigraineGroupDiagEndDate := frankv(migraineGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankepilepsyGroupDiagEndDate := frankv(epilepsyGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankparkinsonsDiseaseGroupDiagEndDate := frankv(parkinsonsDiseaseGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankmultipleSclerosisGroupDiagEndDate := frankv(multipleSclerosisGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankneuropathiesGroupDiagEndDate := frankv(neuropathiesGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankmoodStressrelatedOrAnxietyDisordersGroupDiagEndDate := frankv(moodStressrelatedOrAnxietyDisordersGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankanorexiaBulimiaGroupDiagEndDate := frankv(anorexiaBulimiaGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankbipolarAffectiveDisorderGroupDiagEndDate := frankv(bipolarAffectiveDisorderGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankschizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate := frankv(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankpersonalityDisorderGroupDiagEndDate := frankv(personalityDisorderGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdementiaGroupDiagEndDate := frankv(dementiaGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankotherGroupDiagEndDate := frankv(otherGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankpretermBirthGroupDiagEndDate := frankv(pretermBirthGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankacuteCaesarianSectionGroupDiagEndDate := frankv(acuteCaesarianSectionGroupDiagEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdyslipidemiaGroupLmdbEndDate := frankv(dyslipidemiaGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankischemicHeartDiseaseGroupLmdbEndDate := frankv(ischemicHeartDiseaseGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdiabetesMellitusGroupLmdbEndDate := frankv(diabetesMellitusGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankthyroidDisorderGroupLmdbEndDate := frankv(thyroidDisorderGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankchronicPulmonaryDiseaseGroupLmdbEndDate := frankv(chronicPulmonaryDiseaseGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankallergyGroupLmdbEndDate := frankv(allergyGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankosteoporosisGroupLmdbEndDate := frankv(osteoporosisGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankpainfulConditionGroupLmdbEndDate := frankv(painfulConditionGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankmigraineGroupLmdbEndDate := frankv(migraineGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankepilepsyGroupLmdbEndDate := frankv(epilepsyGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankbipolarAffectiveDisorderGroupLmdbEndDate := frankv(bipolarAffectiveDisorderGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankdementiaGroupLmdbEndDate := frankv(dementiaGroupLmdbEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , rankalcoholAbuseEndDate := frankv(alcoholAbuseEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## fullPopulationChildrenCurrentYear[ , ranksubstanceAbuseEndDate := frankv(substanceAbuseEndDate , order = -1 , ties.method = min , na.last = TRUE) , by = parentID]
    ## ##Making temporary objects for all categories and filling them with the latest enddate that is not NA and is greater than the latest date in the current period (and thus relevant for future years) - this is done through commands generated by the outcommented code below:
    ## ##For control purposes:
    ## print("just before object generation")
    ## ## for (i in paste0("tempObject" ,
    ## ##                  categoriesEndDate ,
    ## ##                  " <- fullPopulationChildrenCurrentYear[" ,
    ## ##                  "rank" , categoriesEndDate ,
    ## ##                  " == 1 & !is.na(" ,
    ## ##                  categoriesEndDate ,
    ## ##                  ") & " ,
    ## ##                  categoriesEndDate ,
    ## ##                  " > lastDate , .(" ,
    ## ##                  categoriesEndDate , " , " ,
    ## ##                  strsplit(categoriesEndDate , "EndDate") ,
    ## ##                  " , parentID , d_inddtoParent)]")) {
    ## ##     print(i)
    ## ## }
    ## ##Autogenerated code:
    ## tempObjecthypertensionGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankhypertensionGroupDiagEndDate == 1 & !is.na(hypertensionGroupDiagEndDate) & hypertensionGroupDiagEndDate > lastDate , .(hypertensionGroupDiagEndDate , hypertensionGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectdyslipidemiaGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankdyslipidemiaGroupDiagEndDate == 1 & !is.na(dyslipidemiaGroupDiagEndDate) & dyslipidemiaGroupDiagEndDate > lastDate , .(dyslipidemiaGroupDiagEndDate , dyslipidemiaGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectischemicHeartDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankischemicHeartDiseaseGroupDiagEndDate == 1 & !is.na(ischemicHeartDiseaseGroupDiagEndDate) & ischemicHeartDiseaseGroupDiagEndDate > lastDate , .(ischemicHeartDiseaseGroupDiagEndDate , ischemicHeartDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectatrialFibrillationGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankatrialFibrillationGroupDiagEndDate == 1 & !is.na(atrialFibrillationGroupDiagEndDate) & atrialFibrillationGroupDiagEndDate > lastDate , .(atrialFibrillationGroupDiagEndDate , atrialFibrillationGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectheartFailureGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankheartFailureGroupDiagEndDate == 1 & !is.na(heartFailureGroupDiagEndDate) & heartFailureGroupDiagEndDate > lastDate , .(heartFailureGroupDiagEndDate , heartFailureGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectperipheralArteryOcclusiveGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankperipheralArteryOcclusiveGroupDiagEndDate == 1 & !is.na(peripheralArteryOcclusiveGroupDiagEndDate) & peripheralArteryOcclusiveGroupDiagEndDate > lastDate , .(peripheralArteryOcclusiveGroupDiagEndDate , peripheralArteryOcclusiveGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectstrokeGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankstrokeGroupDiagEndDate == 1 & !is.na(strokeGroupDiagEndDate) & strokeGroupDiagEndDate > lastDate , .(strokeGroupDiagEndDate , strokeGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectdiabetesMellitusGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankdiabetesMellitusGroupDiagEndDate == 1 & !is.na(diabetesMellitusGroupDiagEndDate) & diabetesMellitusGroupDiagEndDate > lastDate , .(diabetesMellitusGroupDiagEndDate , diabetesMellitusGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectthyroidDisorderGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankthyroidDisorderGroupDiagEndDate == 1 & !is.na(thyroidDisorderGroupDiagEndDate) & thyroidDisorderGroupDiagEndDate > lastDate , .(thyroidDisorderGroupDiagEndDate , thyroidDisorderGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectgoutGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankgoutGroupDiagEndDate == 1 & !is.na(goutGroupDiagEndDate) & goutGroupDiagEndDate > lastDate , .(goutGroupDiagEndDate , goutGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectchronicPulmonaryDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankchronicPulmonaryDiseaseGroupDiagEndDate == 1 & !is.na(chronicPulmonaryDiseaseGroupDiagEndDate) & chronicPulmonaryDiseaseGroupDiagEndDate > lastDate , .(chronicPulmonaryDiseaseGroupDiagEndDate , chronicPulmonaryDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectallergyGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankallergyGroupDiagEndDate == 1 & !is.na(allergyGroupDiagEndDate) & allergyGroupDiagEndDate > lastDate , .(allergyGroupDiagEndDate , allergyGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectulcerChronicGastritisGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankulcerChronicGastritisGroupDiagEndDate == 1 & !is.na(ulcerChronicGastritisGroupDiagEndDate) & ulcerChronicGastritisGroupDiagEndDate > lastDate , .(ulcerChronicGastritisGroupDiagEndDate , ulcerChronicGastritisGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectchronicLiverDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankchronicLiverDiseaseGroupDiagEndDate == 1 & !is.na(chronicLiverDiseaseGroupDiagEndDate) & chronicLiverDiseaseGroupDiagEndDate > lastDate , .(chronicLiverDiseaseGroupDiagEndDate , chronicLiverDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectinflammatoryBowelDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankinflammatoryBowelDiseaseGroupDiagEndDate == 1 & !is.na(inflammatoryBowelDiseaseGroupDiagEndDate) & inflammatoryBowelDiseaseGroupDiagEndDate > lastDate , .(inflammatoryBowelDiseaseGroupDiagEndDate , inflammatoryBowelDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectdiverticularDiseaseOfIntestineGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankdiverticularDiseaseOfIntestineGroupDiagEndDate == 1 & !is.na(diverticularDiseaseOfIntestineGroupDiagEndDate) & diverticularDiseaseOfIntestineGroupDiagEndDate > lastDate , .(diverticularDiseaseOfIntestineGroupDiagEndDate , diverticularDiseaseOfIntestineGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectchronicKidneyDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankchronicKidneyDiseaseGroupDiagEndDate == 1 & !is.na(chronicKidneyDiseaseGroupDiagEndDate) & chronicKidneyDiseaseGroupDiagEndDate > lastDate , .(chronicKidneyDiseaseGroupDiagEndDate , chronicKidneyDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectprostateDisordersGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankprostateDisordersGroupDiagEndDate == 1 & !is.na(prostateDisordersGroupDiagEndDate) & prostateDisordersGroupDiagEndDate > lastDate , .(prostateDisordersGroupDiagEndDate , prostateDisordersGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectconnectiveTissueDisordersGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankconnectiveTissueDisordersGroupDiagEndDate == 1 & !is.na(connectiveTissueDisordersGroupDiagEndDate) & connectiveTissueDisordersGroupDiagEndDate > lastDate , .(connectiveTissueDisordersGroupDiagEndDate , connectiveTissueDisordersGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectosteoporosisGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankosteoporosisGroupDiagEndDate == 1 & !is.na(osteoporosisGroupDiagEndDate) & osteoporosisGroupDiagEndDate > lastDate , .(osteoporosisGroupDiagEndDate , osteoporosisGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectanemiasGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankanemiasGroupDiagEndDate == 1 & !is.na(anemiasGroupDiagEndDate) & anemiasGroupDiagEndDate > lastDate , .(anemiasGroupDiagEndDate , anemiasGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectcancerGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankcancerGroupDiagEndDate == 1 & !is.na(cancerGroupDiagEndDate) & cancerGroupDiagEndDate > lastDate , .(cancerGroupDiagEndDate , cancerGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectvisionProblemGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankvisionProblemGroupDiagEndDate == 1 & !is.na(visionProblemGroupDiagEndDate) & visionProblemGroupDiagEndDate > lastDate , .(visionProblemGroupDiagEndDate , visionProblemGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectmigraineGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankmigraineGroupDiagEndDate == 1 & !is.na(migraineGroupDiagEndDate) & migraineGroupDiagEndDate > lastDate , .(migraineGroupDiagEndDate , migraineGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectepilepsyGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankepilepsyGroupDiagEndDate == 1 & !is.na(epilepsyGroupDiagEndDate) & epilepsyGroupDiagEndDate > lastDate , .(epilepsyGroupDiagEndDate , epilepsyGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectparkinsonsDiseaseGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankparkinsonsDiseaseGroupDiagEndDate == 1 & !is.na(parkinsonsDiseaseGroupDiagEndDate) & parkinsonsDiseaseGroupDiagEndDate > lastDate , .(parkinsonsDiseaseGroupDiagEndDate , parkinsonsDiseaseGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectmultipleSclerosisGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankmultipleSclerosisGroupDiagEndDate == 1 & !is.na(multipleSclerosisGroupDiagEndDate) & multipleSclerosisGroupDiagEndDate > lastDate , .(multipleSclerosisGroupDiagEndDate , multipleSclerosisGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectneuropathiesGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankneuropathiesGroupDiagEndDate == 1 & !is.na(neuropathiesGroupDiagEndDate) & neuropathiesGroupDiagEndDate > lastDate , .(neuropathiesGroupDiagEndDate , neuropathiesGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectmoodStressrelatedOrAnxietyDisordersGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankmoodStressrelatedOrAnxietyDisordersGroupDiagEndDate == 1 & !is.na(moodStressrelatedOrAnxietyDisordersGroupDiagEndDate) & moodStressrelatedOrAnxietyDisordersGroupDiagEndDate > lastDate , .(moodStressrelatedOrAnxietyDisordersGroupDiagEndDate , moodStressrelatedOrAnxietyDisordersGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectanorexiaBulimiaGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankanorexiaBulimiaGroupDiagEndDate == 1 & !is.na(anorexiaBulimiaGroupDiagEndDate) & anorexiaBulimiaGroupDiagEndDate > lastDate , .(anorexiaBulimiaGroupDiagEndDate , anorexiaBulimiaGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectbipolarAffectiveDisorderGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankbipolarAffectiveDisorderGroupDiagEndDate == 1 & !is.na(bipolarAffectiveDisorderGroupDiagEndDate) & bipolarAffectiveDisorderGroupDiagEndDate > lastDate , .(bipolarAffectiveDisorderGroupDiagEndDate , bipolarAffectiveDisorderGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectschizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankschizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate == 1 & !is.na(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate) & schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate > lastDate , .(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate , schizophreniaOrSchizoaffectiveDisorderGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectpersonalityDisorderGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankpersonalityDisorderGroupDiagEndDate == 1 & !is.na(personalityDisorderGroupDiagEndDate) & personalityDisorderGroupDiagEndDate > lastDate , .(personalityDisorderGroupDiagEndDate , personalityDisorderGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectdementiaGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankdementiaGroupDiagEndDate == 1 & !is.na(dementiaGroupDiagEndDate) & dementiaGroupDiagEndDate > lastDate , .(dementiaGroupDiagEndDate , dementiaGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectotherGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankotherGroupDiagEndDate == 1 & !is.na(otherGroupDiagEndDate) & otherGroupDiagEndDate > lastDate , .(otherGroupDiagEndDate , otherGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectpretermBirthGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankpretermBirthGroupDiagEndDate == 1 & !is.na(pretermBirthGroupDiagEndDate) & pretermBirthGroupDiagEndDate > lastDate , .(pretermBirthGroupDiagEndDate , pretermBirthGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectacuteCaesarianSectionGroupDiagEndDate <- fullPopulationChildrenCurrentYear[rankacuteCaesarianSectionGroupDiagEndDate == 1 & !is.na(acuteCaesarianSectionGroupDiagEndDate) & acuteCaesarianSectionGroupDiagEndDate > lastDate , .(acuteCaesarianSectionGroupDiagEndDate , acuteCaesarianSectionGroupDiag , parentID , d_inddtoParent)]
    ## tempObjectdyslipidemiaGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankdyslipidemiaGroupLmdbEndDate == 1 & !is.na(dyslipidemiaGroupLmdbEndDate) & dyslipidemiaGroupLmdbEndDate > lastDate , .(dyslipidemiaGroupLmdbEndDate , dyslipidemiaGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectischemicHeartDiseaseGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankischemicHeartDiseaseGroupLmdbEndDate == 1 & !is.na(ischemicHeartDiseaseGroupLmdbEndDate) & ischemicHeartDiseaseGroupLmdbEndDate > lastDate , .(ischemicHeartDiseaseGroupLmdbEndDate , ischemicHeartDiseaseGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectdiabetesMellitusGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankdiabetesMellitusGroupLmdbEndDate == 1 & !is.na(diabetesMellitusGroupLmdbEndDate) & diabetesMellitusGroupLmdbEndDate > lastDate , .(diabetesMellitusGroupLmdbEndDate , diabetesMellitusGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectthyroidDisorderGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankthyroidDisorderGroupLmdbEndDate == 1 & !is.na(thyroidDisorderGroupLmdbEndDate) & thyroidDisorderGroupLmdbEndDate > lastDate , .(thyroidDisorderGroupLmdbEndDate , thyroidDisorderGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectchronicPulmonaryDiseaseGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankchronicPulmonaryDiseaseGroupLmdbEndDate == 1 & !is.na(chronicPulmonaryDiseaseGroupLmdbEndDate) & chronicPulmonaryDiseaseGroupLmdbEndDate > lastDate , .(chronicPulmonaryDiseaseGroupLmdbEndDate , chronicPulmonaryDiseaseGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectallergyGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankallergyGroupLmdbEndDate == 1 & !is.na(allergyGroupLmdbEndDate) & allergyGroupLmdbEndDate > lastDate , .(allergyGroupLmdbEndDate , allergyGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectosteoporosisGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankosteoporosisGroupLmdbEndDate == 1 & !is.na(osteoporosisGroupLmdbEndDate) & osteoporosisGroupLmdbEndDate > lastDate , .(osteoporosisGroupLmdbEndDate , osteoporosisGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectpainfulConditionGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankpainfulConditionGroupLmdbEndDate == 1 & !is.na(painfulConditionGroupLmdbEndDate) & painfulConditionGroupLmdbEndDate > lastDate , .(painfulConditionGroupLmdbEndDate , painfulConditionGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectmigraineGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankmigraineGroupLmdbEndDate == 1 & !is.na(migraineGroupLmdbEndDate) & migraineGroupLmdbEndDate > lastDate , .(migraineGroupLmdbEndDate , migraineGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectepilepsyGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankepilepsyGroupLmdbEndDate == 1 & !is.na(epilepsyGroupLmdbEndDate) & epilepsyGroupLmdbEndDate > lastDate , .(epilepsyGroupLmdbEndDate , epilepsyGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectbipolarAffectiveDisorderGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankbipolarAffectiveDisorderGroupLmdbEndDate == 1 & !is.na(bipolarAffectiveDisorderGroupLmdbEndDate) & bipolarAffectiveDisorderGroupLmdbEndDate > lastDate , .(bipolarAffectiveDisorderGroupLmdbEndDate , bipolarAffectiveDisorderGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectdementiaGroupLmdbEndDate <- fullPopulationChildrenCurrentYear[rankdementiaGroupLmdbEndDate == 1 & !is.na(dementiaGroupLmdbEndDate) & dementiaGroupLmdbEndDate > lastDate , .(dementiaGroupLmdbEndDate , dementiaGroupLmdb , parentID , d_inddtoParent)]
    ## tempObjectalcoholAbuseEndDate <- fullPopulationChildrenCurrentYear[rankalcoholAbuseEndDate == 1 & !is.na(alcoholAbuseEndDate) & alcoholAbuseEndDate > lastDate , .(alcoholAbuseEndDate , alcoholAbuse , parentID , d_inddtoParent)]
    ## tempObjectsubstanceAbuseEndDate <- fullPopulationChildrenCurrentYear[ranksubstanceAbuseEndDate == 1 & !is.na(substanceAbuseEndDate) & substanceAbuseEndDate > lastDate , .(substanceAbuseEndDate , substanceAbuse , parentID , d_inddtoParent)]
    ## ##Cleaning up the rankings that has now been used:
    ## rankCleanup <- grep('rank' , names(fullPopulationChildrenCurrentYear) , value = TRUE)
    ## fullPopulationChildrenCurrentYear[ , c(rankCleanup) := NULL]
    ## ##Tying together the objects and parentHealthInfo:
    ## ##For monitoring:
    ## print("just before tying objects together")
    ## ##The following code is autogenerated from the outcommented loop below:
    ## ## loopList <- paste0('tempObject' , categoriesEndDate)
    ## ## for (i in paste0("parentHealthInfo <- rbindlist(list(parentHealthInfo , " ,
    ## ##                  loopList ,
    ## ##                  ") , use.names = TRUE , fill = TRUE)")) {
    ## ##     print(i)
    ## ## }
    ## ##Autogenerated code:
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjecthypertensionGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdyslipidemiaGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectischemicHeartDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectatrialFibrillationGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectheartFailureGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectperipheralArteryOcclusiveGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectstrokeGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdiabetesMellitusGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectthyroidDisorderGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectgoutGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectchronicPulmonaryDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectallergyGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectulcerChronicGastritisGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectchronicLiverDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectinflammatoryBowelDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdiverticularDiseaseOfIntestineGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectchronicKidneyDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectprostateDisordersGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectconnectiveTissueDisordersGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectosteoporosisGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectanemiasGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectcancerGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectvisionProblemGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectmigraineGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectepilepsyGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectparkinsonsDiseaseGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectmultipleSclerosisGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectneuropathiesGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectmoodStressrelatedOrAnxietyDisordersGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectanorexiaBulimiaGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectbipolarAffectiveDisorderGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectschizophreniaOrSchizoaffectiveDisorderGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectpersonalityDisorderGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdementiaGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectotherGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectpretermBirthGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectacuteCaesarianSectionGroupDiagEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdyslipidemiaGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectischemicHeartDiseaseGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdiabetesMellitusGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectthyroidDisorderGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectchronicPulmonaryDiseaseGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectallergyGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectosteoporosisGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectpainfulConditionGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectmigraineGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectepilepsyGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectbipolarAffectiveDisorderGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectdementiaGroupLmdbEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectalcoholAbuseEndDate) , use.names = TRUE , fill = TRUE)
    ## parentHealthInfo <- rbindlist(list(parentHealthInfo , tempObjectsubstanceAbuseEndDate) , use.names = TRUE , fill = TRUE)
    ## ##After loops, tying the information onto the main object:
    ## fullPopulationChildrenCurrentYear <- rbindlist(list(fullPopulationChildrenCurrentYear , parentHealthInfo) , use.names = TRUE , fill = TRUE)
    ## fullPopulationChildrenCurrentYear <- unique(fullPopulationChildrenCurrentYear)
    ## ##For monitoring:
    ## print("just after adding diagnoses to remember")

    ##After a number of problems with the number of parents and children at each address, including a few strange registrations with several hundred individuals, and a very large number of missings without any explanation, these variables were simply dropped. Thus, only code below that will be used somewhere downstream, were kept. 
    ##Number of children and adults living in family: count no. of children and adults living on address using kom and bopikom: BE AWARE THAT ADULTS NOT REGISTERED AS EITHER PARENTS OR PERPETRATORS OR CHILDREN THEMSELVES ARE NOT IN THE DATASET - this might underestimate the number of adults living with the child. This variable will mainly be useful to see differences between single and non-single parents. Parents less than 18 years old will be counted as adults. 
    ##Looking at the data below, some children have two addresses at the same time. If one looks at the original data, the parents have the same - it thus seems safe to focus on only one address for each child, as this address would capture both parents. 
    ##For monitoring:
    print("Just before counting children and adults")
    print(Sys.time())
    ##Children
    numberOfAdultsTemp <-
      fullPopulationChildrenCurrentYear[!is.na(pnr) ,
					.(pnr , komChild ,
					  opgikomChild , BOP_VFRABefChild ,
					  studyEntry , ageCensoring ,
					  deathCensoring , emigrationCensoring)]
    numberOfAdultsTemp <- unique(numberOfAdultsTemp)
    setnames(numberOfAdultsTemp ,
	     old = c("komChild" , "opgikomChild" ,
		     "BOP_VFRABefChild") ,
	     new = c("kom" , "opgikom" ,
		     "adrdato"))
    ##Mark children with more than one address and delete one of them (this is feasible as the data for the adults were looked up as well, and for a large number of cases, the same individuals are registered for both addresses:
    numberOfAdultsTemp[ , temp := duplicated(pnr) , by = adrdato]
    numberOfAdultsTemp <- numberOfAdultsTemp[temp == FALSE]
    numberOfAdultsTemp[ , temp := NULL]
    ##A few children has a new address starting at 1997-01-01 - as I will soon set all addresses older than this date to 1997-01-01, some children will have two addresses at this day. I will delete the old addresses - first marking those with this special case:
    numberOfAdultsTemp[adrdato == firstDate , temp := 1]
    ##Set all adrdato older than 1997-01-01 to this date:
    numberOfAdultsTemp[adrdato < firstDate , adrdato := firstDate]
    ##To get the newest addresses: delete observations of two addresses with adrdato 1997-01-01 not marked with temp == 1:
    setorder(numberOfAdultsTemp , pnr , adrdato , temp , na.last = TRUE)
    numberOfAdultsTemp <- unique(numberOfAdultsTemp , by = c("pnr" , "adrdato"))
    numberOfAdultsTemp[ , temp := NULL]

    ##Preparing a dcast to get end dates for the addresses:
    ##Numbering all addresses within a PNR:
    setkey(numberOfAdultsTemp , pnr , adrdato)
    numberOfAdultsTemp[ , adrNo := seq_len(.N) , by = pnr]
    if (max(numberOfAdultsTemp$adrNo) > 1) {
	##dcasting the date from subsequent addresses onto the same line as the first address:
	temp <- dcast(numberOfAdultsTemp , pnr ~ adrNo , value.var = "adrdato")
	setnames(temp , c("1" , "2" , "3" , "4" ,
			  "5" , "6" , "7" , "8" ,
			  "9" , "10" , "11" , "12" ,
			  "13" , "14" , "15" , "16" ,
			  "17" , "18" , "19" , "20" ,
			  "21" , "22" , "23" , "24" ,
			  "25" , "26" , "27" , "28" ,
			  "29" , "30") ,
		 c("one" , "two" , "three" , "four" ,
		   "five" , "six" , "seven" , "eight" ,
		   "nine" , "ten" , "eleven" , "twelve" ,
		   "thirteen" , "fourteen" , "fifteen" ,
		   "sixteen" , "seventeen" , "eighteen" ,
		   "nineteen" , "twenty" , "twentyone" ,
		   "twentytwo" , "twentythree" ,
		   "twentyfour" , "twentyfive" ,
		   "twentysix" , "twentyseven" ,
		   "twentyeight" , "twentynine" ,
		   "thirty") , skip_absent = TRUE)
	##Merging them back onto the original dataset; as there could be a number of address changes, this has to be done in a loop:
	numbers <- c("one" , "two" , "three" , "four" ,
		     "five" , "six" , "seven" , "eight" ,
		     "nine" , "ten" , "eleven" , "twelve" ,
		     "thirteen" , "fourteen" , "fifteen" ,
		     "sixteen" , "seventeen" , "eighteen" ,
		     "nineteen" , "twenty" , "twentyone" ,
		     "twentytwo" , "twentythree" ,
		     "twentyfour" , "twentyfive" ,
		     "twentysix" , "twentyseven" ,
		     "twentyeight" , "twentynine" ,
		     "thirty")
	for (i in 1:(length(names(temp)) - 2)) {
	    numberOfAdultsTemp <- merge(numberOfAdultsTemp ,
					temp[ , .(pnr , get(numbers[i]) ,
						  get(numbers[i + 1]))] ,
					by.x = c("pnr" , "adrdato") ,
					by.y = c("pnr" , "V2") ,
					all.x = TRUE)
	    numberOfAdultsTemp[ , (numbers[i + 1]) := V3]
	    numberOfAdultsTemp[ , V3 := NULL]
	    numberOfAdultsTemp[adrNo != i , (numbers[i + 1]) := NA]
	}
	##Visually inspected, performs as expected.
	##Joining the dates into one variable
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp[!is.na(get(numbers[i])) , adrdatoEnd := get(numbers[i])]
	}
	##Visually inspected, performing as expected.
	##Removing the columns with numbers:
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp[ , (numbers[i]) := NULL]
	}
	##For any parent with two addresses at the same time, one address may look like it "takes over" from the other on the same date they were both registered. I adjust for this by deleting any adrdatoEnd that occurs at the same date as adrdato:
	numberOfAdultsTemp[adrdato == adrdatoEnd , adrdatoEnd := NA]
    } else {
	numberOfAdultsTemp[ , adrdatoEnd := structure(numeric(0) , class = "Date")]
    }
    ##Setting adrdatoEnd to the last date of the year for all who does not change their address:
    numberOfAdultsTemp[is.na(adrdatoEnd) , adrdatoEnd := lastDate]
    ##Reducing the dates to those within the study (taking age and censoring into account):
    numberOfAdultsTemp[studyEntry > adrdato , adrdato := studyEntry]
    numberOfAdultsTemp[ageCensoring < adrdatoEnd & !is.na(ageCensoring), adrdatoEnd := ageCensoring]
    numberOfAdultsTemp[deathCensoring < adrdatoEnd & !is.na(deathCensoring) , adrdatoEnd := deathCensoring]
    numberOfAdultsTemp[emigrationCensoring < adrdatoEnd & !is.na(emigrationCensoring) , adrdatoEnd := emigrationCensoring]
    ##Now some observations should have a negative number of dates where they are living somewhere - this is because someone is censored before they live at an address, or enter the study after they moved. I throw these out:

    numberOfAdultsTemp <- numberOfAdultsTemp[adrdato <= adrdatoEnd]
    ##There might be a few observations where someone lives on an address for exactly one day, and if this is the case at this point in the data, that is accurate, but cannot be handled by the expansion below. I save and delete these observations:
    temp <- numberOfAdultsTemp[adrdato == adrdatoEnd]
    numberOfAdultsTemp <- numberOfAdultsTemp[adrdato != adrdatoEnd]
    ##Expanding all observations to one for each day of the year:
    numberOfAdultsTemp <- numberOfAdultsTemp[ , list(pnr = pnr , kom = kom , opgikom = opgikom , day = seq(adrdato , adrdatoEnd , by = "month")) , by = 1:nrow(numberOfAdultsTemp)]
    numberOfAdultsTemp[ , nrow := NULL]
    numberOfAdultsTemp[ , adrNo := NULL]
    setnames(numberOfAdultsTemp , "day" , "adrdato")
    temp[ , c("studyEntry" , "ageCensoring" , "deathCensoring" , "emigrationCensoring" , "adrdatoEnd" , "adrNo"):= NULL]
    setcolorder(temp , c("pnr" , "kom" , "opgikom" , "adrdato")) 
    numberOfAdultsTemp <- rbindlist(list(numberOfAdultsTemp , temp))

    ##It turns out merging parental addresses to fullPopulationChildrenCurrentYear is simply too resource intensive. Thus, komParent and opgikomParent will be added here:
    numberOfAdultsTemp2 <- fullPopulationChildrenCurrentYear[!is.na(pnr) , .(parentID , deathCensoringParent)]
      ##I will not look at who is the registered parent, but where the child lives, so parenthoodStart and parenthoodEnd is not used here.
    numberOfAdultsTemp2 <- unique(numberOfAdultsTemp2)
    numberOfAdultsTemp2 <- merge(numberOfAdultsTemp2 , befAdrCurrentYear , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE)
    setnames(numberOfAdultsTemp2 , old = c("parentID" , "BOP_VFRABef") , new = c("pnr" , "adrdato"))
    ##Preparing a dcast to get end dates for the addresses:
    ##Numbering all addresses within a PNR:
    setkey(numberOfAdultsTemp2 , pnr , adrdato)
    numberOfAdultsTemp2[ , adrNo := seq_len(.N) , by = pnr]
    if (max(numberOfAdultsTemp2$adrNo) > 1) {
	##dcasting the date from subsequent addresses onto the same line as the first address:
	temp <- dcast(numberOfAdultsTemp2 , pnr ~ adrNo , value.var = "adrdato")
	setnames(temp , c("1" , "2" , "3" , "4" ,
			  "5" , "6" , "7" , "8" ,
			  "9" , "10" , "11" , "12" ,
			  "13" , "14" , "15" , "16" ,
			  "17" , "18" , "19" , "20" ,
			  "21" , "22" , "23" , "24" ,
			  "25" , "26" , "27" , "28" ,
			  "29" , "30") ,
		 c("one" , "two" , "three" , "four" ,
		   "five" , "six" , "seven" , "eight" ,
		   "nine" , "ten" , "eleven" , "twelve" ,
		   "thirteen" , "fourteen" , "fifteen" ,
		   "sixteen" , "seventeen" , "eighteen" ,
		   "nineteen" , "twenty" , "twentyone" ,
		   "twentytwo" , "twentythree" ,
		   "twentyfour" , "twentyfive" ,
		   "twentysix" , "twentyseven" ,
		   "twentyeight" , "twentynine" ,
		   "thirty") , skip_absent = TRUE)
	##Merging them back onto the original dataset; as there could be a number of address changes, this has to be done in a loop:
	numbers <- c("one" , "two" , "three" , "four" ,
		     "five" , "six" , "seven" , "eight" ,
		     "nine" , "ten" , "eleven" , "twelve" ,
		     "thirteen" , "fourteen" , "fifteen" ,
		     "sixteen" , "seventeen" , "eighteen" ,
		     "nineteen" , "twenty" , "twentyone" ,
		     "twentytwo" , "twentythree" ,
		     "twentyfour" , "twentyfive" ,
		     "twentysix" , "twentyseven" ,
		     "twentyeight" , "twentynine" ,
		     "thirty")
	for (i in 1:(length(names(temp)) - 2)) {
	    numberOfAdultsTemp2 <- merge(numberOfAdultsTemp2 ,
					 temp[ , .(pnr , get(numbers[i]) ,
						   get(numbers[i + 1]))] ,
					 by.x = c("pnr" , "adrdato") ,
					 by.y = c("pnr" , "V2") ,
					 all.x = TRUE)
	    numberOfAdultsTemp2[ , (numbers[i + 1]) := V3]
	    numberOfAdultsTemp2[ , V3 := NULL]
	    numberOfAdultsTemp2[adrNo != i , (numbers[i + 1]) := NA]
	}
	##Visually inspected, performs as expected.
	##Joining the dates into one variable
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp2[!is.na(get(numbers[i])) , adrdatoEnd := get(numbers[i])]
	}
	##Visually inspected, performing as expected.
	##Removing the columns with numbers:
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp2[ , (numbers[i]) := NULL]
	}
	##For any parent with two addresses at the same time, one address may look like it "takes over" from the other on the same date they were both registered. I adjust for this by deleting any adrdatoEnd that occurs at the same date as adrdato:
	numberOfAdultsTemp2[adrdato == adrdatoEnd , adrdatoEnd := NA]
	##Visually inspected, performing as expected.
	##If adrdatoEnd is 1997-01-01, at this time in the dataset that means that the person was registered somewhere new at the first day in 1997. This means that the address on that line was only occupied prior to 1997 - thus such lines should be deleted:
	numberOfAdultsTemp2 <- numberOfAdultsTemp2[adrdatoEnd != firstDate | is.na(adrdatoEnd)]
	numberOfAdultsTemp2[ , adrNo := NULL]
	##To remove addresses that were left before entry into the dataset:
	numberOfAdultsTemp2 <- numberOfAdultsTemp2[adrdatoEnd > firstDate | is.na(adrdatoEnd)]
	##To avoid having two addresses at the same time:
	numberOfAdultsTemp2[ , adrdatoEnd := adrdatoEnd - 1]
    } else {
	numberOfAdultsTemp2[ , adrdatoEnd := structure(numeric(0) , class = "Date")]
    }
    ##Setting adrdatoEnd to the last date of the year for all who does not change their address:
    numberOfAdultsTemp2[is.na(adrdatoEnd) , adrdatoEnd := lastDate]
    ##Censoring parents that are deceased:
    numberOfAdultsTemp2[!is.na(deathCensoringParent) , adrdatoEnd := deathCensoringParent]
    ##For all adrdato that is less than 1997-01-01, set the first date to 1997-01-01:
    numberOfAdultsTemp2[adrdato < firstDate , adrdato := firstDate]
    numberOfAdultsTemp2[ , deathCensoringParent := NULL]
    ##There are a few observations spanning one day - these are actually correct, the subjects concerned only lives on the given address for that one day during the dataset. All these dates are from the very first or last day of the year. I will store those dates in a separate dataset, as the expansion going on below cannot handle this:
    temp <- numberOfAdultsTemp2[adrdato == adrdatoEnd]
    ##And then delete them:
    numberOfAdultsTemp2 <- numberOfAdultsTemp2[adrdato != adrdatoEnd]

    ##Expanding all observations to one for each day of the year:
    numberOfAdultsTemp2 <- numberOfAdultsTemp2[ , list(pnr = pnr , kom = kom , opgikom = opgikom , day = seq(adrdato , adrdatoEnd , by = "month")) , by = 1:nrow(numberOfAdultsTemp2)]
    numberOfAdultsTemp2[ , nrow := NULL]
    setnames(numberOfAdultsTemp2 , "day" , "adrdato")
    ##Mark the dates that should be replaced by those stored in temp:
    ##Upon inspection, all dates stored in temp are not in the expanded dataset - thus they are appended:
    temp[ , adrdatoEnd := NULL]
    temp <- temp[ , .(pnr , kom , opgikom , adrdato)]
    numberOfAdultsTemp2 <- rbindlist(list(numberOfAdultsTemp2 , temp))
    ##Merge the children and the adults on kom, opgikom and adrdato; this will result in a (very large) dataset that allows counting the number of pnrAdult on any given date, by any given pnr.
    numberOfAdults <- merge(numberOfAdultsTemp , numberOfAdultsTemp2 , by.x = c("adrdato" , "kom" , "opgikom") , by.y = c("adrdato" , "kom" , "opgikom") , all.x = TRUE , suffixes = c("Child" , "Adult") , allow.cartesian = TRUE)
    setkey(numberOfAdults , pnrChild , adrdato)
    ##Count the number of adults on a particular address on each date:
    countTemp <- numberOfAdults[order(pnrChild , adrdato) , .N , by = c("pnrChild" , "adrdato")]
    ##Extract the dates with changes - first, create a lag variable for each child pnr (that is, the count but shifted one row downwards, then extract all rows where the count and lag does not match (that is, the lines with changes). 
    ##Commenting this out as I think I need the object above for the subsequent merge:
    ## countTemp[ , Nlag := shift(N , n = 1 , type = "lag") , by = pnrChild]
    ## countTemp[is.na(Nlag) , Nlag := 99999]
    ## countAdults <- countTemp[N != Nlag]
    ## countAdults[ , Nlag := NULL]
    ## setnames(countAdults , "N" , "numberOfAdults")

    ##Count the number of children at an address on any particular date:
    numberOfChildren <- merge(numberOfAdultsTemp , numberOfAdultsTemp , by.x = c("adrdato" , "kom" , "opgikom") , by.y = c("adrdato" , "kom" , "opgikom") , all.x = TRUE , suffixes = c("Child" , "Sibling") , allow.cartesian = TRUE)
    setkey(numberOfChildren , pnrChild , adrdato)
    ##Count the number of children on a particular address on each date:
    countTempChild <- numberOfChildren[order(pnrChild , adrdato) , .N , by = c("pnrChild" , "adrdato")]
    ##Extract the dates with changes - first, create a lag variable for each child pnr (that is, the count but shifted one row downwards, then extract all rows where the count and lag does not match (that is, the lines with changes). 
    ##Commenting this out - I think I need countTempChild for a full merge with the subsequent dataset.
    ## countTempChild[ , Nlag := shift(N , n = 1 , type = "lag") , by = pnrChild]
    ## countTempChild[is.na(Nlag) , Nlag := 99999]
    ## countChildren <- countTempChild[N != Nlag]
    ## countChildren[ , Nlag := NULL]
    ## setnames(countChildren , "N" , "numberOfChildren")
    ## rm(countTemp , countTempChild , numberOfAdults , numberOfAdultsTemp , numberOfAdultsTemp2 , numberOfChildren)


    ##The variable for reconstituted family will need a dataset with a different structure - this has been written into the proposed dataset above. 
    ##The same for the remaining variables - will begin to construct this dataset: 
    ##For monitoring:
    print("Just before initiating analysisDataset")
    print(Sys.time())
    analysisDatasetCurrentYearTemp <-
	fullPopulationChildrenCurrentYear[!is.na(pnr) ,
					  .(pnr , parentID ,
					    studyEntry , ageCensoring ,
					    birthDateParent ,
					    parenthoodStart ,
					    parenthoodEnd)]
    analysisDatasetCurrentYearTemp <- unique(analysisDatasetCurrentYearTemp)
    ##Reducing the adoption variable to one:                                      
    ## analysisDatasetCurrentYearTemp[parentRole == "FAR" , parentFoedAdop := FAR_FOED_ADOP]
    ## analysisDatasetCurrentYearTemp[parentRole == "MOR" , parentFoedAdop := MOR_FOED_ADOP]
    ## analysisDatasetCurrentYearTemp[ , c("FAR_FOED_ADOP" , "MOR_FOED_ADOP" , "parentRole") := NULL]
    ##Removing parenthoodEnds that are either smaller than 1997-01-01 or smaller than parenthoodStart:
    analysisDatasetCurrentYearTemp <- analysisDatasetCurrentYearTemp[parenthoodEnd > firstDate | is.na(parenthoodEnd)]
    analysisDatasetCurrentYearTemp <- analysisDatasetCurrentYearTemp[parenthoodEnd > parenthoodStart | is.na(parenthoodEnd)] ##It seems to be mere errors that creates situations where parents stop being parents before they start. Another option is the result of the arbitrary parental start date of the first of July. All observations that apply are deleted. 
    ##Preparing a dcast to get parents aligned in wide format: 
    ##Numbering all parents within a PNR:
    setkey(analysisDatasetCurrentYearTemp , pnr , parenthoodStart)
    analysisDatasetCurrentYearTemp[ , parentNo := seq_len(.N) , by = pnr]
    ##dcasting all parents onto the same line:
    analysisDatasetCurrentYearTemp <- dcast(analysisDatasetCurrentYearTemp , pnr ~ parentNo , value.var = c("parentID" , "birthDateParent" , "parenthoodStart" , "parenthoodEnd"))

    ##Importing "first" parents by use of non-year-limited dataset: 
    setorder(fullPopulationChildren , pnr , parenthoodStart , na.last = TRUE)
    fullPopulationChildren[ , parentNo := seq_len(.N) , by = pnr]
    analysisDatasetCurrentYearTemp[fullPopulationChildren[parentNo == 1] ,
				   on ="pnr" ,
				   originalParent1 := i.parentID]
    analysisDatasetCurrentYearTemp[fullPopulationChildren[parentNo == 2] ,
				   on ="pnr" ,
				   originalParent2 := i.parentID]
    fullPopulationChildren[ , parentNo := NULL]
    ##Importing adoption status based on the original parents:
    setnames(analysisDatasetCurrentYearTemp , "originalParent1" , "FAR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(FAR1 , FAR_FOED_ADOP)] ,
				   on = "FAR1" ,
				   parentFoedAdopOrig1 := i.FAR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "FAR1" , "MOR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(MOR1 , MOR_FOED_ADOP)] ,
				   on = "MOR1" ,
				   parentFoedAdopOrig1 := i.MOR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "MOR1" , "originalParent1")
    setnames(analysisDatasetCurrentYearTemp , "originalParent2" , "FAR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(FAR1 , FAR_FOED_ADOP)] ,
				   on = "FAR1" ,
				   parentFoedAdopOrig2 := i.FAR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "FAR1" , "MOR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(MOR1 , MOR_FOED_ADOP)] ,
				   on = "MOR1" ,
				   parentFoedAdopOrig2 := i.MOR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "MOR1" , "originalParent2")

    ##Prepare expansion by adjusting dates to the beginning of the year in question:
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYearTemp)))) {
      analysisDatasetCurrentYearTemp[get(paste0("parenthoodStart_" , i)) <
				       firstDate &
				       !is.na(get(paste0("parenthoodStart_" , i))) ,
				     (paste0("parenthoodStart_" , i)) :=
				       firstDate]
      analysisDatasetCurrentYearTemp[is.na(get(paste0("parenthoodEnd_" , i))) &
				       !is.na(get(paste0("parenthoodStart_" , i))) ,
				     (paste0("parenthoodEnd_" , i)) :=
				       lastDate]
      analysisDatasetCurrentYearTemp[get(paste0("parenthoodEnd_" , i)) >
				       lastDate &
				       !is.na(get(paste0("parenthoodEnd_" , i))) ,
				     (paste0("parenthoodEnd_" , i)) :=
				       lastDate]
    }
    ##Avoid confusion with old objects from former years:
    suppressWarnings(
	rm(parent1 , parent2 ,
	   parent3 , parent4 ,
	   parent5 , parent6))
    ##Make a number of new datasets based on analysisDatasetCurrentYearTemp: 
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYearTemp)))) {
      colNames <- c("pnr" ,
		    grep(paste0(".*_" , i) ,
			 names(analysisDatasetCurrentYearTemp) , value = TRUE))
      assign(paste0("parent" , i) ,
	     analysisDatasetCurrentYearTemp[!is.na(get(paste0("parentID_" , i))) ,
					    ..colNames])
    }
    rm(colNames)
    ##Rename them
    for (i in ls(pattern = 'parent[1-9]+')) {
      ##The stringsplit part is a horrible way to get r to extract the number from i
      j <- strsplit(i , 'parent')[[1]][2]
      setnames(get(i) , c("pnr" , paste0("parentID_" , j) ,
			  paste0("birthDateParent_" , j) ,
			  paste0("parenthoodStart_" , j) ,
			  paste0("parenthoodEnd_" , j)) ,
	       c("pnr" , "parentID" , "birthDateParent" ,
		 "parenthoodStart" , "parenthoodEnd"))
    }
    ##Add originalParent and adoption status to parent1:
    parent1[analysisDatasetCurrentYearTemp , on = "pnr" , c("originalParent1" , "originalParent2" , "parentFoedAdopOrig1" , "parentFoedAdopOrig2") := list(i.originalParent1 , i.originalParent2 , i.parentFoedAdopOrig1 , i.parentFoedAdopOrig2)]

    ##Expand them into registrations for each day
    ##The special case of parent1:
    parent1 <- parent1[ , list(pnr = pnr ,
			       parentID = parentID ,
			       birthDateParent = birthDateParent ,
			       parentFoedAdopOrig1 = parentFoedAdopOrig1 ,
			       parentFoedAdopOrig2 = parentFoedAdopOrig2 ,
			       originalParent1 = originalParent1 ,
			       originalParent2 = originalParent2 ,
			       day = seq.Date(from = parenthoodStart ,
					      to = parenthoodEnd ,
					      by = "month")) ,
		       by = 1:nrow(parent1)]
    for (i in ls(pattern = 'parent[2-9]+')) {
      ##The stringsplit part is a horrible way to get r to extract the number 1 from i
      j <- strsplit(i , 'parent')[[1]][2]
      assign(i , get(i)[ , list(pnr = pnr , parentID = parentID ,
				birthDateParent = birthDateParent ,
				day = seq.Date(from = parenthoodStart ,
					       to = parenthoodEnd ,
					       by = "month")) ,
			 by = 1:nrow(get(i))])
    }
    ##Merge all datasets together on date and pnr: 
    ##Clean up unneccesary columns:
    for (i in ls(pattern = 'parent[1-9]+')) {
      get(i)[ , nrow := NULL]
    }
    ##Do the merge:
    for (i in 1:(length(grep('parentID.*' ,
			     names(analysisDatasetCurrentYearTemp)))-1)) {
      parent1 <- merge(parent1 ,
		       get(paste0("parent" , (i+1))) ,
		       by.x = c("day" , "pnr") ,
		       by.y = c("day" , "pnr") ,
		       all = TRUE ,
		       suffixes = c(i , (i+1)))
      ##For merges subsequent to the first, there is no proper naming of subsequent variables - setting these: 
      setnames(parent1 , c("parentID" ,
			   "birthDateParent") ,
	       c(paste0("parentID" , (i + 1)) ,
		 paste0("birthDateParent" , (i + 1))) ,
	       skip_absent = TRUE)
    }
    ##By taking observations from parent4 and looking for their counterpart in parent1 it shows that all parents were merged as expected. 
    analysisDatasetCurrentYear <- parent1 
    analysisDatasetCurrentYear[ , c("currentParent1" , "currentParent2") := character()]
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYear)))) {
      analysisDatasetCurrentYear[!is.na(get(paste0("parentID" , i))) &
				   is.na(currentParent1) ,
				 c("currentParent1" ,
				   "currentParent2" ,
				   "newBirthDateParent1" ,
				   "newBirthDateParent2") := list(
				     get(paste0("parentID" , i)) ,
				     get(paste0("parentID" , (i+1))) ,
				     get(paste0("birthDateParent" , i)) ,
				     get(paste0("birthDateParent" , (i+1)))
				 )]
    }
    ##Some parents are not adjacent - that is, sometimes it is parent 1 and parent 4 that is filled out, thus currentParent2 remains empty. Fixing this:

    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYear)))) {
      analysisDatasetCurrentYear[!is.na(get(paste0("parentID" , i))) &
				   is.na(currentParent2) &
				   get(paste0("parentID" , i)) != currentParent1 ,
				 c("currentParent2" ,
				   "newBirthDateParent2") := list(
				     get(paste0("parentID" , i)) ,
				     get(paste0("birthDateParent" , i))
				 )]
    }
    ##Results inspected visually, including with restrictions to those with a parent in parentID3 - results as expected. 
    ##Making a list of variables that can be deleted now:
    temp <- grep('.*[0-9]' , names(analysisDatasetCurrentYear) , value = TRUE)
    temp2 <- c(grep('current.*|new.*|original.*' , temp , value = TRUE) ,
	       "parentFoedAdopOrig1" ,
	       "parentFoedAdopOrig2")
    temp <- temp[!temp %in% temp2]
    ##Inserting this list of variables in a command that deletes the variables, and looping over this:
    for (i in paste0("analysisDatasetCurrentYear[ , " , temp , " := NULL]")) {
      eval(parse(text = i))
    }
    setnames(analysisDatasetCurrentYear , old = c("day" , "newBirthDateParent1" , "newBirthDateParent2") , new = c("date" , "birthDateParent1" , "birthDateParent2"))
    ##Applying censoring information for the parents - which is only death:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , dod , by.x = "currentParent1" , by.y = "pnr" , all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , dod , by.x = "currentParent2" , by.y = "pnr" , all.x = TRUE , suffixes = c("Parent1" , "Parent2"))
    analysisDatasetCurrentYear[!is.na(doddatoParent1) & date >= doddatoParent1 , c("currentParent1" , "birthDateParent1") := list(NA , NA)]
    analysisDatasetCurrentYear[!is.na(doddatoParent2) & date >= doddatoParent2 , c("currentParent2" , "birthDateParent2") := list(NA , NA)]
    ##For monitoring:
    print("Just finished structuring parents in analysis dataset")
    print(Sys.time())
    ##Defining reconstituted family: 
    ##Finding all with current parent being the biological parent
    notBiologically <- c("11" , "12" , "14" , "15" , "16" , "17" , "22" , "35" , "39")
    fosterCare <- c("0" , "11" , "12" , "14" , "15" , "16" , "17" , "22" , "35" , "39") 
    ##Reconstituted family is primarily defined from FM_MARK, secondarily by manually comparing PNRs. Changes in FM_MARK are not dated separately in the source dataset - thus the status from last year is used:
    ##Drawing the relevant data:
    befFMMARK <- bef[YEAR == (k - 1) , .(pnr , FM_MARK , YEAR)]
    befFMMARK <- unique(befFMMARK)
    befFMMARK <- befFMMARK[!is.na(FM_MARK)]
    ##Defining a variable from this:
    ##Living with parent(s) and no new partner(s):
    befFMMARK[FM_MARK == 1 | FM_MARK == 3 | FM_MARK == 5 , reconstitutedFamily := 1]
    ##Living with one parent and a new partner: 
    befFMMARK[FM_MARK == 2 | FM_MARK == 4 , reconstitutedFamily := 2]
    ##Living apart from parents: 
    befFMMARK[FM_MARK == 6 , reconstitutedFamily := 3]
    ##Matching - this will allocate last year's status at year-end to the next full year:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , befFMMARK[ , .(pnr , reconstitutedFamily)] ,
					by.x = "pnr" ,
					by.y = "pnr" ,
					all.x = TRUE)   
    ##Commenting parts of this out as I've misunderstood the BEF-registry - thought parents also meant co-habitating, but it isn't so, parents means legally registered parent.
    ## ##Living with biological parents (will only work if these were the "first" parents for the child - if the child was temporarily placed away from home for long enough to affect the registers, originalParents won't correspond to currentParents:
    ## analysisDatasetCurrentYear[((currentParent1 == originalParent1 |
    ##     			 currentParent1 == originalParent2 |
    ##     			 (is.na(currentParent1) & is.na(originalParent1)) |
    ##     			 (is.na(currentParent1) & is.na(originalParent2))) &
    ##     			((currentParent2 == originalParent1 |
    ##     			  currentParent2 == originalParent2) |
    ##     			 (is.na(currentParent2) & is.na(originalParent1)) |
    ##     			 (is.na(currentParent2) & is.na(originalParent2)))) &
    ##     		       !(parentFoedAdop1 %in% notBiologically) &
    ##     		       !(parentFoedAdop2 %in% notBiologically) ,
    ##     		       reconstitutedFamily := 1]
    ## ##If there is only one biological parent and no other parent: 
    ## analysisDatasetCurrentYear[is.na(currentParent2) & (currentParent1 == originalParent1 |
    ##     						currentParent1 == originalParent2) &
    ##     		       !(parentFoedAdop1 %in% notBiologically),
    ##     		       reconstitutedFamily := 1]
    ##Parented by one biological and one non-biological parent (assuming this rules out living with both biological parents):
    analysisDatasetCurrentYear[((currentParent1 == originalParent1 &
				 !(parentFoedAdopOrig1 %in% fosterCare) &
				 !is.na(originalParent1))|
				(currentParent1 == originalParent2 &
				 !(parentFoedAdopOrig2 %in% fosterCare) &
				 !is.na(originalParent2)) |
				(currentParent2 == originalParent1 &
				 !(parentFoedAdopOrig1 %in% fosterCare) &
				 !is.na(originalParent1))|
				(currentParent2 == originalParent2 &
				 !(parentFoedAdopOrig2 %in% fosterCare) &
				 is.na(originalParent2))) & #Initial blocks: living with at least one biological parent
			       ((currentParent1 != originalParent1 &
				 currentParent1 != originalParent2) |
				(currentParent2 != originalParent1 &
				 currentParent2 != originalParent2)) , ##These blocks: living with at least one non-biological parent ,
			       reconstitutedFamily := 2]
    ##Taking care of the special case of one non-biological parent, this should result in category 3:
    analysisDatasetCurrentYear[(!is.na(currentParent1) & is.na(currentParent2)) &
			       ((parentFoedAdopOrig1 %in% fosterCare &
				 currentParent1 == originalParent1) |
				(parentFoedAdopOrig2 %in% fosterCare &
				 currentParent1 == originalParent2) |
				(currentParent1 != originalParent1 &
				 currentParent1 != originalParent2)) ,
			       reconstitutedFamily := 3]
    analysisDatasetCurrentYear[(!is.na(currentParent2) & is.na(currentParent1)) &
			       ((parentFoedAdopOrig1 %in% fosterCare &
				 currentParent2 == originalParent1) |
				(parentFoedAdopOrig2 %in% fosterCare &
				 currentParent2 == originalParent2) |
				(currentParent2 != originalParent1 &
				 currentParent2 != originalParent2)) ,
			       reconstitutedFamily := 3]
    ##Adopted or in foster care:
    analysisDatasetCurrentYear[((parentFoedAdopOrig1 %in% fosterCare) &
			       (parentFoedAdopOrig2 %in% fosterCare)) |
			       (currentParent1 != originalParent1 &
				currentParent1 != originalParent2 &
				currentParent2 != originalParent1 &
				currentParent2 != originalParent2) ,
			       reconstitutedFamily := 3] 
    ##Applying censoring information - creating dataset for this and merging:
    censoring <- unique(fullPopulationChildrenCurrentYear[!is.na(pnr) , .(pnr , studyEntry , ageCensoring , deathCensoring , emigrationCensoring)])
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , censoring ,
					by.x = "pnr" ,
					by.y = "pnr" ,
					all.x = TRUE)
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date >= studyEntry]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= ageCensoring |
							       is.na(ageCensoring)]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= deathCensoring |
							       is.na(deathCensoring)]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= emigrationCensoring |
							       is.na(emigrationCensoring)]
    ##Calculating mean parental age:
    analysisDatasetCurrentYear[!is.na(currentParent2) & !is.na(currentParent1) ,
			       meanParentalAge := (
				 ((date - birthDateParent1) / 365.24) +
				   ((date - birthDateParent2) / 365.24)) / 2]
    analysisDatasetCurrentYear[is.na(currentParent2) ,
			       meanParentalAge := ((date - birthDateParent1) / 365.24)]
    analysisDatasetCurrentYear[is.na(currentParent1) ,
			       meanParentalAge := ((date - birthDateParent2) / 365.24)]
    ##Calculating current child age:
    ##Merging with fullPopulationChildrenCurrentYear
    fullPopulationChildrenCurrentYear[!is.na(pnr) , duplTest := duplicated(pnr)]
    fullPopulationChildrenCurrentYear[duplTest == FALSE , mergePnr := pnr]
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					fullPopulationChildrenCurrentYear[ ,
									   .(mergePnr , birthDate)] ,
					by.x = "pnr" , by.y = "mergePnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergePnr") := NULL]
    ##Calculating current age:
    analysisDatasetCurrentYear[ , childAge := (date - birthDate) / 365.24]
    ##For monitoring:
    print("Just before health categories")
    print(Sys.time())
    ##Adding health categories for the parents
    ##Making a list of all disease categories:
    categories <- grep('.*GroupDiag$' ,
		       names(fullPopulationChildrenCurrentYear) ,
		       value = TRUE)
    categories <- c(categories ,
		    grep('.*Charlson$' ,
			 names(fullPopulationChildrenCurrentYear) ,
			 value = TRUE) ,
		    "alcoholAbuse" ,
		    "substanceAbuse" ,
		    "unspecificEver" ,
		    "unspecificTwoYear")

    for (i in categories) {
      temp <-  fullPopulationChildrenCurrentYear[get(i) > 0 ,
						 .(parentID ,
						   d_inddtoParent ,
						   get(i) ,
						   get(paste0(i , "EndDate")))]
      temp <- unique(temp)
      temp <- temp[!is.na(V3)]
      for (j in c("currentParent1" , "currentParent2")) {
	analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					    temp ,
					    by.x = j ,
					    by.y = "parentID" ,
					    all.x = TRUE ,
					    allow.cartesian = TRUE)
	analysisDatasetCurrentYear[date <= V4 & date >= d_inddtoParent ,
				   (paste0(i , j)) := V3]
	##This works - but this expands the number of rows, when for example one parent has three admissions for liver disease during a year. Reducing the number of rows to one for each date and parent:
	setorderv(analysisDatasetCurrentYear ,
		  cols = c("pnr" ,
			   "date" ,
			   paste0(i , j)) ,
		  na.last = TRUE)
	analysisDatasetCurrentYear <- unique(analysisDatasetCurrentYear ,
					     by = c("pnr" , "date"))
	##Visually inspected - for any date relevant, there is now one entry for each PNR and in this date, the correct status for the relevant category is printed.
	analysisDatasetCurrentYear[ , c("d_inddtoParent" ,
					"V3" ,
					"V4") := NULL]
      }
    }
    ##The above loop was tested with two categories of disease and compared to the disease categories in healthMergeTotal - there is consistency between these two. 

    categoriesLmdb <- grep('.*GroupLmdb$' , names(fullPopulationChildrenCurrentYear) , value = TRUE)

    print("Just after diag categories")
    print(Sys.time())
    for (i in categoriesLmdb) {
      print(i)
      print(Sys.time())
      temp <-  fullPopulationChildrenCurrentYear[get(i) > 0 ,
						 .(parentID ,
						   eksd ,
						   get(i) ,
						   get(paste0(i , "EndDate")))]
      temp <- unique(temp)
      ##Studying prescription data one notices that some individuals buy two packages of the same prescription medicine during the same month (and in this dataset, everything is reduced to months). This could either be the same actual date, it could be because of small packages available or it could be because of high use. In this study, prescriptions twice or more a year is interpreted as prescriptions bought in separate months.  
      temp <- temp[!is.na(V3)]
      for (j in c("currentParent1" , "currentParent2")) {
	analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					    temp ,
					    by.x = j ,
					    by.y = "parentID" ,
					    all.x = TRUE ,
					    allow.cartesian = TRUE)
	analysisDatasetCurrentYear[date <= V4 & date >= eksd ,
				   (paste0(i , j , "LmdbTemp")) := V3]
	## Add column with sum for each group:
	analysisDatasetCurrentYear[ ,
				    (paste0(i , j , "LmdbTotal")) :=
				      sum(get(paste0(i , j , "LmdbTemp"))) ,
				    by = c("pnr" , "date")]
	##This works - but this expands the number of rows, when for example one parent collects three subscriptions for a painful condition during a year.

	##Reducing the number of rows to one for each date and parent:
	analysisDatasetCurrentYear <- unique(analysisDatasetCurrentYear ,
					     by = c("pnr" , "date")) ## This should not be commented, but will be for the first run to check that the loop sums correctly
	##Visually inspected - for any date relevant, there is now one entry for each PNR and in this date, the correct status for the relevant category is printed.
	analysisDatasetCurrentYear[ , c("eksd" , "V3" , "V4") := NULL]
      }
    }

    ##Backup of the for-loops with working - but ever so slow - code using the lastLine memory "transfer" to next year
    ## for (i in categories) {
    ##     temp <-  fullPopulationChildrenCurrentYear[get(i) > 0 ,
    ##     					   .(parentID ,
    ##     					     d_inddtoParent ,
    ##     					     get(i) ,
    ##     					     get(paste0(i , "EndDate")))]
    ##     temp <- unique(temp)
    ##     temp <- temp[!is.na(V3)]
    ##     for (j in c("currentParent1" , "currentParent2")) {
    ##         analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
    ##     					temp ,
    ##     					by.x = j ,
    ##     					by.y = "parentID" ,
    ##     					all.x = TRUE ,
    ##     					allow.cartesian = TRUE)
    ##         analysisDatasetCurrentYear[date <= V4 & date >= d_inddtoParent ,
    ##         (paste0(i , j)) := V3]
    ##         ##This works - but this expands the number of rows, when for example one parent has three admissions for liver disease during a year. Reducing the number of rows to one for each date and parent:
    ##         setorderv(analysisDatasetCurrentYear ,
    ##     	      cols = c("pnr" ,
    ##     		       "date" ,
    ##     		       paste0(i , j)) ,
    ##     	      na.last = TRUE)
    ##         analysisDatasetCurrentYear <- unique(analysisDatasetCurrentYear ,
    ##     					 by = c("pnr" , "date"))
    ##         ##Visually inspected - for any date relevant, there is now one entry for each PNR and in this date, the correct status for the relevant category is printed.
    ##         ##Keeping the variable for end date in the dataset for memory of chronic conditions:
    ##         analysisDatasetCurrentYear[ , (paste0(i , "EndDate" , j)) := V4]
    ##         analysisDatasetCurrentYear[ , c("V3" ,
    ##     				    "V4") := NULL]
    ##         ##To avoid merge problems with two d_inddto:
    ##         setnames(analysisDatasetCurrentYear , "d_inddtoParent" ,
    ##     	     paste0("d_inddtoParent" , i , j))
    ##     }
    ## }
    ## ##The above loop was tested with two categories of disease and compared to the disease categories in healthMergeTotal - there is consistency between these two. 

    ## categoriesLmdb <- grep('.*GroupLmdb$' , names(fullPopulationChildrenCurrentYear) , value = TRUE)

    ## print("Just after diag categories")
    ## print(Sys.time())
    ## for (i in categoriesLmdb) {
    ##     print(i)
    ##     print(Sys.time())
    ##     temp <-  fullPopulationChildrenCurrentYear[get(i) > 0 ,
    ##     					   .(parentID ,
    ##     					     eksd ,
    ##     					     get(i) ,
    ##     					     get(paste0(i , "EndDate")))]
    ##     temp <- unique(temp)
    ##     temp <- temp[!is.na(V3)]
    ##     for (j in c("currentParent1" , "currentParent2")) {
    ##         analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
    ##     					temp ,
    ##     					by.x = j ,
    ##     					by.y = "parentID" ,
    ##     					all.x = TRUE ,
    ##     					allow.cartesian = TRUE)
    ##         analysisDatasetCurrentYear[date <= V4 & date >= eksd ,
    ##     			       c(paste0(i , j , "LmdbTemp") ,
    ##     				 paste0(i , j , "LmdbEndDate")) :=
    ##     				   list(V3 , V4)]
    ##         ## Add column with sum for each group and a string with the original values and EndDates:
    ##         analysisDatasetCurrentYear[ ,
    ##                                    c(paste0(i ,
    ##                                             j ,
    ##                                             "LmdbTotal") ,
    ##                                      paste0(i ,
    ##                                             j ,
    ##                                             "LmdbText") , 
    ##                                      paste0(i ,
    ##                                             j ,
    ##                                             "LmdbEndDateText")) := list(
    ##                                        sum(get(paste0(i ,
    ##                                                       j ,
    ##                                                       "LmdbTemp"))) ,
    ##                                        toString(get(paste0(i ,
    ##                                                            j ,
    ##                                                            "LmdbTemp"))) ,
    ##                                        toString(get(paste0(i ,
    ##                                                            j ,
    ##                                                            "LmdbEndDate")))) ,
    ##                                    by = c("pnr" , "date")]
    ##         ##This works - but this expands the number of rows, when for example one parent collects three subscriptions for a painful condition during a year.

    ##         ##Reducing the number of rows to one for each date and parent:
    ##         analysisDatasetCurrentYear <- unique(analysisDatasetCurrentYear ,
    ##     					 by = c("pnr" , "date")) ## This should not be commented, but will be for the first run to check that the loop sums correctly
    ##         ##Visually inspected - for any date relevant, there is now one entry for each PNR and in this date, the correct status for the relevant category is printed.
    ##         analysisDatasetCurrentYear[ , c("V3" , "V4") := NULL]
    ##         ##To avoid merge problems with two d_inddto:
    ##         setnames(analysisDatasetCurrentYear , "eksd" , paste0("eksd" , i , j))
    ##     }
    ## }
    ##Visually inspected, the total sums up current prescriptions so that someone with for example 6 prescriptions within the last year has a score of 3. This works exactly as intended. Will switch on the downsizing algorithm, so that there is only one line for each date. 

    ##Correct the use of currentParent with a small c (against naming conventions but convenient in the loop):
    temp <- grep('[a-z]+currentParent.*' , names(analysisDatasetCurrentYear) , value = TRUE)
    temp2 <- gsub('currentParent' , 'CurrentParent' , temp)
    setnames(analysisDatasetCurrentYear , temp , temp2)


    ##For monitoring:
    print("Just after adding health categories")
    print(Sys.time())

    ##For memory of chronic disease:
    categoriesMemory <- categories[!grepl('.*Charlson$' , categories)]

    memoryLastYear <- data.table()
    ##For all the data in the non-Lmdb format:
    for (i in categoriesMemory) {
      tempList <- c("parentID" , "d_inddtoParent" , i , paste0(i , "EndDate"))
      tempMemory <- fullPopulationChildrenCurrentYear[!is.na(get(i)) & get(paste0(i , "EndDate")) > lastDate , ..tempList]
      tempMemory <- unique(tempMemory)
      memoryLastYear <- rbindlist(list(memoryLastYear , tempMemory) , use.names = TRUE , fill = TRUE)
    }

    ##Adding all the LMDB-data:
    for (i in categoriesLmdb) {
      tempList <- c("parentID" , "eksd" , i , paste0(i , "EndDate"))
      tempMemory <- fullPopulationChildrenCurrentYear[!is.na(get(i)) & get(paste0(i , "EndDate")) > lastDate , ..tempList]
      tempMemory <- unique(tempMemory)
      ##This makes sense because of how multiple prescriptions is interpreted in this study - see comment in prescription algorithm above. 
      memoryLastYear <- rbindlist(list(memoryLastYear , tempMemory) , use.names = TRUE , fill = TRUE)
    }


    ##Summing the score:
    charlsonCategories <- grep('.*Charlson*' ,
			       names(analysisDatasetCurrentYear) ,
			       value = TRUE)
    temp <- grep('.*EndDate.*|^d_inddto.*' , charlsonCategories , value = TRUE)
    charlsonCategories <- setdiff(charlsonCategories , temp)
    ##charlsonCategories inspected, contains all relevant entries and none unwanted
    analysisDatasetCurrentYear[ , jointCharlsonParents :=
				  rowSums(.SD , na.rm = TRUE) ,
				.SDcols = charlsonCategories]
    ##Summing as expected

    ##Coding the outcome
    ##The merge on health data is also performed above as it is necessary for exclusion of the individuals already exposed to abuse - it is re-used here, but first death certificates within three weeks after admission will result in re-classification as lethal abuse:
    ##dodAbuse is expanded with two months backwards:
    dodAbuseExpandedTwoMonths <- dodAbuse[ , list(pnr = pnr ,
						   lethalPhysicalAbuse = lethalPhysicalAbuse ,
						   predatingDeath = seq((d_statdato %m-% period("2 months")) ,
									d_statdato ,
									by = "month")) ,
					    by = 1:nrow(dodAbuse)]
    dodAbuseExpandedTwoMonths[ , nrow := NULL]
    healthAbuseAlsoLethal <- merge(healthAbuse , 
				   dodAbuseExpandedTwoMonths , 
				   by.x = c("pnr" , "d_inddto") , 
				   by.y = c("pnr" , "predatingDeath") , 
				   all.x = TRUE)
    ##So by this I am assuming that health events classified as abuse within two months of the person's death was actually lethal abuse - a strong assumption, but also a guard against misclassifying health information with lethal prognosis. 
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , 
					healthAbuseAlsoLethal , 
					by.x = c("pnr" , "date") , 
					by.y = c("pnr" , "d_inddto") , 
					all.x = TRUE)
    ##Inputs from death certificates:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , 
					dodAbuse , 
					by.x = c("pnr" , "date") , 
					by.y = c("pnr" , "d_statdato") , 
					all.x = TRUE , 
					suffixes = c("" , "Certificate"))


    ##Linking krof with death certificates - to enable classification of lethal abuse by parents:
    ##To enable this, dodAbuse is expanded to three months before the date of finding or death of the child. It is assumed that the start of the act that led to conviction and the death of the child (ofr_gerfradt) will be within these three months. 
    dodAbuseExpanded <- dodAbuse[ , list(pnr = pnr , lethalPhysicalAbuse = lethalPhysicalAbuse , predatingDeath = seq(d_statdato , length = 3 , by = "-1 months")) , by = 1:nrow(dodAbuse)]
    dodAbuseExpanded[ , nrow := NULL]
    krof <- merge(krof , dodAbuseExpanded , by.x = c("pnr" , "ofr_gerfradt") , by.y = c("pnr" , "predatingDeath") , all.x = TRUE)
    ##The lethalPysicalAbuse variable is expanded by a list of police codes known to denote lethal violence:
    policeLethal <- fread("policeLethal.csv" ,
			  colClasses = ("policeLethal" = "character"))
    krof[ofr_ger7 %in% policeLethal$policeLethal , lethalPhysicalAbuse := 1]
    ##Marking observations with physical abuse:
    physicalAbusePolice <- fread("physicalAbusePolice.csv" , colClasses = ("physicalAbusePolice" = "character"))
    krof[ofr_ger7 %in% physicalAbusePolice$physicalAbusePolice , physicalAbuse := 1]
    ##In 1997, noone has been registered as murdered by their parents (which is not surprising since KROF starts in 2001). The entries for years after 2001 seems somewhat evenly distributed.
    ##Preparing to reduce krof to the first incident:
    setorder(krof , pnr , physicalAbuse , ofr_gerfradt ,
	     pnrPerpetrator , parentPerpetrator , na.last = TRUE)
    ##Now for each incident, the earliest record related to physical abuse, and among separate records on the same date the first one with a pnr, and among such records with several pnrs the one with a parent, is first. Thus, the first incident with the most information for classification is chosen. Reducing on this:
    krofFirst <- unique(krof , by = "pnr")
    ##Reducing to only incidents with physical violence:
    krofFirst <- krofFirst[physicalAbuse == 1]
    ##Preparing KROF for future merges:
    krof[ , c("lethalPhysicalAbuse" , "physicalAbuse") := NULL]
    ##Since krofFirst is now reduced to physical abuse only, deleting physical abuse indicator:
    krofFirst[ , physicalAbuse := NULL]
    ##Classifying on this:
    #Parent(s) committing non-lethal abuse: 
    krofFirst[parentPerpetrator == 1 & is.na(lethalPhysicalAbuse) ,
	      outcomePhysicalAbuse := 1]
    ##Known, non-parental perpetrator committing non-lethal abuse:
    krofFirst[is.na(parentPerpetrator) & 
		!is.na(pnrPerpetrator) & 
		is.na(lethalPhysicalAbuse) ,
	      outcomePhysicalAbuse := 2]
    ##Unknown perpetrator committing non-lethal abuse:
    krofFirst[is.na(pnrPerpetrator) & 
		is.na(lethalPhysicalAbuse) ,
	      outcomePhysicalAbuse := 3]
    ##Lethal physical abuse by parents:
    krofFirst[parentPerpetrator == 1 & 
		lethalPhysicalAbuse == 1 ,
	      outcomePhysicalAbuse := 4]
    ##Lethal physical abuse by other than parents:
    krofFirst[!is.na(pnrPerpetrator) & 
		is.na(parentPerpetrator) & 
		lethalPhysicalAbuse == 1 ,
	      outcomePhysicalAbuse := 5]
    ##Lethal physical abuse by unknown perpetrator:
    krofFirst[is.na(pnrPerpetrator) & 
		lethalPhysicalAbuse == 1 ,
	      outcomePhysicalAbuse := 6]
    ##From krofFirst[ , table(outcomePhysicalAbuse)] it is seen that all entries are categorized and from visual inspection they fall into the categories expected.
    ##Adding on the classifications:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					krofFirst[ ,
						   .(pnr ,
						     ofr_gerfradt ,
						     outcomePhysicalAbuse)] ,
					by.x = c("pnr" , "date") ,
					by.y = c("pnr" , "ofr_gerfradt") ,
					all.x = TRUE)
    ##Lethal physical abuse by unknown perpetrator (using death certificates and health data): 
    analysisDatasetCurrentYear[lethalPhysicalAbuse == 1 & 
				 is.na(outcomePhysicalAbuse) ,
			       outcomePhysicalAbuse := 6]
    ##Lethal physical abuse by unknown perpetrator (using death certificates): 
    analysisDatasetCurrentYear[lethalPhysicalAbuseCertificate == 1 & 
				 is.na(outcomePhysicalAbuse) ,
			       outcomePhysicalAbuse := 6]
    ##Non-lethal physical abuse by unknown perpetrator (using only health data):
    analysisDatasetCurrentYear[physicalAbuse == 1 & 
				 is.na(outcomePhysicalAbuse) ,
			       outcomePhysicalAbuse := 3]
    ##Deleting unnecessary variables:
    analysisDatasetCurrentYear[ , c("physicalAbuse" , "lethalPhysicalAbuse" , "lethalPhysicalAbuseCertificate") := NULL]

    ##For monitoring:
    print("Just after the outcome")
    print(Sys.time())

    ##Removing subsequent entries and making an exclusion list for subsequent years:
    outcome <- analysisDatasetCurrentYear[!is.na(outcomePhysicalAbuse) , .(pnr , date)]
    outcomeTemp <- outcome[date >= (lastDate %m-% period("1 month"))]
    outcome <- outcome[date < (lastDate %m-% period("1 month"))]
    ##Now the range of dates in outcome is from January until and including October, and outcomeTemp stores remaining entries.
    ##Expanding outcome to all dates after the event (but the date of the event):
    outcome <- outcome[ , list(pnr = pnr , date = seq((date %m+% period("1 month")) , lastDate , by = "1 month")) , by = 1:nrow(outcome)]
    outcome[ , nrow := NULL]
    ##Taking all outcomeTemp dates in November, changing them to December and adding them to outcome:
    outcomeTempTemp <- outcomeTemp[date == (lastDate %m-% period("1 month"))]
    ##Checked outcomeTempTemp, it exclusively contains dates from November. Changing those to December and adding to outcome:
    outcomeTempTemp[ , date := lastDate]
    outcome <- rbindlist(list(outcome , outcomeTempTemp) , use.names = TRUE)
    ##Merging outcome to main dataset and deleting records after the outcome has occurred:
    outcome[ , delete := 1]
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					outcome ,
					by.x = c("pnr" , "date") ,
					by.y = c("pnr" , "date") ,
					all.x = TRUE)
    ##Dataset inspected (View(analysisDatasetCurrentYear[pnr %in% outcome[ , pnr]][1:1000])) and dates subsequent to abuse are marked with delete. Deleting those:
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[is.na(delete)]
    analysisDatasetCurrentYear[ , delete := NULL]
    ##Making a list to exclude these children from future data:
    if (exists("outcomeList")) {
	outcomeList <- rbindlist(list(outcome ,
				  outcomeTemp[date == lastDate] ,
				  outcomeList) ,
			     use.names = TRUE ,
			     fill = TRUE)
	outcomeList[ , c("date" , "delete") := NULL]
    } else {
	outcomeList <- rbindlist(list(outcome ,
				      outcomeTemp[date == lastDate]) ,
				 use.names = TRUE ,
				 fill = TRUE)
	outcomeList[ , c("date" , "delete") := NULL]
    }
    ##Now this list contains unique pnrs that should be excluded in future years. 
    outcomeList <- unique(outcomeList)

    ##Making a list to ensure not to include dead children:
    if (exists("deathList")) {
	deathList <- rbindlist(list(analysisDatasetCurrentYear[!is.na(deathCensoring) ,
							       .(pnr , deathCensoring)] ,
				    deathList) , fill = TRUE)
    } else {
	deathList <- analysisDatasetCurrentYear[!is.na(deathCensoring) ,
						.(pnr , deathCensoring)]
    }
    deathList[ , deathCensoring := NULL]
    deathList <- unique(deathList)

    ##Doing a check for children without parents(View(analysisDatasetCurrentYear[is.na(currentParent1) & is.na(currentParent2)])), one sees a number of dates where children have no parents registered. It seems the parents are de-registered for one reason or another. These children have a zero-risk of the exposure at these times and thus should be excluded from re-entering the study:
    if (exists("noParentsList")) {
	noParentsList <- rbindlist(list(analysisDatasetCurrentYear[is.na(currentParent1) &
								   is.na(currentParent2) ,
								   .(pnr , currentParent1 , currentParent2)] , noParentsList) , use.names = TRUE , fill = TRUE)
    } else {
	noParentsList <- analysisDatasetCurrentYear[is.na(currentParent1) &
						    is.na(currentParent2) ,
						    .(pnr , currentParent1 , currentParent2)]
    }
    noParentsList[ , c("currentParent1" , "currentParent2") := NULL]
    noParentsList <- unique(noParentsList)

    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[!is.na(currentParent1) |
							     !is.na(currentParent2)] 


    ##Implementing interparental violence-variable; the element IPVCertainHealth is derived from healthMergeTotal, that is all health-events in the dataset. This is merged onto analysisDatasetCurrentYear, and for each match a parental couple and a match date is extracted. This is subsequently expanded to all dates until the end of 1997, and matched onto analysisDatasetCurrentYear:

    ##If there is any list from previous years, update that to the current year:
    if (exists("listIPVCouples")) {
      listIPVCouples[ , date := firstDate]
    }

    ##There is a risk that couples formerly known to have IPV are not known in 1997 - however, IPV is connected to couples and not individuals, and since the couple history is known through the child, only new incidents of IPV during the study period is included. This will make interpretation of the time variable difficult. 

    ##First certain diagnoses:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					IPVCertainHealth ,
					by.x = c("currentParent1" , "date") ,
					by.y = c("pnr" , "d_inddto") , all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					IPVCertainHealth ,
					by.x = c("currentParent2" , "date") ,
					by.y = c("pnr" , "d_inddto") , all.x = TRUE)
    analysisDatasetCurrentYear[IPVCertain.x == 1 |
				 IPVCertain.y == 1 ,
			       IPVCertain := 1]
    analysisDatasetCurrentYear[ , c("IPVCertain.x" , "IPVCertain.y") := NULL]
    if (exists("listIPVCouples")) {
      listIPVCouples <- rbindlist(list(listIPVCouples ,
				       analysisDatasetCurrentYear[IPVCertain == 1 ,
								  .(currentParent1 ,
								    currentParent2 ,
								    date)]) , use.names = TRUE)
    }
    if (!exists("listIPVCouples")) {
      listIPVCouples <- analysisDatasetCurrentYear[IPVCertain == 1 ,
						   .(currentParent1 , currentParent2 , date)]
    }

    listIPVCouples <- unique(listIPVCouples)

    ##Then partial interparental violence-variable - this variable requires a match between a violence-related diagnosis or police-code in the victim registry on one partner, and a police code for perpetration of violence (or some other, IPV-related event) on the other partner. The dates for IPVPartialHealth has been expanded to one month surrounding the original date to facilitate a match:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					IPVPartialHealth ,
					by.x = c("currentParent1" , "date") ,
					by.y = c("pnr" , "matchDate") ,
					all.x = TRUE)

    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					IPVPartialHealth ,
					by.x = c("currentParent2" , "date") ,
					by.y = c("pnr" , "matchDate") ,
					suffixes = c("1" , "2") ,
					all.x = TRUE)
    ##Visually inspected, marked as intended.

    ##Adding marks for any parent listed as perpetrator in KROF (you're not using KRAF and related registers as there is no variable indicating the beginning of the action):
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					krofIPVPartial[!is.na(pnrPerpetrator) ,
						       .(pnrPerpetrator ,
							 ofr_gerfradt ,
							 IPVPartialPolice)] ,
					by.x = c("currentParent1" , "date") ,
					by.y = c("pnrPerpetrator" , "ofr_gerfradt") ,
					all.x = TRUE)

    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					krofIPVPartial[!is.na(pnrPerpetrator) ,
							.(pnrPerpetrator ,
							  ofr_gerfradt ,
							  IPVPartialPolice)] ,
					by.x = c("currentParent2" , "date") ,
					by.y = c("pnrPerpetrator" , "ofr_gerfradt") ,
					all.x = TRUE ,
					suffixes = c("1" , "2"))

    ##Adding marks for any parent listed as victim in KROF:
    setnames(krofIPVPartial , "IPVPartialPolice" , "IPVPartialVictimPolice")
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					krofIPVPartial[ , .(pnr ,
							    ofr_gerfradt ,
							    IPVPartialVictimPolice)] ,
					by.x = c("currentParent1" , "date") ,
					by.y = c("pnr" , "ofr_gerfradt") ,
					all.x = TRUE)

    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					krofIPVPartial[ , .(pnr ,
							    ofr_gerfradt ,
							    IPVPartialVictimPolice)] ,
					by.x = c("currentParent2" , "date") ,
					by.y = c("pnr" , "ofr_gerfradt") ,
					all.x = TRUE ,
					suffixes = c("1" , "2"))
    setnames(krofIPVPartial , "IPVPartialVictimPolice" , "IPVPartialPolice")

    ##If either parent has suffered injuries and the other is listed as a perpetrator:
    listIPVCouples <- rbindlist(list(listIPVCouples ,
				     analysisDatasetCurrentYear[(IPVPartialHealth1 == 1 &
								 IPVPartialPolice2 == 1) |
								(IPVPartialHealth2 == 1 &
								 IPVPartialPolice1 == 1) ,
								.(currentParent1 ,
								  currentParent2 , date)]
    )
    )
    ##If either parent is listed as victim and the other as perpetrator on the same date:
    listIPVCouples <- rbindlist(
	list(listIPVCouples ,
	     analysisDatasetCurrentYear[(IPVPartialPolice1 == 1 &
					 IPVPartialVictimPolice2 == 1) |
					(IPVPartialPolice2 == 1 &
					 IPVPartialVictimPolice1 == 1) ,
					.(currentParent1 ,
					  currentParent2 , date)]
	     )
    )

    listIPVCouples <- unique(listIPVCouples)
    analysisDatasetCurrentYear[ , c("IPVCertain" ,
				    "IPVPartialHealth1" ,
				    "IPVPartialHealth2" ,
				    "IPVPartialPolice1" ,
				    "IPVPartialPolice2" ,
				    "IPVPartialVictimPolice1" ,
				    "IPVPartialVictimPolice2") := NULL]

    ##Preparing a time-series for merge: 
    IPVForMerge <- listIPVCouples[ , list(currentParent1 = currentParent1 ,
					  currentParent2 = currentParent2 ,
					  allDates = seq(date ,
							 lastDate ,
							 by = "month")) ,
				   by = 1:nrow(listIPVCouples)]
    IPVForMerge[ , nrow := NULL]
    IPVForMerge <- unique(IPVForMerge)
    IPVForMerge[ , interparentalViolence := 1]
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , IPVForMerge ,
					by.x = c("currentParent1" ,
						 "currentParent2" ,
						 "date") ,
					by.y = c("currentParent1" ,
						 "currentParent2" ,
						 "allDates") ,
					all.x = TRUE)
    setnames(IPVForMerge , c("currentParent1" , "currentParent2") ,
	     c("currentParent2" , "currentParent1"))
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , IPVForMerge ,
					by.x = c("currentParent1" ,
						 "currentParent2" ,
						 "date") ,
					by.y = c("currentParent1" ,
						 "currentParent2" ,
						 "allDates") ,
					all.x = TRUE)
    analysisDatasetCurrentYear[interparentalViolence.x == 1 |
				 interparentalViolence.y == 1 ,
			       interparentalViolence := 1]
    analysisDatasetCurrentYear[ , c("interparentalViolence.x" ,
				    "interparentalViolence.y") := NULL]

    ##At this point in the dataset, there is a curious expansion of the first and only the first date of the year for four individuals (analysisDatasetCurrentYear[ , index := 1:.N , by = pnr] ; tempList <- analysisDatasetCurrentYear[index == 13 , pnr] ; View(analysisDatasetCurrentYear[pnr %in% tempList])), two of these experiencing IPV in the family. I cannot find any reason why this duplication happens - but it disappears with a unique:
    analysisDatasetCurrentYear <- unique(analysisDatasetCurrentYear)
    ##I will not analyze this any further, I expect some list somewhere to operate with a duplicate. 

    ##Classifying education (previously loaded and formatted):
    ##Giving all parents a baseline, that is some education prior to last year:
    allParentsCurrentYear <- fullPopulationChildrenCurrentYear[ , .(parentID)]
    allParentsCurrentYear <- unique(allParentsCurrentYear)
    allParentsCurrentYearTemp <- copy(allParentsCurrentYear)
    allParentsCurrentYear <- merge(allParentsCurrentYear ,
				   udda[HF_VFRA <= floor_date((firstDate %m-%
							       period("1 month")) ,
							      unit = "month"),
					.(pnr , education , HF_VFRA)] ,
				   by.x = "parentID" ,
				   by.y = "pnr" ,
				   all.x = TRUE)
    setorder(allParentsCurrentYear , parentID , -HF_VFRA , na.last = TRUE)
    ##Now everyone has their education status, ordered by time, with the newest education (before current year) as the first. 
    allParentsCurrentYear <- unique(allParentsCurrentYear , by = "parentID")
    ##Now everyone has one line with newest education before current year - viewed and formatted as expected.
    ##Setting HF_VFRA to same starting date:
    allParentsCurrentYear[!is.na(HF_VFRA) , HF_VFRA := firstDate %m-% period("1 month")]
    allParentsCurrentYearTemp <- merge(allParentsCurrentYearTemp ,
				       udda[HF_VFRA <= lastDate &
					      HF_VFRA > (firstDate - 1) ,
					    .(pnr , education , HF_VFRA)] ,
				       by.x = "parentID" ,
				       by.y = "pnr" ,
				       all.x = TRUE , allow.cartesian = TRUE)
    allParentsCurrentYear <- rbindlist(list(allParentsCurrentYear , allParentsCurrentYearTemp) , use.names = TRUE)
    allParentsCurrentYear <- allParentsCurrentYear[!is.na(education)]
    allParentsCurrentYear <- unique(allParentsCurrentYear)
    setorder(allParentsCurrentYear , parentID , HF_VFRA)
    ##Inspected, now everyone has a basic level of education, and any updates during the year are listed after this basic level. 
    allParentsCurrentYear[ , dateTo := shift(HF_VFRA , n = 1 , type = "lead") , by = "parentID"]
    ##dateTo will be used as the end of an education - I subtract 1 month to avoid having two educational status on the same month:
    allParentsCurrentYear[ , dateTo := (dateTo %m-% period("1 month"))]
    ##Data inspected, dateTo classifies as expected. 
    ##For the last entry, set dateTo to lastDate
    setorder(allParentsCurrentYear , parentID , -HF_VFRA)
    allParentsCurrentYear[ , index := 1:.N , by = parentID]
    allParentsCurrentYear[index == 1 , dateTo := lastDate]
    ##Data inspected, the last education is marked with lastDate as dateTo
    ##I've come across a few observations where two educational levels are registered on the same date. My algorithm preserves the highest one, and the lower level is given a NA in dateTo. Upon inspection, there is no indication that I will loose any information by deleting these entries:
    allParentsCurrentYear <- allParentsCurrentYear[!is.na(dateTo)]
    ##Extend the educational status across all dates:
    allParentsCurrentYearExtended <- allParentsCurrentYear[ , list(parentID = parentID , education = education , date = seq(HF_VFRA , dateTo , by = "month")) , by = 1:nrow(allParentsCurrentYear)]
    allParentsCurrentYearExtended[ , nrow := NULL]
    ##setorder(allParentsCurrentYearExtended , parentID , date) #Just to make inspection more intiutive
    ##Data inspected, ordered expected with an entry of educational level for each month for all participants with data available.
    ##Merging onto main dataset: 
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					allParentsCurrentYearExtended ,
					by.x = c("currentParent1" , "date") ,
					by.y = c("parentID" , "date") ,
					all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					allParentsCurrentYearExtended ,
					by.x = c("currentParent2" , "date") ,
					by.y = c("parentID" , "date") ,
					all.x = TRUE)
    ##Classifying highest family level of education:
    analysisDatasetCurrentYear[education.x == "Tertiary education or higher" |
				 education.y == "Tertiary education or higher" ,
			       familyEducationalLevel := "Tertiary education or higher"]
    analysisDatasetCurrentYear[is.na(familyEducationalLevel) &
				 (education.x == "Secondary education" |
				    education.y == "Secondary education") ,                      
			       familyEducationalLevel := "Secondary education"]
    analysisDatasetCurrentYear[is.na(familyEducationalLevel) &
				 (education.x == "Primary education" |
				    education.y == "Primary education") ,                      
			       familyEducationalLevel := "Primary education"]
    analysisDatasetCurrentYear[ , familyEducationalLevel :=
				  factor(familyEducationalLevel ,
					 levels = c("Primary education" ,
						    "Secondary education" ,
						    "Tertiary education or higher"))]
    ##For monitoring:
    print("Just after educational status")
    print(Sys.time())
    ##Parental abuse as a child:
    parentalAdversity <- fread("parentalAdversity.csv" ,
			       colClasses = c("parentID" = "character" ,
					      "abuseParent" = "integer"))
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					parentalAdversity ,
					by.x = "currentParent1" ,
					by.y = "parentID" ,
					all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					parentalAdversity ,
					by.x = "currentParent2" ,
					by.y = "parentID" ,
					all.x = TRUE ,
					suffixes = c("1" , "2"))
    ##If either parent have been abused but not both (or if the parent is a single-parent):
    analysisDatasetCurrentYear[abuseParent1 == 1 | abuseParent2 == 1 ,
			       parentalAbuseAsChild := 1]
    ##If both parents have been abused:
    analysisDatasetCurrentYear[abuseParent1 == 1 & abuseParent2 == 1 ,
			       parentalAbuseAsChild := 2]
    ##If no parents have been abused:
    analysisDatasetCurrentYear[is.na(abuseParent1) & is.na(abuseParent2) ,
			       parentalAbuseAsChild := 0]

    ##Importing immigration background and status as a refugee:

    ##During inspection there is a peculiar error - for 534 individuals, several origins or refugee status are present. This should not be possible - in principle. To avoid computing-intensive operations on large objects, the error is corrected for the few individuals that make up the problem. The origins of the problem with OPR_LAND seems to stem from bef, where a few individuals have several origins. For these individuals, the code below extracts OPR_LAND from BEF and picks the mode (assuming the administration got it right the majority of times during the available years):  

    Mode <- function(x , na.rm = FALSE) {
	if(na.rm) {
	    x = x[!is.na(x)]
	}
	ux <- unique(x)
	return(ux[which.max(tabulate(match(x , ux)))])
    }
    ##Thank you to jprockbelly from stackexchange.com for providing the above solution for a mode for R (which doesn't have one itself)
    ##Extracting the relevant information from fullPopulation...:
    parentsVarious <- unique(fullPopulationChildrenCurrentYear[ ,
								.(parentID ,
								  foreignParent ,
								  needProtection)])

    ##Creating an index to identify doubles:
    parentsVarious[ , index := 1:.N , by = parentID]
    ##Listing these doubles:
    tempList <- parentsVarious[index == 2 , parentID]
    ##Extracting OPR_LAND for all persons in the doubles:
    befTemp <- bef[pnr %in% tempList , .(pnr , OPR_LAND)]
    ##Reducing to one OPR_LAND for each individual:
    befOprLand <- befTemp[ , OPR_LAND := Mode(OPR_LAND) , by = pnr]
    ##Coding the befOprLand re-using the classification code from above:
    befOprLand[OPR_LAND %in% danishOrigin , foreignParent := 0]
    befOprLand[!(OPR_LAND %in% danishOrigin) & !is.na(OPR_LAND) , foreignParent := 1]
    befOprLand[is.na(OPR_LAND) , foreignParent := NA]
    befOprLand[OPR_LAND %in% unknownOrigin , foreignParent := NA]

    ##The origins of the problem with refugee status is assumed to be several entries for the same individual in ophgin and ophg. It is assumed that the first status is likely to be most relevant, as later changes of status might be related to job changes etc., and also to minimize conditioning on the future. Thus for everyone with several states, the state at the first official permit for residence is preferred. From ophg there are a number of entries dated 1600-01-01 - these are assumed to be first entries but without specific dates.  
    ##Extracting relevant PNRs:
    ophginTemp <- rbindlist(list(ophgin[PNR %in% tempList] ,
				 ophg[PNR %in% tempList]) ,
				 use.names = TRUE ,
				 fill = TRUE)
    ophginTemp[!is.na(TILLADELSESDATO) , DATO := TILLADELSESDATO]
    ophginTemp[!is.na(INDVANDRINGSDATO) , DATO := INDVANDRINGSDATO]
    ##Reducing to first entry:
    setorder(ophginTemp , PNR , DATO)
    ophginTemp <- unique(ophginTemp , by = "PNR")
    ##Classifying using this:
    ophginTemp[KATEGORI %in% kategoriRefugee , needProtection := 1]
    ophginTemp[GRUNDLAG %in% grundlagRefugee , needProtection := 1]
    ophginTemp[FORKLAR %in% forklarRefugee , needProtection := 1]
    ophginTemp[is.na(needProtection) , needProtection := 0]
    ##Joining ophginTemp and befOprLand against tempList to mimic the form of parentsVarious:
    replaceParentsVarious <- as.data.table(tempList)
    replaceParentsVarious <-
	merge(replaceParentsVarious ,
	      befOprLand ,
	      by.x = "tempList" ,
	      by.y = "pnr" ,
	      all.x = TRUE)
    replaceParentsVarious <- unique(replaceParentsVarious)
    replaceParentsVarious <-
	merge(replaceParentsVarious ,
	      ophginTemp[ ,
			 .(PNR , needProtection)] ,
	      by.x = "tempList" ,
	      by.y = "PNR" ,
	      all.x = TRUE)
    ##This makes sense because of how the variable is coded - see above: 
    replaceParentsVarious[is.na(needProtection) , needProtection := 0]
    replaceParentsVarious[ , OPR_LAND := NULL]
    setnames(replaceParentsVarious , "tempList" , "parentID")
    ##Replacing the values in parentsVarious with the duplicate-corrected version:
    parentsVarious[ , index := NULL]
    parentsVarious <- parentsVarious[!(parentID %in% tempList)]
    parentsVarious <- rbindlist(list(parentsVarious , replaceParentsVarious) , use.names = TRUE)

    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					parentsVarious ,
					by.x = "currentParent1" ,
					by.y = "parentID" ,
					all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					parentsVarious ,
					by.x = "currentParent2" ,
					by.y = "parentID" ,
					all.x = TRUE ,
					suffixes = c("1" , "2"))
    analysisDatasetCurrentYear[foreignParent1 == 1 |
				 foreignParent2 == 1 ,
			       oneForeignParent := 1]
    analysisDatasetCurrentYear[foreignParent1 == 0 &
				 foreignParent2 == 0 , oneForeignParent := 0]
    analysisDatasetCurrentYear[oneForeignParent != 1 &
				 (is.na(foreignParent1) |
				    is.na(foreignParent2)) , oneForeignParent := NA]
    analysisDatasetCurrentYear[needProtection1 == 1 |
				 needProtection2 == 1 , familyNeedProtection := 1]
    analysisDatasetCurrentYear[familyNeedProtection != 1 , familyNeedProtection := 0]
    analysisDatasetCurrentYear[is.na(familyNeedProtection) , familyNeedProtection := 0]

    ##Importing income and neighborhood support, while re-using an object from the count of children for each address:
    ##Adding income and neighborhood support to numberOfAdultsTemp:
    fullPopulationChildrenCurrentYearTemp <-
      unique(fullPopulationChildrenCurrentYear ,
	     by = c("pnr" , "komChild" ,
		    "opgikomChild" , "incomeVariable" ,
		    "parishQuantileDifference100Euros"))[ ,
							  .(pnr ,
							    komChild ,
							    opgikomChild ,
							    incomeVariable ,
							    parishQuantileDifference100Euros)]

    numberOfAdultsTemp <-
      merge(numberOfAdultsTemp ,
	    fullPopulationChildrenCurrentYearTemp ,
	    by.x = c("pnr" ,
		     "kom" ,
		     "opgikom") ,
	    by.y = c("pnr" ,
		     "komChild" ,
		     "opgikomChild") ,
	    all.x = TRUE)
    ##There are some instances here where a child lives at two addresses during the same month. Choosing one arbitrarily over the other (but prioritizing non-missing values):
    setorder(numberOfAdultsTemp , pnr , adrdato , incomeVariable , parishQuantileDifference100Euros , na.last = TRUE)
    numberOfAdultsTemp <- unique(numberOfAdultsTemp , by = c("pnr" , "adrdato"))
    ##Merging the income and parishQuantileDifference to the main dataset:
    analysisDatasetCurrentYear <-
      merge(analysisDatasetCurrentYear ,
	    numberOfAdultsTemp[ ,
				.(pnr , adrdato ,
				  incomeVariable ,
				  parishQuantileDifference100Euros)] ,
	    by.x = c("pnr" , "date") ,
	    by.y = c("pnr" , "adrdato") ,
	    all.x = TRUE)
    ##There are a number of missings here - that is because DST can only give parish info ranging back to 2002. 
    ## ##Importing income and neighborhood support:
    ## childrenVarious <-
    ##     unique(fullPopulationChildrenCurrentYear[!is.na(pnr) ,
    ##     					 .(pnr ,
    ##     					   parishQuantileDifference100Euros ,
    ##     					   incomeVariable)])
    ## analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
    ##     				childrenVarious ,
    ##     				by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ## setnames(analysisDatasetCurrentYear , c("incomeVariable" ,
    ##     				    "parishQuantileDifference100EurosMinusRollingMean") ,
    ##          c("income" , "neighborhoodResources"))


    ##Adding number of (cohabitating) adults in a family
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					unique(countTemp[
					   ,.(pnrChild , adrdato , N)]) ,
					by.x = c("pnr" , "date") ,
					by.y = c("pnrChild" , "adrdato") ,
					all.x = TRUE)
    setnames(analysisDatasetCurrentYear , "N" , "numberOfAdults")

    ##Adding number of (cohabitating) children in a family

    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					unique(countTempChild[
					   ,.(pnrChild , adrdato , N)]) ,
					by.x = c("pnr" , "date") ,
					by.y = c("pnrChild" , "adrdato") ,
					all.x = TRUE)
    setnames(analysisDatasetCurrentYear , "N" , "numberOfChildren")

    ##There is a number of missing values - this seems to correspond to missing values of opgikom in the original dataset. Looking at single cases, there seems to be a number of missing lines for some individuals in BEF - a (hypothetical) pnr could for example have a record in 1996 and 2000 but not in the years between or after these. Upon inspection, there are examples of these children experiencing both the outcome and the exposure - thus, it does not make sense to sensor them. Also, they are not registered as emigrated (looked in VNDS) or dead (looked in DOD) - thus, they seem to exist but are only intermittently surveyed by the population register BEF. The cause for this is unknown to me. I will let them stay in the dataset.  


    ##Setting up variables for the final analysis:  
    ##Preparing the variables for modelling:

    analysisDatasetCurrentYear[ , numberOfAdultsFactor :=
			  cut(numberOfAdults ,
			      breaks = c(0 , 1 , 2 , 10000) ,
			      labels = c("One adult" ,
					 "Two adults" ,
					 "Three or more adults"))]

    analysisDatasetCurrentYear[ , numberOfChildrenFactor :=
			  cut(numberOfChildren ,
			      breaks = c(0 , 1 , 2 , 5 , 10000) ,
			      labels = c("One child" ,
					 "Two children" ,
					 "Three to five children" ,
					 "Six children or more"))]

    analysisDatasetCurrentYear[ ,
			       reconstitutedFamily :=
				   factor(
				       reconstitutedFamily ,
				       levels = c(1 , 2 , 3) ,
				       labels = c("Living with biological parent(s)" ,
						  "Living with one or more unrelated adults" ,
						  "Adopted or in foster care"))]

    analysisDatasetCurrentYear[moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1 == 1 |
			       moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2 == 1 |
			       anorexiaBulimiaGroupDiagCurrentParent1 == 1 |
			       anorexiaBulimiaGroupDiagCurrentParent2 == 1 |
			       bipolarAffectiveDisorderGroupDiagCurrentParent1 == 1 |
			       bipolarAffectiveDisorderGroupDiagCurrentParent2 == 1 |
			       schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1 == 1 |
			       schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2 == 1 |
			       personalityDisorderGroupDiagCurrentParent1 == 1 |
			       personalityDisorderGroupDiagCurrentParent2 == 1 |
			       dementiaGroupDiagCurrentParent1 == 1 |
			       dementiaGroupDiagCurrentParent2 == 1 ,
			       parentalPsychiatricDisease := 1]

    analysisDatasetCurrentYear[
	is.na(parentalPsychiatricDisease) ,
	parentalPsychiatricDisease := 0]

    analysisDatasetCurrentYear[ ,
			       parentalPsychiatricDisease :=
				   factor(parentalPsychiatricDisease ,
					  levels = c(0 , 1) ,
					  labels = c("No psychiatric disease" ,
						     "Any psychiatric disease"))]

    analysisDatasetCurrentYear[is.na(interparentalViolence) ,
			       interparentalViolence := 0] 

    analysisDatasetCurrentYear[ ,
			       interparentalViolence :=
				   factor(interparentalViolence ,
					  levels = c(0 , 1) ,
					  labels = c("No interparental violence" ,
						     "Interparental violence"))]

    analysisDatasetCurrentYear[alcoholAbuseCurrentParent1 == 1 |
			       alcoholAbuseCurrentParent2 == 1 |
			       substanceAbuseCurrentParent1 == 1 |
			       substanceAbuseCurrentParent2 == 1 ,
			       parentalSubstanceAbuse:= 1]

    analysisDatasetCurrentYear[is.na(parentalSubstanceAbuse) ,
			       parentalSubstanceAbuse := 0]

    analysisDatasetCurrentYear[ , parentalSubstanceAbuse :=
				      factor(parentalSubstanceAbuse ,
					     levels = c(0 , 1) ,
					     labels = c("No parental substance abuse" ,
							"Parental substance abuse"))]

    analysisDatasetCurrentYear[ , calendarTimeGroup := cut(date ,
					       breaks = c(as.Date("1997-01-01") ,
							  as.Date("2003-01-01") ,
							  as.Date("2010-01-01") ,
							  as.Date("2019-01-01")) ,
					       labels = c("1997-2002" ,
							  "2003-2009" ,
							  "2010-2018"))]
    ##For some reason, the last date is not accepted in the interval when using dates (but it is in cut when using numbers). Maybe there is some hidden property, a la some hours or something, hidden somewhere - moving the dates one month solves the problem. 

    analysisDatasetCurrentYear[ ,
			       parentalAbuseAsChild :=
				   factor(parentalAbuseAsChild ,
					  levels = c(0 , 1 , 2) ,
					  labels = c("No maltreatment or neglect" ,
						     "Maltreatment or neglect, one parent" ,
						     "Maltreatment or neglect, both parents"))]

    analysisDatasetCurrentYear[ , oneForeignParent :=
				      factor(oneForeignParent ,
					     levels = c(0 , 1) ,
					     labels = c("No foreign parents" ,
						 "One or more foreign parents"))]

    analysisDatasetCurrentYear[ ,
			       familyNeedProtection :=
				   factor(familyNeedProtection ,
					  levels = c(0 , 1) ,
					  labels = c("Not in need of protection" ,
						     "In need of protection"))]
    analysisDatasetCurrentYear[ , childAge := as.numeric(childAge)]

    analysisDatasetCurrentYear[ , childAgeGroup :=
				      cut(childAge ,
					  breaks = c(-1 , 7 , 19) ,
					  labels = c("Child 0-6 years old" ,
						     "Child 7-18 years old"))]

    analysisDatasetCurrentYear[ , meanParentalAge := as.numeric(meanParentalAge)]
    analysisDatasetCurrentYear[ , parentalAgeGroup :=
				      cut(meanParentalAge ,
					  breaks = c(10 , 25 , 35 , 65 , 100) ,
					  labels = c("Mean parental age 25 or less" ,
						     "Mean parental age >25-35" ,
						     "Mean parental age >35-65" ,
						     "Mean parental age >65-100"))]

    analysisDatasetCurrentYear[is.na(outcomePhysicalAbuse) , outcomePhysicalAbuse := 0]

    analysisDatasetCurrentYear[ , c("birthDateParent1" ,
				    "birthDateParent2" ,
				    "parentFoedAdopOrig1" ,
				    "parentFoedAdopOrig2" ,
				    "originalParent1" ,
				    "originalParent2" ,
				    "doddatoParent1" ,
				    "doddatoParent2" ,
				    "education.x" ,
				    "education.y" ,
				    "abuseParent1" ,
				    "abuseParent2" ,
				    "foreignParent1" ,
				    "foreignParent2" ,
				    "needProtection1" ,
				    "needProtection2") := NULL]


    ##Commenting the last line-strategy out - I've found something far more effective, see the memoryLastYear object
    ## ##Writing the last line for every parent to a separate file to enable transfer of chronic diagnoses to next year - as entries from earlier years are already written into new years and thus will be "catched" here, this list needs no memory from year to year: 
    ## setorder(analysisDatasetCurrentYear , currentParent1 , -date)
    ## lastLine <- unique(analysisDatasetCurrentYear , by = "currentParent1")
    ## setorder(analysisDatasetCurrentYear , currentParent2 , -date)
    ## lastLine <- rbindlist(list(lastLine , unique(analysisDatasetCurrentYear , by = "currentParent2")))
    ## ##Removing entries with no disease:
    ## lastLine <- lastLine[!is.na(hypertensionGroupDiagCurrentParent1) | 
    ##     		 !is.na(hypertensionGroupDiagCurrentParent2) |
    ##     		 !is.na(dyslipidemiaGroupDiagCurrentParent1) |
    ##     		 !is.na(dyslipidemiaGroupDiagCurrentParent2) |
    ##     		 !is.na(ischemicHeartDiseaseGroupDiagCurrentParent1) |
    ##     		 !is.na(ischemicHeartDiseaseGroupDiagCurrentParent2) |
    ##     		 !is.na(atrialFibrillationGroupDiagCurrentParent1) |
    ##     		 !is.na(atrialFibrillationGroupDiagCurrentParent2) |
    ##     		 !is.na(heartFailureGroupDiagCurrentParent1) |
    ##     		 !is.na(heartFailureGroupDiagCurrentParent2) |
    ##     		 !is.na(peripheralArteryOcclusiveGroupDiagCurrentParent1) | 
    ##     		 !is.na(peripheralArteryOcclusiveGroupDiagCurrentParent2) | 
    ##     		 !is.na(strokeGroupDiagCurrentParent1) |
    ##     		 !is.na(strokeGroupDiagCurrentParent2) |
    ##     		 !is.na(diabetesMellitusGroupDiagCurrentParent1) |
    ##     		 !is.na(diabetesMellitusGroupDiagCurrentParent2) |
    ##     		 !is.na(thyroidDisorderGroupDiagCurrentParent1) | 
    ##     		 !is.na(thyroidDisorderGroupDiagCurrentParent2) | 
    ##     		 !is.na(goutGroupDiagCurrentParent1) |
    ##     		 !is.na(goutGroupDiagCurrentParent2) |
    ##     		 !is.na(chronicPulmonaryDiseaseGroupDiagCurrentParent1) | 
    ##     		 !is.na(chronicPulmonaryDiseaseGroupDiagCurrentParent2) | 
    ##     		 !is.na(allergyGroupDiagCurrentParent1) | 
    ##     		 !is.na(allergyGroupDiagCurrentParent2) | 
    ##     		 !is.na(ulcerChronicGastritisGroupDiagCurrentParent1) | 
    ##     		 !is.na(ulcerChronicGastritisGroupDiagCurrentParent2) | 
    ##     		 !is.na(chronicLiverDiseaseGroupDiagCurrentParent1) | 
    ##     		 !is.na(chronicLiverDiseaseGroupDiagCurrentParent2) | 
    ##     		 !is.na(inflammatoryBowelDiseaseGroupDiagCurrentParent1) |
    ##     		 !is.na(inflammatoryBowelDiseaseGroupDiagCurrentParent2) |
    ##     		 !is.na(diverticularDiseaseOfIntestineGroupDiagCurrentParent1) |
    ##     		 !is.na(diverticularDiseaseOfIntestineGroupDiagCurrentParent2) |
    ##     		 !is.na(chronicKidneyDiseaseGroupDiagCurrentParent1) |
    ##     		 !is.na(chronicKidneyDiseaseGroupDiagCurrentParent2) |
    ##     		 !is.na(prostateDisordersGroupDiagCurrentParent1) | 
    ##     		 !is.na(prostateDisordersGroupDiagCurrentParent2) | 
    ##     		 !is.na(connectiveTissueDisordersGroupDiagCurrentParent1) | 
    ##     		 !is.na(connectiveTissueDisordersGroupDiagCurrentParent2) | 
    ##     		 !is.na(osteoporosisGroupDiagCurrentParent1) |
    ##     		 !is.na(osteoporosisGroupDiagCurrentParent2) |
    ##     		 !is.na(anemiasGroupDiagCurrentParent1) | 
    ##     		 !is.na(anemiasGroupDiagCurrentParent2) | 
    ##     		 !is.na(cancerGroupDiagCurrentParent1) |
    ##     		 !is.na(cancerGroupDiagCurrentParent2) |
    ##     		 !is.na(visionProblemGroupDiagCurrentParent1) | 
    ##     		 !is.na(visionProblemGroupDiagCurrentParent2) | 
    ##     		 !is.na(migraineGroupDiagCurrentParent1) |
    ##     		 !is.na(migraineGroupDiagCurrentParent2) |
    ##     		 !is.na(epilepsyGroupDiagCurrentParent1) |
    ##     		 !is.na(epilepsyGroupDiagCurrentParent2) |
    ##     		 !is.na(parkinsonsDiseaseGroupDiagCurrentParent1) | 
    ##     		 !is.na(parkinsonsDiseaseGroupDiagCurrentParent2) | 
    ##     		 !is.na(multipleSclerosisGroupDiagCurrentParent1) | 
    ##     		 !is.na(multipleSclerosisGroupDiagCurrentParent2) | 
    ##     		 !is.na(neuropathiesGroupDiagCurrentParent1) |
    ##     		 !is.na(neuropathiesGroupDiagCurrentParent2) |
    ##     		 !is.na(moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1) | 
    ##     		 !is.na(moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2) | 
    ##     		 !is.na(anorexiaBulimiaGroupDiagCurrentParent1) | 
    ##     		 !is.na(anorexiaBulimiaGroupDiagCurrentParent2) | 
    ##     		 !is.na(bipolarAffectiveDisorderGroupDiagCurrentParent1) |
    ##     		 !is.na(bipolarAffectiveDisorderGroupDiagCurrentParent2) |
    ##     		 !is.na(schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1) |
    ##     		 !is.na(schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2) |
    ##     		 !is.na(personalityDisorderGroupDiagCurrentParent1) | 
    ##     		 !is.na(personalityDisorderGroupDiagCurrentParent2) | 
    ##     		 !is.na(dementiaGroupDiagCurrentParent1) |
    ##     		 !is.na(dementiaGroupDiagCurrentParent2) |
    ##     		 !is.na(otherGroupDiagCurrentParent1) | 
    ##     		 !is.na(otherGroupDiagCurrentParent2) | 
    ##     		 !is.na(pretermBirthGroupDiagCurrentParent1) |
    ##     		 !is.na(pretermBirthGroupDiagCurrentParent2) |
    ##     		 !is.na(acuteCaesarianSectionGroupDiagCurrentParent1) | 
    ##     		 !is.na(acuteCaesarianSectionGroupDiagCurrentParent2) | 
    ##     		 !is.na(alcoholAbuseCurrentParent1) | 
    ##     		 !is.na(alcoholAbuseCurrentParent2) | 
    ##     		 !is.na(substanceAbuseCurrentParent1) | 
    ##     		 !is.na(substanceAbuseCurrentParent2) | 
    ##     		 dyslipidemiaGroupLmdbCurrentParent1LmdbText != "NA" |
    ##     		 dyslipidemiaGroupLmdbCurrentParent2LmdbText != "NA" |
    ##     		 ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 diabetesMellitusGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 thyroidDisorderGroupLmdbCurrentParent1LmdbText == "NA" | 
    ##     		 chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 allergyGroupLmdbCurrentParent1LmdbText == "NA" | 
    ##     		 osteoporosisGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 painfulConditionGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 migraineGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 epilepsyGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbText == "NA" |
    ##     		 dementiaGroupLmdbCurrentParentCurrentParent1LmdbText == "NA" |
    ##     		 ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 diabetesMellitusGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 thyroidDisorderGroupLmdbCurrentParent2LmdbText == "NA" | 
    ##     		 chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 allergyGroupLmdbCurrentParent2LmdbText == "NA" | 
    ##     		 osteoporosisGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 painfulConditionGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 migraineGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 epilepsyGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbText == "NA" |
    ##     		 dementiaGroupLmdbCurrentParent2LmdbText == "NA"]
    ## ##Removing entries that are too old:
    ## lastLine <- lastLine[(hypertensionGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(hypertensionGroupDiagEndDateCurrentParent1)) | 
    ##     		 (hypertensionGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(hypertensionGroupDiagEndDateCurrentParent2)) | 
    ##     		 (dyslipidemiaGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(dyslipidemiaGroupDiagEndDateCurrentParent1)) | 
    ##     		 (dyslipidemiaGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(dyslipidemiaGroupDiagEndDateCurrentParent2)) | 
    ##     		 (ischemicHeartDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(ischemicHeartDiseaseGroupDiagEndDateCurrentParent1)) | 
    ##     		 (ischemicHeartDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(ischemicHeartDiseaseGroupDiagEndDateCurrentParent2)) | 
    ##     		 (atrialFibrillationGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(atrialFibrillationGroupDiagEndDateCurrentParent1)) | 
    ##     		 (atrialFibrillationGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(atrialFibrillationGroupDiagEndDateCurrentParent2)) | 
    ##     		 (heartFailureGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(heartFailureGroupDiagEndDateCurrentParent1)) | 
    ##     		 (heartFailureGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(heartFailureGroupDiagEndDateCurrentParent2)) | 
    ##     		 (peripheralArteryOcclusiveGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(peripheralArteryOcclusiveGroupDiagEndDateCurrentParent1)) |
    ##     		 (peripheralArteryOcclusiveGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(peripheralArteryOcclusiveGroupDiagEndDateCurrentParent2)) |
    ##     		 (strokeGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(strokeGroupDiagEndDateCurrentParent1)) | 
    ##     		 (strokeGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(strokeGroupDiagEndDateCurrentParent2)) | 
    ##     		 (diabetesMellitusGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(diabetesMellitusGroupDiagEndDateCurrentParent1)) | 
    ##     		 (diabetesMellitusGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(diabetesMellitusGroupDiagEndDateCurrentParent2)) | 
    ##     		 (thyroidDisorderGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(thyroidDisorderGroupDiagEndDateCurrentParent1)) |
    ##     		 (thyroidDisorderGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(thyroidDisorderGroupDiagEndDateCurrentParent2)) |
    ##     		 (goutGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(goutGroupDiagEndDateCurrentParent1)) | 
    ##     		 (goutGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(goutGroupDiagEndDateCurrentParent2)) | 
    ##     		 (chronicPulmonaryDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(chronicPulmonaryDiseaseGroupDiagEndDateCurrentParent1)) |
    ##     		 (chronicPulmonaryDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(chronicPulmonaryDiseaseGroupDiagEndDateCurrentParent2)) |
    ##     		 (allergyGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(allergyGroupDiagEndDateCurrentParent1)) |
    ##     		 (allergyGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(allergyGroupDiagEndDateCurrentParent2)) |
    ##     		 (ulcerChronicGastritisGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(ulcerChronicGastritisGroupDiagEndDateCurrentParent1)) |
    ##     		 (ulcerChronicGastritisGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(ulcerChronicGastritisGroupDiagEndDateCurrentParent2)) |
    ##     		 (chronicLiverDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(chronicLiverDiseaseGroupDiagEndDateCurrentParent1)) |
    ##     		 (chronicLiverDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(chronicLiverDiseaseGroupDiagEndDateCurrentParent2)) |
    ##     		 (inflammatoryBowelDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(inflammatoryBowelDiseaseGroupDiagEndDateCurrentParent1)) | 
    ##     		 (inflammatoryBowelDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(inflammatoryBowelDiseaseGroupDiagEndDateCurrentParent2)) | 
    ##     		 (diverticularDiseaseOfIntestineGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(diverticularDiseaseOfIntestineGroupDiagEndDateCurrentParent1)) | 
    ##     		 (diverticularDiseaseOfIntestineGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(diverticularDiseaseOfIntestineGroupDiagEndDateCurrentParent2)) | 
    ##     		 (chronicKidneyDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(chronicKidneyDiseaseGroupDiagEndDateCurrentParent1)) | 
    ##     		 (chronicKidneyDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(chronicKidneyDiseaseGroupDiagEndDateCurrentParent2)) | 
    ##     		 (prostateDisordersGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(prostateDisordersGroupDiagEndDateCurrentParent1)) |
    ##     		 (prostateDisordersGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(prostateDisordersGroupDiagEndDateCurrentParent2)) |
    ##     		 (connectiveTissueDisordersGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(connectiveTissueDisordersGroupDiagEndDateCurrentParent1)) |
    ##     		 (connectiveTissueDisordersGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(connectiveTissueDisordersGroupDiagEndDateCurrentParent2)) |
    ##     		 (osteoporosisGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(osteoporosisGroupDiagEndDateCurrentParent1)) | 
    ##     		 (osteoporosisGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(osteoporosisGroupDiagEndDateCurrentParent2)) | 
    ##     		 (anemiasGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(anemiasGroupDiagEndDateCurrentParent1)) |
    ##     		 (anemiasGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(anemiasGroupDiagEndDateCurrentParent2)) |
    ##     		 (cancerGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(cancerGroupDiagEndDateCurrentParent1)) | 
    ##     		 (cancerGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(cancerGroupDiagEndDateCurrentParent2)) | 
    ##     		 (visionProblemGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(visionProblemGroupDiagEndDateCurrentParent1)) |
    ##     		 (visionProblemGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(visionProblemGroupDiagEndDateCurrentParent2)) |
    ##     		 (migraineGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(migraineGroupDiagEndDateCurrentParent1)) | 
    ##     		 (migraineGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(migraineGroupDiagEndDateCurrentParent2)) | 
    ##     		 (epilepsyGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(epilepsyGroupDiagEndDateCurrentParent1)) | 
    ##     		 (epilepsyGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(epilepsyGroupDiagEndDateCurrentParent2)) | 
    ##     		 (parkinsonsDiseaseGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(parkinsonsDiseaseGroupDiagEndDateCurrentParent1)) |
    ##     		 (parkinsonsDiseaseGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(parkinsonsDiseaseGroupDiagEndDateCurrentParent2)) |
    ##     		 (multipleSclerosisGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(multipleSclerosisGroupDiagEndDateCurrentParent1)) |
    ##     		 (multipleSclerosisGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(multipleSclerosisGroupDiagEndDateCurrentParent2)) |
    ##     		 (neuropathiesGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(neuropathiesGroupDiagEndDateCurrentParent1)) | 
    ##     		 (neuropathiesGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(neuropathiesGroupDiagEndDateCurrentParent2)) | 
    ##     		 (moodStressrelatedOrAnxietyDisordersGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(moodStressrelatedOrAnxietyDisordersGroupDiagEndDateCurrentParent1)) |
    ##     		 (moodStressrelatedOrAnxietyDisordersGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(moodStressrelatedOrAnxietyDisordersGroupDiagEndDateCurrentParent2)) |
    ##     		 (anorexiaBulimiaGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(anorexiaBulimiaGroupDiagEndDateCurrentParent1)) |
    ##     		 (anorexiaBulimiaGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(anorexiaBulimiaGroupDiagEndDateCurrentParent2)) |
    ##     		 (bipolarAffectiveDisorderGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(bipolarAffectiveDisorderGroupDiagEndDateCurrentParent1)) | 
    ##     		 (bipolarAffectiveDisorderGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(bipolarAffectiveDisorderGroupDiagEndDateCurrentParent2)) | 
    ##     		 (schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDateCurrentParent1)) | 
    ##     		 (schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(schizophreniaOrSchizoaffectiveDisorderGroupDiagEndDateCurrentParent2)) | 
    ##     		 (personalityDisorderGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(personalityDisorderGroupDiagEndDateCurrentParent1)) |
    ##     		 (personalityDisorderGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(personalityDisorderGroupDiagEndDateCurrentParent2)) |
    ##     		 (dementiaGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(dementiaGroupDiagEndDateCurrentParent1)) | 
    ##     		 (dementiaGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(dementiaGroupDiagEndDateCurrentParent2)) | 
    ##     		 (otherGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(otherGroupDiagEndDateCurrentParent1)) |
    ##     		 (otherGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(otherGroupDiagEndDateCurrentParent2)) |
    ##     		 (pretermBirthGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(pretermBirthGroupDiagEndDateCurrentParent1)) | 
    ##     		 (pretermBirthGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(pretermBirthGroupDiagEndDateCurrentParent2)) | 
    ##     		 (acuteCaesarianSectionGroupDiagEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(acuteCaesarianSectionGroupDiagEndDateCurrentParent1)) |
    ##     		 (acuteCaesarianSectionGroupDiagEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(acuteCaesarianSectionGroupDiagEndDateCurrentParent2)) |
    ##     		 (alcoholAbuseEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(alcoholAbuseEndDateCurrentParent1)) |
    ##     		 (alcoholAbuseEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(alcoholAbuseEndDateCurrentParent2)) |
    ##     		 (substanceAbuseEndDateCurrentParent1 >= firstDate &
    ##     		  !is.na(substanceAbuseEndDateCurrentParent1)) |
    ##     		 (substanceAbuseEndDateCurrentParent2 >= firstDate &
    ##     		  !is.na(substanceAbuseEndDateCurrentParent2))]
    ## categoriesLastLine <- categories[!grepl('Charlson' , categories)]
    ## mergeFromLastLine <- data.table()
    ## for (i in categoriesLastLine) {
    ##     for (j in c("CurrentParent1" , "CurrentParent2")) {
    ##         tempLast <- lastLine[!is.na(get(paste0(i , j)))]
    ##         tempList <- c(paste0("d_inddtoParent" , i , j) , paste0(i , j) , paste0(i , "EndDate" , j) , gsub('C' , 'c' , j))##The gsub-part is just because CurrentParent is with a lowercase in the last variable 
    ##         tempDT <- tempLast[ , ..tempList]
    ##         setnames(tempDT , c(paste0("d_inddtoParent" , i , j) , paste0(i , j) , paste0(i , "EndDate" , j) , gsub('C' , 'c' , j)) , c("d_inddtoParent" , i , paste0(i , "EndDate") , "parentID"))
    ##         mergeFromLastLine <- rbindlist(list(mergeFromLastLine , tempDT) , use.names = TRUE , fill = TRUE)
    ##     }
    ## }
    ## ##Please note the eksd added by the following algorithm might not be correct - this is because it would drain even more computer power to get them, and they do not disturb the correct allocation of doses as long as the endDate is correct. 

    ## for (i in categoriesLmdb) {
    ##     for (j in c("CurrentParent1" , "CurrentParent2")) {
    ##         tempLast <- lastLine[!is.na(get(paste0(i , j , "LmdbTotal")))]
    ##         tempList <- c(paste0("eksd" , i , j) , paste0(i , j , "LmdbText") , paste0(i , j , "LmdbEndDateText") , gsub('C' , 'c' , j))##The gsub-part is just because CurrentParent is with a lowercase in the last variable
    ##         tempDT <- tempLast[ , ..tempList]
    ##         ##This terrifying block takes the conjugated prescriptions (one cell containing for example 4 dates) and expands them into separate lines:
    ##         eval(parse(text = paste0("tempDT <- tempDT[ , list(" ,
    ##     			     gsub('C' , 'c' , j) ,
    ##     			     " = " ,
    ##     			     gsub('C' , 'c' , j) ,
    ##     			     " , eksd = " ,
    ##     			     paste0("eksd" , i , j) ,
    ##     			     " , " ,
    ##     			     i ,
    ##     			     " = regmatches(" ,
    ##     			     paste0(i , j , "LmdbText") ,
    ##     			     " , gregexpr(', ' , " ,
    ##     			     paste0(i , j , "LmdbText") ,
    ##     			     " , perl = T) , invert = TRUE)[[1]] , " ,
    ##     			     paste0(i , "EndDate") ,
    ##     			     " = regmatches(" ,
    ##     			     paste0(i , j , "LmdbEndDateText") ,
    ##     			     " , gregexpr(', ' , " ,
    ##     			     paste0(i , j , "LmdbEndDateText") ,
    ##     			     " , perl = T) , invert = TRUE)[[1]]) , by = 1:nrow(tempDT)]")))
    ##         tempDT[ , nrow := NULL]
    ##         mergeFromLastLine <-
    ##     	rbindlist(list(
    ##     	    mergeFromLastLine ,
    ##     	    tempDT) ,
    ##     	    use.names = TRUE ,
    ##     	    fill = TRUE)
    ##     }
    ## } 
    fwrite(analysisDatasetCurrentYear , paste0("analysisDataset" , k , ".csv"))
    ##For monitoring:
    print("Just wrote year file")
    ##Writing a few additional files to secure myself against breakdowns:
    fwrite(memoryLastYear , paste0("memoryLastYear" , k , ".csv"))
    fwrite(deathList , paste0("deathList" , k , ".csv"))
    fwrite(outcomeList , paste0("outcomeList" , k , ".csv"))
    fwrite(noParentsList , paste0("noParentsList" , k , ".csv"))
    fwrite(exclusionList , paste0("exclusionList" , k , ".csv"))
    print(Sys.time())
  }

  ##Just checking what takes up space in the memory:
  ## obj <- ls()
  ## total <- 0
  ## for (i in obj) {
  ##   print(i)
  ##   temp <- object.size(get(i))
  ##   print(temp)
  ##   total <- total + temp
  ##   print(total)
  ## }

#+end_src

** Code block to generate counts and economic data - this block and the variables therein should take over from previous versions
#+begin_src R :session rsession :results output :exports both
  library(lubridate)
  library(data.table)
  nrows <- Inf
  setDTthreads(20)

  ##This is a special version of the code above, only generating economic and count variables but doing so without some of the censoring relevant in the dataset above. This should be run in sequence with the above script.

  ##Getting the full population
  setwd("d:/data/Workdata/707544/Population")
  fullPopulation <- fread("population_final.csv" , nrows = nrows , colClasses = (pnr = "character"))
  ##Figuring out which ones are children and at what times
  setwd("d:/data/Workdata/707544/Grunddata")
  ##lprFoedsler <- fread("lprfoedsler_pop_080621.csv" , nrows = nrows) #Does not tie parents and child - only info on parity and length of pregnancy.
  ##lprFoeds <- fread("lprfoeds_pop_080621.csv" , nrows = nrows)
  ftBarn <- fread("ftbarn_pop_070621.csv" , nrows = nrows , colClasses = (pnr = "character")) #FOED_DAG
  ##cpst <- fread("cpst_pop_070621.csv" , nrows = nrows)
  ftBarn <- ftBarn[!is.na(pnr)]
  ftBarn <- ftBarn[pnr != ""]
  bef <- fread("bef_pop_230921.csv" ,
	       nrows = nrows ,
	       select = c("pnr" , "opgikom" , "MOR_ID" ,
			  "FAR_ID" , "BOP_VFRA" , "FOED_DAG" ,
			  "OPR_LAND" , "VAN_VTIL" , "YEAR" ,
			  "kom" , "FM_MARK") ,
	       colClasses = c("pnr" = "character" , "opgikom" = "character" , "MOR_ID" = "character" , "FAR_ID" = "character" , "OPR_LAND" = "character" , "kom" = "character"))
  bef <- bef[!is.na(pnr)]
  bef <- bef[pnr != ""]
  ##Make everything dates:
  ftBarn[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  ftBarn[ , MOR_VFRA := floor_date(as.Date(MOR_VFRA , format = "%m/%d/%Y") , unit = "month")]
  ftBarn[ , FAR_VFRA := floor_date(as.Date(FAR_VFRA , format = "%m/%d/%Y") , unit = "month")]
  bef[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  bef[ , BOP_VFRA := floor_date(as.Date(BOP_VFRA , format = "%m/%d/%Y") , unit = "month")]
  bef[ , VAN_VTIL := floor_date(as.Date(VAN_VTIL , format = "%m/%d/%Y") , unit = "month")]
  ##Side note on performance - seems I am loading full datasets here, likely not necessary, could be cut down if memory is an issue.
  mfr <- fread("mfr_pop_070621.csv" , nrows = nrows , colClasses = c("pnr" = "character" , "cpr_fader" = "character" , "cpr_moder" = "character")) #foedselsdato
  mfr <- mfr[!is.na(pnr)]
  mfr <- mfr[pnr != ""]
  mfr[ , foedselsdato := floor_date(as.Date(foedselsdato , format = "%m/%d/%Y") , unit = "month")]

  setkey(fullPopulation , pnr)
  setkey(ftBarn , pnr)
  setkey(bef , pnr)
  setkey(mfr , pnr)

  ##Producing a version of ftBarn without concurrent parents (likely the result of immediate adoption after birth - two parents with the same role "start" at the same time:
  ftBarnMod <- copy(ftBarn)
  ftBarnMod[MOR_VFRA == FOED_DAG & MOR2 != "" , MOR1 := ""]
  ftBarnMod[FAR_VFRA == FOED_DAG & FAR2 != "" , FAR1 := ""]
  ##Merging on birth date information:
  fullPopulation <- merge(fullPopulation , ftBarn[ , .(pnr , FOED_DAG)] , all.x = TRUE)
  fullPopulation <- merge(fullPopulation , bef[ , .(pnr , FOED_DAG)] , all.x = TRUE , suffixes = c("ftBarn" , "bef") , no.dups = TRUE)
  ##bef introduces a number of duplicates - removing those:
  fullPopulation <- unique(fullPopulation)
  fullPopulation <- merge(fullPopulation , mfr[ , .(pnr , foedselsdato)] , all.x = TRUE)
  ##Define for each date who's a child (<18 years old):
  ##Prioritize data from bef over ftBarn over MFR:
  fullPopulation[!is.na(FOED_DAGbef) , birthDate := FOED_DAGbef]
  fullPopulation[!is.na(FOED_DAGftBarn) & is.na(birthDate) , birthDate := FOED_DAGftBarn]
  fullPopulation[!is.na(foedselsdato) & is.na(birthDate) , birthDate := foedselsdato]
  ##Checked by viewing - gives correctly formatted date for all individuals who has a non-missing entry in one of three variables.
  ##Reducing the dataset to the subjects that are children at some point between 1997 and 2018:
  ##6575 comes from 18*365.24 - if the birth date minus the starting date of the study is less than -6575 this means that the subject was already 18 years old when the study started. All larger numbers means the person was less than 18 at some time during the study.
  fullPopulation[(birthDate-as.Date("1997-01-01")) > -6575 , child := TRUE]
  fullPopulationChildren <- fullPopulation[child == TRUE , .(pnr , birthDate)]
  ##Writing a list of children to facilitate exclusion if physical abuse took place before the study began:
  fwrite(fullPopulationChildren , "fullPopulationChildren.csv")
  ##Importing the results of that list and removing the children:
  childAbuseExclusion <- fread("childAbuseExclusion.csv" , colClasses =("pnr" = "character"))
  fullPopulationChildren <- merge(fullPopulationChildren , childAbuseExclusion , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
  fullPopulationChildren <- fullPopulationChildren[is.na(childAbuseExclusion)]
  fullPopulationChildren[ , childAbuseExclusion := NULL]
  ##Adding the parents:
  setkey(fullPopulationChildren , pnr)
  setkey(ftBarn , pnr)
  fullPopulationChildren <- merge(x = fullPopulationChildren , y = ftBarnMod[ , .(pnr , MOR1 , MOR2 , FAR1 , FAR2 , MOR_VFRA , FAR_VFRA)] , all.x = TRUE)
  rm(ftBarnMod)
  fullPopulationChildren <- unique(fullPopulationChildren)
  ##Looking for additional parents, that is children with more than two parents during their childhood. I have not yet found any such children, but instead some inconsistensies between ftbarn and bef. Will go with parent 1 and 2 for now.
  ##fullPopulationChildren <- merge(fullPopulationChildren , bef[ , .(pnr , FAMILIE_ID , MOR_ID , FAR_ID)] , all.x = TRUE)
  ##fullPopulationChildren <- unique(fullPopulationChildren)
  ##Read in family register - I have no variable in BEF that can tell me when a family changes, so I need estimates of when the child had a new parent
  ##fam <- fread("fam_pop_080621.csv" , nrows = nrows , colClasses = (FAMILIE_ID = "character"))
  ##fullPopulationChildren <- merge(fullPopulationChildren , fam , by.x = "FAMILIE_ID" , by.y = "FAMILIE_ID" , all.x = TRUE)

  ##Preparing add-on of additional parents:
  ##Upon inspecting the data structure of ftBarn I conclude that MOR and FAR_VFRA are for the last parent - thus if there is no father or mother 2, the date is usually the same as the birth date, and belongs to parent one. If there is a parent 2, the date is for this person. I will code this (for some reason, when character is the class of a column, all NAs are coded as "")
  fullPopulationChildren[MOR2 == "" , MOR_VFRA1 := MOR_VFRA]
  fullPopulationChildren[FAR2 == "" , FAR_VFRA1 := FAR_VFRA]
  fullPopulationChildren[MOR2 != "" & !is.na(MOR2) , MOR_VFRA2 := MOR_VFRA]
  fullPopulationChildren[MOR2 != "" & !is.na(MOR2) , MOR_VFRA1 := birthDate]
  fullPopulationChildren[FAR2 != "" & !is.na(FAR2) , FAR_VFRA2 := FAR_VFRA]
  fullPopulationChildren[FAR2 != "" & !is.na(FAR2) , FAR_VFRA1 := birthDate]
  ##Adding these lines as some MOR and FAR1 has been deleted to avoid "double parenting" as a result of early adoption:
  fullPopulationChildren[FAR1 == "" , FAR_VFRA1 := NA]
  fullPopulationChildren[MOR1 == "" , MOR_VFRA1 := NA]
  ##Adding on "new" parents for each year:
  parentNo <- 3
  for (i in 1997:2018) {
    fullPopulationChildren <- merge(fullPopulationChildren , bef[YEAR == i , .(pnr , FAR_ID , MOR_ID , YEAR)] ,
				    by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ##As I do not know when the change in parent occurred, the first of July is assumed:
    fullPopulationChildren[ , (paste0("FAR_VFRA" , parentNo)) :=
			      as.Date(paste0(YEAR , "-07-01"))]
    fullPopulationChildren[ , (paste0("MOR_VFRA" , parentNo)) :=
			      as.Date(paste0(YEAR , "-07-01"))]
    fullPopulationChildren[ , YEAR := NULL]
    setnames(fullPopulationChildren , c("FAR_ID" , "MOR_ID") ,
	     c(paste0("FAR" , parentNo) , paste0("MOR" , parentNo)))
    print(i)
    parentNo <- parentNo + 1
  }
  ##Visually inspected, performs as expected
  ##Remove IDs for parents that are already there - there should be some far4 without deletion, check again:
  for (i in 3:24) {
    for (j in 1:(i-1)) {
      fullPopulationChildren[get(paste0("MOR" , i)) == get(paste0("MOR" , j)) , (paste0("MOR_VFRA" , i)) := NA]
      fullPopulationChildren[get(paste0("MOR" , i)) == get(paste0("MOR" , j)) , (paste0("MOR" , i)) := ""]
      fullPopulationChildren[get(paste0("FAR" , i)) == get(paste0("FAR" , j)) , (paste0("FAR_VFRA" , i)) := NA]
      fullPopulationChildren[get(paste0("FAR" , i)) == get(paste0("FAR" , j)) , (paste0("FAR" , i)) := ""]
    }
  }
  ##Also remove new VFRA for unknown parents - the dataset should present the latest known parent. This holds a risk of connecting children to parents from which they have been removed for adoption or institutionalized - but usually these children should receive new pnrs for parents. If this does not happen, for these very few cases, the last known parent is used. Determining whether a child actually have any contact with parents with or without parental rights is beyond the capacities of this dataset.
  for (i in 1:24) {
    fullPopulationChildren[is.na(get(paste0("MOR" , i))) , (paste0("MOR_VFRA" , i)) := NA]
    fullPopulationChildren[is.na(get(paste0("FAR" , i))) , (paste0("FAR_VFRA" , i)) := NA]
    fullPopulationChildren[(get(paste0("MOR" , i))) == "" , (paste0("MOR_VFRA" , i)) := NA]
    fullPopulationChildren[(get(paste0("FAR" , i))) == "" , (paste0("FAR_VFRA" , i)) := NA]
  }


  ##When compared with inspections before loop, it is seen that parents that differs from earlier parents remains, but parents that replicate are deleted.
  ##First some helping variables are declared:
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VFRATemp" , i)) := as.Date(character())]
    fullPopulationChildren[ , (paste0("MOR_VFRATemp" , i)) := as.Date(character())]
  }
  ##Then a loop does the following: for each VFRA it 1: empties the helper variables, 2: defines new helper variables for only those that are larger than itself, 3: use this date as VTIL for a parent. Thus the parent has both a start and an end-date, presuming there is a parent-replacement. Otherwise, the end-date is empty.
  for (i in 1:24) {
    for (k in 1:24) {
      fullPopulationChildren[ , (paste0("FAR_VFRATemp" , k)) := NA]
      fullPopulationChildren[ , (paste0("MOR_VFRATemp" , k)) := NA]
    }
    for (j in 1:24) {
      fullPopulationChildren[get(paste0("FAR_VFRA" , i)) <
			       get(paste0("FAR_VFRA" , j)) &
			       !is.na(get(paste0("FAR_VFRA" , j))) ,
			     (paste0("FAR_VFRATemp" , j)) :=
			       get(paste0("FAR_VFRA" , j))]
      fullPopulationChildren[get(paste0("MOR_VFRA" , i)) <
			       get(paste0("MOR_VFRA" , j)) &
			       !is.na(get(paste0("MOR_VFRA" , j))) ,
			     (paste0("MOR_VFRATemp" , j)) :=
			       get(paste0("MOR_VFRA" , j))]
    }
    fullPopulationChildren[ , (paste0("FAR_VTIL" , i)) := pmin(FAR_VFRATemp1 ,
							       FAR_VFRATemp2 ,
							       FAR_VFRATemp3 ,
							       FAR_VFRATemp4 ,
							       FAR_VFRATemp5 ,
							       FAR_VFRATemp6 ,
							       FAR_VFRATemp7 ,
							       FAR_VFRATemp8 ,
							       FAR_VFRATemp9 ,
							       FAR_VFRATemp10 ,
							       FAR_VFRATemp11 ,
							       FAR_VFRATemp12 ,
							       FAR_VFRATemp13 ,
							       FAR_VFRATemp14 ,
							       FAR_VFRATemp15 ,
							       FAR_VFRATemp16 ,
							       FAR_VFRATemp17 ,
							       FAR_VFRATemp18 ,
							       FAR_VFRATemp19 ,
							       FAR_VFRATemp20 ,
							       FAR_VFRATemp21 ,
							       FAR_VFRATemp22 ,
							       FAR_VFRATemp23 ,
							       FAR_VFRATemp24 , na.rm = TRUE)]
    fullPopulationChildren[ , (paste0("MOR_VTIL" , i)) := pmin(MOR_VFRATemp1 ,
							       MOR_VFRATemp2 ,
							       MOR_VFRATemp3 ,
							       MOR_VFRATemp4 ,
							       MOR_VFRATemp5 ,
							       MOR_VFRATemp6 ,
							       MOR_VFRATemp7 ,
							       MOR_VFRATemp8 ,
							       MOR_VFRATemp9 ,
							       MOR_VFRATemp10 ,
							       MOR_VFRATemp11 ,
							       MOR_VFRATemp12 ,
							       MOR_VFRATemp13 ,
							       MOR_VFRATemp14 ,
							       MOR_VFRATemp15 ,
							       MOR_VFRATemp16 ,
							       MOR_VFRATemp17 ,
							       MOR_VFRATemp18 ,
							       MOR_VFRATemp19 ,
							       MOR_VFRATemp20 ,
							       MOR_VFRATemp21 ,
							       MOR_VFRATemp22 ,
							       MOR_VFRATemp23 ,
							       MOR_VFRATemp24 , na.rm = TRUE)]
  }
  ##Results visually inspected, performing as described.
  ##The helper variables are deleted
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VFRATemp" , i)) := NULL]
    fullPopulationChildren[ , (paste0("MOR_VFRATemp" , i)) := NULL]
  }
  ##To avoid a child having two mothers or fathers at a time, the VTIL is subtracted with a single day:
  for (i in 1:24) {
    fullPopulationChildren[ , (paste0("FAR_VTIL" , i)) := (get(paste0("FAR_VTIL" , i)) - 1)]
    fullPopulationChildren[ , (paste0("MOR_VTIL" , i)) := (get(paste0("MOR_VTIL" , i)) - 1)]
  }

  ##Setting up rows and dates for each parent within the current year:
  foraeldreID <- c(paste0("FAR" , 1:24) , paste0("MOR" , 1:24))
  foraeldreFra <- c(paste0("FAR_VFRA" , 1:24) , paste0("MOR_VFRA" , 1:24))
  foraeldreTil <- c(paste0("FAR_VTIL" , 1:24) , paste0("MOR_VTIL" , 1:24))
  fullPopulationChildren <- melt(fullPopulationChildren , measure = list(foraeldreID , foraeldreFra , foraeldreTil) , value.name = c("parentID" , "parenthoodStart" , "parenthoodEnd"))
  fullPopulationChildren[variable %in% c(1:24) , parentRole := "FAR"]
  fullPopulationChildren[variable %in% c(25:48) , parentRole := "MOR"]
  fullPopulationChildren <- fullPopulationChildren[parentID != ""]
  fullPopulationChildren <- fullPopulationChildren[!is.na(parentID)]
  fullPopulationChildren[ , c("MOR_VFRA" , "FAR_VFRA" , "variable") := NULL]
  ##Adding parental birthdays:
  ##Merging FOED_DAG from bef for parents:
  befFoeds <- bef[ , .(pnr , FOED_DAG)]
  befFoeds <- unique(befFoeds)
  fullPopulationChildren <- merge(fullPopulationChildren , befFoeds , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  setnames(fullPopulationChildren , old = "FOED_DAG" , new = "birthDateParentBef")
  rm(befFoeds)
  ##Merging parental FOED_DAG from ftbarn:
  fullPopulationChildren <- merge(fullPopulationChildren , ftBarn[ , .(pnr , FOED_DAG)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  setnames(fullPopulationChildren , old = "FOED_DAG" , new = "birthDateParentFtBarn" , skip_absent = TRUE)
  ##Importing mfr for parental birthdate - this dataset has already been loaded, only using relevant variables:
  fullPopulationChildren <- merge(fullPopulationChildren , mfr[ , .(pnr , foedselsdato)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE)
  ##Prioritize data from bef over ftBarn over MFR and generate birthDateParent:
  fullPopulationChildren[!is.na(birthDateParentBef) , birthDateParent := birthDateParentBef]
  fullPopulationChildren[!is.na(birthDateParentFtBarn) & is.na(birthDateParent) , birthDateParent := birthDateParentFtBarn]
  fullPopulationChildren[!is.na(foedselsdato) & is.na(birthDateParent) , birthDateParent := foedselsdato]
  fullPopulationChildren[ , c("birthDateParentFtBarn" , "birthDateParentBef" , "foedselsdato") := NULL]
  ##Removing pnrs for single use (with letters in them):
  fullPopulationChildren <- fullPopulationChildren[!grepl('.*[A-Z].*' , pnr)]
  ##Checked and this also removes all parents with single-use pnrs.



  fullPopulationChildrenParents <- fullPopulationChildren[ , .(parentID , birthDateParent)]
  fullPopulationChildrenParents <- unique(fullPopulationChildrenParents)
  ##Removing parents with non-real pnrs(with letters in them):
  fullPopulationChildrenParents <- fullPopulationChildrenParents[!grepl('.*[A-Z].*' , parentID)]

  ##fwrite(fullPopulationChildrenParents , "fullPopulationChildrenParents.csv")


  ##Loading further registries for use in the loop below:
  ##A number of BEF versions:
  bef <- unique(bef)
  bef[ , BOP_VFRA := floor_date(as.Date(BOP_VFRA , format = "%m/%d/%Y") , unit = "month")]
  ##bef[ , FOED_DAG := floor_date(as.Date(FOED_DAG , format = "%m/%d/%Y") , unit = "month")]
  bef[ , VAN_VTIL := floor_date(as.Date(VAN_VTIL , format = "%m/%d/%Y") , unit = "month")]
  ##Merging dates for immigration for children:
  befImmi <- bef[ , .(pnr , VAN_VTIL)]
  befImmi <- unique(befImmi)
  befOrig <- bef[ , .(pnr , OPR_LAND)]
  befOrig <- unique(befOrig)
  befAdr <- bef[ , .(pnr , opgikom , kom , BOP_VFRA)]
  befAdr <- befAdr[!is.na(opgikom)]
  befAdr <- befAdr[opgikom != ""]
  befAdr <- befAdr[!is.na(kom)]
  befAdr <- befAdr[kom != ""]
  setnames(befAdr , "BOP_VFRA" , "BOP_VFRABef")


  ##Importing aekvivadisp_13 from IND:
  indFileList <- c("ind_1991_2000_pop_190621.csv" ,
		   "ind_2001_2010_pop_190621.csv" ,
		   "ind_2011_2017_pop_190621.csv")
  indList <- lapply(indFileList , fread ,
		    nrows = nrows ,
		    select = c("pnr" , "AEKVIVADISP_13" , "aar") ,
		    colClasses = c("pnr" = "character"))
  ind <- rbindlist(indList)
  rm(indFileList , indList)
  ##Adjusting to 2018 currency using purchasing power as index:
  purchasingPower <- fread("purchasingPower.csv")
  ind <- merge(ind , purchasingPower ,
	       by.x = "aar" ,
	       by.y = "Year" ,
	       all.x = TRUE)
  ind[ , AEKVIVADISP_13Adjusted := (AEKVIVADISP_13 * 7045)/Value]
  ind <- ind[pnr != ""]
  ind <- ind[!is.na(pnr)]

  ##Loading dod:
  dod <- fread("dod_pop_110621.csv" , colClasses = ("pnr" = "character"))
  dod[ , doddato := floor_date(as.Date(doddato) , unit = "month")]
  vnds <- fread("vnds_pop_070621.csv" , select = c("pnr" , "indud_kode" , "haend_dato") , colClasses = ("pnr" = "character"))
  vnds[ , haend_dato := floor_date(as.Date(haend_dato) , unit = "month")]
  vnds <- vnds[pnr != ""]
  vnds <- vnds[indud_kode == "U"]

  ##Loading SOGN:
  sognFilesList <- c(paste0("sogn" , 2002:2012 , ".csv") , "sogn2014.csv")
  sognList <- lapply(sognFilesList , fread ,
		     nrows = nrows ,
		     select = c("OPGIKOM" , "KOM" , "SOGN") ,
		     colClasses = c("OPGIKOM" = "character" ,
				    "KOM" = "character" ,
				    "SOGN" = "character"))
  ##Preserving the names of the sogn files:
  sognFilesList <- gsub('\\.csv' , '' , sognFilesList)
  names(sognList) <- sognFilesList
  invisible(lapply(sognList ,
		   setnames ,
		   old = c("SOGN" , "OPGIKOM" , "KOM") ,
		   new = c("SOGN" , "opgikomChild" , "komChild") ,
		   skip_absent = TRUE)) ##This name change is contra-intuitive, but accommodates downstream code.
  ##Getting the sogn data into the current R environment:
  list2env(sognList , globalenv())
  ##Loading the sogn files with sogn in lower case:
  sognFilesList <- c("sogn2013.csv" , "sogn2015.csv" , "sogn2016.csv")
  sognList <- lapply(sognFilesList , fread , nrows = nrows , select = c("OPGIKOM" , "KOM" , "sogn") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "sogn" = "character"))
  ##Harmonizing - making SOGN in capital letters:
  invisible(lapply(sognList , setnames , old = c("sogn" , "OPGIKOM" , "KOM") , new = c("SOGN" , "opgikomChild" , "komChild") , skip_absent = TRUE)) ##This name change is contra-intuitive, but accomodates downstream code.
  sognFilesList <- gsub('\\.csv' , '' , sognFilesList)
  names(sognList) <- sognFilesList
  list2env(sognList , globalenv())
  rm(sognList , sognFilesList)
  ##Adding sogn for 2017-2018:
  sogn2017 <- fread("dar2017.csv" , select =c("OPGIKOM" , "KOM" , "SOGNEKODE") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "SOGNEKODE" = "character"))
  sogn2018 <- fread("dar2018.csv" , select =c("OPGIKOM" , "KOM" , "SOGNEKODE") , colClasses = c("OPGIKOM" = "character" , "KOM" = "character" , "SOGNEKODE" = "character"))
  setnames(sogn2017 ,
	   c("OPGIKOM" , "KOM" , "SOGNEKODE") ,
	   c("opgikomChild" , "komChild" , "SOGN"))
  setnames(sogn2018 ,
	   c("OPGIKOM" , "KOM" , "SOGNEKODE") ,
	   c("opgikomChild" , "komChild" , "SOGN"))

  ##For breakdowns:
  ## deathList <- fread("deathListAddress2015.csv" , colClasses = ("pnr" = "character"))
  ## exclusionList <- fread("exclusionListAddress2015.csv" , colClasses = ("pnr" = "character"))

  exclusionList <- data.table(pnr = character())
  ##Freeing up some space before the loop:
  rm(fullPopulation)
  ##Looping over all included years:
  for (k in 1997:2018) {
    firstDate <- as.Date(paste0(k , "-01-01"))
    lastDate <- as.Date(paste0(k , "-12-01"))
    fullPopulationChildrenCurrentYear <- fullPopulationChildren[(birthDate - firstDate) > -6575 & (birthDate - lastDate) <= 0]
    ##fullPopulationChildrenCurrentYear[ , currentAge := (firstDate - birthDate)/365.24]
    ##All ages less than 18 years on first day of year - or unborn, thus a negative value but not lower than 0.99....
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) <= 0 , studyEntry := firstDate]
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) > 0 , studyEntry := birthDate]
    fullPopulationChildrenCurrentYear[(birthDate - firstDate) <= 0 &
					(birthDate - lastDate) <= -6575 , ageCensoring := birthDate + 6575]
    ##Age censoring visually inspected, staying within the relevant year and corresponding to the 18th year birthday
    ##Implementing censoring for death and emigration:
    ##dod[ , summary(doddato)]
    ##This command showed a reasonable interval for death incidents
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , dod , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , dod , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent"))
    fullPopulationChildrenCurrentYear[ , doddatoChild := floor_date(as.Date(doddatoChild) , unit = "month")]
    fullPopulationChildrenCurrentYear[ , doddatoParent := floor_date(as.Date(doddatoParent) , unit = "month")]
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[doddatoChild >= firstDate | is.na(doddatoChild)]
    fullPopulationChildrenCurrentYear[doddatoChild <= lastDate , deathCensoring := doddatoChild]
    ##The next line may censor some children but that is okay as having a parent is an inclusion criterion (otherwise you cannot have the exposure, and you cannot re-enter after getting new parents(being adopted)).
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[doddatoParent >= firstDate | is.na(doddatoParent)]
    ##A parental death will not be used for censoring unless this means you have no parents.
    fullPopulationChildrenCurrentYear[doddatoParent <= lastDate , deathCensoringParent := doddatoParent]
    ##Emigration - anyone dead is assumed not to re-appear in the registries, but anyone emigrated could easily re-emerge later - this would create a strange bias where they have insufficient observation compared to their peers, thus a list is created of all that has emigrated at least once, from whereon they are excluded from the remainder of the study:
    exclusionList[ , delete := 1]
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , exclusionList , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
    exclusionList[ , delete := NULL]
    fullPopulationChildrenCurrentYear[ , delete := NULL]
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , vnds[haend_dato <= lastDate & haend_dato >= firstDate] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear[!is.na(haend_dato) , emigrationCensoring := haend_dato]
    exclusionList <- rbindlist(list(exclusionList , fullPopulationChildrenCurrentYear[!is.na(haend_dato)][ , .(pnr)]))
    exclusionList <- unique(exclusionList)

    ##Also ensure that children dead in earlier datasets are not included again:
    if (exists("deathList")) {
	deathList[ , delete := 1]
	fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , deathList , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
	fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[is.na(delete)]
	deathList[ , delete := NULL]
	fullPopulationChildrenCurrentYear[ , delete := NULL]
    }



    ##Removing parents that were never parents during 1997 or for which there is no entry:
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[!parenthoodStart > lastDate]
    ##For monitoring:
    print("Just finished censoring")
    print(Sys.time())
    print("Doing some garbage cleaning and printing time afterwards")
    gc()
    print(Sys.time())

    ##Merging parental FOEDREG_KODE:
    setnames(ftBarn , "pnr" , "parentID")
    fullPopulationChildrenCurrentYear[ftBarn , on = "parentID" , FOEDREG_KODE := i.FOEDREG_KODE]
    setnames(ftBarn , "parentID" , "pnr")
    ##Merging FAR_FOED_ADOP and MOR_FOED_ADOP to children:
    ##fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , ftBarn[ , .(pnr , FAR_FOED_ADOP , MOR_FOED_ADOP)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ##Merging BEF
    ##bef <- fread("bef_pop_070621.csv" , nrows = nrows , drop = c("FAMILIE_ID" , "MOR_ID" , "FAR_ID" , "efalle" , "civst" , "CIV_VFRA" , "FAMILIE_TYPE" , "FM_MARK" , "generation" , "hustype" , "IE_TYPE" , "koen" , "plads" , "reg") , colClasses = c("pnr" = "character"))

    ##Merging OPGIKOM and KOM for children and parents(the last is only to see how many people reside in the family):
    befAdrCurrentYear <- befAdr[BOP_VFRABef <= lastDate]
    befAdrCurrentYear <- unique(befAdrCurrentYear)
    fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befAdrCurrentYear , by.x = "pnr" , by.y = "pnr" , all.x = TRUE , allow.cartesian = TRUE)
    ##This merge is postponed as it expands the dataset significantly - see at analysisDataset instead:
    ##fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , befAdrCurrentYear , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent") , allow.cartesian = TRUE)

    ##Commenting out this code as I will try with IND:
    ## ##Importing famaekvivadisp_13 from faik:
    ## faik <- fread("faik_pop_190621.csv" , nrows = nrows , select = c("FAMILIE_ID" , "famaekvivadisp_13" , "aar") , colClasses = c("FAMILIE_ID" = "character"))
    ## ##I need dates for FAMILIE_ID here - if I can't get them, I might have to rely on fain but it would be better to have actual dates.
    ## ##Merging on currency conversions to 2018-level:
    ## faik <- merge(faik , purchasingPower , by.x = "aar" , by.y = "Year" , all.x = TRUE)
    ## faik[ , famaekvivadisp_13Adjusted := (famaekvivadisp_13 * 7045)/Value]

    ##Merging IND onto main dataset for children (this is done one year back as ind is a full-year income and using this in the beginning of the current year will condition on the future - thus, instead of using income data from 1997 for 1997, data for 1996, 1995 1nd 1994 are used):
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 1) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE)
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 2) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE ,
	    suffixes = c("Current" , "OneYearBack"))
    fullPopulationChildrenCurrentYear <-
      merge(fullPopulationChildrenCurrentYear ,
	    ind[aar == (k - 3) ,
		.(pnr , AEKVIVADISP_13Adjusted)] ,
	    by.x = "pnr" ,
	    by.y = "pnr" ,
	    all.x = TRUE)
    setnames(fullPopulationChildrenCurrentYear ,
	     "AEKVIVADISP_13Adjusted" ,
	     "AEKVIVADISP_13AdjustedTwoYearsBack")
    ##Computing the mean of the last three years of income:
    fullPopulationChildrenCurrentYear[ ,
				       meanIncome := rowMeans(.SD , na.rm = TRUE) , .SDcols = c("AEKVIVADISP_13AdjustedCurrent" ,
							"AEKVIVADISP_13AdjustedOneYearBack" ,
							"AEKVIVADISP_13AdjustedTwoYearsBack")]
    fullPopulationChildrenCurrentYear[ ,
				       c("AEKVIVADISP_13AdjustedCurrent" ,
					 "AEKVIVADISP_13AdjustedOneYearBack" ,
					 "AEKVIVADISP_13AdjustedTwoYearsBack") := NULL]
    ##Results checked by inspection of the dataset, including the special case of children between 0-1 years old. All children except those 0-1 year old have values if there are any values present for preceding years. Filling in values for the youngest:
    ##Further calculations on parish after merging of sogn.
    ##There is a special case of children between 0 and 1 years old. These children will be handled by computing the mean of their parents' last year income, and parent is classified as anyone connected to their pnr with a parentID during the current year. Thus, income is merged to the parents as well:
    setnames(ind , "pnr" , "parentID")
    fullPopulationChildrenCurrentYear[ind[aar == (k - 1)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentCurrent :=
					  i.AEKVIVADISP_13Adjusted]
    fullPopulationChildrenCurrentYear[ind[aar == (k - 2)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentOneYearBack :=
					  i.AEKVIVADISP_13Adjusted]
    fullPopulationChildrenCurrentYear[ind[aar == (k - 3)] ,
				      on = "parentID" ,
				      AEKVIVADISP_13AdjustedParentTwoYearsBack :=
					  i.AEKVIVADISP_13Adjusted]
    setnames(ind , "parentID" , "pnr")
    fullPopulationChildrenCurrentYear[ ,
				      meanIncomeParentIndividual :=
					  rowMeans(.SD , na.rm = TRUE) ,
				      .SDcols = c("AEKVIVADISP_13AdjustedParentCurrent" ,
						 "AEKVIVADISP_13AdjustedParentOneYearBack" ,
						 "AEKVIVADISP_13AdjustedParentTwoYearsBack")]
    ##Reducing to one line for each parent:
    temp <- unique(fullPopulationChildrenCurrentYear , by = c("pnr" , "parentID"))
    ##Calculating the mean parental income (so this would be the mean income of all parents connected to the child in the year prior to the current one):
    temp[ , meanIncomeParent := mean(meanIncomeParentIndividual , na.rm = TRUE) , by = "pnr"]
    ##Merging this result to the main dataset:
    fullPopulationChildrenCurrentYear[temp , on = "pnr" , meanIncomeParent := i.meanIncomeParent]
    ##Replacing missings among the children with values from their parents:
    fullPopulationChildrenCurrentYear[is.na(meanIncome) , meanIncome := meanIncomeParent]
    ##All steps of calculating meanIncome have been evaluated by manual inspection and performs as expected.
    ##Reducing to only those showing the current address - and reducing one year before:
    ## setkey(cpst , pnr , adrdatoCpst)
    ## View(cpst[is.na(adrdatoCpst)][1:10000])
    ## cpst[is.na(adrdatoCpst) , table(van_vtilCpst)]
    ## cpst[is.na(adrdatoCpst) , table(van_vfraCpst)]
    ##From the commands above, one sees that van_vfra and van_vtil is not recorded in a way useful to this study in any records with missing adrdato. There are some van_vtil, but with the most recent dates being in 1978 - this is not relevant for censoring or entering in this study. Thus, lines with adrdato are removed and the dataset is reduced to dates relevant to the current year-1 (status at the first date of the year, as this variable will be derived from a yearly register, and to avoid contidioning on the future):
    ## cpst <- cpst[!is.na(adrdatoCpst)]
    ## cpst1996 <- cpst[adrdatoCpst <= as.Date("1996-12-31")]
    ##Results visually inspected, as expected
    ##Creating an index of the last line for each PNR, when ordered by pnr and adrdatoCpst:
    ## setkey(cpst1996 , pnr , adrdatoCpst)
    ## cpstTemp <- cpst1996[order(pnr , adrdatoCpst) , .I[.N] , by = pnr]
    ## ##Using the index to retrieve the latest date:
    ## cpst1996 <- cpst1996[cpstTemp$V1]
    ## ##Results compared visually to cpst1996 before changes - behaving as expected.
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , cpst1996 , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
    ## ##Also joining OPGIKOM and KOM for parents to facilitate counting no. of members in the family:
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , cpst1996[ , .(pnr , opgikom , kom , adrdatoCpst)] , by.x = "parentID" , by.y = "pnr" , all.x = TRUE , suffixes = c("Child" , "Parent"))
    ## rm(cpstTemp , cpst1996)
    ##Dates of immigration has not been utilized in this data draw - this will likely have to be done based on van_vtil and van_vfra, a new set can be constructed using these variables instead of adrdato.

    ##Setting names because of downstream code:
    setnames(fullPopulationChildrenCurrentYear , c("opgikom" , "kom" , "BOP_VFRABef") , c("opgikomChild" , "komChild" , "BOP_VFRABefChild"))

    ##Merging SOGN onto BEF-data
    if (k <=2002) {
	fullPopulationChildrenCurrentYear[sogn2002 ,
					  on = c("opgikomChild" , "komChild") ,
					  SOGN := i.SOGN]
    } else { eval(parse(text = paste0("fullPopulationChildrenCurrentYear[sogn" , k , " , on = c('opgikomChild' , 'komChild') , SOGN := i.SOGN]")))
	for (i in rev(2002:k)[-1]) { ##The strange i-expression is all years up to the current, minus the current year - the idea is to go through all years, with priority to the most adjacent, and add matches as they are found.
	    eval(parse(text = paste0("fullPopulationChildrenCurrentYear[sogn" , i , " , on = c('opgikomChild' , 'komChild') , SOGNTemp := i.SOGN]")))
	    fullPopulationChildrenCurrentYear[is.na(SOGN) , SOGN := SOGNTemp]
	}
    }
    suppressWarnings(fullPopulationChildrenCurrentYear[ , SOGNTemp := NULL])
    ##Evaluated, gives an increased number of matches
    ##Merging SOGN onto ADRESSE_ID:
    ##Will outcomment this as we will be using opgikom and kom instead:
    ##Loading befadr:
    ## befadr <- fread("befadr_pop_070621.csv" , nrows = nrows , colClasses = c("opgikom" = "character" , "ADRESSE_ID" = "character" , "kom" = "character"))
    ## befadr[ , ADR_VFRA := floor_date(as.Date(ADR_VFRA , format = "%m/%d/%Y") , unit = "month")]
    ## befadr[ , ADR_RFRA := floor_date(as.Date(ADR_RFRA , format = "%m/%d/%Y") , unit = "month")]
    ## befadr[ , ADR_VTIL := floor_date(as.Date(ADR_VTIL , format = "%m/%d/%Y") , unit = "month")]
    ## ##This merge will only give non-NA values after 2007, as ADR_RFRA and ADR_VFRA mostly specify this date:
    ## ##if (i > 2007) {
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear ,
    ## 	      befadr[ADR_VFRA <= lastDate &
    ## 		     ADR_RFRA <= lastDate &
    ## 		     ADR_VTIL >= firstDate ,
    ## 		     .(opgikom , kom , ADRESSE_ID)] ,
    ## 	      by.x = "ADRESSE_IDChild" ,
    ## 	      by.y = "ADRESSE_ID" ,
    ## 	      all.x = TRUE)
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear ,
    ## 	      befadr[ADR_VFRA <= lastDate &
    ## 		     ADR_RFRA <= lastDate &
    ## 		     ADR_VTIL >= firstDate ,
    ## 		     .(opgikom , kom , ADRESSE_ID)] ,
    ## 	      by.x = "ADRESSE_IDParent" ,
    ## 	      by.y = "ADRESSE_ID" ,
    ## 	      all.x = TRUE , suffixes = c("BefadrChild" , "BefadrParent"))
    ## ##Merging sogn onto bef-data (only after 2007):
    ## fullPopulationChildrenCurrentYear <- merge(fullPopulationChildrenCurrentYear , sogn2008 , by.x = c("opgikomBefadrChild" , "komBefadrChild") , by.y = c("OPGIKOM" , "KOM") , all.x = TRUE)
    ## fullPopulationChildrenCurrentYear[!is.na(SOGN.x) & SOGN.x != "", SOGN := SOGN.x]
    ## fullPopulationChildrenCurrentYear[!is.na(SOGN.y) & SOGN.y != "", SOGN := SOGN.y]
    ## fullPopulationChildrenCurrentYear[ , c("SOGN.x" , "SOGN.y") := NULL]
    ## fullPopulationChildrenCurrentYear[BOP_VFRABefChild > lastDate , SOGN := NA]
    ##}
    ##Introducing grouped SOGN after Carsten Bcker Pedersen:
    parishGroups <- fread("parishGroups.csv" ,
			  colClasses = c("Parish" = "character" ,
					 "ParishGrp" = "character"))
    setnames(parishGroups , "Parish" , "SOGN")
    fullPopulationChildrenCurrentYear[parishGroups , on = "SOGN" , ParishGrp := i.ParishGrp]
    fullPopulationChildrenCurrentYear[!is.na(ParishGrp) , sognGrouped := ParishGrp]
    fullPopulationChildrenCurrentYear[is.na(ParishGrp) , sognGrouped := SOGN]
    ##Computing dataset for parish levels of income:
    parishIncomeCurrentYear <- fullPopulationChildrenCurrentYear[!is.na(sognGrouped) , .(pnr , sognGrouped , meanIncome)]
    parishIncomeCurrentYear <- unique(parishIncomeCurrentYear)
    ##Converting to Euros:
    parishIncomeCurrentYear[ , meanIncomeEuros := meanIncome/7.46038] ##Number from the Central Bank of Denmark - please note Euros were not used until 2002.
    ##Checking that every pnr is only used once in each sogn:
    ## parishIncomeCurrentYear[ , test := duplicated(pnr) , by = SOGN]
    ## parishIncomeCurrentYear[ , table(test)]
    ##Returns no duplicates. A child can thus contribute in several parishes during a year if this child moves between these parishes. A parish-derived variable is derived from the three-year rolling mean of its inhabitants during the year in this dataset, no matter how long they have lived there.
    parishIncomeCurrentYear[ , lowerQuantile :=
				   quantile(meanIncomeEuros ,
					    probs = 0.25  ,
					    na.rm = TRUE) ,
			    by = sognGrouped]
    parishIncomeCurrentYear[ , upperQuantile :=
			       quantile(meanIncomeEuros ,
					probs = 0.75  ,
					na.rm = TRUE) ,
			     by = sognGrouped]
    parishIncomeCurrentYear[ , parishQuantileDifference100Euros :=
			       (upperQuantile - lowerQuantile)/100 ,
			     by = sognGrouped]
    ##Visually inspected, provides upper and lower quartiles, and parish differences, as expected.
    ##Reducing the dataset for subsequent merging:
    parishIncomeCurrentYear[ ,
			     c("pnr" , "meanIncome" ,
			       "meanIncomeEuros" , "lowerQuantile" ,
			       "upperQuantile") := NULL]
    parishIncomeCurrentYear <- unique(parishIncomeCurrentYear)
    ##The quality of this variable will have to be checked against a real, full-scale dataset - here there are some oddities which may be derived from missing values.
    ##Using this dataset for merging back to the main dataset:
    fullPopulationChildrenCurrentYear[parishIncomeCurrentYear , on = "sognGrouped" , parishQuantileDifference100Euros := i.parishQuantileDifference100Euros]
    ##Computing income subtracted with the limit for risk of poverty, defined from rolling mean of median income in Denmark and subsequently converted to Euros:
    ##Importing numbers on median income in Denmark, adjusting for purchasing power (taken from Statistics Denmark, table PRIS8) and converting them to a rolling mean:
    medianIncomeDenmark <- fread("equivalentIncome.csv")
    medianIncomeDenmark <- merge(medianIncomeDenmark , purchasingPower , by.x = "Year" , by.y = "Year" , all.x = TRUE)
    medianIncomeDenmark[ , equivalentIncomeAdjusted := (EquivalentIncome * 7045)/Value]
    medianIncomeDenmark[ , rollingMeanIncomeDenmark := frollmean(equivalentIncomeAdjusted , 3)]
    ##Checked by manual calculation, computes as expected from the two prior and one current year
    ##Multiplied with 0.6 and converted to euros:
    medianIncomeDenmark[ , rollingMeanSixtyPercent := (rollingMeanIncomeDenmark * 0.6)]
    medianIncomeDenmark[ , rollingMeanSixtyPercentEuros := rollingMeanSixtyPercent / 7.46038]
    ##Using 1996 to avoid conditioning on the future:
    fullPopulationChildrenCurrentYear[ ,
				       rollingMeanSixtyPercentEuros :=
					 ..medianIncomeDenmark[Year == (k - 1) ,
							       rollingMeanSixtyPercentEuros]]
    ##Calculating mean income Euros:
    fullPopulationChildrenCurrentYear[ , meanIncomeEuros := meanIncome / 7.46038]
    ##Calculating mean income from rolling mean subtracted by the rolling national mean and reported in hundreds of euros:
    fullPopulationChildrenCurrentYear[ , incomeVariable :=
					 (meanIncomeEuros -
					    rollingMeanSixtyPercentEuros) / 100]
    ##To do as stated in the pre-registration the difference between upper and lower quartile in parishes should be subtracted with the yearly rate for relative poverty:
    fullPopulationChildrenCurrentYear[ , parishQuantileDifference100EurosMinusRollingMean := parishQuantileDifference100Euros - (rollingMeanSixtyPercentEuros / 100)]
    fullPopulationChildrenCurrentYear[ , c("meanIncomeEuros" , "rollingMeanSixtyPercentEuros") := NULL]

    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[!is.na(pnr)]
    fullPopulationChildrenCurrentYear <- fullPopulationChildrenCurrentYear[pnr != ""]
    ##For monitoring:
    print("Just finished adding and calculating economic variables")
    print(Sys.time())

    ##Number of children and adults living in family: count no. of children and adults living on address using kom and bopikom: BE AWARE THAT ADULTS NOT REGISTERED AS EITHER PARENTS OR PERPETRATORS OR CHILDREN THEMSELVES ARE NOT IN THE DATASET - this might underestimate the number of adults living with the child. This variable will mainly be useful to see differences between single and non-single parents. Parents less than 18 years old will be counted as adults.
    ##Looking at the data below, some children have two addresses at the same time. If one looks at the original data, the parents have the same - it thus seems safe to focus on only one address for each child, as this address would capture both parents.

  ## In principle, there is nothing wrong with the code below. However, first of all the resulting numbers are strange. Many are completely outside the range of what could be reasonably expected (more than 1000 adults or children living in the same household), and also a large number of missings exist without any apparent explanation. Thus, the section is commented out for now. And then again, I had to outcomment the first part to allow for an element needed downstream. 
    ##For monitoring:
    print("Just before counting children and adults")
    print(Sys.time())
    ##Children
    numberOfAdultsTemp <-
      fullPopulationChildrenCurrentYear[!is.na(pnr) ,
					.(pnr , komChild ,
					  opgikomChild , BOP_VFRABefChild ,
					  studyEntry , ageCensoring ,
					  deathCensoring , emigrationCensoring)]
    numberOfAdultsTemp <- unique(numberOfAdultsTemp)
    setnames(numberOfAdultsTemp ,
	     old = c("komChild" , "opgikomChild" ,
		     "BOP_VFRABefChild") ,
	     new = c("kom" , "opgikom" ,
		     "adrdato"))
    ##Mark children with more than one address and delete one of them (this is feasible as the data for the adults were looked up as well, and for a large number of cases, the same individuals are registered for both addresses:
    numberOfAdultsTemp[ , temp := duplicated(pnr) , by = adrdato]
    numberOfAdultsTemp <- numberOfAdultsTemp[temp == FALSE]
    numberOfAdultsTemp[ , temp := NULL]
    ##A few children has a new address starting at 1997-01-01 - as I will soon set all addresses older than this date to 1997-01-01, some children will have two addresses at this day. I will delete the old addresses - first marking those with this special case:
    numberOfAdultsTemp[adrdato == firstDate , temp := 1]
    ##Set all adrdato older than 1997-01-01 to this date:
    numberOfAdultsTemp[adrdato < firstDate , adrdato := firstDate]
    ##To get the newest addresses: delete observations of two addresses with adrdato 1997-01-01 not marked with temp == 1:
    setorder(numberOfAdultsTemp , pnr , adrdato , temp , na.last = TRUE)
    numberOfAdultsTemp <- unique(numberOfAdultsTemp , by = c("pnr" , "adrdato"))
    numberOfAdultsTemp[ , temp := NULL]

    ##Preparing a dcast to get end dates for the addresses:
    ##Numbering all addresses within a PNR:
    setkey(numberOfAdultsTemp , pnr , adrdato)
    numberOfAdultsTemp[ , adrNo := seq_len(.N) , by = pnr]
    if (max(numberOfAdultsTemp$adrNo) > 1) {
	##dcasting the date from subsequent addresses onto the same line as the first address:
	temp <- dcast(numberOfAdultsTemp , pnr ~ adrNo , value.var = "adrdato")
	setnames(temp , c("1" , "2" , "3" , "4" ,
			  "5" , "6" , "7" , "8" ,
			  "9" , "10" , "11" , "12" ,
			  "13" , "14" , "15" , "16" ,
			  "17" , "18" , "19" , "20" ,
			  "21" , "22" , "23" , "24" ,
			  "25" , "26" , "27" , "28" ,
			  "29" , "30") ,
		 c("one" , "two" , "three" , "four" ,
		   "five" , "six" , "seven" , "eight" ,
		   "nine" , "ten" , "eleven" , "twelve" ,
		   "thirteen" , "fourteen" , "fifteen" ,
		   "sixteen" , "seventeen" , "eighteen" ,
		   "nineteen" , "twenty" , "twentyone" ,
		   "twentytwo" , "twentythree" ,
		   "twentyfour" , "twentyfive" ,
		   "twentysix" , "twentyseven" ,
		   "twentyeight" , "twentynine" ,
		   "thirty") , skip_absent = TRUE)
	##Merging them back onto the original dataset; as there could be a number of address changes, this has to be done in a loop:
	numbers <- c("one" , "two" , "three" , "four" ,
		     "five" , "six" , "seven" , "eight" ,
		     "nine" , "ten" , "eleven" , "twelve" ,
		     "thirteen" , "fourteen" , "fifteen" ,
		     "sixteen" , "seventeen" , "eighteen" ,
		     "nineteen" , "twenty" , "twentyone" ,
		     "twentytwo" , "twentythree" ,
		     "twentyfour" , "twentyfive" ,
		     "twentysix" , "twentyseven" ,
		     "twentyeight" , "twentynine" ,
		     "thirty")
	for (i in 1:(length(names(temp)) - 2)) {
	    numberOfAdultsTemp <- merge(numberOfAdultsTemp ,
					temp[ , .(pnr , get(numbers[i]) ,
						  get(numbers[i + 1]))] ,
					by.x = c("pnr" , "adrdato") ,
					by.y = c("pnr" , "V2") ,
					all.x = TRUE)
	    numberOfAdultsTemp[ , (numbers[i + 1]) := V3]
	    numberOfAdultsTemp[ , V3 := NULL]
	    numberOfAdultsTemp[adrNo != i , (numbers[i + 1]) := NA]
	}
	##Visually inspected, performs as expected.
	##Joining the dates into one variable
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp[!is.na(get(numbers[i])) , adrdatoEnd := get(numbers[i])]
	}
	##Visually inspected, performing as expected.
	##Removing the columns with numbers:
	for (i in 2:(length(names(temp)) - 1)) {
	    numberOfAdultsTemp[ , (numbers[i]) := NULL]
	}
	##For any parent with two addresses at the same time, one address may look like it "takes over" from the other on the same date they were both registered. I adjust for this by deleting any adrdatoEnd that occurs at the same date as adrdato:
	numberOfAdultsTemp[adrdato == adrdatoEnd , adrdatoEnd := NA]
    } else {
	numberOfAdultsTemp[ , adrdatoEnd := structure(numeric(0) , class = "Date")]
    }
    ##Setting adrdatoEnd to the last date of the year for all who does not change their address:
    numberOfAdultsTemp[is.na(adrdatoEnd) , adrdatoEnd := lastDate]
    ##Reducing the dates to those within the study (taking age and censoring into account):
    numberOfAdultsTemp[studyEntry > adrdato , adrdato := studyEntry]
    numberOfAdultsTemp[ageCensoring < adrdatoEnd & !is.na(ageCensoring), adrdatoEnd := ageCensoring]
    numberOfAdultsTemp[deathCensoring < adrdatoEnd & !is.na(deathCensoring) , adrdatoEnd := deathCensoring]
    numberOfAdultsTemp[emigrationCensoring < adrdatoEnd & !is.na(emigrationCensoring) , adrdatoEnd := emigrationCensoring]
    ##Now some observations should have a negative number of dates where they are living somewhere - this is because someone is censored before they live at an address, or enter the study after they moved. I throw these out:

    numberOfAdultsTemp <- numberOfAdultsTemp[adrdato <= adrdatoEnd]
    ##There might be a few observations where someone lives on an address for exactly one day, and if this is the case at this point in the data, that is accurate, but cannot be handled by the expansion below. I save and delete these observations:
    temp <- numberOfAdultsTemp[adrdato == adrdatoEnd]
    numberOfAdultsTemp <- numberOfAdultsTemp[adrdato != adrdatoEnd]
    ##Expanding all observations to one for each day of the year:
    numberOfAdultsTemp <- numberOfAdultsTemp[ , list(pnr = pnr , kom = kom , opgikom = opgikom , day = seq(adrdato , adrdatoEnd , by = "month")) , by = 1:nrow(numberOfAdultsTemp)]
    numberOfAdultsTemp[ , nrow := NULL]
    numberOfAdultsTemp[ , adrNo := NULL]
    setnames(numberOfAdultsTemp , "day" , "adrdato")
    temp[ , c("studyEntry" , "ageCensoring" , "deathCensoring" , "emigrationCensoring" , "adrdatoEnd" , "adrNo"):= NULL]
    setcolorder(temp , c("pnr" , "kom" , "opgikom" , "adrdato"))
    numberOfAdultsTemp <- rbindlist(list(numberOfAdultsTemp , temp))

    ## ##The variable for reconstituted family will need a dataset with a different structure - this has been written into the proposed dataset above.
    ## ##The same for the remaining variables - will begin to construct this dataset:
    ## ##For monitoring:
    print("Just before initiating analysisDataset")
    print(Sys.time())
    analysisDatasetCurrentYearTemp <-
	fullPopulationChildrenCurrentYear[!is.na(pnr) ,
					  .(pnr , parentID ,
					    studyEntry , ageCensoring ,
					    birthDateParent ,
					    parenthoodStart ,
					    parenthoodEnd)]
    analysisDatasetCurrentYearTemp <- unique(analysisDatasetCurrentYearTemp)
    ##Reducing the adoption variable to one:
    ## analysisDatasetCurrentYearTemp[parentRole == "FAR" , parentFoedAdop := FAR_FOED_ADOP]
    ## analysisDatasetCurrentYearTemp[parentRole == "MOR" , parentFoedAdop := MOR_FOED_ADOP]
    ## analysisDatasetCurrentYearTemp[ , c("FAR_FOED_ADOP" , "MOR_FOED_ADOP" , "parentRole") := NULL]
    ##Removing parenthoodEnds that are either smaller than 1997-01-01 or smaller than parenthoodStart:
    analysisDatasetCurrentYearTemp <- analysisDatasetCurrentYearTemp[parenthoodEnd > firstDate | is.na(parenthoodEnd)]
    analysisDatasetCurrentYearTemp <- analysisDatasetCurrentYearTemp[parenthoodEnd > parenthoodStart | is.na(parenthoodEnd)] ##It seems to be mere errors that creates situations where parents stop being parents before they start. Another option is the result of the arbitrary parental start date of the first of July. All observations that apply are deleted.
    ##Preparing a dcast to get parents aligned in wide format:
    ##Numbering all parents within a PNR:
    setkey(analysisDatasetCurrentYearTemp , pnr , parenthoodStart)
    analysisDatasetCurrentYearTemp[ , parentNo := seq_len(.N) , by = pnr]
    ##dcasting all parents onto the same line:
    analysisDatasetCurrentYearTemp <- dcast(analysisDatasetCurrentYearTemp , pnr ~ parentNo , value.var = c("parentID" , "birthDateParent" , "parenthoodStart" , "parenthoodEnd"))

    ##Importing "first" parents by use of non-year-limited dataset:
    setorder(fullPopulationChildren , pnr , parenthoodStart , na.last = TRUE)
    fullPopulationChildren[ , parentNo := seq_len(.N) , by = pnr]
    analysisDatasetCurrentYearTemp[fullPopulationChildren[parentNo == 1] ,
				   on ="pnr" ,
				   originalParent1 := i.parentID]
    analysisDatasetCurrentYearTemp[fullPopulationChildren[parentNo == 2] ,
				   on ="pnr" ,
				   originalParent2 := i.parentID]
    fullPopulationChildren[ , parentNo := NULL]
    ##Importing adoption status based on the original parents:
    setnames(analysisDatasetCurrentYearTemp , "originalParent1" , "FAR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(FAR1 , FAR_FOED_ADOP)] ,
				   on = "FAR1" ,
				   parentFoedAdopOrig1 := i.FAR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "FAR1" , "MOR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(MOR1 , MOR_FOED_ADOP)] ,
				   on = "MOR1" ,
				   parentFoedAdopOrig1 := i.MOR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "MOR1" , "originalParent1")
    setnames(analysisDatasetCurrentYearTemp , "originalParent2" , "FAR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(FAR1 , FAR_FOED_ADOP)] ,
				   on = "FAR1" ,
				   parentFoedAdopOrig2 := i.FAR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "FAR1" , "MOR1")
    analysisDatasetCurrentYearTemp[ftBarn[ ,
					  .(MOR1 , MOR_FOED_ADOP)] ,
				   on = "MOR1" ,
				   parentFoedAdopOrig2 := i.MOR_FOED_ADOP]
    setnames(analysisDatasetCurrentYearTemp , "MOR1" , "originalParent2")

    ##Prepare expansion by adjusting dates to the beginning of the year in question:
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYearTemp)))) {
      analysisDatasetCurrentYearTemp[get(paste0("parenthoodStart_" , i)) <
				       firstDate &
				       !is.na(get(paste0("parenthoodStart_" , i))) ,
				     (paste0("parenthoodStart_" , i)) :=
				       firstDate]
      analysisDatasetCurrentYearTemp[is.na(get(paste0("parenthoodEnd_" , i))) &
				       !is.na(get(paste0("parenthoodStart_" , i))) ,
				     (paste0("parenthoodEnd_" , i)) :=
				       lastDate]
      analysisDatasetCurrentYearTemp[get(paste0("parenthoodEnd_" , i)) >
				       lastDate &
				       !is.na(get(paste0("parenthoodEnd_" , i))) ,
				     (paste0("parenthoodEnd_" , i)) :=
				       lastDate]
    }
    ##Avoid confusion with old objects from former years:
    suppressWarnings(
	rm(parent1 , parent2 ,
	   parent3 , parent4 ,
	   parent5 , parent6))
    ##Make a number of new datasets based on analysisDatasetCurrentYearTemp:
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYearTemp)))) {
      colNames <- c("pnr" ,
		    grep(paste0(".*_" , i) ,
			 names(analysisDatasetCurrentYearTemp) , value = TRUE))
      assign(paste0("parent" , i) ,
	     analysisDatasetCurrentYearTemp[!is.na(get(paste0("parentID_" , i))) ,
					    ..colNames])
    }
    rm(colNames)
    ##Rename them
    for (i in ls(pattern = 'parent[1-9]+')) {
      ##The stringsplit part is a horrible way to get r to extract the number from i
      j <- strsplit(i , 'parent')[[1]][2]
      setnames(get(i) , c("pnr" , paste0("parentID_" , j) ,
			  paste0("birthDateParent_" , j) ,
			  paste0("parenthoodStart_" , j) ,
			  paste0("parenthoodEnd_" , j)) ,
	       c("pnr" , "parentID" , "birthDateParent" ,
		 "parenthoodStart" , "parenthoodEnd"))
    }
    ##Add originalParent and adoption status to parent1:
    parent1[analysisDatasetCurrentYearTemp , on = "pnr" , c("originalParent1" , "originalParent2" , "parentFoedAdopOrig1" , "parentFoedAdopOrig2") := list(i.originalParent1 , i.originalParent2 , i.parentFoedAdopOrig1 , i.parentFoedAdopOrig2)]

    ##Expand them into registrations for each day
    ##The special case of parent1:
    parent1 <- parent1[ , list(pnr = pnr ,
			       parentID = parentID ,
			       birthDateParent = birthDateParent ,
			       parentFoedAdopOrig1 = parentFoedAdopOrig1 ,
			       parentFoedAdopOrig2 = parentFoedAdopOrig2 ,
			       originalParent1 = originalParent1 ,
			       originalParent2 = originalParent2 ,
			       day = seq.Date(from = parenthoodStart ,
					      to = parenthoodEnd ,
					      by = "month")) ,
		       by = 1:nrow(parent1)]
    for (i in ls(pattern = 'parent[2-9]+')) {
      ##The stringsplit part is a horrible way to get r to extract the number 1 from i
      j <- strsplit(i , 'parent')[[1]][2]
      assign(i , get(i)[ , list(pnr = pnr , parentID = parentID ,
				birthDateParent = birthDateParent ,
				day = seq.Date(from = parenthoodStart ,
					       to = parenthoodEnd ,
					       by = "month")) ,
			 by = 1:nrow(get(i))])
    }
    ##Merge all datasets together on date and pnr:
    ##Clean up unneccesary columns:
    for (i in ls(pattern = 'parent[1-9]+')) {
      get(i)[ , nrow := NULL]
    }
    ##Do the merge:
    for (i in 1:(length(grep('parentID.*' ,
			     names(analysisDatasetCurrentYearTemp)))-1)) {
      parent1 <- merge(parent1 ,
		       get(paste0("parent" , (i+1))) ,
		       by.x = c("day" , "pnr") ,
		       by.y = c("day" , "pnr") ,
		       all = TRUE ,
		       suffixes = c(i , (i+1)))
      ##For merges subsequent to the first, there is no proper naming of subsequent variables - setting these:
      setnames(parent1 , c("parentID" ,
			   "birthDateParent") ,
	       c(paste0("parentID" , (i + 1)) ,
		 paste0("birthDateParent" , (i + 1))) ,
	       skip_absent = TRUE)
    }
    ##By taking observations from parent4 and looking for their counterpart in parent1 it shows that all parents were merged as expected.
    analysisDatasetCurrentYear <- parent1
    analysisDatasetCurrentYear[ , c("currentParent1" , "currentParent2") := character()]
    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYear)))) {
      analysisDatasetCurrentYear[!is.na(get(paste0("parentID" , i))) &
				   is.na(currentParent1) ,
				 c("currentParent1" ,
				   "currentParent2" ,
				   "newBirthDateParent1" ,
				   "newBirthDateParent2") := list(
				     get(paste0("parentID" , i)) ,
				     get(paste0("parentID" , (i+1))) ,
				     get(paste0("birthDateParent" , i)) ,
				     get(paste0("birthDateParent" , (i+1)))
				 )]
    }
    ##Some parents are not adjacent - that is, sometimes it is parent 1 and parent 4 that is filled out, thus currentParent2 remains empty. Fixing this:

    for (i in 1:length(grep('parentID.*' , names(analysisDatasetCurrentYear)))) {
      analysisDatasetCurrentYear[!is.na(get(paste0("parentID" , i))) &
				   is.na(currentParent2) &
				   get(paste0("parentID" , i)) != currentParent1 ,
				 c("currentParent2" ,
				   "newBirthDateParent2") := list(
				     get(paste0("parentID" , i)) ,
				     get(paste0("birthDateParent" , i))
				 )]
    }
    ##Results inspected visually, including with restrictions to those with a parent in parentID3 - results as expected.
    ##Making a list of variables that can be deleted now:
    temp <- grep('.*[0-9]' , names(analysisDatasetCurrentYear) , value = TRUE)
    temp2 <- c(grep('current.*|new.*|original.*' , temp , value = TRUE) ,
	       "parentFoedAdopOrig1" ,
	       "parentFoedAdopOrig2")
    temp <- temp[!temp %in% temp2]
    ##Inserting this list of variables in a command that deletes the variables, and looping over this:
    for (i in paste0("analysisDatasetCurrentYear[ , " , temp , " := NULL]")) {
      eval(parse(text = i))
    }
    setnames(analysisDatasetCurrentYear , old = c("day" , "newBirthDateParent1" , "newBirthDateParent2") , new = c("date" , "birthDateParent1" , "birthDateParent2"))
    ##Applying censoring information for the parents - which is only death:
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , dod , by.x = "currentParent1" , by.y = "pnr" , all.x = TRUE)
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , dod , by.x = "currentParent2" , by.y = "pnr" , all.x = TRUE , suffixes = c("Parent1" , "Parent2"))
    analysisDatasetCurrentYear[!is.na(doddatoParent1) & date >= doddatoParent1 , c("currentParent1" , "birthDateParent1") := list(NA , NA)]
    analysisDatasetCurrentYear[!is.na(doddatoParent2) & date >= doddatoParent2 , c("currentParent2" , "birthDateParent2") := list(NA , NA)]
    ##For monitoring:
    print("Just finished structuring parents in analysis dataset")
    print(Sys.time())

    ##Applying censoring information - creating dataset for this and merging:
    censoring <- unique(fullPopulationChildrenCurrentYear[!is.na(pnr) , .(pnr , studyEntry , ageCensoring , deathCensoring , emigrationCensoring)])
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear , censoring ,
					by.x = "pnr" ,
					by.y = "pnr" ,
					all.x = TRUE)
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date >= studyEntry]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= ageCensoring |
							       is.na(ageCensoring)]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= deathCensoring |
							       is.na(deathCensoring)]
    analysisDatasetCurrentYear <- analysisDatasetCurrentYear[date <= emigrationCensoring |
							       is.na(emigrationCensoring)]
    ##Calculating mean parental age:
    analysisDatasetCurrentYear[!is.na(currentParent2) & !is.na(currentParent1) ,
			       meanParentalAge := (
				 ((date - birthDateParent1) / 365.24) +
				   ((date - birthDateParent2) / 365.24)) / 2]
    analysisDatasetCurrentYear[is.na(currentParent2) ,
			       meanParentalAge := ((date - birthDateParent1) / 365.24)]
    analysisDatasetCurrentYear[is.na(currentParent1) ,
			       meanParentalAge := ((date - birthDateParent2) / 365.24)]
    ##Calculating current child age:
    ##Merging with fullPopulationChildrenCurrentYear
    fullPopulationChildrenCurrentYear[!is.na(pnr) , duplTest := duplicated(pnr)]
    fullPopulationChildrenCurrentYear[duplTest == FALSE , mergePnr := pnr]
    analysisDatasetCurrentYear <- merge(analysisDatasetCurrentYear ,
					fullPopulationChildrenCurrentYear[ ,
									   .(mergePnr , birthDate)] ,
					by.x = "pnr" , by.y = "mergePnr" , all.x = TRUE)
    fullPopulationChildrenCurrentYear[ , c("duplTest" , "mergePnr") := NULL]
    ##Calculating current age:
    analysisDatasetCurrentYear[ , childAge := (date - birthDate) / 365.24]
    ##For monitoring:

    ##Making a list to ensure not to include dead children:
    if (exists("deathList")) {
	deathList <- rbindlist(list(analysisDatasetCurrentYear[!is.na(deathCensoring) ,
							       .(pnr , deathCensoring)] ,
				    deathList) , fill = TRUE)
    } else {
	deathList <- analysisDatasetCurrentYear[!is.na(deathCensoring) ,
						.(pnr , deathCensoring)]
    }
    deathList[ , deathCensoring := NULL]
    deathList <- unique(deathList)

    ##Importing income and neighborhood support, while re-using an object from the count of children for each address:
    ##Adding income and neighborhood support to numberOfAdultsTemp:
    fullPopulationChildrenCurrentYearTemp <-
      unique(fullPopulationChildrenCurrentYear ,
	     by = c("pnr" , "komChild" ,
		    "opgikomChild" , "incomeVariable" ,
		    "parishQuantileDifference100Euros"))[ ,
							  .(pnr ,
							    komChild ,
							    opgikomChild ,
							    incomeVariable ,
							    parishQuantileDifference100Euros)]

    numberOfAdultsTemp <-
      merge(numberOfAdultsTemp ,
	    fullPopulationChildrenCurrentYearTemp ,
	    by.x = c("pnr" ,
		     "kom" ,
		     "opgikom") ,
	    by.y = c("pnr" ,
		     "komChild" ,
		     "opgikomChild") ,
	    all.x = TRUE)
    ##There are some instances here where a child lives at two addresses during the same month. Choosing one arbitrarily over the other (but prioritizing non-missing values):
    setorder(numberOfAdultsTemp , pnr , adrdato , incomeVariable , parishQuantileDifference100Euros , na.last = TRUE)
    numberOfAdultsTemp <- unique(numberOfAdultsTemp , by = c("pnr" , "adrdato"))
    ##Merging the income and parishQuantileDifference to the main dataset:
    analysisDatasetCurrentYear <-
      merge(analysisDatasetCurrentYear ,
	    numberOfAdultsTemp[ ,
				.(pnr , adrdato ,
				  incomeVariable ,
				  parishQuantileDifference100Euros)] ,
	    by.x = c("pnr" , "date") ,
	    by.y = c("pnr" , "adrdato") ,
	    all.x = TRUE)


    analysisDatasetCurrentYear[ , calendarTimeGroup := cut(date ,
					       breaks = c(as.Date("1997-01-01") ,
							  as.Date("2003-01-01") ,
							  as.Date("2010-01-01") ,
							  as.Date("2019-01-01")) ,
					       labels = c("1997-2002" ,
							  "2003-2009" ,
							  "2010-2018"))]
    ##For some reason, the last date is not accepted in the interval when using dates (but it is in cut when using numbers). Maybe there is some hidden property, a la some hours or something, hidden somewhere - moving the dates one month solves the problem.

    analysisDatasetCurrentYear[ , childAge := as.numeric(childAge)]

    analysisDatasetCurrentYear[ , childAgeGroup :=
				      cut(childAge ,
					  breaks = c(-1 , 7 , 19) ,
					  labels = c("Child 0-6 years old" ,
						     "Child 7-18 years old"))]

    analysisDatasetCurrentYear[ , meanParentalAge := as.numeric(meanParentalAge)]
    analysisDatasetCurrentYear[ , parentalAgeGroup :=
				      cut(meanParentalAge ,
					  breaks = c(10 , 25 , 35 , 65 , 100) ,
					  labels = c("Mean parental age 25 or less" ,
						     "Mean parental age >25-35" ,
						     "Mean parental age >35-65" ,
						     "Mean parental age >65-100"))]

    analysisDatasetCurrentYear[ , c("birthDateParent1" ,
				    "birthDateParent2" ,
				    "originalParent1" ,
				    "originalParent2" ,
				    "doddatoParent1" ,
				    "doddatoParent2") := NULL]

    fwrite(analysisDatasetCurrentYear , paste0("analysisDataset" , k , "OnlyCountsAndEconomy.csv"))
    ##For monitoring:
    print("Just wrote year file")
    ##Writing a few additional files to secure myself against breakdowns:
    fwrite(deathList , paste0("deathListAddress" , k , ".csv"))
    fwrite(exclusionList , paste0("exclusionListAddress" , k , ".csv"))
    print(Sys.time())
  }
#+end_src
** Code block to re-assemble all the individual files produced above to one analysis dataset
#+begin_src R :session rsession :results output :exports both
  ##Joining the files into one:
  analysisFilesList <- paste0("analysisDataset" , 1997:2018 , ".csv")
  analysisList <-
      lapply(analysisFilesList ,
	     fread ,
	     colClasses = c("pnr" = "character" ,
			    "date" = "Date" ,
			    "currentParent2" = "character" ,
			    "currentParent1" = "character" ,
			    "reconstitutedFamily" = "factor" ,
			    "studyEntry" = "Date" ,
			    "ageCensoring" = "Date" ,
			    "deathCensoring" = "Date" ,
			    "emigrationCensoring" = "Date" ,
			    "meanParentalAge" = "numeric" ,
			    "birthDate" = "Date" ,
			    "childAge" = "numeric" ,
			    "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			    "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			    "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			    "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			    "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			    "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			    "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			    "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			    "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			    "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			    "strokeGroupDiagCurrentParent1" = "numeric" ,
			    "strokeGroupDiagCurrentParent2" = "numeric" ,
			    "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			    "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			    "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			    "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			    "goutGroupDiagCurrentParent1" = "numeric" ,
			    "goutGroupDiagCurrentParent2" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "allergyGroupDiagCurrentParent1" = "numeric" ,
			    "allergyGroupDiagCurrentParent2" = "numeric" ,
			    "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			    "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			    "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			    "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			    "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			    "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			    "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			    "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			    "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			    "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			    "anemiasGroupDiagCurrentParent1" = "numeric" ,
			    "anemiasGroupDiagCurrentParent2" = "numeric" ,
			    "cancerGroupDiagCurrentParent1" = "numeric" ,
			    "cancerGroupDiagCurrentParent2" = "numeric" ,
			    "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			    "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			    "migraineGroupDiagCurrentParent1" = "numeric" ,
			    "migraineGroupDiagCurrentParent2" = "numeric" ,
			    "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			    "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			    "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			    "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			    "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			    "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			    "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			    "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			    "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			    "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			    "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			    "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			    "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			    "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			    "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			    "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			    "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			    "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			    "dementiaGroupDiagCurrentParent1" = "numeric" ,
			    "dementiaGroupDiagCurrentParent2" = "numeric" ,
			    "otherGroupDiagCurrentParent1" = "numeric" ,
			    "otherGroupDiagCurrentParent2" = "numeric" ,
			    "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			    "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			    "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			    "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			    "aidsHivCharlsonCurrentParent1" = "numeric" ,
			    "aidsHivCharlsonCurrentParent2" = "numeric" ,
			    "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			    "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			    "leukemiaCharlsonCurrentParent1" = "numeric" ,
			    "leukemiaCharlsonCurrentParent2" = "numeric" ,
			    "lymphomaCharlsonCurrentParent1" = "numeric" ,
			    "lymphomaCharlsonCurrentParent2" = "numeric" ,

"cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "dementiaCharlsonCurrentParent1" = "numeric" ,
			    "dementiaCharlsonCurrentParent2" = "numeric" ,
			    "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			    "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			    "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			    "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			    "heartFailureCharlsonCurrentParent1" = "numeric" ,
			    "heartFailureCharlsonCurrentParent2" = "numeric" ,
			    "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			    "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			    "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			    "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			    "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			    "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			    "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			    "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			    "alcoholAbuseCurrentParent1" = "numeric" ,
			    "alcoholAbuseCurrentParent2" = "numeric" ,
			    "substanceAbuseCurrentParent1" = "numeric" ,
			    "substanceAbuseCurrentParent2" = "numeric" ,
			    "unspecificEverCurrentParent1" = "numeric" , 
			    "unspecificEverCurrentParent2" = "numeric" , 
			    "unspecificTwoYearCurrentParent1" = "numeric" , 
			    "unspecificTwoYearCurrentParent2" = "numeric" ,
			    "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			    "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			    "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			    "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			    "jointCharlsonParents" = "numeric" ,
			    "outcomePhysicalAbuse" = "numeric" ,
			    "interparentalViolence" = "factor" ,
			    "familyEducationalLevel" = "factor" ,
			    "parentalAbuseAsChild" = "factor" ,
			    "oneForeignParent" = "factor" ,
			    "familyNeedProtection" = "factor" ,
			    "parentalPsychiatricDisease" = "factor" ,
			    "parentalSubstanceAbuse" = "factor" ,
			    "calendarTimeGroup" = "factor" ,
			    "childAgeGroup" = "factor" ,
			    "parentalAgeGroup" = "factor") ,
	     drop = c("incomeVariable" ,
		      "parishQuantileDifference100Euros" ,
		      "numberOfAdults" ,
		      "numberOfChildren" ,
		      "numberOfAdultsFactor" ,
		      "numberOfChildrenFactor"))

  ##Formatting the levels correctly (all formatting tested on the arbitrary analysisDataset2010.csv):
  analysisFilesList <- gsub('\\.csv' , '' , analysisFilesList)
  names(analysisList) <- analysisFilesList



  list2env(analysisList , globalenv())

  for (i in analysisFilesList) {
      eval(parse(text = paste0(i , '[ , familyEducationalLevel :=
			 factor(familyEducationalLevel ,
				levels = c("Primary education" ,
					   "Secondary education" ,
					   "Tertiary education or higher"))]')))

      eval(parse(text = paste0(i , '[ ,
		      reconstitutedFamily :=
			  factor(
			      reconstitutedFamily ,
					 levels = c("Living with biological parent(s)" ,
						    "Living with one or more unrelated adults" ,
						    "Adopted or in foster care"))]')))

      eval(parse(text = paste0(i , '[ ,
		      parentalPsychiatricDisease :=
			  factor(parentalPsychiatricDisease ,
				 levels = c("No psychiatric disease" ,
					    "Any psychiatric disease"))]')))

      eval(parse(text = paste0(i , '[ ,
		      interparentalViolence :=
			  factor(interparentalViolence ,
				 levels = c("No interparental violence" ,
					    "Interparental violence"))]')))

      eval(parse(text = paste0(i , '[ , parentalSubstanceAbuse :=
			     factor(parentalSubstanceAbuse ,
				    levels = c("No parental substance abuse" ,
					       "Parental substance abuse"))]')))

      eval(parse(text = paste0(i , '[ , calendarTimeGroup :=
			     factor(calendarTimeGroup ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]')))

      eval(parse(text = paste0(i , '[ ,
		      parentalAbuseAsChild :=
			  factor(parentalAbuseAsChild ,
				 levels = c("No maltreatment or neglect" ,
					    "Maltreatment or neglect, one parent" ,
					    "Maltreatment or neglect, both parents"))]')))

      eval(parse(text = paste0(i , '[ , oneForeignParent :=
			     factor(oneForeignParent ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]')))

      eval(parse(text = paste0(i , '[ ,
		      familyNeedProtection :=
			  factor(familyNeedProtection ,
				 levels = c("Not in need of protection" ,
					    "In need of protection"))]')))

      eval(parse(text = paste0(i , '[ , childAgeGroup :=
			     factor(childAgeGroup , 
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]')))

      eval(parse(text = paste0(i , '[ , parentalAgeGroup := factor(parentalAgeGroup , 
						    levels = c("Mean parental age 25 or less" ,
							       "Mean parental age >25-35" ,
							       "Mean parental age >35-65" ,
							       "Mean parental age >65-100"))]')))
  }

  ## This seems to not be relevant anymore
  ##For some reason, analysisDataset1999 contains some columns that should have been deleted - I haven't been able to locate the reason for this periodic error. Deleting these columns:

  ## analysisDataset1999[ , c("parentID" , "birthDateParent" , "parentFoedAdop") := NULL]

  analysisDataset <- rbindlist(list(analysisDataset1997 ,
				    analysisDataset1998 ,
				    analysisDataset1999 ,
				    analysisDataset2000 ,
				    analysisDataset2001 ,
				    analysisDataset2002 ,
				    analysisDataset2003 ,
				    analysisDataset2004 ,
				    analysisDataset2005 ,
				    analysisDataset2006 ,
				    analysisDataset2007 ,
				    analysisDataset2008 ,
				    analysisDataset2009 ,
				    analysisDataset2010 ,
				    analysisDataset2011 ,
				    analysisDataset2012 ,
				    analysisDataset2013 ,
				    analysisDataset2014 ,
				    analysisDataset2015 ,
				    analysisDataset2016 ,
				    analysisDataset2017 ,
				    analysisDataset2018))

  ##Removing the yearly datasets from memory:

  rm(analysisDataset1997 ,
     analysisDataset1998 ,
     analysisDataset1999 ,
     analysisDataset2000 ,
     analysisDataset2001 ,
     analysisDataset2002 ,
     analysisDataset2003 ,
     analysisDataset2004 ,
     analysisDataset2005 ,
     analysisDataset2006 ,
     analysisDataset2007 ,
     analysisDataset2008 ,
     analysisDataset2009 ,
     analysisDataset2010 ,
     analysisDataset2011 ,
     analysisDataset2012 ,
     analysisDataset2013 ,
     analysisDataset2014 ,
     analysisDataset2015 ,
     analysisDataset2016 ,
     analysisDataset2017 ,
     analysisDataset2018 ,
     analysisList)
  gc()

  ##Correcting some minor errors occurring because of the join:
  analysisDataset[ , studyEntry := min(studyEntry) , by = pnr]

  ##Expanding this section with a parallel preparation of the dataset for counts and economy:
  ##Joining the files into one:
  analysisFilesList <- paste0("analysisDataset" , 1997:2018 , "OnlyCountsAndEconomy" , ".csv")
  analysisListCounts <-
      lapply(analysisFilesList ,
	     fread ,
	     colClasses = c("pnr" = "character" ,
			    "date" = "Date" ,
			    "incomeVariable" = "numeric" ,
			    "parishQuantileDifference100Euros" = "numeric") ,
	     drop = c("currentParent2" ,
		      "currentParent1" ,
		      "parentFoedAdopOrig1" ,
		      "parentFoedAdopOrig2" ,
		      "studyEntry" ,
		      "ageCensoring" ,
		      "deathCensoring" ,
		      "emigrationCensoring" ,
		      "meanParentalAge" ,
		      "birthDate" ,
		      "childAge" ,
		      "calendarTimeGroup" ,
		      "childAgeGroup" ,
		      "parentalAgeGroup"))

  ##Formatting the levels correctly (all formatting tested on the arbitrary analysisDataset2010.csv):
  analysisFilesList <- gsub('\\.csv' , '' , analysisFilesList)
  names(analysisListCounts) <- analysisFilesList

  list2env(analysisListCounts , globalenv())


  analysisDatasetOnlyCountsAndEconomy <- rbindlist(list(analysisDataset1997OnlyCountsAndEconomy ,
				    analysisDataset1998OnlyCountsAndEconomy ,
				    analysisDataset1999OnlyCountsAndEconomy ,
				    analysisDataset2000OnlyCountsAndEconomy ,
				    analysisDataset2001OnlyCountsAndEconomy ,
				    analysisDataset2002OnlyCountsAndEconomy ,
				    analysisDataset2003OnlyCountsAndEconomy ,
				    analysisDataset2004OnlyCountsAndEconomy ,
				    analysisDataset2005OnlyCountsAndEconomy ,
				    analysisDataset2006OnlyCountsAndEconomy ,
				    analysisDataset2007OnlyCountsAndEconomy ,
				    analysisDataset2008OnlyCountsAndEconomy ,
				    analysisDataset2009OnlyCountsAndEconomy ,
				    analysisDataset2010OnlyCountsAndEconomy ,
				    analysisDataset2011OnlyCountsAndEconomy ,
				    analysisDataset2012OnlyCountsAndEconomy ,
				    analysisDataset2013OnlyCountsAndEconomy ,
				    analysisDataset2014OnlyCountsAndEconomy ,
				    analysisDataset2015OnlyCountsAndEconomy ,
				    analysisDataset2016OnlyCountsAndEconomy ,
				    analysisDataset2017OnlyCountsAndEconomy ,
				    analysisDataset2018OnlyCountsAndEconomy))

  ##Joining the two on values:

  analysisDataset[analysisDatasetOnlyCountsAndEconomy ,
		  on = c("pnr" , "date") ,
		  c("incomeVariable" ,
		    "parishQuantileDifference100Euros") :=
		      list(i.incomeVariable ,
			   i.parishQuantileDifference100Euros)]

  ##There is a curious number of missings of the parental age - the present values are correct, and when checking individual values there are no apparent reason that these values should be missing. Values are re-calculated using BEF:

  ##If bef is not loaded (will need koen in imputation):
  library(lubridate)
  bef <- fread("bef_pop_230921.csv" ,
	       select = c("pnr" , "opgikom" , "MOR_ID" ,
			  "FAR_ID" , "BOP_VFRA" , "FOED_DAG" ,
			  "OPR_LAND" , "VAN_VTIL" , "YEAR" ,
			  "kom" , "FM_MARK" , "koen") ,
	       colClasses = c("pnr" = "character" , "opgikom" = "character" , "MOR_ID" = "character" , "FAR_ID" = "character" , "OPR_LAND" = "character" , "kom" = "character")) 
  bef <- bef[!is.na(pnr)]
  bef <- bef[pnr != ""]
  ##Make everything dates:
  bef[ , FOED_DAG := as.Date(FOED_DAG , format = "%m/%d/%Y")]
  bef[ , BOP_VFRA := floor_date(as.Date(BOP_VFRA , format = "%m/%d/%Y") , unit = "month")]
  bef[ , VAN_VTIL := floor_date(as.Date(VAN_VTIL , format = "%m/%d/%Y") , unit = "month")]


  setorder(bef , pnr , FOED_DAG , na.last = TRUE)
  befBirth <- unique(bef , by = "pnr")
  befBirth <- befBirth[ , .(pnr , FOED_DAG)]
  setnames(befBirth , "pnr" , "currentParent1")
  analysisDataset[befBirth , on = "currentParent1" , FOED_DAGParent1 := i.FOED_DAG]
  setnames(befBirth , "currentParent1" , "currentParent2")
  analysisDataset[befBirth , on = "currentParent2" , FOED_DAGParent2 := i.FOED_DAG]


  ##Calculating mean parental age:
  analysisDataset[!is.na(FOED_DAGParent1) & !is.na(FOED_DAGParent2) ,
		  meanParentalAge := (
		      ((date - FOED_DAGParent1) / 365.24) +
		      ((date - FOED_DAGParent2) / 365.24)) / 2]
  analysisDataset[is.na(FOED_DAGParent2) ,
		  meanParentalAge := ((date - FOED_DAGParent1) / 365.24)]
  analysisDataset[is.na(FOED_DAGParent1) ,
		  meanParentalAge := ((date - FOED_DAGParent2) / 365.24)]
  analysisDataset[ , meanParentalAge := as.numeric(meanParentalAge)]
  analysisDataset[meanParentalAge < 10 , meanParentalAge := NA]
  analysisDataset[ , parentalAgeGroup :=
				    cut(meanParentalAge ,
					breaks = c(10 , 25 , 35 , 65 , 100) ,
					labels = c("Mean parental age 25 or less" ,
						   "Mean parental age >25-35" ,
						   "Mean parental age >35-65" ,
						   "Mean parental age >65-100"))]

  ##Cleaning up some helping variables:
  analysisDataset[ , c("FOED_DAGParent1" , "FOED_DAGParent2") := NULL]


  ##The number of missings is somewhat lower. There is a number of very young parents - with a mean age of somewhere between 0 and 10. This is assumed to be registry errors and left as NAs for imputation. Difficult to know whether the wrong parent or age is entered - the implicit assumption in my data is that all parents are entered correctly. Remaining NAs are due to missing birth dates in BEF. 

  ##There is further comments on all individual variables except health classifications under the heading Individual Variables - all changes are, however, coded here.

  ##There is also a number of missings on the familyEducationalLevel variable. A few cases were looked up in both UDDA, KOTO and KOTRE and in all cases, these registers contained either meaningless or no records on these pnr. In principle, it should not be possible to not have a value - there is a code in UDDA for no registered education. Thus, I will interpret these values as missings. 

  ##Reasons for missings in oneForeignParent are documented earlier - this is because of either missings, or coded values corresponding to missings.

  ##In reconstitutedFamily It seems reasonable to assume that a child with unchanged parents, previously with the status "Living with biological parent(s)", no change of FM_MARK to another status but NAs in FM_MARK still have the same status. Thus, some missings in this variable will be labeled as such:

  temp <- analysisDataset[reconstitutedFamily == "Living with biological parent(s)" ,
			  .(pnr , currentParent1 , currentParent2)]
  temp[ , tempVariable := factor("Living with biological parent(s)" ,
					 levels = c("Living with biological parent(s)" ,
						    "Living with one or more unrelated adults" ,
						    "Adopted or in foster care"))]
  temp <- unique(temp)
  analysisDataset[temp ,
		  on = c("pnr" , "currentParent1" , "currentParent2") ,
		  tempVariable := i.tempVariable]
  setnames(temp , c("currentParent1" , "currentParent2") ,
	   c("currentParent2" , "currentParent1"))
  analysisDataset[temp ,
		  on = c("pnr" , "currentParent1" , "currentParent2") ,
		  tempVariable := i.tempVariable]
  ##For any combinations with other values than "Living with biological parent(s)" and NAs (should not be replaced - there is a change in status and the NAs may indicate either of the states, or uncertainty concerning the transition of these states):
  analysisDataset[reconstitutedFamily != tempVariable &
		  !is.na(reconstitutedFamily)&
		  !is.na(tempVariable), doNotReplace := 1]
  tempDoNotReplace <- analysisDataset[doNotReplace == 1 ,
				      .(pnr , currentParent1 ,
					currentParent2 , doNotReplace)]
  tempDoNotReplace <- unique(tempDoNotReplace)
  analysisDataset[ , doNotReplace := NULL]
  analysisDataset[tempDoNotReplace ,
		  on = c("pnr" , "currentParent1" , "currentParent2") ,
		  doNotReplace := i.doNotReplace]
  setnames(tempDoNotReplace , c("currentParent1" , "currentParent2") ,
	   c("currentParent2" , "currentParent1"))
  analysisDataset[tempDoNotReplace ,
		  on = c("pnr" , "currentParent1" , "currentParent2") ,
		  doNotReplace := i.doNotReplace]
  ##Now all observations with "Living with biological parent(s)" should be marked, and all trajectories with changes in this variable should be marked as well - an inspection confirms this. Replacing values for those with a NA in reconstitutedFamily, with "Living with biological parent(s)" in tempVariable and without a 1 in doNotReplace:
  analysisDataset[is.na(reconstitutedFamily) &
		  is.na(doNotReplace) &
		  tempVariable == "Living with biological parent(s)" ,
		  reconstitutedFamily := "Living with biological parent(s)"]

  ##This caused the number of NAs to drop substantially. I find it too speculative to replace within the other categories - FM_MARK may change no matter the values in currentParent, and all other family types than one with biological parents have already "changed" once during the child's trajectory and could be hypothesized to change again, perhaps reflected in a NA in FM_MARK.

  ##Cleaning after the above:
  analysisDataset[ , c("doNotReplace" , "tempVariable") := NULL]
  rm(temp , tempDoNotReplace)

  ##Writing the most accurate dataset as of the current status of my work (2022-02-11):
  fwrite(analysisDataset , "analysisDataset.csv")
#+end_src
** Individual variables - oversight of missings, solutions to problems implemented in code elsewhere
This is an oversight of all individual variables, except health
  categories, and some comments - all code for corrections after  
+ "pnr" :: checked for missings - none found                                                         

+ "date" :: checked for missings and range, no missings and range equals study period                                                       

+ "currentParent2" some missings                                              

+ "currentParent1" some missings, no entries with both parents missing (that would make an individual unexposable to the exposure)                                              

+ "reconstitutedFamily" :: see table. Upon inspection of the data, it seems reasonable to replace missings in the case where the personal identification number for parents does not change, FM_MARK does not change to indicate that the child lives alone and the remaining observations have "Living with biological parent(s)" as their value. 
reconstitutedFamily
        Living with biological parent(s) 
                               250972706 
Living with one or more unrelated adults 
                                20635346 
               Adopted or in foster care 
                                 6982915 
                                    <NA> 
                                39960777

+ "studyEntry" :: no missings, range corresponds to study period.                                                   

+ "ageCensoring" :: 310470863 missings which seems reasonable, range close to study range.                                                

+ "deathCensoring" :: 318519635 missings which seems reasonable, range corresponds to study range.                                              

+ "emigrationCensoring" :: 317642089 missings which seems reasonable, range corresponds to study range.                                          

+ "meanParentalAge" ::  For undetermined reasons, there are fewer missings when age is "re-generated" from bef. With this arrangement, 1388385 missings are left. Some of these are less than 10 years old - I delete these as missings, as I assume they are the result of errors in data. After this, 1388521 missings exist. 

+ "birthDate" No missings, range is within what is expected for the dataset to only contain adults.                                                     

+ "childAge" :: no missings, range is from 0 to (CENSORED - LESS THAN A HUNDRETH ABOVE 18) - this is acceptable.
 The disease variables below will not be checked except for the first one, as they are all created through the same algorithm. 

+ "hypertensionGroupDiagCurrentParent1" :: This is a 1-0 variable and the only existing values are 1 and NA, as expected.                         

+ "hypertensionGroupDiagCurrentParent2"                          

+ "dyslipidemiaGroupDiagCurrentParent1"                          

+ "dyslipidemiaGroupDiagCurrentParent2"                          

+ "ischemicHeartDiseaseGroupDiagCurrentParent1"                  

+ "ischemicHeartDiseaseGroupDiagCurrentParent2"                  

+ "atrialFibrillationGroupDiagCurrentParent1"                    

+ "atrialFibrillationGroupDiagCurrentParent2"                    

+ "heartFailureGroupDiagCurrentParent1"                          

+ "heartFailureGroupDiagCurrentParent2"                          

+ "peripheralArteryOcclusiveGroupDiagCurrentParent1"             

+ "peripheralArteryOcclusiveGroupDiagCurrentParent2"             

+ "strokeGroupDiagCurrentParent1"                                

+ "strokeGroupDiagCurrentParent2"                                

+ "diabetesMellitusGroupDiagCurrentParent1"                      

+ "diabetesMellitusGroupDiagCurrentParent2"                      

+ "thyroidDisorderGroupDiagCurrentParent1"                       

+ "thyroidDisorderGroupDiagCurrentParent2"                       

+ "goutGroupDiagCurrentParent1"                                  

+ "goutGroupDiagCurrentParent2"                                  

+ "chronicPulmonaryDiseaseGroupDiagCurrentParent1"               

+ "chronicPulmonaryDiseaseGroupDiagCurrentParent2"               

+ "allergyGroupDiagCurrentParent1"                               

+ "allergyGroupDiagCurrentParent2"                               

+ "ulcerChronicGastritisGroupDiagCurrentParent1"                 

+ "ulcerChronicGastritisGroupDiagCurrentParent2"                 

+ "chronicLiverDiseaseGroupDiagCurrentParent1"                   

+ "chronicLiverDiseaseGroupDiagCurrentParent2"                   

+ "inflammatoryBowelDiseaseGroupDiagCurrentParent1"              

+ "inflammatoryBowelDiseaseGroupDiagCurrentParent2"              

+ "diverticularDiseaseOfIntestineGroupDiagCurrentParent1"        

+ "diverticularDiseaseOfIntestineGroupDiagCurrentParent2"        

+ "chronicKidneyDiseaseGroupDiagCurrentParent1"                  

+ "chronicKidneyDiseaseGroupDiagCurrentParent2"                  

+ "prostateDisordersGroupDiagCurrentParent1"                     

+ "prostateDisordersGroupDiagCurrentParent2"                     

+ "connectiveTissueDisordersGroupDiagCurrentParent1"             

+ "connectiveTissueDisordersGroupDiagCurrentParent2"             

+ "osteoporosisGroupDiagCurrentParent1"                          

+ "osteoporosisGroupDiagCurrentParent2"                          

+ "anemiasGroupDiagCurrentParent1"                               

+ "anemiasGroupDiagCurrentParent2"                               

+ "cancerGroupDiagCurrentParent1"                                

+ "cancerGroupDiagCurrentParent2"                                

+ "visionProblemGroupDiagCurrentParent1"                         

+ "visionProblemGroupDiagCurrentParent2"                         

+ "migraineGroupDiagCurrentParent1"                              

+ "migraineGroupDiagCurrentParent2"                              

+ "epilepsyGroupDiagCurrentParent1"                              

+ "epilepsyGroupDiagCurrentParent2"                              

+ "parkinsonsDiseaseGroupDiagCurrentParent1"                     

+ "parkinsonsDiseaseGroupDiagCurrentParent2"                     

+ "multipleSclerosisGroupDiagCurrentParent1"                     

+ "multipleSclerosisGroupDiagCurrentParent2"                     

+ "neuropathiesGroupDiagCurrentParent1"                          

+ "neuropathiesGroupDiagCurrentParent2"                          

+ "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1"   

+ "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2"   

+ "anorexiaBulimiaGroupDiagCurrentParent1"                       

+ "anorexiaBulimiaGroupDiagCurrentParent2"                       

+ "bipolarAffectiveDisorderGroupDiagCurrentParent1"              

+ "bipolarAffectiveDisorderGroupDiagCurrentParent2"              

+ "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1"

+ "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2"

+ "personalityDisorderGroupDiagCurrentParent1"                   

+ "personalityDisorderGroupDiagCurrentParent2"                   

+ "dementiaGroupDiagCurrentParent1"                              

+ "dementiaGroupDiagCurrentParent2"                              

+ "otherGroupDiagCurrentParent1"                                 

+ "otherGroupDiagCurrentParent2"                                 

+ "pretermBirthGroupDiagCurrentParent1"                          

+ "pretermBirthGroupDiagCurrentParent2"                          

+ "acuteCaesarianSectionGroupDiagCurrentParent1"                 

+ "acuteCaesarianSectionGroupDiagCurrentParent2"                 

+ "aidsHivCharlsonCurrentParent1"                                

+ "aidsHivCharlsonCurrentParent2"                                

+ "anyMalignancyCharlsonCurrentParent1"                          

+ "anyMalignancyCharlsonCurrentParent2"                          

+ "cerebrovascularDiseaseCharlsonCurrentParent1"                 

+ "cerebrovascularDiseaseCharlsonCurrentParent2"                 

+ "chronicPulmonaryDiseaseCharlsonCurrentParent1"                

+ "chronicPulmonaryDiseaseCharlsonCurrentParent2"                

+ "dementiaCharlsonCurrentParent1"                               

+ "dementiaCharlsonCurrentParent2"                               

+ "diabetesWithComplicationsCharlsonCurrentParent1"              

+ "diabetesWithComplicationsCharlsonCurrentParent2"              

+ "diabetesWithoutComplicationsCharlsonCurrentParent1"           

+ "diabetesWithoutComplicationsCharlsonCurrentParent2"           

+ "heartFailureCharlsonCurrentParent1"                           

+ "heartFailureCharlsonCurrentParent2"                           

+ "hemiplegiaParaplegiaCharlsonCurrentParent1"                   

+ "hemiplegiaParaplegiaCharlsonCurrentParent2"                   

+ "metastaticSolidTumorCharlsonCurrentParent1"                   

+ "metastaticSolidTumorCharlsonCurrentParent2"                   

+ "mildLiverDiseaseCharlsonCurrentParent1"                       

+ "mildLiverDiseaseCharlsonCurrentParent2"                       

+ "myocardialInfarctionCharlsonCurrentParent1"                   

+ "myocardialInfarctionCharlsonCurrentParent2"                   

+ "pepticUlcerDiseaseCharlsonCurrentParent1"                     

+ "pepticUlcerDiseaseCharlsonCurrentParent2"                     

+ "peripheralVascularDiseaseCharlsonCurrentParent1"              

+ "peripheralVascularDiseaseCharlsonCurrentParent2"              

+ "renalDiseaseCharlsonCurrentParent1"                           

+ "renalDiseaseCharlsonCurrentParent2"                           

+ "rheumaticDiseaseCharlsonCurrentParent1"                       

+ "rheumaticDiseaseCharlsonCurrentParent2"                       

+ "severeLiverDiseaseCharlsonCurrentParent1"                     

+ "severeLiverDiseaseCharlsonCurrentParent2"                     

+ "alcoholAbuseCurrentParent1"                                   

+ "alcoholAbuseCurrentParent2"                                   

+ "substanceAbuseCurrentParent1"                                 

+ "substanceAbuseCurrentParent2"                                 

+ "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp"                  

+ "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal"                 

+ "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp"                  

+ "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal"                 

+ "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp"          

+ "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal"         

+ "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp"          

+ "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal"         

+ "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp"              

+ "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal"             

+ "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp"              

+ "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal"             

+ "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp"               

+ "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal"              

+ "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp"               

+ "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal"              

+ "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp"       

+ "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal"      

+ "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp"       

+ "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal"      

+ "allergyGroupLmdbCurrentParent1LmdbTemp"                       

+ "allergyGroupLmdbCurrentParent1LmdbTotal"                      

+ "allergyGroupLmdbCurrentParent2LmdbTemp"                       

+ "allergyGroupLmdbCurrentParent2LmdbTotal"                      

+ "osteoporosisGroupLmdbCurrentParent1LmdbTemp"                  

+ "osteoporosisGroupLmdbCurrentParent1LmdbTotal"                 

+ "osteoporosisGroupLmdbCurrentParent2LmdbTemp"                  

+ "osteoporosisGroupLmdbCurrentParent2LmdbTotal"                 

+ "painfulConditionGroupLmdbCurrentParent1LmdbTemp"              

+ "painfulConditionGroupLmdbCurrentParent1LmdbTotal"             

+ "painfulConditionGroupLmdbCurrentParent2LmdbTemp"              

+ "painfulConditionGroupLmdbCurrentParent2LmdbTotal"             

+ "migraineGroupLmdbCurrentParent1LmdbTemp"                      

+ "migraineGroupLmdbCurrentParent1LmdbTotal"                     

+ "migraineGroupLmdbCurrentParent2LmdbTemp"                      

+ "migraineGroupLmdbCurrentParent2LmdbTotal"                     

+ "epilepsyGroupLmdbCurrentParent1LmdbTemp"                      

+ "epilepsyGroupLmdbCurrentParent1LmdbTotal"                     

+ "epilepsyGroupLmdbCurrentParent2LmdbTemp"                      

+ "epilepsyGroupLmdbCurrentParent2LmdbTotal"                     

+ "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp"      

+ "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal"     

+ "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp"      

+ "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal"     

+ "dementiaGroupLmdbCurrentParent1LmdbTemp"                      

+ "dementiaGroupLmdbCurrentParent1LmdbTotal"                     

+ "dementiaGroupLmdbCurrentParent2LmdbTemp"                      

+ "dementiaGroupLmdbCurrentParent2LmdbTotal"                     

+ "jointCharlsonParents" No missings, range from 0 to 20 which seems reasonable (the Charlson index here is a sum of the parents' index). After this check an error was found in coding mutually exclusive categories of Charlson, the index is re-coded in the code for analyses (the error only affects values larger than 2)
jointCharlsonParents
        0         1         2         3         4         5         6         7 
288084674  19326461   7737355   1760507    572943    217090    179001     51149 
        8         9        10        11        12        13        14        15 
   510873     73631     23716      7789      3218      1407       931       136 
       16        17        18        19        20      <NA> 
      539       115       156        45         8         0 

+ "outcomePhysicalAbuse" :: No missings, all in all 71140 incidents.
outcomePhysicalAbuse
        0         1         2         3         4         5         6      <NA> 
318480604      3999     17733     49297        26        10        75         0 

+ "interparentalViolence"
interparentalViolence :: no missings, a little less than one million indicators (these may be within the same individials, so fewer incidents) - this is as expected. 
No interparental violence    Interparental violence                      <NA> 
                317562356                    989388                         0

+ "familyEducationalLevel" :: the number of missings seems reasonable. Missings were checked during the last run of this algorithm, and after investigating a number of missings they turned out to be actual missings in the underlying registries.
familyEducationalLevel
           Primary education          Secondary education 
                        8370                    171868745 
Tertiary education or higher                         <NA> 
                   119180533                     27494096

+ "parentalAbuseAsChild" :: No missings, the distribution of maltreatment seems reasonable. The large number of maltreatment entries is likely the result of these being a constant variable, thus a parent with this variable will carry it through all dates while being in the dataset. 
parentalAbuseAsChild
           No maltreatment or neglect   Maltreatment or neglect, one parent 
                            295782884                              20848156 
Maltreatment or neglect, both parents                                  <NA> 
                              1920704                                     0 

+ "oneForeignParent" :: again, the distribution seems reasonable. NAs are reflections of actual missing data in the dataset. 
oneForeignParent
         No foreign parents One or more foreign parents 
                  246407699                    62531221 
                       <NA> 
                    9612824

+ "familyNeedProtection" :: no missings, distribution seems reasonable
familyNeedProtection
Not in need of protection     In need of protection                      <NA> 
                309247449                   9304295                         0 

+ "parentalPsychiatricDisease" :: No missings, distribution seems reasonable
parentalPsychiatricDisease
 No psychiatric disease Any psychiatric disease                    <NA> 
              302190469                16361275                       0

+ "parentalSubstanceAbuse" :: no missings, reasonable distribution
parentalSubstanceAbuse
No parental substance abuse    Parental substance abuse 
                  315019448                     3532296 
                       <NA> 
                          0 

+ "calendarTimeGroup" :: no missings, approximately fair distribution. Low risk of "small cells" in the analysis. 
calendarTimeGroup
1997-2002 2003-2009 2010-2018      <NA> 
 86173884 103521110 128856750         0
 

+ "childAgeGroup" :: No missings, nice spread across categories, reasonable with subgroup analysis here.
childAgeGroup
 Child 0-6 years old Child 7-18 years old                 <NA> 
           126121831            192429913                    0 

+ "parentalAgeGroup" :: Distribution seems reasonable. Number of missings corresponds to missings in the original variable. 
parentalAgeGroup
Mean parental age 25 or less     Mean parental age >25-35 
                     3526770                     76068118 
    Mean parental age >35-65    Mean parental age >65-100 
                   237501900                        66435 
                        <NA> 
                     1388521 

+ "incomeVariable" :: Distribution seems reasonable. Number of NAs acceptable.
analysisDataset[ , summary(incomeVariable)]
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.         NA's 
 (CENSORED)       58      116      133      180   (CENSORED) 20381158 (MIN AND MAX CENSORED, LIES BETWEEN APPROX -200000 AND 100000)

+ "parishQuantileDifference100Euros" Distribution seems reasonable. Number of missings acceptable - have been optimized in current dataset and is unlikely to be further improved. 
analysisDataset[ , summary(parishQuantileDifference100Euros)]
    Min.            1st Qu.   Median     Mean  3rd Qu.     Max.     NA's 
       (CENSORED)       94      112      121      138     (CENSORED) 38541447 (MIN AND MAX CENSORED, LIES BETWEEN 0 AND 1300)

The variables numberOfAdults and numberOfChildren in the versions displayed here were abandoned, see the article and subsequent code for a new variable for number of children. 

+ "numberOfAdults" :: number of missings seems reasonable. Distribution is as expected - as noted previously, there are some strange, very large numbers of co-habitating persons. I  the dataset this is truncated into categories. The most values, by far, makes sense.
> analysisDataset[ , summary(numberOfAdults)]
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's 
(CENSORED - A LARGE QUANTITY OF NAs, SOME STRANGE EXTREME VALUES)

+ "numberOfChildren" :: As above - same number of missings, reasonable distribution of values. 
analysisDataset[ , summary(numberOfChildren)]
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's 
(CENSORED - A LARGE QUANTITY OF NAs, SOME STRANGE EXTREME VALUES)

+ "numberOfAdultsFactor" :: distribution here seems reasonable. Missings is the same as in the original variable.
           One adult           Two adults Three or more adults 
(CENSORED)

+ "numberOfChildrenFactor" :: distribution here seems reasonable. Missings is the same as in the original variable. 
numberOfChildrenFactor 
(CENSORED)

** Code for re-loading dataset after crash and adding variables for imputation
#+begin_src R :session rsession :results output :exports both
  ##First is a version that goes for the "raw" data without any modifications after running all the individual years. Then follows a version that fits the "refined" data as they are currently stored. 

  analysisDataset <-
      fread("analysisDataset.csv" ,
	    colClasses = c("pnr" = "character" ,
			   "date" = "Date" ,
			   "currentParent2" = "character" ,
			   "currentParent1" = "character" ,
			   "reconstitutedFamily" = "factor" ,
			   "studyEntry" = "Date" ,
			   "ageCensoring" = "Date" ,
			   "deathCensoring" = "Date" ,
			   "emigrationCensoring" = "Date" ,
			   "meanParentalAge" = "numeric" ,
			   "birthDate" = "Date" ,
			   "childAge" = "numeric" ,
			   "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			   "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			   "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			   "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			   "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			   "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			   "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			   "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			   "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			   "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			   "strokeGroupDiagCurrentParent1" = "numeric" ,
			   "strokeGroupDiagCurrentParent2" = "numeric" ,
			   "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			   "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			   "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "goutGroupDiagCurrentParent1" = "numeric" ,
			   "goutGroupDiagCurrentParent2" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "allergyGroupDiagCurrentParent1" = "numeric" ,
			   "allergyGroupDiagCurrentParent2" = "numeric" ,
			   "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			   "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			   "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			   "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			   "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			   "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			   "anemiasGroupDiagCurrentParent1" = "numeric" ,
			   "anemiasGroupDiagCurrentParent2" = "numeric" ,
			   "cancerGroupDiagCurrentParent1" = "numeric" ,
			   "cancerGroupDiagCurrentParent2" = "numeric" ,
			   "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			   "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			   "migraineGroupDiagCurrentParent1" = "numeric" ,
			   "migraineGroupDiagCurrentParent2" = "numeric" ,
			   "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			   "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			   "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			   "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			   "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			   "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			   "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			   "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			   "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "dementiaGroupDiagCurrentParent1" = "numeric" ,
			   "dementiaGroupDiagCurrentParent2" = "numeric" ,
			   "otherGroupDiagCurrentParent1" = "numeric" ,
			   "otherGroupDiagCurrentParent2" = "numeric" ,
			   "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			   "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			   "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			   "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			   "aidsHivCharlsonCurrentParent1" = "numeric" ,
			   "aidsHivCharlsonCurrentParent2" = "numeric" ,
			   "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			   "anyMalignancyCharlsonCurrentParent2" = "numeric" ,

"leukemiaCharlsonCurrentParent1" = "numeric" ,
			   "leukemiaCharlsonCurrentParent2" = "numeric" ,
			   "lymphomaCharlsonCurrentParent1" = "numeric" ,
			   "lymphomaCharlsonCurrentParent2" = "numeric" ,			   

"cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "dementiaCharlsonCurrentParent1" = "numeric" ,
			   "dementiaCharlsonCurrentParent2" = "numeric" ,
			   "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			   "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			   "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			   "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			   "heartFailureCharlsonCurrentParent1" = "numeric" ,
			   "heartFailureCharlsonCurrentParent2" = "numeric" ,
			   "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			   "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			   "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			   "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			   "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			   "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			   "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "alcoholAbuseCurrentParent1" = "numeric" ,
			   "alcoholAbuseCurrentParent2" = "numeric" ,
			   "substanceAbuseCurrentParent1" = "numeric" ,
			   "substanceAbuseCurrentParent2" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "jointCharlsonParents" = "numeric" ,
			   "outcomePhysicalAbuse" = "numeric" ,
			   "interparentalViolence" = "factor" ,
			   "familyEducationalLevel" = "factor" ,
			   "parentalAbuseAsChild" = "factor" ,
			   "oneForeignParent" = "factor" ,
			   "familyNeedProtection" = "factor" ,
			   "parentalPsychiatricDisease" = "factor" ,
			   "parentalSubstanceAbuse" = "factor" ,
			   "calendarTimeGroup" = "factor" ,
			   "childAgeGroup" = "factor" ,
			   "parentalAgeGroup" = "factor" ,
			   "incomeVariable" = "numeric" ,
			   "parishQuantileDifference100Euros" = "numeric" ,
			   "numberOfAdults" = "numeric" ,
			   "numberOfChildren" = "numeric" ,
			   "numberOfAdultsFactor" = "factor" ,
			   "numberOfChildrenFactor" = "factor"))

  analysisDataset[ , familyEducationalLevel :=
			 factor(familyEducationalLevel ,
				levels = c("Primary education" ,
					   "Secondary education" ,
					   "Tertiary education or higher"))]

  analysisDataset[ , numberOfAdultsFactor :=
			 factor(numberOfAdultsFactor ,
				levels = c("One adult" ,
					   "Two adults" ,
					   "Three or more adults"))]

  analysisDataset[ , numberOfChildrenFactor :=
			 factor(numberOfChildrenFactor ,
				levels = c("One child" ,
					   "Two children" ,
					   "Three to five children" ,
					   "Six children or more"))]

  analysisDataset[ , reconstitutedFamily :=
			 factor(
			     reconstitutedFamily ,
			     levels = c("Living with biological parent(s)" ,
					"Living with one or more unrelated adults" ,
					"Adopted or in foster care"))]

  analysisDataset[ , parentalPsychiatricDisease :=
			 factor(parentalPsychiatricDisease ,
				levels = c("No psychiatric disease" ,
					   "Any psychiatric disease"))]

  analysisDataset[ ,
		  interparentalViolence :=
		      factor(interparentalViolence ,
			     levels = c("No interparental violence" ,
					"Interparental violence"))]

  analysisDataset[ , parentalSubstanceAbuse :=
			 factor(parentalSubstanceAbuse ,
				levels = c("No parental substance abuse" ,
					   "Parental substance abuse"))]

  analysisDataset[ , calendarTimeGroup :=
			 factor(calendarTimeGroup ,
				levels = c("1997-2002" ,
					   "2003-2009" ,
					   "2010-2018"))]

  analysisDataset[ , parentalAbuseAsChild :=
			 factor(parentalAbuseAsChild ,
				levels = c("No maltreatment or neglect" ,
					   "Maltreatment or neglect, one parent" ,
					   "Maltreatment or neglect, both parents"))]

  analysisDataset[ , oneForeignParent :=
			 factor(oneForeignParent ,
				levels = c("No foreign parents" ,
					   "One or more foreign parents"))]

  analysisDataset[ , familyNeedProtection :=
			 factor(familyNeedProtection ,
				levels = c("Not in need of protection" ,
					   "In need of protection"))]

  analysisDataset[ , childAgeGroup :=
			 factor(childAgeGroup , 
				levels = c("Child 0-6 years old" ,
					   "Child 7-18 years old"))]

  analysisDataset[ , parentalAgeGroup :=
			 factor(parentalAgeGroup , 
				levels = c("Mean parental age 25 or less" ,
					   "Mean parental age >25-35" ,
					   "Mean parental age >35-65" ,
					   "Mean parental age >65-100"))]

  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Commenting this section out, as it turns out the imputation models have to be kept quite simple in order to run. 
  ## ##Only for imputation:

  ## analysisDataset[ , reconstitutedFamily :=
  ## 		       factor(reconstitutedFamily ,
  ## 			      ordered =TRUE)]
  ## analysisDataset[ , familyEducationalLevel :=
  ## 		       factor(familyEducationalLevel ,
  ## 			      ordered = TRUE)]
  ## ##Attaching gender as an extra variable for imputation:
  ## ##Loading bef:
  ## befGender <- fread("bef_pop_230921.csv" ,
  ## 	     select = c("pnr" , "koen") ,
  ## 	     colClasses = c("pnr" = "character")) 
  ## befGender <- befGender[!is.na(pnr)]
  ## befGender <- befGender[pnr != ""]
  ## befGender <- unique(befGender)
  ## analysisDataset[befGender ,
  ## 		on = "pnr" ,
  ## 		genderChild := factor(i.koen ,
  ## 				      levels = c(1 , 2) ,
  ## 				      labels = c("Male" , "Female"))]

  ## ##There is a peculiar number of missings - attaching ftBarn
  ## ftBarnGender <- fread("ftbarn_pop_070621.csv" , colClasses = (pnr = "character") , select = c("pnr" , "koen"))
  ##   ##cpst <- fread("cpst_pop_070621.csv" , nrows = nrows)
  ## ftBarnGender <- ftBarnGender[!is.na(pnr)]
  ## ftBarnGender <- ftBarnGender[pnr != ""]
  ## ftBarnGender <- unique(ftBarnGender)
  ## analysisDataset[ftBarnGender ,
  ## 		on = "pnr" ,
  ## 		genderChildFtBarn := factor(i.koen ,
  ## 				      levels = c(1 , 2) ,
  ## 				      labels = c("Male" , "Female"))]
  ## analysisDataset[is.na(genderChild) &
  ## 		!is.na(genderChildFtBarn) ,
  ## 		genderChild := genderChildFtBarn] 

  ## ##Much fewer missings but still some - adding MFR:
  ## mfrGender <- fread("mfr_pop_070621.csv" ,
  ## 	     colClasses = c("pnr" = "character") ,
  ## 	     select = c("pnr" , "KOEN_BARN"))
  ## mfrGender <- mfrGender[!is.na(pnr)]
  ## mfrGender <- mfrGender[pnr != ""]
  ## mfrGender <- unique(mfrGender)
  ## analysisDataset[mfrGender ,
  ## 		on = "pnr" ,
  ## 		genderChildMfr := factor(i.KOEN_BARN ,
  ## 				      levels = c("M" , "K") ,
  ## 				      labels = c("Male" , "Female"))]
  ## analysisDataset[is.na(genderChild) &
  ## 		!is.na(genderChildMfr) , 
  ## 		genderChild := genderChildMfr]

  ## ##Even after reading bef, ftBarn and mfr, there are still 3705 missings. I will include these in the imputation algorithm.

  ## ##Cleaning after this:
  ## analysisDataset[ , c("genderChildFtBarn" , "genderChildMfr") := NULL]

  ## ##Generating derived variables for imputation only:
  ## analysisDataset[!is.na(deathCensoring) , deathCensoringImpute := 1]
  ## temp <- analysisDataset[deathCensoringImpute == 1 , .(pnr)]
  ## temp <- unique(temp)
  ## temp[ , deathCensoringImpute := 1]
  ## analysisDataset[ , deathCensoringImpute := NULL]
  ## analysisDataset[temp , on = "pnr" , deathCensoringImpute := i.deathCensoringImpute]
  ## analysisDataset[is.na(deathCensoringImpute) , deathCensoringImpute := 0]
  ## ##Results checked by manual inspection, classifying as expected.

  ## analysisDataset[!is.na(emigrationCensoring) , emigrationCensoringImpute := 1]
  ## temp <- analysisDataset[emigrationCensoringImpute == 1 , .(pnr)]
  ## temp <- unique(temp)
  ## temp[ , emigrationCensoringImpute := 1]
  ## analysisDataset[ , emigrationCensoringImpute := NULL]
  ## analysisDataset[temp , on = "pnr" , emigrationCensoringImpute := i.emigrationCensoringImpute]
  ## analysisDataset[is.na(emigrationCensoringImpute) , emigrationCensoringImpute := 0]
  ## ##Method replicated from above, counts looks reasonable. 

  ##Adding time variable:
  setorder(analysisDataset , pnr , date)
  analysisDataset[ , time := 0:(.N - 1) , by = pnr]

  ##Turns out that some individuals are followed for 216 and not 215 months, this is likely because of specific dates - th have everybody treated equally, these observations are thrown out:
  analysisDataset <- analysisDataset[time != 216]
  analysisDataset <- analysisDataset[time != 215] #This is because the count starts at 0
  ##Now, all counts end at 214, as expected. 


  ##VERSION FOR REFINED DATA:
  library(data.table)
  setDTthreads(20)
  analysisDataset <-
      fread("analysisDataset.csv" ,
	    colClasses = c("pnr" = "character" ,
			   "date" = "Date" ,
			   "currentParent2" = "character" ,
			   "currentParent1" = "character" ,
			   "reconstitutedFamily" = "factor" ,
			   "studyEntry" = "Date" ,
			   "ageCensoring" = "Date" ,
			   "deathCensoring" = "Date" ,
			   "emigrationCensoring" = "Date" ,
			   "meanParentalAge" = "numeric" ,
			   "birthDate" = "Date" ,
			   "childAge" = "numeric" ,
			   "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			   "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			   "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			   "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			   "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			   "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			   "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			   "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			   "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			   "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			   "strokeGroupDiagCurrentParent1" = "numeric" ,
			   "strokeGroupDiagCurrentParent2" = "numeric" ,
			   "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			   "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			   "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "goutGroupDiagCurrentParent1" = "numeric" ,
			   "goutGroupDiagCurrentParent2" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "allergyGroupDiagCurrentParent1" = "numeric" ,
			   "allergyGroupDiagCurrentParent2" = "numeric" ,
			   "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			   "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			   "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			   "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			   "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			   "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			   "anemiasGroupDiagCurrentParent1" = "numeric" ,
			   "anemiasGroupDiagCurrentParent2" = "numeric" ,
			   "cancerGroupDiagCurrentParent1" = "numeric" ,
			   "cancerGroupDiagCurrentParent2" = "numeric" ,
			   "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			   "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			   "migraineGroupDiagCurrentParent1" = "numeric" ,
			   "migraineGroupDiagCurrentParent2" = "numeric" ,
			   "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			   "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			   "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			   "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			   "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			   "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			   "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			   "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			   "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			   "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			   "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			   "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			   "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			   "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			   "dementiaGroupDiagCurrentParent1" = "numeric" ,
			   "dementiaGroupDiagCurrentParent2" = "numeric" ,
			   "otherGroupDiagCurrentParent1" = "numeric" ,
			   "otherGroupDiagCurrentParent2" = "numeric" ,
			   "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			   "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			   "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			   "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			   "aidsHivCharlsonCurrentParent1" = "numeric" ,
			   "aidsHivCharlsonCurrentParent2" = "numeric" ,
			   "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			   "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			   
"leukemiaCharlsonCurrentParent1" = "numeric" ,
			   "leukemiaCharlsonCurrentParent2" = "numeric" ,
			   "lymphomaCharlsonCurrentParent1" = "numeric" ,
			   "lymphomaCharlsonCurrentParent2" = "numeric" ,

"cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "dementiaCharlsonCurrentParent1" = "numeric" ,
			   "dementiaCharlsonCurrentParent2" = "numeric" ,
			   "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			   "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			   "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			   "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			   "heartFailureCharlsonCurrentParent1" = "numeric" ,
			   "heartFailureCharlsonCurrentParent2" = "numeric" ,
			   "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			   "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			   "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			   "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			   "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			   "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			   "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			   "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			   "alcoholAbuseCurrentParent1" = "numeric" ,
			   "alcoholAbuseCurrentParent2" = "numeric" ,
			   "substanceAbuseCurrentParent1" = "numeric" ,
			   "substanceAbuseCurrentParent2" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			   "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			   "jointCharlsonParents" = "numeric" ,
			   "outcomePhysicalAbuse" = "numeric" ,
			   "interparentalViolence" = "factor" ,
			   "familyEducationalLevel" = "factor" ,
			   "parentalAbuseAsChild" = "factor" ,
			   "oneForeignParent" = "factor" ,
			   "familyNeedProtection" = "factor" ,
			   "parentalPsychiatricDisease" = "factor" ,
			   "parentalSubstanceAbuse" = "factor" ,
			   "calendarTimeGroup" = "factor" ,
			   "childAgeGroup" = "factor" ,
			   "parentalAgeGroup" = "factor" ,
			   "incomeVariable" = "numeric" ,
			   "parishQuantileDifference100Euros" = "numeric" ,
			   "numberOfAdults" = "numeric" ,
			   "numberOfChildren" = "numeric" ,
			   "numberOfAdultsFactor" = "factor" ,
			   "numberOfChildrenFactor" = "factor" ,
			   "genderChild" = "factor" ,
			   "deathCensoringImpute" = "numeric" ,
			   "emigrationCensoringImpute" = "numeric" ,
			   "time" = "numeric"))

  analysisDataset[ , familyEducationalLevel :=
			 factor(familyEducationalLevel ,
				levels = c("Primary education" ,
					   "Secondary education" ,
					   "Tertiary education or higher"))]

  analysisDataset[ , numberOfAdultsFactor :=
			 factor(numberOfAdultsFactor ,
				levels = c("One adult" ,
					   "Two adults" ,
					   "Three or more adults"))]

  analysisDataset[ , numberOfChildrenFactor :=
			 factor(numberOfChildrenFactor ,
				levels = c("One child" ,
					   "Two children" ,
					   "Three to five children" ,
					   "Six children or more"))]

  analysisDataset[ , reconstitutedFamily :=
			 factor(
			     reconstitutedFamily ,
			     levels = c("Living with biological parent(s)" ,
					"Living with one or more unrelated adults" ,
					"Adopted or in foster care"))]

  analysisDataset[ , parentalPsychiatricDisease :=
			 factor(parentalPsychiatricDisease ,
				levels = c("No psychiatric disease" ,
					   "Any psychiatric disease"))]

  analysisDataset[ ,
		  interparentalViolence :=
		      factor(interparentalViolence ,
			     levels = c("No interparental violence" ,
					"Interparental violence"))]

  analysisDataset[ , parentalSubstanceAbuse :=
			 factor(parentalSubstanceAbuse ,
				levels = c("No parental substance abuse" ,
					   "Parental substance abuse"))]

  analysisDataset[ , calendarTimeGroup :=
			 factor(calendarTimeGroup ,
				levels = c("1997-2002" ,
					   "2003-2009" ,
					   "2010-2018"))]

  analysisDataset[ , parentalAbuseAsChild :=
			 factor(parentalAbuseAsChild ,
				levels = c("No maltreatment or neglect" ,
					   "Maltreatment or neglect, one parent" ,
					   "Maltreatment or neglect, both parents"))]

  analysisDataset[ , oneForeignParent :=
			 factor(oneForeignParent ,
				levels = c("No foreign parents" ,
					   "One or more foreign parents"))]

  analysisDataset[ , familyNeedProtection :=
			 factor(familyNeedProtection ,
				levels = c("Not in need of protection" ,
					   "In need of protection"))]

  analysisDataset[ , childAgeGroup :=
			 factor(childAgeGroup , 
				levels = c("Child 0-6 years old" ,
					   "Child 7-18 years old"))]

  analysisDataset[ , parentalAgeGroup :=
			 factor(parentalAgeGroup , 
				levels = c("Mean parental age 25 or less" ,
					   "Mean parental age >25-35" ,
					   "Mean parental age >35-65" ,
					   "Mean parental age >65-100"))]
#+end_src

** Code block to impute missings in the resulting dataset - because of resource intensity this should only be run on a reduced dataset, code for this is included
#+begin_src R :session rsession :results output :exports both
  ##Commenting these changes out as it turns out the final imputation models have to be very simple to actually be computed. 
  ## ##Make a few changes to facilitate imputation:
  ## analysisDataset[ , reconstitutedFamily :=
  ## 		       factor(reconstitutedFamily ,
  ## 			      ordered =TRUE)]
  ## analysisDataset[ , familyEducationalLevel :=
  ## 		       factor(familyEducationalLevel ,
  ## 			      ordered = TRUE)]
  ## ##Attaching gender as an extra variable for imputation:
  ## befGender <- bef[ , .(pnr , koen)]
  ## befGender <- unique(befGender)
  ## analysisDataset[befGender ,
  ## 		on = "pnr" ,
  ## 		genderChild := factor(i.koen ,
  ## 				      levels = c(1 , 2) ,
  ## 				      labels = c("Male" , "Female"))]

  ## ##There is a peculiar number of missings - attaching ftBarn
  ## ftBarnGender <- fread("ftbarn_pop_070621.csv" , colClasses = (pnr = "character") , select = c("pnr" , "koen"))
  ##   ##cpst <- fread("cpst_pop_070621.csv" , nrows = nrows)
  ## ftBarnGender <- ftBarnGender[!is.na(pnr)]
  ## ftBarnGender <- ftBarnGender[pnr != ""]
  ## ftBarnGender <- unique(ftBarnGender)
  ## analysisDataset[ftBarnGender ,
  ## 		on = "pnr" ,
  ## 		genderChildFtBarn := factor(i.koen ,
  ## 				      levels = c(1 , 2) ,
  ## 				      labels = c("Male" , "Female"))]
  ## analysisDataset[is.na(genderChild) &
  ## 		!is.na(genderChildFtBarn) ,
  ## 		genderChild := genderChildFtBarn] 

  ## ##Much fewer missings but still some - adding MFR:
  ## mfrGender <- fread("mfr_pop_070621.csv" ,
  ## 	     colClasses = c("pnr" = "character") ,
  ## 	     select = c("pnr" , "KOEN_BARN"))
  ## mfrGender <- mfrGender[!is.na(pnr)]
  ## mfrGender <- mfrGender[pnr != ""]
  ## mfrGender <- unique(mfrGender)
  ## analysisDataset[mfrGender ,
  ## 		on = "pnr" ,
  ## 		genderChildMfr := factor(i.KOEN_BARN ,
  ## 				      levels = c("M" , "K") ,
  ## 				      labels = c("Male" , "Female"))]
  ## analysisDataset[is.na(genderChild) &
  ## 		!is.na(genderChildMfr) , 
  ## 		genderChild := genderChildMfr]

  ## ##Even after reading bef, ftBarn and mfr, there are still 3705 missings. I will include these in the imputation algorithm.

  ## ##Cleaning after this:
  ## analysisDataset[ , c("genderChildFtBarn" , "genderChildMfr") := NULL]

  ## ##Generating derived variables for imputation only:
  ## analysisDataset[!is.na(deathCensoring) , deathCensoringImpute := 1]
  ## temp <- analysisDataset[deathCensoringImpute == 1 , .(pnr)]
  ## temp <- unique(temp)
  ## temp[ , deathCensoringImpute := 1]
  ## analysisDataset[ , deathCensoringImpute := NULL]
  ## analysisDataset[temp , on = "pnr" , deathCensoringImpute := i.deathCensoringImpute]
  ## analysisDataset[is.na(deathCensoringImpute) , deathCensoringImpute := 0]
  ## ##Results checked by manual inspection, classifying as expected.

  ## analysisDataset[!is.na(emigrationCensoring) , emigrationCensoringImpute := 1]
  ## temp <- analysisDataset[emigrationCensoringImpute == 1 , .(pnr)]
  ## temp <- unique(temp)
  ## temp[ , emigrationCensoringImpute := 1]
  ## analysisDataset[ , emigrationCensoringImpute := NULL]
  ## analysisDataset[temp , on = "pnr" , emigrationCensoringImpute := i.emigrationCensoringImpute]
  ## analysisDataset[is.na(emigrationCensoringImpute) , emigrationCensoringImpute := 0]
  ## ##Method replicated from above, counts looks reasonable. 

  ##Adding time variable:
  setorder(analysisDataset , pnr , date)
  analysisDataset[ , time := 0:(.N - 1) , by = pnr]

  ##Turns out that some individuals are followed for 216 and not 215 months, this is likely because of specific dates - th have everybody treated equally, these observations are thrown out:
  analysisDataset <- analysisDataset[time != 216]
  analysisDataset <- analysisDataset[time != 215] #This is because the count starts at 0
  ##Now, all counts end at 214, as expected.

  ##Due to small cells-problems discovered downstream, a number of recodings are performed:

  ##familyEducationalLevel
  analysisDataset[ , familyEducationalLevelReleveled := familyEducationalLevel]
  analysisDataset[familyEducationalLevelReleveled == "Primary education" ,
		  familyEducationalLevelReleveled := "Secondary education"]
  analysisDataset[ , familyEducationalLevelReleveled :=
			droplevels(familyEducationalLevelReleveled)]
  setattr(analysisDataset$familyEducationalLevelReleveled , "levels" , c("Primary or secondary education" , "Tertiary education or higher"))

  ##This works but copies the dataset - replaced by the line above
  ##levels(analysisDataset$familyEducationalLevelReleveled)[levels(analysisDataset$familyEducationalLevelReleveled) == "Secondary education"] <- "Primary or secondary education"
  ##ParentalAbuseAsChild
  analysisDataset[ , parentalAbuseAsChildReleveled := parentalAbuseAsChild]
  analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, both parents" , parentalAbuseAsChildReleveled := "Maltreatment or neglect, one parent"]
  analysisDataset[ , parentalAbuseAsChildReleveled := droplevels(parentalAbuseAsChildReleveled)]
  setattr(analysisDataset$parentalAbuseAsChildReleveled , "levels" , c("No maltreatment or neglect" , "Maltreatment or neglect, one or both parents"))

  ##Parental age group
  analysisDataset[ , parentalAgeGroupReleveled := parentalAgeGroup]
  analysisDataset[parentalAgeGroupReleveled == "Mean parental age >65-100" , parentalAgeGroupReleveled := "Mean parental age >35-65"]
  analysisDataset[ , parentalAgeGroupReleveled := droplevels(parentalAgeGroupReleveled)]
  setattr(analysisDataset$parentalAgeGroupReleveled , "levels" , c("Mean parental age 25 or less" , "Mean parental age >25-35" , "Mean parental age >35"))

  ##Re-code the exposure and outcome:

  analysisDataset[jointCharlsonParents <= 1 , gTreatment := 1]
  analysisDataset[jointCharlsonParents > 1 , gTreatment := 0]
  analysisDataset[outcomePhysicalAbuse > 0 , anyPhysicalAbuse := 1]
  analysisDataset[is.na(anyPhysicalAbuse) , anyPhysicalAbuse := 0]

  ##Adding a number of binary variables, replacing some factor variables:
  analysisDataset[familyEducationalLevelReleveled == "Primary or secondary education" , familyEducationalLevelBinary := 0]
  analysisDataset[familyEducationalLevelReleveled == "Tertiary education or higher" , familyEducationalLevelBinary := 1]
  analysisDataset[oneForeignParent == "No foreign parents" , oneForeignParentBinary := 0]
  analysisDataset[oneForeignParent == "One or more foreign parents" , oneForeignParentBinary := 1]
  analysisDataset[familyNeedProtection == "Not in need of protection" , familyNeedProtectionBinary := 0]
  analysisDataset[familyNeedProtection == "In need of protection" , familyNeedProtectionBinary := 1]
  analysisDataset[parentalPsychiatricDisease == "No psychiatric disease" , parentalPsychiatricDiseaseBinary := 0]
  analysisDataset[parentalPsychiatricDisease == "Any psychiatric disease" , parentalPsychiatricDiseaseBinary := 1]
  analysisDataset[parentalAbuseAsChildReleveled == "No maltreatment or neglect" , parentalAbuseAsChildBinary := 0]
  analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, one or both parents" , parentalAbuseAsChildBinary := 1]

  ##Making an alternative to calendarTimeGroup which represents time - this variable represents time at inclusion:
  tempAge <- unique(analysisDataset[time == 0 , .(pnr , childAgeGroup)])
  analysisDataset[tempAge , on = "pnr" , childAgeGroupAtInclusion := i.childAgeGroup]
  tempCalendarTime <- unique(analysisDataset[time == 0 , .(pnr , calendarTimeGroup)])
  analysisDataset[tempCalendarTime , on = "pnr" , calendarTimeGroupAtInclusion  := i.calendarTimeGroup]

  ##Recoding childAgeGroupAtInclusion as a binary:
  analysisDataset[childAgeGroupAtInclusion == "Child 0-6 years old" , childAgeGroupAtInclusionBinary := 0]  
  analysisDataset[childAgeGroupAtInclusion == "Child 7-18 years old" , childAgeGroupAtInclusionBinary := 1]

  ##Adding familyIndex and new count of children:
  ##Coding for siblings, defined as anyone with the same pair of parents (of which one may be missing) at any point in time (original definition was abandoned because of questionable geolocation data):

  parents <- analysisDataset[ , .(currentParent1 , currentParent2)]
  parents <- unique(parents)
  parents[ , temp1 := pmax(currentParent1 , currentParent2 , na.rm = TRUE)]
  parents[ , temp2 := pmin(currentParent1 , currentParent2)]
  parents[ , c("currentParent1" , "currentParent2") := NULL]
  setnames(parents , c("temp1" , "temp2") , c("currentParent1" , "currentParent2"))
  parents <- unique(parents)
  parents[ , familyIndex := 1:.N]
  analysisDataset[parents , on = c("currentParent1" , "currentParent2") , familyIndex := i.familyIndex]
  setnames(parents , c("currentParent1" , "currentParent2") , c("currentParent2" , "currentParent1"))
  analysisDataset[parents , on = c("currentParent1" , "currentParent2") , familyIndex := i.familyIndex]
  ##Generated a list of all pnrs and their family index, found any familyIndex with more than one pnr and looked them up in the original dataset - all children within the same familyIndex had the same combination of parents, thus the algorithm works as expected.

  ##Trying to work around the many missings in the numberOfChildren and the numberOfAdults variables. Now generating an alternative variable, telling how many children lives with any combination of parents (including a parent combined with an empty slot, alias a single parent) at any given time(familyIndex is build over unique combinations of parental IDs):

  analysisDataset[ , newNoOfChildren := .N , by = c("date" , "familyIndex")]

  ##At present, this represents the most complete dataset available - saving:
  fwrite(analysisDataset , "analysisDataset.csv")


  ##As it will be seen downstream, the server is not able to handle the size of the current dataset - for some somewhat arbitrary reduction, derived from a number of tests, I will reduce number of participants to somewhere around 50000 and change spacing of time to half-year intervals (in another time with a better server, a full analysis of the dataset, or even of the original once-a-day intervals used in the first version of this code, would be interesting):

  ##Reducing the dataset to half-years, as the server does not have enough capacity to do the simulations for the current number of time points (215). If a subject is being censored or experiencing the outcome close to the last included date, this subject may get an additional time count in comparison with the remainder of the participants - this will be handled by moving this last count one quarter back.
  analysisDataset[ , halfYearDate := floor_date(date , unit = "halfyear")]
  analysisDataset[halfYearDate == date , halfYearDates := 1]
  ## analysisDataset[ , quarterDates := quarter(date , type = "date_first")]
  ## analysisDataset[quarterDates == date , quarter := 1]
  ## analysisDataset[quarter == 1 , indexQuarter := 1:.N , by = "pnr"]
  ## ##Go check if this actually indicates half-year intervals
  ## analysisDataset[indexQuarter%%2 == 1 , halfyearDates := 1]


  analysisDataset[outcomePhysicalAbuse > 0 & is.na(halfYearDates) , newDate := ceiling_date(date , unit = "halfyear")]
  analysisDataset[ageCensoring == date & is.na(halfYearDates) , newDate := ceiling_date(date , unit = "halfyear")]
  analysisDataset[deathCensoring == date & is.na(halfYearDates) , newDate := ceiling_date(date , unit = "halfyear")]
  analysisDataset[emigrationCensoring == date & is.na(halfYearDates) , newDate := ceiling_date(date , unit = "halfyear")]


  analysisDatasetHalfyearly <- analysisDataset[halfYearDates == 1 | !is.na(newDate)]
  analysisDatasetHalfyearly[!is.na(newDate) , date := newDate]
  #analysisDatasetHalfyearly[ , studyEntry := quarter(studyEntry , type = "date_first")]

  ##Making new time intervals:
  setorder(analysisDatasetHalfyearly , pnr , date)
  analysisDatasetHalfyearly[ , time := 0:(.N-1) , by = "pnr"]
  ##Correcting the "extra" time slot because of the ceiling_date command - simply deleting the former time slot and moving the new one one slot back:
  analysisDatasetHalfyearly[ , keep := NULL]
  analysisDatasetHalfyearly[time == 35 , keep := 1]
  analysisDatasetHalfyearly[time == 35 , time := 34]
  deletePnrs <- analysisDatasetHalfyearly[keep == 1 , .(pnr)]
  analysisDatasetHalfyearly[deletePnrs , on = "pnr" , delete := 1]
  analysisDatasetHalfyearly <- analysisDatasetHalfyearly[is.na(delete) | (delete == 1 & (time <=33 | keep == 1))]
  ##Inspected visually, now all counts are 34 at maximum and the preserved rows are those with censoring or outcome information.
  analysisDatasetHalfyearly[ , c("halfYearDates" , "halfYearDate" , "newDate" , "keep" , "delete") := NULL]
  analysisDataset[ , c("halfYearDates" , "halfYearDate" , "newDate" , "keep" , "delete") := NULL]

  fwrite(analysisDatasetHalfyearly , "analysisDatsetHalfyearly.csv")

  ##Now reducing the dataset above to about 50000 children to enable imputation:

  tempPnrs <- unique(analysisDatasetHalfyearly[ , .(pnr)])
  set.seed(25328621)
  tempPnrs[ , randomIndex := sample(1:.N , .N)]
  setorder(tempPnrs , randomIndex)
  tempPnrs <- tempPnrs[1:50000]
  ## keepPnrs <- 1:(tempPnrs[ , .N]/65)
  ## keepPnrs <- as.data.table(keepPnrs)
  ## setnames(keepPnrs , "keepPnrs" , "randomIndex")
  ## tempPnrs[keepPnrs , on = "randomIndex" , keep := 1]
  ## tempPnrs <- tempPnrs[keep == 1]
  tempPnrs[ , randomIndex := NULL]
  analysisDatasetHalfyearly[tempPnrs , on = "pnr" , keep := 1]
  analysisDatasetHalfyearlyReduced <- analysisDatasetHalfyearly[keep == 1]
  analysisDatasetHalfyearlyReduced[ , keep := NULL]

  fwrite(analysisDatasetHalfyearlyReduced , "analysisDatasetHalfyearlyReduced.csv")


  ##The implementation below of an imputation is based on the MICE package, and modeled after the longitudinal data example in Stef van Buuren's book Flexible Imputation of Missing Data. First I define the algorithm for imputation and then I paralellize it:

  ##Now the missing data will be imputed:
  analysisDatasetHalfyearlyReduced <- readAnalysisDatasetHalfyearlyReduced()

  ## library("mice")
  ## library("miceadds")
  ## library("pan")
  ## library("micemd")

  analysisDatasetHalfyearlyReduced[ , pnr := as.numeric(pnr)]
  ##For garbage cleaning
  gc()
  imputationFunction <- function () {
      ##The predictor matrix should be read as each line defining a formula - that is, if there are 1s corresponding to a variable, this column-variable will be used in predicting this particular variable. 
      pred <- make.predictorMatrix(analysisDatasetHalfyearlyReduced)
      pred[1:nrow(pred) , 1:ncol(pred)] <- 0

      ##What we want to impute:
      ##Based on output from model, I simplify the imputation - the model is too complex and does not work, thus I tailor a model for each imputation, will try to limit myself to 5 independent variables:
      ##A few general independent variables:
      Y <- c("reconstitutedFamily" , "meanParentalAge" , "familyEducationalLevelReleveled" , "oneForeignParent" , "familyNeedProtection" , "incomeVariable" , "parishQuantileDifference100Euros")## , "numberOfAdults" , "numberOfChildren") ##, "genderChild")
      pred[Y , "pnr"] <- (-2) #Identify ID variable
      pred[Y , "jointCharlsonParents"] <- 2 #Set as random variable 
      pred[Y , "outcomePhysicalAbuse"] <- 2 
      pred[Y , "calendarTimeGroup"] <- 2 

      ##Despite several tries with 2lonly.mean, 2lonly.norm and 2lonly.pmm I cannot get this variable in a cluster analysis - without missings. Thus I set up a model for predicting it without taking the clusters into consideration:
      ##Reconstituted family
      pred["reconstitutedFamily" , "pnr"] <- 0
      pred["reconstitutedFamily" , "parentalAbuseAsChildBinary"] <- 1
      pred["reconstitutedFamily" , "oneForeignParent"] <- 1
      pred["reconstitutedFamily" , "familyEducationalLevelReleveled"] <- 1
      pred["reconstitutedFamily" , "jointCharlsonParents"] <- 1
      pred["reconstitutedFamily" , "outcomePhysicalAbuse"] <- 1
      pred["reconstitutedFamily" , "calendarTimeGroup"] <- 1

      ##Mean parental age
      ##pred["meanParentalAge" , "incomeVariable"] <- 2
      ##pred["meanParentalAge" , "reconstitutedFamily"] <- 2
      ##pred["meanParentalAge" , "numberOfChildren"] <- 2

      ##Family educational level
      ##pred["familyEducationalLevelBinary" , "incomeVariable"] <- 1
      ##pred["familyEducationalLevelBinary" , "oneForeignParentBinary"] <- 2
      ##pred["familyEducationalLevelBinary" , "meanParentalAge"] <- 2
      pred["familyEducationalLevelReleveled" , "jointCharlsonParents"] <- 1
      pred["familyEducationalLevelReleveled" , "outcomePhysicalAbuse"] <- 1
      pred["familyEducationalLevelReleveled" , "calendarTimeGroup"] <- 0

      ##One foreign parent (this model seems to be hard to run - trying with even fewer independent variables than the other models:)
      ##pred["oneForeignParentBinary" , "incomeVariable"] <- 2
      ##pred["oneForeignParentBinary" , "numberOfChildren"] <- 2
      pred["oneForeignParent" , "calendarTimeGroup"] <- 0
      pred["oneForeignParent" , "jointCharlsonParents"] <- 1
      pred["oneForeignParent" , "outcomePhysicalAbuse"] <- 1

      ##Family need protection
      pred["familyNeedProtection" , "oneForeignParent"] <- 2
      ##pred["familyNeedProtectionBinary" , "incomeVariable"] <- 2
      pred["familyNeedProtection" , "calendarTimeGroup"] <- 0


      ##Income
      ##pred["incomeVariable" , "familyEducationalLevelBinary"] <- 2
      pred["incomeVariable" , "meanParentalAge"] <- 2
      pred["incomeVariable" , "parentalPsychiatricDisease"] <- 2


      ##The difference between quantiles of income in parishes, measured in hundreds of Euros
      pred["parishQuantileDifference100Euros" , "familyEducationalLevelReleveled"] <- 2
      ##pred["parishQuantileDifference100Euros" , "parentalPsychiatricDiseaseBinary"] <- 2

      ## ##Number of adults
      ## pred["numberOfAdults" , "meanParentalAge"] <- 2
      ## ##pred["numberOfAdults" , "numberOfChildren"] <- 2
      ## pred["numberOfAdults" , "familyEducationalLevelBinary"] <- 2

      ##Number of children
      ## pred["numberOfChildren" , "meanParentalAge"] <- 2
      ## pred["numberOfChildren" , "childAge"] <- 2
      ## pred["numberOfChildren" , "familyEducationalLevelBinary"] <- 2


      ## pred[Y , "interparentalViolence"] <- 2 #COMPLETE
      ## pred[Y , "familyEducationalLevelBinary"] <- 2 
      ## pred[Y , "parentalAbuseAsChild"] <- 2 #COMPLETE
      ## pred[Y , "oneForeignParentBinary"] <- 2 
      ## pred[Y , "familyNeedProtectionBinary"] <- 2
      ## pred[Y , "incomeVariable"] <- 2
      ## pred[Y , "parishQuantileDifference100Euros"] <- 2
      ## pred[Y , "numberOfAdults"] <- 2
      ## pred[Y , "numberOfChildren"] <- 2
      ## pred[Y , "parentalPsychiatricDisease"] <- 2 #COMPLETE
      ## pred[Y , "parentalSubstanceAbuse"] <- 2 #COMPLETE

      ## pred[Y , "meanParentalAge"] <- 2
      ## pred[Y , "childAgeGroup"] <- 1 #COMPLETE
      ## pred[Y , "genderChild"] <- 1
      ## pred[Y , "deathCensoringImpute"] <- 1 #COMPLETE
      ## pred[Y , "emigrationCensoringImpute"] <- 1 #COMPLETE
      ## pred[Y , "time"] <- 1 #COMPLETE

      analysisDatasetImputed <-
	  mice(analysisDatasetHalfyearlyReduced ,
	       predictorMatrix = pred ,
	       ##seed = 25328621 ,
	       visitSequence = c("oneForeignParent" ,
				 "familyNeedProtection" ,
				 "familyEducationalLevelReleveled" ,
				 "meanParentalAge" ,
				 "parishQuantileDifference100Euros" ,
				 "incomeVariable" ,
				 "reconstitutedFamily") , 
	       meth = c("" , #"pnr" ""means need not be imputed, see options in table one, read methods on page 18, read rest of document from page 23 when done from 18 and forth 
			"" , #"date"
			"" , #"currentParent2" = "character" ,
			"" , #"currentParent1" = "character" ,
			"pmm" , #"reconstitutedFamily" = "factor" ,
			"" , #"studyEntry" = "Date" ,
			"" , #"ageCensoring" = "Date" ,
			"" , #"deathCensoring" = "Date" ,
			"" , #"emigrationCensoring" = "Date" ,
			"2l.pan" , #"meanParentalAge" = "numeric" ,
			"" , #"birthDate" = "Date" ,
			"" , #"childAge" = "numeric" ,
			"" , #"hypertensionGroupDiagCurrentParent1" = "numeric" ,
			"" , #"hypertensionGroupDiagCurrentParent2" = "numeric" ,
			"" , #"dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			"" , #"dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			"" , #"atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			"" , #"heartFailureGroupDiagCurrentParent1" = "numeric" ,
			"" , #"heartFailureGroupDiagCurrentParent2" = "numeric" ,
			"" , #"peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			"" , #"peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			"" , #"strokeGroupDiagCurrentParent1" = "numeric" ,
			"" , #"strokeGroupDiagCurrentParent2" = "numeric" ,
			"" , #"diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			"" , #"diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			"" , #"thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			"" , #"thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			"" , #"goutGroupDiagCurrentParent1" = "numeric" ,
			"" , #"goutGroupDiagCurrentParent2" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"allergyGroupDiagCurrentParent1" = "numeric" ,
			"" , #"allergyGroupDiagCurrentParent2" = "numeric" ,
			"" , #"ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			"" , #"ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			"" , #"chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			"" , #"diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			"" , #"chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			"" , #"prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			"" , #"connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			"" , #"connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			"" , #"osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			"" , #"osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			"" , #"anemiasGroupDiagCurrentParent1" = "numeric" ,
			"" , #"anemiasGroupDiagCurrentParent2" = "numeric" ,
			"" , #"cancerGroupDiagCurrentParent1" = "numeric" ,
			"" , #"cancerGroupDiagCurrentParent2" = "numeric" ,
			"" , #"visionProblemGroupDiagCurrentParent1" = "numeric" ,
			"" , #"visionProblemGroupDiagCurrentParent2" = "numeric" ,
			"" , #"migraineGroupDiagCurrentParent1" = "numeric" ,
			"" , #"migraineGroupDiagCurrentParent2" = "numeric" ,
			"" , #"epilepsyGroupDiagCurrentParent1" = "numeric" ,
			"" , #"epilepsyGroupDiagCurrentParent2" = "numeric" ,
			"" , #"parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			"" , #"parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			"" , #"multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			"" , #"multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			"" , #"neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			"" , #"neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			"" , #"moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			"" , #"moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			"" , #"anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			"" , #"anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			"" , #"schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			"" , #"schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			"" , #"personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			"" , #"personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			"" , #"dementiaGroupDiagCurrentParent1" = "numeric" ,
			"" , #"dementiaGroupDiagCurrentParent2" = "numeric" ,
			"" , #"otherGroupDiagCurrentParent1" = "numeric" ,
			"" , #"otherGroupDiagCurrentParent2" = "numeric" ,
			"" , #"pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			"" , #"pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			"" , #"acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			"" , #"acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			"" , #"aidsHivCharlsonCurrentParent1" = "numeric" ,
			"" , #"aidsHivCharlsonCurrentParent2" = "numeric" ,
			"" , #"anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			"" , #"anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			"" , 
#"leukemiaCharlsonCurrentParent1" = "numeric" ,
			"" , #"leukemiaCharlsonCurrentParent2" = "numeric" ,
			"" , #"lymphomaCharlsonCurrentParent1" = "numeric" ,
			"" , #"lymphomaCharlsonCurrentParent2" = "numeric" ,
			"" ,
#"cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"dementiaCharlsonCurrentParent1" = "numeric" ,
			"" , #"dementiaCharlsonCurrentParent2" = "numeric" ,
			"" , #"diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			"" , #"diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			"" , #"diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			"" , #"diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			"" , #"heartFailureCharlsonCurrentParent1" = "numeric" ,
			"" , #"heartFailureCharlsonCurrentParent2" = "numeric" ,
			"" , #"hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			"" , #"hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			"" , #"metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			"" , #"metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			"" , #"mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			"" , #"myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			"" , #"pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			"" , #"severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			"" , #"alcoholAbuseCurrentParent1" = "numeric" ,
			"" , #"alcoholAbuseCurrentParent2" = "numeric" ,
			"" , #"substanceAbuseCurrentParent1" = "numeric" ,
			"" , #"substanceAbuseCurrentParent2" = "numeric" ,
			"" , #"unspecificEverCurrentParent1" = "numeric" ,
			"" , #"unspecificEverCurrentParent2" = "numeric" , 
			"" , #"unspecificTwoYearCurrentParent1" = "numeric" , 
			"" , #"unspecificTwoYearCurrentParent2" = "numeric" ,
			"" , #"dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			"" , #"dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			"" , #"dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			"" , #"dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			"" , #"jointCharlsonParents" = "numeric" ,
			"" , #"outcomePhysicalAbuse" = "numeric" ,
			"" , #"interparentalViolence" = "factor" ,
			"" , #"familyEducationalLevel" = "factor" ,
			"" , #"parentalAbuseAsChild" = "factor" ,
			"2l.bin" , #"oneForeignParent" = "factor" ,
			"" , #"familyNeedProtection" = "factor" ,
			"" , #"parentalPsychiatricDisease" = "factor" ,
			"" , #"parentalSubstanceAbuse" = "factor" ,
			"" , #"calendarTimeGroup" = "factor" ,
			"" , #"childAgeGroup" = "factor" ,
			"" , #"parentalAgeGroup" = "factor"))
			"2l.pan" , #"incomeVariable" = "numeric" ,
			"2l.pan" , #"parishQuantileDifference100Euros" = "numeric" ,
			"" , #time
			"2l.bin" , #familyEducationalLevelReleveled 
			"" , #parentalAbuseAsChildReleveled
			"" , #parentalAgeGroupReleveled , 
			"" , #gTreatment
			"" , #anyPhysicalAbuse 
			"" , #familyEducationalLevelBinary
			"" , #oneForeignParentBinary
			"" , #familyNeedProtectionBinary
			"" , #parentalPsychiatricDiseaseBinary
			"" , #parentalAbuseAsChildBinary
			"" , #childAgeGroupAtInclusion
			"" , #calendarTimeGroupAtInclusion
			"" , #childAgeGroupAtInclusionBinary
			"" , #familyIndex
			"") , #newNoOfChildren
	       m = 1 ,
	       maxit = 20 ,
	       ##nnodes = 5
	       ##n.core = 5 ,
	       ##n.imp.core = 1         
	       ) #This is much less than recommended, but I will start out conservatively to avoid memory problems.
      return(analysisDatasetImputed)
  }


  ##Here I paralellize the execution of mice, as suggested by Max Gordon on StackOverflow, https://stackoverflow.com/Questions/24040280/Parallel-Computation-of-Multiple-Imputation-by-Using-Mice-R-Package - only change is that all the mice options and the prediction table is wrapped in a function and exported to the clusters. 

  numberOfCores <- 5
  library(parallel)
  clusters <- makeCluster(numberOfCores)
  clusterSetRNGStream(clusters , 25328621)
  clusterExport(clusters , "analysisDatasetHalfyearlyReduced")
  clusterExport(clusters , "imputationFunction")
  clusterEvalQ(clusters , library(mice))
  clusterEvalQ(clusters , library(miceadds))
  clusterEvalQ(clusters , library(pan))
  impPars <-
      parLapply(cl = clusters , X = 1:numberOfCores , fun = function(no) {
	  imputationFunction()
      })
  stopCluster(clusters)

  impMerged <- impPars[[1]]
  for (n in 2:length(impPars)){
      impMerged <-
	  ibind(impMerged ,
		impPars[[n]])
  }

  ##Diagnostics:
  pdf("imputationStreams.pdf" ,
      width = 8 ,
      height = 7 ,
      bg = "white" ,
      colormodel = "cmyk" ,
      paper = "A4")
  plot(impMerged , layout = c(2 , 6))
  dev.off()
  ##All imputations show freely intermingling streams without showing any definite trends - this is as described by van Buuren in his book Flexible Imputation of Missing Data assessed on stefvanbuuren.name on the 14th of May 2022.
  ##Diagnostics:
  contVariables <- c("meanParentalAge" , "incomeVariable" , "parishQuantileDifference100Euros")
  for (i in contVariables) {
      pdf(paste0(i , "Box.pdf") ,
	  width = 8 ,
	  height = 7 ,
	  bg = "white" ,
	  colormodel = "cmyk" ,
	  paper = "A4")
      eval(parse(text = paste0("print(bwplot(impMerged , " , i , " ~ .imp))")))
      dev.off()
      pdf(paste0(i , "Density.pdf") ,
	  width = 8 ,
	  height = 7 ,
	  bg = "white" ,
	  colormodel = "cmyk" ,
	  paper = "A4")
      eval(parse(text = paste0("print(densityplot(impMerged , ~" , i , "))")))
      dev.off()
  }


  ##These plots are generated based on advice from van Buuren's book Flexible Imputation of Missing Data assessed on stefvanbuuren.name on the 14th of May 2022.

  ##For all three continous variables, the kernel density plots show distributions approaching that of the observed data, and does not raise reasons for concern based on my knowledge of the dataset. On the box and whiskers-plot, for parishQuantileDifference100Euros and meanParentalAge there are some extreme values taking up impossible values. For parishQuantileDifference100Euros there are a few examples of negative differences between neighborhood income. For meanParentalAge, in some imputations, there are a few very young parents - no parents younger than 0 but some less than 10 years old. Interestingly, some of the imputed values are imputed over values of parents younger than 10, as I thought these values were biologically implausible.
  ##The best approach here would be to impute only with values that already exist in the dataset, using the predictive mean matching or a similar approach. This is however not possible, as predictive mean matching, as implemented in MICE, does not tolerate clusters with missing level-2 data. Thus, the current implementation seems to be the best possible solution. The "impossible" values are very few, will only be used as covariates and are not expected to have a large influence on the final result - thus they are kept as is.

  ##In van Buuren's book there is no implementation of a graphical tool to check distributions of imputed categorical variables - or if there is, they are not described. I am implementing a tool to compare distributions of observed and imputed variables in a box plot:

  library(mice)
  ##Get all the imputed datasets out of impMerged:
  listFullDatasets <- list()
  for(i in 1:5) {
      temp <- complete(impMerged , i)
      setDT(temp)
      name <- paste0("datasetImputed" , i) 
      listFullDatasets[[name]] <- temp 
  }
  ##Get the three variables that are factors or binary from the original dataset and append them to the imputed (for comparison): 
  observed <-
      analysisDatasetHalfyearlyReduced[ ,
				       .(reconstitutedFamily ,
					 oneForeignParent ,
					 familyEducationalLevelReleveled)]
  setnames(observed ,
	   c("reconstitutedFamily" ,
	     "oneForeignParent" ,
	     "familyEducationalLevelReleveled") ,
	   c("reconstitutedFamilyObserved" ,
	     "oneForeignParentObserved" ,
	     "familyEducationalLevelReleveledObserved"))
  listFullDatasets <- lapply(listFullDatasets , cbind , observed)
  ##Get the imputed datasets into the global environment:
  list2env(listFullDatasets , envir = .GlobalEnv)
  ##For all variables and all datasets, make a column named Imputed with only the values that were NA before the imputation (the imputed values): 
  binaryAndFactorVariables <- c("reconstitutedFamily" ,
				"oneForeignParent" ,
				"familyEducationalLevelReleveled")
  imputedNames <- paste0("datasetImputed" , 1:5)
  for (i in binaryAndFactorVariables) {

      for (j in imputedNames) {
	  eval(parse(text =
			 paste0(j ,
				"[is.na(" ,
				i ,
				"Observed) , " ,
				i ,
				"Imputed := " ,
				i ,
				"]")))
      }
  }
  ##For all variables and all datasets, make frequency tables:
  for (i in binaryAndFactorVariables) {
      assign(paste0("tempFrequency" , i) ,
	     as.data.table(datasetImputed1[ ,
					   prop.table(table(get(paste0(i , "Observed"))))]))
      for (j in imputedNames) {
	  assign(paste0("tempFrequency" , i) , cbind(get(paste0("tempFrequency" , i)) ,
					   get(j)[ ,
						  prop.table(table(get(paste0(i , "Imputed"))))]))
      }
  }
  ##Set names to something meaningful:
  listTempFrequency <- mget(grep("tempFrequency" , ls() , value = TRUE))
  listTempFrequency <- lapply(listTempFrequency ,
			      setNames ,
			      c("Categories" ,
				"Observed" ,
				"Delete1" ,
				"Imputed1" ,
				"Delete2" ,
				"Imputed2" ,
				"Delete3" ,
				"Imputed3" ,
				"Delete4" ,
				"Imputed4" ,
				"Delete5" ,
				"Imputed5"))
  ##Set the elements to data.tables
  list2env(lapply(listTempFrequency , setDT) , envir = .GlobalEnv)
  ##Melt the data into ggplot format:
  rm(listTempFrequency)
  ##Removing redundant columns:
  frequencyObjects <- grep("tempFrequency" , ls() , value = TRUE)
  for (i in frequencyObjects) {
      eval(parse(text = paste0(i , "[ , c(paste0('Delete' , 1:5)) := NULL]")))
  }
  ##Melting data into ggplot format: 
  listTempFrequency <- mget(grep("tempFrequency" , ls() , value = TRUE))
  list2env(lapply(listTempFrequency ,
		  melt ,
		  id = "Categories" ,
		  measure = c("Observed" ,
			      paste0("Imputed" , 1:5))) ,
	   envir = .GlobalEnv)

  ##Plotting and saving the graphs:
  library(ggplot2)
  frequencyObjects <- grep("tempFrequency" , ls() , value = TRUE)
  for (i in frequencyObjects) {
      temp <- ggplot() +
	  geom_col(data = get(i) , 
		   aes(x = Categories ,
		       y = value ,
		       fill = variable) ,
		   position = "dodge") +
	  labs(title =
		   strsplit(i ,
			    split =
				"tempFrequency")[[1]][2])
      ggsave(paste0("frequencyPlot" ,
		    strsplit(i ,
			     split =
				 "tempFrequency")[[1]][2] ,
		    ".pdf") ,
	     plot = temp ,
	     width = 8 ,
	     height = 7)
  }

  ##Looking at the plots:

  ##FamilyEducationalLevelReleveled, binary: there is an overweight of lower education in imputed values compared to those observed. This may be reasonable if the population with missings is different from the population with full information based on other variables - this is supported by the numbers below:

  ## ##Mean for the imputed (with missing familyEducationalLevelReleveled):
  ## datasetImputed1[is.na(familyEducationalLevelReleveledObserved) , mean(incomeVariable)] #25.4
  ## ##Mean for the observed (without missing familyEducationalLevelReleveled):
  ## datasetImputed1[is.na(familyEducationalLevelReleveledImputed) , mean(incomeVariable)] #139.5

  ## ##Median for the imputed:
  ## datasetImputed1[is.na(familyEducationalLevelReleveledObserved) , median(incomeVariable)] #9.6
  ## ##Median for the observed:
  ## datasetImputed1[is.na(familyEducationalLevelReleveledImputed) , median(incomeVariable)] #121.1

  ##Even though incomeVariable and familyEducationalLevelReleveled are not imputed using each other (this is because of the need of very simple models in two-level imputations) - there are very clear differences between the two groups in income, supporting that the imputations reflect real differences rather than grave misspecifications.

  ##oneForeignParent, binary: this variable shows a systematic over-imputation of non-foreign origin. This may, however, be fully reasonable, but I do not know of a variable equally useful to validate this difference as income was for educational level, see above. As the levels differ but do not seem out of order or extreme compared to the observed values, and as the model did not report any problems during imputation, I will assume the imputations are reasonable.

  ##reconstitutedFamily: on eyesight, the distributions of variables among the fully observed and the imputed are very similar across all four imputations. I do not have any reason to doubt the validity of this assumption. 

  ##I have thus checked the imputations as much as I have been able to - there are some caveats that should be noted. ReconstitutedFamily is imputed without taking clustering into account, as the model broke down in spite of many alternative specifications. The remaining models are all quite simple; this is again due to small clusters. There were (very few) impossible imputed values in the parishQuantileDifference100Euros variable, and also very few biologically implausible values in meanParentalAge - in both cases, the "diagnostics" plots of the imputations looked healthy, and the values are kept. All binary and categorical imputations were checked, the imputations of reconstitutedFamily looked very similar to the observed values. Educational level imputations were clearly skewed compared to the values observed, but even though income and education were not used to impute each other the mean and median income levels among the missings compared to the observed confirmed that the imputations were plausible. oneForeignParent were also somewhat skewed but not to any extremes. As no variables were known to "validate" this skew, and the underlying model ran without problems during the imputation, the results are assumed to be reasonable. Writing the results:

  fwrite(datasetImputed1 , "datasetImputed1.csv")
  fwrite(datasetImputed2 , "datasetImputed2.csv")
  fwrite(datasetImputed3 , "datasetImputed3.csv")
  fwrite(datasetImputed4 , "datasetImputed4.csv")
  fwrite(datasetImputed5 , "datasetImputed5.csv")

#+end_src
** Code for re-loading of datasets and analysis
#+begin_src R :session rsession :results output :exports both
  library(data.table)
  setDTthreads(20)
  sink(file = "logFile.txt" , split = TRUE)
  ##Re-loading of the full dataset: 
  readAnalysisDataset <- function() {
      analysisDataset <-
	  fread("analysisDataset.csv" ,
		colClasses = c("pnr" = "character" ,
			       "date" = "Date" ,
			       "currentParent2" = "character" ,
			       "currentParent1" = "character" ,
			       "reconstitutedFamily" = "factor" ,
			       "studyEntry" = "Date" ,
			       "ageCensoring" = "Date" ,
			       "deathCensoring" = "Date" ,
			       "emigrationCensoring" = "Date" ,
			       "meanParentalAge" = "numeric" ,
			       "birthDate" = "Date" ,
			       "childAge" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			       "strokeGroupDiagCurrentParent1" = "numeric" ,
			       "strokeGroupDiagCurrentParent2" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "goutGroupDiagCurrentParent1" = "numeric" ,
			       "goutGroupDiagCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "allergyGroupDiagCurrentParent1" = "numeric" ,
			       "allergyGroupDiagCurrentParent2" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			       "anemiasGroupDiagCurrentParent1" = "numeric" ,
			       "anemiasGroupDiagCurrentParent2" = "numeric" ,
			       "cancerGroupDiagCurrentParent1" = "numeric" ,
			       "cancerGroupDiagCurrentParent2" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			       "migraineGroupDiagCurrentParent1" = "numeric" ,
			       "migraineGroupDiagCurrentParent2" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "dementiaGroupDiagCurrentParent1" = "numeric" ,
			       "dementiaGroupDiagCurrentParent2" = "numeric" ,
			       "otherGroupDiagCurrentParent1" = "numeric" ,
			       "otherGroupDiagCurrentParent2" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			       "aidsHivCharlsonCurrentParent1" = "numeric" ,
			       "aidsHivCharlsonCurrentParent2" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			       "leukemiaCharlsonCurrentParent1" = "numeric" ,
			       "leukemiaCharlsonCurrentParent2" = "numeric" ,
			       "lymphomaCharlsonCurrentParent1" = "numeric" ,
			       "lymphomaCharlsonCurrentParent2" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "dementiaCharlsonCurrentParent1" = "numeric" ,
			       "dementiaCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "heartFailureCharlsonCurrentParent1" = "numeric" ,
			       "heartFailureCharlsonCurrentParent2" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "alcoholAbuseCurrentParent1" = "numeric" ,
			       "alcoholAbuseCurrentParent2" = "numeric" ,
			       "substanceAbuseCurrentParent1" = "numeric" ,
			       "substanceAbuseCurrentParent2" = "numeric" ,
			       "unspecificEverCurrentParent1" = "numeric" ,
			       "unspecificEverCurrentParent2" = "numeric" , 
			       "unspecificTwoYearCurrentParent1" = "numeric" , 
			       "unspecificTwoYearCurrentParent2" = "numeric" , 
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "jointCharlsonParents" = "numeric" ,
			       "outcomePhysicalAbuse" = "numeric" ,
			       "interparentalViolence" = "factor" ,
			       "familyEducationalLevel" = "factor" ,
			       "parentalAbuseAsChild" = "factor" ,
			       "oneForeignParent" = "factor" ,
			       "familyNeedProtection" = "factor" ,
			       "parentalPsychiatricDisease" = "factor" ,
			       "parentalSubstanceAbuse" = "factor" ,
			       "calendarTimeGroup" = "factor" ,
			       "childAgeGroup" = "factor" ,
			       "parentalAgeGroup" = "factor" ,
			       "incomeVariable" = "numeric" ,
			       "parishQuantileDifference100Euros" = "numeric" ,
			       "time" = "numeric" ,
			       "familyEducationalLevelReleveled" = "factor" ,
			       "parentalAbuseAsChildReleveled" = "factor" ,
			       "parentalAgeGroupReleveled"  = "factor" ,
			       "gTreatment" = "numeric" ,
			       "anyPhysicalAbuse" = "numeric" ,
			       "familyEducationalLevelBinary" = "numeric"  ,
			       "oneForeignParentBinary" = "numeric" ,
			       "familyNeedProtectionBinary" = "numeric" ,
			       "parentalPsychiatricDiseaseBinary" = "numeric" ,
			       "parentalAbuseAsChildBinary" = "numeric" ,
			       "childAgeGroupAtInclusion" = "factor" ,
			       "calendarTimeGroupAtInclusion" = "factor" ,
			       "childAgeGroupAtInclusionBinary" = "numeric"  ,
			       "familyIndex" = "numeric" ,
			       "newNoOfChildren" = "numeric"))

      analysisDataset[ , familyEducationalLevel :=
			     factor(familyEducationalLevel ,
				    levels = c("Primary education" ,
					       "Secondary education" ,
					       "Tertiary education or higher"))]

      analysisDataset[ , reconstitutedFamily :=
			     factor(
				 reconstitutedFamily ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDataset[ , parentalPsychiatricDisease :=
			     factor(parentalPsychiatricDisease ,
				    levels = c("No psychiatric disease" ,
					       "Any psychiatric disease"))]

      analysisDataset[ ,
		      interparentalViolence :=
			  factor(interparentalViolence ,
				 levels = c("No interparental violence" ,
					    "Interparental violence"))]

      analysisDataset[ , parentalSubstanceAbuse :=
			     factor(parentalSubstanceAbuse ,
				    levels = c("No parental substance abuse" ,
					       "Parental substance abuse"))]

      analysisDataset[ , calendarTimeGroup :=
			     factor(calendarTimeGroup ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]

      analysisDataset[ , parentalAbuseAsChild :=
			     factor(parentalAbuseAsChild ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one parent" ,
					       "Maltreatment or neglect, both parents"))]

      analysisDataset[ , oneForeignParent :=
			     factor(oneForeignParent ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDataset[ , familyNeedProtection :=
			     factor(familyNeedProtection ,
				    levels = c("Not in need of protection" ,
					       "In need of protection"))]

      analysisDataset[ , childAgeGroup :=
			     factor(childAgeGroup , 
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDataset[ , parentalAgeGroup :=
			     factor(parentalAgeGroup , 
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35-65" ,
					       "Mean parental age >65-100"))]
      analysisDataset[ , familyEducationalLevelReleveled :=
			     factor(familyEducationalLevelReleveled ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDataset[ , parentalAbuseAsChildReleveled :=
			     factor(parentalAbuseAsChildReleveled ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one or both parents"))]

      analysisDataset[ , parentalAgeGroupReleveled :=
			     factor(parentalAgeGroupReleveled ,
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35"))]

      analysisDataset[ , childAgeGroupAtInclusion :=
			     factor(childAgeGroupAtInclusion ,
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDataset[ , calendarTimeGroupAtInclusion :=
			     factor(calendarTimeGroupAtInclusion ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]


      return(analysisDataset)
  }

  ##Re-loading of the full dataset: 
  readAnalysisDatasetHalfyearlyReduced <- function() {
      analysisDatasetHalfyearlyReduced <-
	  fread("analysisDatasetHalfyearlyReduced.csv" ,
		colClasses = c("pnr" = "character" ,
			       "date" = "Date" ,
			       "currentParent2" = "character" ,
			       "currentParent1" = "character" ,
			       "reconstitutedFamily" = "factor" ,
			       "studyEntry" = "Date" ,
			       "ageCensoring" = "Date" ,
			       "deathCensoring" = "Date" ,
			       "emigrationCensoring" = "Date" ,
			       "meanParentalAge" = "numeric" ,
			       "birthDate" = "Date" ,
			       "childAge" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			       "strokeGroupDiagCurrentParent1" = "numeric" ,
			       "strokeGroupDiagCurrentParent2" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "goutGroupDiagCurrentParent1" = "numeric" ,
			       "goutGroupDiagCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "allergyGroupDiagCurrentParent1" = "numeric" ,
			       "allergyGroupDiagCurrentParent2" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			       "anemiasGroupDiagCurrentParent1" = "numeric" ,
			       "anemiasGroupDiagCurrentParent2" = "numeric" ,
			       "cancerGroupDiagCurrentParent1" = "numeric" ,
			       "cancerGroupDiagCurrentParent2" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			       "migraineGroupDiagCurrentParent1" = "numeric" ,
			       "migraineGroupDiagCurrentParent2" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "dementiaGroupDiagCurrentParent1" = "numeric" ,
			       "dementiaGroupDiagCurrentParent2" = "numeric" ,
			       "otherGroupDiagCurrentParent1" = "numeric" ,
			       "otherGroupDiagCurrentParent2" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			       "aidsHivCharlsonCurrentParent1" = "numeric" ,
			       "aidsHivCharlsonCurrentParent2" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			       "leukemiaCharlsonCurrentParent1" = "numeric" ,
			       "leukemiaCharlsonCurrentParent2" = "numeric" ,
			       "lymphomaCharlsonCurrentParent1" = "numeric" ,
			       "lymphomaCharlsonCurrentParent2" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "dementiaCharlsonCurrentParent1" = "numeric" ,
			       "dementiaCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "heartFailureCharlsonCurrentParent1" = "numeric" ,
			       "heartFailureCharlsonCurrentParent2" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "alcoholAbuseCurrentParent1" = "numeric" ,
			       "alcoholAbuseCurrentParent2" = "numeric" ,
			       "substanceAbuseCurrentParent1" = "numeric" ,
			       "substanceAbuseCurrentParent2" = "numeric" ,
			       "unspecificEverCurrentParent1" = "numeric" ,
			       "unspecificEverCurrentParent2" = "numeric" , 
			       "unspecificTwoYearCurrentParent1" = "numeric" , 
			       "unspecificTwoYearCurrentParent2" = "numeric" , 
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "jointCharlsonParents" = "numeric" ,
			       "outcomePhysicalAbuse" = "numeric" ,
			       "interparentalViolence" = "factor" ,
			       "familyEducationalLevel" = "factor" ,
			       "parentalAbuseAsChild" = "factor" ,
			       "oneForeignParent" = "factor" ,
			       "familyNeedProtection" = "factor" ,
			       "parentalPsychiatricDisease" = "factor" ,
			       "parentalSubstanceAbuse" = "factor" ,
			       "calendarTimeGroup" = "factor" ,
			       "childAgeGroup" = "factor" ,
			       "parentalAgeGroup" = "factor" ,
			       "incomeVariable" = "numeric" ,
			       "parishQuantileDifference100Euros" = "numeric" ,
			       "time" = "numeric" ,
			       "familyEducationalLevelReleveled" = "factor" ,
			       "parentalAbuseAsChildReleveled" = "factor" ,
			       "parentalAgeGroupReleveled"  = "factor" ,
			       "gTreatment" = "numeric" ,
			       "anyPhysicalAbuse" = "numeric" ,
			       "familyEducationalLevelBinary" = "numeric"  ,
			       "oneForeignParentBinary" = "numeric" ,
			       "familyNeedProtectionBinary" = "numeric" ,
			       "parentalPsychiatricDiseaseBinary" = "numeric" ,
			       "parentalAbuseAsChildBinary" = "numeric" ,
			       "childAgeGroupAtInclusion" = "factor" ,
			       "calendarTimeGroupAtInclusion" = "factor" ,
			       "childAgeGroupAtInclusionBinary" = "numeric"  ,
			       "familyIndex" = "numeric" ,
			       "newNoOfChildren" = "numeric"))

      analysisDatasetHalfyearlyReduced[ , familyEducationalLevel :=
			     factor(familyEducationalLevel ,
				    levels = c("Primary education" ,
					       "Secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetHalfyearlyReduced[ , reconstitutedFamily :=
			     factor(
				 reconstitutedFamily ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDatasetHalfyearlyReduced[ , parentalPsychiatricDisease :=
			     factor(parentalPsychiatricDisease ,
				    levels = c("No psychiatric disease" ,
					       "Any psychiatric disease"))]

      analysisDatasetHalfyearlyReduced[ ,
		      interparentalViolence :=
			  factor(interparentalViolence ,
				 levels = c("No interparental violence" ,
					    "Interparental violence"))]

      analysisDatasetHalfyearlyReduced[ , parentalSubstanceAbuse :=
			     factor(parentalSubstanceAbuse ,
				    levels = c("No parental substance abuse" ,
					       "Parental substance abuse"))]

      analysisDatasetHalfyearlyReduced[ , calendarTimeGroup :=
			     factor(calendarTimeGroup ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]

      analysisDatasetHalfyearlyReduced[ , parentalAbuseAsChild :=
			     factor(parentalAbuseAsChild ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one parent" ,
					       "Maltreatment or neglect, both parents"))]

      analysisDatasetHalfyearlyReduced[ , oneForeignParent :=
			     factor(oneForeignParent ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDatasetHalfyearlyReduced[ , familyNeedProtection :=
			     factor(familyNeedProtection ,
				    levels = c("Not in need of protection" ,
					       "In need of protection"))]

      analysisDatasetHalfyearlyReduced[ , childAgeGroup :=
			     factor(childAgeGroup , 
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDatasetHalfyearlyReduced[ , parentalAgeGroup :=
			     factor(parentalAgeGroup , 
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35-65" ,
					       "Mean parental age >65-100"))]
      analysisDatasetHalfyearlyReduced[ , familyEducationalLevelReleveled :=
			     factor(familyEducationalLevelReleveled ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetHalfyearlyReduced[ , parentalAbuseAsChildReleveled :=
			     factor(parentalAbuseAsChildReleveled ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one or both parents"))]

      analysisDatasetHalfyearlyReduced[ , parentalAgeGroupReleveled :=
			     factor(parentalAgeGroupReleveled ,
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35"))]

      analysisDatasetHalfyearlyReduced[ , childAgeGroupAtInclusion :=
			     factor(childAgeGroupAtInclusion ,
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDatasetHalfyearlyReduced[ , calendarTimeGroupAtInclusion :=
			     factor(calendarTimeGroupAtInclusion ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]


      return(analysisDatasetHalfyearlyReduced)
  }

  ##Reload imputed dataset:
  readAnalysisDatasetImputed <- function(m) {
      analysisDatasetImputed <-
	  fread(paste0("datasetImputed" , m , ".csv") ,
		colClasses = c("pnr" = "character" ,
			       "date" = "Date" ,
			       "currentParent2" = "character" ,
			       "currentParent1" = "character" ,
			       "reconstitutedFamily" = "factor" ,
			       "studyEntry" = "Date" ,
			       "ageCensoring" = "Date" ,
			       "deathCensoring" = "Date" ,
			       "emigrationCensoring" = "Date" ,
			       "meanParentalAge" = "numeric" ,
			       "birthDate" = "Date" ,
			       "childAge" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent1" = "numeric" ,
			       "hypertensionGroupDiagCurrentParent2" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
			       "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
			       "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent1" = "numeric" ,
			       "heartFailureGroupDiagCurrentParent2" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
			       "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
			       "strokeGroupDiagCurrentParent1" = "numeric" ,
			       "strokeGroupDiagCurrentParent2" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
			       "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "goutGroupDiagCurrentParent1" = "numeric" ,
			       "goutGroupDiagCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "allergyGroupDiagCurrentParent1" = "numeric" ,
			       "allergyGroupDiagCurrentParent2" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
			       "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
			       "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
			       "anemiasGroupDiagCurrentParent1" = "numeric" ,
			       "anemiasGroupDiagCurrentParent2" = "numeric" ,
			       "cancerGroupDiagCurrentParent1" = "numeric" ,
			       "cancerGroupDiagCurrentParent2" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent1" = "numeric" ,
			       "visionProblemGroupDiagCurrentParent2" = "numeric" ,
			       "migraineGroupDiagCurrentParent1" = "numeric" ,
			       "migraineGroupDiagCurrentParent2" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent1" = "numeric" ,
			       "epilepsyGroupDiagCurrentParent2" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
			       "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
			       "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
			       "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
			       "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
			       "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
			       "dementiaGroupDiagCurrentParent1" = "numeric" ,
			       "dementiaGroupDiagCurrentParent2" = "numeric" ,
			       "otherGroupDiagCurrentParent1" = "numeric" ,
			       "otherGroupDiagCurrentParent2" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
			       "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
			       "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
			       "aidsHivCharlsonCurrentParent1" = "numeric" ,
			       "aidsHivCharlsonCurrentParent2" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
			       "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
			       "leukemiaCharlsonCurrentParent1" = "numeric" ,
			       "leukemiaCharlsonCurrentParent2" = "numeric" ,
			       "lymphomaCharlsonCurrentParent1" = "numeric" ,
			       "lymphomaCharlsonCurrentParent2" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "dementiaCharlsonCurrentParent1" = "numeric" ,
			       "dementiaCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "heartFailureCharlsonCurrentParent1" = "numeric" ,
			       "heartFailureCharlsonCurrentParent2" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "alcoholAbuseCurrentParent1" = "numeric" ,
			       "alcoholAbuseCurrentParent2" = "numeric" ,
			       "substanceAbuseCurrentParent1" = "numeric" ,
			       "substanceAbuseCurrentParent2" = "numeric" ,
			       "unspecificEverCurrentParent1" = "numeric" ,
			       "unspecificEverCurrentParent2" = "numeric" , 
			       "unspecificTwoYearCurrentParent1" = "numeric" , 
			       "unspecificTwoYearCurrentParent2" = "numeric" , 
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
			       "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
			       "jointCharlsonParents" = "numeric" ,
			       "outcomePhysicalAbuse" = "numeric" ,
			       "interparentalViolence" = "factor" ,
			       "familyEducationalLevel" = "factor" ,
			       "parentalAbuseAsChild" = "factor" ,
			       "oneForeignParent" = "factor" ,
			       "familyNeedProtection" = "factor" ,
			       "parentalPsychiatricDisease" = "factor" ,
			       "parentalSubstanceAbuse" = "factor" ,
			       "calendarTimeGroup" = "factor" ,
			       "childAgeGroup" = "factor" ,
			       "parentalAgeGroup" = "factor" ,
			       "incomeVariable" = "numeric" ,
			       "parishQuantileDifference100Euros" = "numeric" ,
			       "time" = "numeric" ,
			       "familyEducationalLevelReleveled" = "factor" ,
			       "parentalAbuseAsChildReleveled" = "factor" ,
			       "parentalAgeGroupReleveled"  = "factor" ,
			       "gTreatment" = "numeric" ,
			       "anyPhysicalAbuse" = "numeric" ,
			       "familyEducationalLevelBinary" = "numeric"  ,
			       "oneForeignParentBinary" = "numeric" ,
			       "familyNeedProtectionBinary" = "numeric" ,
			       "parentalPsychiatricDiseaseBinary" = "numeric" ,
			       "parentalAbuseAsChildBinary" = "numeric" ,
			       "childAgeGroupAtInclusion" = "factor" ,
			       "calendarTimeGroupAtInclusion" = "factor" ,
			       "childAgeGroupAtInclusionBinary" = "numeric"  ,
			       "familyIndex" = "numeric" ,
			       "newNoOfChildren" = "numeric" ,
			       "reconstitutedFamilyObserved" = "factor" ,
			       "oneForeignParentObserved" = "factor" ,
			       "familyEducationalLevelReleveledObserved" = "factor" ,
			       "reconstitutedFamilyImputed" = "factor" ,
			       "oneForeignParentImputed" = "factor" ,
			       "familyEducationalLevelReleveledImputed" = "factor"))

      analysisDatasetImputed[ , familyEducationalLevel :=
			     factor(familyEducationalLevel ,
				    levels = c("Primary education" ,
					       "Secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetImputed[ , reconstitutedFamily :=
			     factor(
				 reconstitutedFamily ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDatasetImputed[ , reconstitutedFamilyObserved :=
			     factor(
				 reconstitutedFamilyObserved ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDatasetImputed[ , reconstitutedFamilyImputed :=
			     factor(
				 reconstitutedFamilyImputed ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDatasetImputed[ , parentalPsychiatricDisease :=
			     factor(parentalPsychiatricDisease ,
				    levels = c("No psychiatric disease" ,
					       "Any psychiatric disease"))]

      analysisDatasetImputed[ ,
		      interparentalViolence :=
			  factor(interparentalViolence ,
				 levels = c("No interparental violence" ,
					    "Interparental violence"))]

      analysisDatasetImputed[ , parentalSubstanceAbuse :=
			     factor(parentalSubstanceAbuse ,
				    levels = c("No parental substance abuse" ,
					       "Parental substance abuse"))]

      analysisDatasetImputed[ , calendarTimeGroup :=
			     factor(calendarTimeGroup ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]

      analysisDatasetImputed[ , parentalAbuseAsChild :=
			     factor(parentalAbuseAsChild ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one parent" ,
					       "Maltreatment or neglect, both parents"))]

      analysisDatasetImputed[ , oneForeignParent :=
			     factor(oneForeignParent ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDatasetImputed[ , oneForeignParentObserved :=
			     factor(oneForeignParentObserved ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDatasetImputed[ , oneForeignParentImputed :=
			     factor(oneForeignParentImputed ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDatasetImputed[ , familyNeedProtection :=
			     factor(familyNeedProtection ,
				    levels = c("Not in need of protection" ,
					       "In need of protection"))]

      analysisDatasetImputed[ , childAgeGroup :=
			     factor(childAgeGroup , 
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDatasetImputed[ , parentalAgeGroup :=
			     factor(parentalAgeGroup , 
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35-65" ,
					       "Mean parental age >65-100"))]
      analysisDatasetImputed[ , familyEducationalLevelReleveled :=
			     factor(familyEducationalLevelReleveled ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetImputed[ , familyEducationalLevelReleveledObserved :=
			     factor(familyEducationalLevelReleveledObserved ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetImputed[ , familyEducationalLevelReleveledImputed :=
			     factor(familyEducationalLevelReleveledImputed ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDatasetImputed[ , parentalAbuseAsChildReleveled :=
			     factor(parentalAbuseAsChildReleveled ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one or both parents"))]

      analysisDatasetImputed[ , parentalAgeGroupReleveled :=
			     factor(parentalAgeGroupReleveled ,
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35"))]

      analysisDatasetImputed[ , childAgeGroupAtInclusion :=
			     factor(childAgeGroupAtInclusion ,
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDatasetImputed[ , calendarTimeGroupAtInclusion :=
			     factor(calendarTimeGroupAtInclusion ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]


      return(analysisDatasetImputed)
  }


  analysisDataset <- readAnalysisDataset()

  ##Only use records with full data:
  analysisDataset[ , complete :=
			 complete.cases(.SD) ,
		  .SDcols = c(
		      ## "pnr" ,
		      "date" ,
		      ## "currentParent2" ,
		      ## "currentParent1" ,
		      "reconstitutedFamily" ,
		      ## "studyEntry" ,
		      ## "ageCensoring" ,
		      ## "deathCensoring" ,
		      ## "emigrationCensoring" ,
		      ## "meanParentalAge" ,
		      ## "birthDate" ,
		      "childAge" ,
		      ## "hypertensionGroupDiagCurrentParent1" ,
		      ## "hypertensionGroupDiagCurrentParent2" ,
		      ## "dyslipidemiaGroupDiagCurrentParent1" ,
		      ## "dyslipidemiaGroupDiagCurrentParent2" ,
		      ## "ischemicHeartDiseaseGroupDiagCurrentParent1" ,
		      ## "ischemicHeartDiseaseGroupDiagCurrentParent2" ,
		      ## "atrialFibrillationGroupDiagCurrentParent1" ,
		      ## "atrialFibrillationGroupDiagCurrentParent2" ,
		      ## "heartFailureGroupDiagCurrentParent1" ,
		      ## "heartFailureGroupDiagCurrentParent2" ,
		      ## "peripheralArteryOcclusiveGroupDiagCurrentParent1" ,
		      ## "peripheralArteryOcclusiveGroupDiagCurrentParent2" ,
		      ## "strokeGroupDiagCurrentParent1" ,
		      ## "strokeGroupDiagCurrentParent2" ,
		      ## "diabetesMellitusGroupDiagCurrentParent1" ,
		      ## "diabetesMellitusGroupDiagCurrentParent2" ,
		      ## "thyroidDisorderGroupDiagCurrentParent1" ,
		      ## "thyroidDisorderGroupDiagCurrentParent2" ,
		      ## "goutGroupDiagCurrentParent1" ,
		      ## "goutGroupDiagCurrentParent2" ,
		      ## "chronicPulmonaryDiseaseGroupDiagCurrentParent1" ,
		      ## "chronicPulmonaryDiseaseGroupDiagCurrentParent2" ,
		      ## "allergyGroupDiagCurrentParent1" ,
		      ## "allergyGroupDiagCurrentParent2" ,
		      ## "ulcerChronicGastritisGroupDiagCurrentParent1" ,
		      ## "ulcerChronicGastritisGroupDiagCurrentParent2" ,
		      ## "chronicLiverDiseaseGroupDiagCurrentParent1" ,
		      ## "chronicLiverDiseaseGroupDiagCurrentParent2" ,
		      ## "inflammatoryBowelDiseaseGroupDiagCurrentParent1" ,
		      ## "inflammatoryBowelDiseaseGroupDiagCurrentParent2" ,
		      ## "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" ,
		      ## "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" ,
		      ## "chronicKidneyDiseaseGroupDiagCurrentParent1" ,
		      ## "chronicKidneyDiseaseGroupDiagCurrentParent2" ,
		      ## "prostateDisordersGroupDiagCurrentParent1" ,
		      ## "prostateDisordersGroupDiagCurrentParent2" ,
		      ## "connectiveTissueDisordersGroupDiagCurrentParent1" ,
		      ## "connectiveTissueDisordersGroupDiagCurrentParent2" ,
		      ## "osteoporosisGroupDiagCurrentParent1" ,
		      ## "osteoporosisGroupDiagCurrentParent2" ,
		      ## "anemiasGroupDiagCurrentParent1" ,
		      ## "anemiasGroupDiagCurrentParent2" ,
		      ## "cancerGroupDiagCurrentParent1" ,
		      ## "cancerGroupDiagCurrentParent2" ,
		      ## "visionProblemGroupDiagCurrentParent1" ,
		      ## "visionProblemGroupDiagCurrentParent2" ,
		      ## "migraineGroupDiagCurrentParent1" ,
		      ## "migraineGroupDiagCurrentParent2" ,
		      ## "epilepsyGroupDiagCurrentParent1" ,
		      ## "epilepsyGroupDiagCurrentParent2" ,
		      ## "parkinsonsDiseaseGroupDiagCurrentParent1" ,
		      ## "parkinsonsDiseaseGroupDiagCurrentParent2" ,
		      ## "multipleSclerosisGroupDiagCurrentParent1" ,
		      ## "multipleSclerosisGroupDiagCurrentParent2" ,
		      ## "neuropathiesGroupDiagCurrentParent1" ,
		      ## "neuropathiesGroupDiagCurrentParent2" ,
		      ## "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" ,
		      ## "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" ,
		      ## "anorexiaBulimiaGroupDiagCurrentParent1" ,
		      ## "anorexiaBulimiaGroupDiagCurrentParent2" ,
		      ## "bipolarAffectiveDisorderGroupDiagCurrentParent1" ,
		      ## "bipolarAffectiveDisorderGroupDiagCurrentParent2" ,
		      ## "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" ,
		      ## "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" ,
		      ## "personalityDisorderGroupDiagCurrentParent1" ,
		      ## "personalityDisorderGroupDiagCurrentParent2" ,
		      ## "dementiaGroupDiagCurrentParent1" ,
		      ## "dementiaGroupDiagCurrentParent2" ,
		      ## "otherGroupDiagCurrentParent1" ,
		      ## "otherGroupDiagCurrentParent2" ,
		      ## "pretermBirthGroupDiagCurrentParent1" ,
		      ## "pretermBirthGroupDiagCurrentParent2" ,
		      ## "acuteCaesarianSectionGroupDiagCurrentParent1" ,
		      ## "acuteCaesarianSectionGroupDiagCurrentParent2" ,
		      ## "aidsHivCharlsonCurrentParent1" ,
		      ## "aidsHivCharlsonCurrentParent2" ,
		      ## "anyMalignancyCharlsonCurrentParent1" ,
		      ## "anyMalignancyCharlsonCurrentParent2" ,
		      ## "cerebrovascularDiseaseCharlsonCurrentParent1" ,
		      ## "cerebrovascularDiseaseCharlsonCurrentParent2" ,
		      ## "chronicPulmonaryDiseaseCharlsonCurrentParent1" ,
		      ## "chronicPulmonaryDiseaseCharlsonCurrentParent2" ,
		      ## "dementiaCharlsonCurrentParent1" ,
		      ## "dementiaCharlsonCurrentParent2" ,
		      ## "diabetesWithComplicationsCharlsonCurrentParent1" ,
		      ## "diabetesWithComplicationsCharlsonCurrentParent2" ,
		      ## "diabetesWithoutComplicationsCharlsonCurrentParent1" ,
		      ## "diabetesWithoutComplicationsCharlsonCurrentParent2" ,
		      ## "heartFailureCharlsonCurrentParent1" ,
		      ## "heartFailureCharlsonCurrentParent2" ,
		      ## "hemiplegiaParaplegiaCharlsonCurrentParent1" ,
		      ## "hemiplegiaParaplegiaCharlsonCurrentParent2" ,
		      ## "metastaticSolidTumorCharlsonCurrentParent1" ,
		      ## "metastaticSolidTumorCharlsonCurrentParent2" ,
		      ## "mildLiverDiseaseCharlsonCurrentParent1" ,
		      ## "mildLiverDiseaseCharlsonCurrentParent2" ,
		      ## "myocardialInfarctionCharlsonCurrentParent1" ,
		      ## "myocardialInfarctionCharlsonCurrentParent2" ,
		      ## "pepticUlcerDiseaseCharlsonCurrentParent1" ,
		      ## "pepticUlcerDiseaseCharlsonCurrentParent2" ,
		      ## "peripheralVascularDiseaseCharlsonCurrentParent1" ,
		      ## "peripheralVascularDiseaseCharlsonCurrentParent2" ,
		      ## "renalDiseaseCharlsonCurrentParent1" ,
		      ## "renalDiseaseCharlsonCurrentParent2" ,
		      ## "rheumaticDiseaseCharlsonCurrentParent1" ,
		      ## "rheumaticDiseaseCharlsonCurrentParent2" ,
		      ## "severeLiverDiseaseCharlsonCurrentParent1" ,
		      ## "severeLiverDiseaseCharlsonCurrentParent2" ,
		      ## "alcoholAbuseCurrentParent1" ,
		      ## "alcoholAbuseCurrentParent2" ,
		      ## "substanceAbuseCurrentParent1" ,
		      ## "substanceAbuseCurrentParent2" ,
		      ## "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "allergyGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "allergyGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "allergyGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "allergyGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "osteoporosisGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "osteoporosisGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "osteoporosisGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "osteoporosisGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "painfulConditionGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "painfulConditionGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "painfulConditionGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "painfulConditionGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "migraineGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "migraineGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "migraineGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "migraineGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "epilepsyGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "epilepsyGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "epilepsyGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "epilepsyGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" ,
		      ## "dementiaGroupLmdbCurrentParent1LmdbTemp" ,
		      ## "dementiaGroupLmdbCurrentParent1LmdbTotal" ,
		      ## "dementiaGroupLmdbCurrentParent2LmdbTemp" ,
		      ## "dementiaGroupLmdbCurrentParent2LmdbTotal" ,
		      "jointCharlsonParents" ,
		      "outcomePhysicalAbuse" ,
		      "interparentalViolence" ,
		      "familyEducationalLevel" ,
		      "parentalAbuseAsChild" ,
		      "oneForeignParent" ,
		      "familyNeedProtection" ,
		      "parentalPsychiatricDisease" ,
		      "parentalSubstanceAbuse" ,
		      "calendarTimeGroup" ,
		      "childAgeGroup" ,
		      "parentalAgeGroup" ,
		      "incomeVariable" ,
		      "parishQuantileDifference100Euros")]
		      ## "numberOfAdults" ,
		      ## "numberOfChildren" ,
		      ## "numberOfAdultsFactor" ,
		      ## "numberOfChildrenFactor" ,
		      ## "genderChild" ,
		      ## "deathCensoringImpute" ,
		      ## "emigrationCensoringImpute" ,
		      ## "time" ,
		      ##"newNoOfChildren")]

  print(Sys.time())
  library(survival)
  library(geepack)
  library(lubridate)

  suppressWarnings(analysisDataset[ , case := NULL])
  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  cases <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , "jointCharlsonParents"))
  cases <- cases[jointCharlsonParents >= 2]
  cases <- unique(cases , by = "pnr")
  ##Reduce cases to variables listed below:
  temp <- names(cases)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  cases[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSet <-
      analysisDataset[complete == TRUE ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSet <-
      analysisMatchingSet[jointCharlsonParents < 2]
  ##Commenting this out, analysisDataset[complete == TRUE] has been "cleaned" from incomplete records:
  ## ##Cases and controls need data on matching variables
  ## cases <-
  ##     cases[!is.na(numberOfAdultsFactor) &
  ## 	  !is.na(numberOfChildrenFactor) &
  ## 	  !is.na(meanParentalAge) &
  ## 	  !is.na(childAge)]
  ## analysisMatchingSet <-
  ##     analysisMatchingSet[!is.na(numberOfAdultsFactor) &
  ## 			!is.na(numberOfChildrenFactor) &
  ## 			!is.na(meanParentalAge) &
  ## 			!is.na(childAge)]
  ##Cleaning data before merge
  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSet[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSet[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSet[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSet[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 


  ##In my original setup I wanted cases and controls to be able to switch status - so that a control became a match if their parents got ill. But I cannot get around this in the matching algorithm - if I do a merge that allows for unlimited matches between cases and controls, the numbers become unwieldy for the machine (merge does not allow unequi-joins) and if I do a unequi-join, every possible match only gets to match once. Downstream, there is a solution where cases are split up into small portions, making the merge operation feasible within memory.

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSet , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(cases , "casesComplete.csv")
  fwrite(analysisMatchingSet , "analysisMatchingSetComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  cases[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSet[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSet:
  ## analysisMatchingSet <-
  ##     fread("analysisMatchingSetComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSet[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSet[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ## ##If you need to read the cases-set:
  ## cases <-
  ##     fread("casesComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  ##Splitting cases into m pieces by an index (number of m could be optimized for computer capacity, speed and number of matches) - I split for two reasons: one is computer power (the server cannot do the full match at once), the other one is to avoid one or a few individuals taking up too many matches. Without splitting, the first individuals gets a large number of matches while subsequent matches are (rightly) detected as duplicates and deleted - which makes the number of available matches small to the last on the list. By cutting the dataset into smaller chunks, limiting the number of matches to 300 (this number is arbitrary, picked to try and ensure 10 matches after de-duplicating but avoiding "over-use" on the small lists), de-duplicating and then reducing to only 10 matches for each person, I should mitigate the "over-use" of matches by the first individuals on the list: 
  ##First run was with m = 200, 10 matches required and 300 matches before pruning for duplicates - this proved to be finished within 9 hours. Approx. 20000 individuals never found matches in this algorithm, but the results were vastly better than before. To optimize further, the number of splits is doubled to 400, the number of matches reduced to 5 and the number of "pre-matches" reduced to 250. 
  m <- 400
  cases[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the cases-dataset:
  casesMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- cases[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSet ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSet[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 5 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSet[temp , on = "pnr" , delete := 1]
      analysisMatchingSet <- analysisMatchingSet[is.na(delete)]
      analysisMatchingSet[ , delete := NULL]
      casesMatchedJoint <- rbindlist(list(casesMatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesMatchedJoint , "casesMatchedJointComplete.csv")

  ##The resulting dataset has been checked manually - there are no controls used twice, almost all cases have controls (see numbers below and each case has 5 controls available matched exactly on number of adults and number of children, and matched within 

  ##Reading in the results from above:
  ## casesMatchedJoint <-
  ##     fread("casesMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]

  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesMatchedJoint[ , .(pnr)]) ,
		     casesMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 


  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesMatchedJoint[ , .(pnr)])
  ##208270 unique pnrs
  temp <- casesMatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesMatchedJoint[ , table(keepThisRecord)]
  casesMatchedJoint <- casesMatchedJoint[!is.na(keepThisRecord)]
  ##casesMatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesMatchedJoint[ , .(pnr)])
  ###208137 unique pnrs after this, meaning 141 lost pnrs - this seems acceptable
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesMatchedJoint[ , .(pnr)]) ,
		     casesMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesMatchedLong <- melt(casesMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesMatchedLong , "date" , "studyEntry")
  casesMatchedLong[variable == "pnr" , case := 1]
  casesMatchedLong[variable == "pnrControl" , case := 0]
  casesMatchedLong[ , variable := NULL]
  setnames(casesMatchedLong , "value" , "pnr")
  setorder(casesMatchedLong , pnr , case , studyEntry)
  casesMatchedLong <- unique(casesMatchedLong , by = c("pnr" , "case"))

  ##In this dataset there were a few entries, 181, with missing values upon merge with the main dataset - that was because the cases, during the matching algorithm are expanded to three dates to increase the chance of a match. In the code above, the dataset is again reduced (the unique command) to the first available dates, deleting most of the "expanded" records. However, if there is no match for a case on the first date, a later date within the three month expansion is used - and this will be the first available date above. If this later date has a missing value, the algorithm will throw an error. This is corrected by merging the cases in casesMatchedLong with the original, correct dates from the cases-object:
  casesMatchedLong[cases , on = "pnr" , originalDate := i.date]
  casesMatchedLong[case == 1 , studyEntry := originalDate]
  casesMatchedLong[ , originalDate := NULL]

  ##Testing how many entries are without full control:
  ## setorder(casesMatchedLong , indexCasesMatches , studyEntry)
  ## casesMatchedLong[ , groupCount := 1:.N , by = indexCasesMatches]
  ## casesMatchedLong[ , table(groupCount)]
  ##The block above showed that all groups had 6 members - one case and 5 controls. After removing "doubles", that is only allowing any member of the population to count as case and control once, all groups are still complete. 

  ##Re-reading analysisDataset
  ##analysisDataset <- readAnalysisDataset() #Defined above

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesMatchedLong , "studyEntry" , "date")
  analysisDataset[casesMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  ##Going through the full dataset, 9191 children dies during their childhood, which is a reasonable number considering national statistics on the subject(Denmark,2006-2018: 4534 deaths (dataset FOD207, Statistics Denmark) dataset, 1997-2018: 9191 deaths). 
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]
  ##Now the dataset should include an event-variable with 0 as censoring and 1 as physical abuse, a time-variable and a unique identifier. This should be sufficient to do the pseudo-numbers (the 215 is a result of seq(as.Date("2000-01-01") , as.Date("2017-12-01") , by = "month")) - 1 , that is the number of months it takes for someone to be 18 and thus the longest time anyone could remain in the study):
  ##Make sure this code runs as supposed - so that the right times goes to the right persons:
  ##A survival-version - check out what the dataset looks like, perhaps on some subset of the data:

  ##A downstream sensitivity analysis has shown that censoring is dependent on time periods - splitting on those and making pseudovalues:

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))


  ## ##An older version from the package pseudo (very slow - haven't taken the time to see it finish):
  ## pseudo <- pseudoci(time = pseudoAnalysis$time , event = pseudoAnalysis$eventNoFactor , tmax =214)


  ## pseudoResults <- pseudoci(time = pseudoTest$time , event = pseudoTest$eventNoFactor , tmax =214)

  ## pseudoAnalysis[ , pseudo := pseudo$pseudo]
  ## pseudoAnalysis[ , pseudoTime := pseudo$time]

  ## ##Creating a covariate from the date variable to be calendar time starting from 1997:
  ## pseudoAnalysis[ , calendarTime :=
  ## 		      sapply(date ,
  ## 			     function(date) length(seq(as.Date("1997-01-01") ,
  ## 						       date ,
  ## 						       by = "month")) - 1)]

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Have decided to use numbers from the reduced dataset actually analyzed to avoid inflating the available follow-up time:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]

  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulation <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulation)
  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }
  resultsPseudoFitFullPopulation <- formatResultsGeese(pseudoFitFullPopulation)
  fwrite(resultsPseudoFitFullPopulation , "resultsPseudoFitFullPopulation.csv")

  ## ##Recoding due to "small cells" problem(moved upstream):
  ## ##familyEducationalLevel
  ## pseudoAnalysis[familyEducationalLevel == "Primary education" , familyEducationalLevel := "Secondary education"]
  ## pseudoAnalysis[ , familyEducationalLevel := droplevels(familyEducationalLevel)]
  ## levels(pseudoAnalysis$familyEducationalLevel)[levels(pseudoAnalysis$familyEducationalLevel) == "Secondary education"] <- "Primary or secondary education"
  ## ##ParentalAbuseAsChild
  ## pseudoAnalysis[parentalAbuseAsChild == "Maltreatment or neglect, both parents" , parentalAbuseAsChild := "Maltreatment or neglect, one parent"]
  ## levels(pseudoAnalysis$parentalAbuseAsChild)[levels(pseudoAnalysis$parentalAbuseAsChild) == "Maltreatment or neglect, one parent"] <- "Maltreatment or neglect, one or both parents"
  ## pseudoAnalysis[ , parentalAbuseAsChild := droplevels(parentalAbuseAsChild)]
  ## ##Checking for colinearity:
  ## library(GGally)
  ## temp <- pseudoAnalysis[ , .(incomeVariable , 
  ## 			    parishQuantileDifference100Euros ,
  ## 			    reconstitutedFamily , 
  ## 			    oneForeignParent ,
  ## 			    ##familyNeedProtection ,
  ## 			    calendarTimeGroup ,
  ## 			    ##Parental health and history
  ## 			    familyEducationalLevel ,
  ## 			    parentalPsychiatricDisease ,
  ## 			    ##interparentalViolence ,
  ## 			    parentalSubstanceAbuse ,
  ## 			    parentalAbuseAsChild)]
  ## ggpairs(temp)

  ## ##Doing some two-way tables based on the results from above:
  ## table(pseudoAnalysis$reconstitutedFamily , pseudoAnalysis$oneForeignParent)
  ## chisq.test(table(pseudoAnalysis$reconstitutedFamily , pseudoAnalysis$oneForeignParent))
  ## table(pseudoAnalysis$familyEducationalLevel , pseudoAnalysis$parentalAbuseAsChild)
  ## chisq.test(table(pseudoAnalysis$familyEducationalLevel , pseudoAnalysis$parentalAbuseAsChild))
  ## table(pseudoAnalysis$parentalAbuseAsChild , pseudoAnalysis$parentalPsychiatricDisease)
  ## chisq.test(table(pseudoAnalysis$parentalAbuseAsChild , pseudoAnalysis$parentalPsychiatricDisease))
  ## table(pseudoAnalysis$reconstitutedFamily , pseudoAnalysis$parentalPsychiatricDisease)
  ## chisq.test(table(pseudoAnalysis$reconstitutedFamily , pseudoAnalysis$parentalPsychiatricDisease))



  ##New fit with recoded variables to avoid small cells: 
  ##The geese way:
  pseudoFitFullPopulationNoSmallCells <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros +
				       ##reconstitutedFamily + 
				       oneForeignParent +
				       ##familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       ##interparentalViolence +
				       ##parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoSmallCells)
  resultsPseudoFitFullPopulationNoSmallCells <- formatResultsGeese(pseudoFitFullPopulationNoSmallCells)
  fwrite(resultsPseudoFitFullPopulationNoSmallCells , "resultsPseudoFitFullPopulationNoSmallCells.csv")

  ##Avoiding most obvious colinearity:
  ##The geese way:
  pseudoFitFullPopulationNoSmallCellsLessColinearity <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros +
				       ##reconstitutedFamily + 
				       ##oneForeignParent +
				       ##familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       ##interparentalViolence +
				       ##parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoSmallCellsLessColinearity)
  resultsPseudoFitFullPopulationNoSmallCellsLessColinearity <- formatResultsGeese(pseudoFitFullPopulationNoSmallCellsLessColinearity)
  fwrite(resultsPseudoFitFullPopulationNoSmallCellsLessColinearity , "resultsPseudoFitFullPopulationNoSmallCellsLessColinearity.csv")

  ##None of these changes make any substantial changes to the results - the case-non-case status is remarkably close to 1 and with no significance whatsoever under different specifications.

  ##Making sensitivity analyses:

  ##Model control - introducing quadratic terms for continous variables:
  pseudoAnalysis[ , incomeVariableQuadratic := incomeVariable^2]
  pseudoAnalysis[ , parishQuantileDifference100EurosQuadratic := parishQuantileDifference100Euros^2]
  ##The geese way:
  pseudoFitFullPopulationQuadraticTerms <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable +
				       incomeVariableQuadratic + 
				       parishQuantileDifference100Euros +
				       parishQuantileDifference100EurosQuadratic + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationQuadraticTerms)
  resultsPseudoFitFullPopulationQuadraticTerms <- formatResultsGeese(pseudoFitFullPopulationQuadraticTerms)
  fwrite(resultsPseudoFitFullPopulationQuadraticTerms , "resultsPseudoFitFullPopulationQuadraticTerms.csv")

  ##Both terms are significant but does not yield any relevant difference in the main estimate - in doubt whether I should leave it, change it to the main model or go spline on it. The statistician says ignore as the coefficients aren't very strong. 

  ##Checking the assumption of marginal independence for pseudovalues:
  ##The model that has been run should be replaced with this one, not tested yet:
  ##Code for testing the assumption of marginal independence of covariates: 
  pseudoAnalysis[time != 214 &
		 event == "Censored" ,
		 censoringEvent := 1]

  pseudoAnalysis[is.na(censoringEvent) , censoringEvent := 0]

  testPseudoValuesCox <- coxph(Surv(time , censoringEvent) ~
				   case +
				   ##Family characteristics                     
				   incomeVariable + 
				   parishQuantileDifference100Euros + 
				   oneForeignParent +
				   familyNeedProtection +
				   calendarTimeGroup +
				   ##Parental health and history
				   familyEducationalLevelReleveled +
				   parentalPsychiatricDisease +
				   interparentalViolence +
				   parentalSubstanceAbuse +
				   parentalAbuseAsChildReleveled ,
			     , data = pseudoAnalysis , 
			       cluster = familyIndex)
  sink(file = "resultsCox.txt" , split = TRUE)
  summary(testPseudoValuesCox)
  publish(testPseudoValuesCox , org = TRUE)
  sink()

  ##This is a simpler version, basically asking the question if being censored at any time is associated with the covariates. The Cox model above includes survival time and is superior to this approach:
  ## pseudoAnalysis[event == "Censored" & time != 214 , censoredBeforeTruncated := 1]
  ## pseudoAnalysis[is.na(censoredBeforeTruncated) , censoredBeforeTruncated := 0]
  ## ##Doing a model similar to the main, but putting censoredBeforeTruncated as the dependent:
  ## pseudoFitFullPopulationPseudovaluesControl <- geese(censoredBeforeTruncated ~ case +
  ## 				     ##Family characteristics                     
  ## 				     incomeVariable +
  ## 				     parishQuantileDifference100Euros +
  ## 				     oneForeignParent +
  ## 				     familyNeedProtection +
  ## 				     calendarTimeGroup +
  ## 				     ##Parental health and history
  ## 				     familyEducationalLevelReleveled +
  ## 				     parentalPsychiatricDisease +
  ## 				     interparentalViolence +
  ## 				     parentalSubstanceAbuse +
  ## 				     parentalAbuseAsChildReleveled ,
  ## 				 data = pseudoAnalysis ,
  ## 				 id = familyIndex ,
  ## 				 scale.fix = TRUE ,
  ## 				 family = gaussian ,
  ## 				 mean.link = "log" ,
  ## 				 corstr = "independence")
  ## summary(pseudoFitFullPopulationPseudovaluesControl)
  ## resultsPseudoFitFullPopulationPseudovaluesControl <- formatResultsGeese(pseudoFitFullPopulationPseudovaluesControl)
  ## fwrite(resultsPseudoFitFullPopulationPseudovaluesControl , "resultsPseudoFitFullPopulationPseudovaluesControl.csv")

  ##THIS IS NOT USED ANYMORE - SEE RESULTS OF COX MODEL INSTEAD. 


  ##Preparing a number of models:

  ##For most analyses here, the existing draw of cases and controls will be kept, partly because of the high cost of computing power - this will distort the relation between cases and controls and thus possibly introduce some weights that will weaken the adjustment on parental age, child age and family constitution. All of the sensitivity analyses where this is done is relatively rare cases; thus, almost all remaining famlies will still be balanced with similar families, and the bias introduced is assumed to be neglible. 
  pseudoAnalysisNoDeadParents <- copy(pseudoAnalysis)
  ##Removing children with parents who die:
  dod <- fread("dod_pop_110621.csv" , colClasses = ("pnr" = "character"))
  dod[ , doddato := floor_date(as.Date(doddato) , unit = "month")]
  dod <- dod[!is.na(pnr)]
  setnames(dod , "pnr" , "currentParent1")
  pseudoAnalysisNoDeadParents[dod , on = "currentParent1" , doddato1 := i.doddato]
  setnames(dod , "currentParent1" , "currentParent2")
  pseudoAnalysisNoDeadParents[dod , on = "currentParent2" , doddato2 := i.doddato]
  pseudoAnalysisNoDeadParents[doddato1 <= as.Date("2018-12-31") | doddato2 <= as.Date("2018-12-31") , parentDeathSensitivity := 1]
  pnrParentDeathSensitivity <- pseudoAnalysisNoDeadParents[parentDeathSensitivity == 1 , .(pnr)]
  pnrParentDeathSensitivity <- unique(pnrParentDeathSensitivity)
  pseudoAnalysisNoDeadParents[pnrParentDeathSensitivity , on = "pnr" , delete := 1]
  pseudoAnalysisNoDeadParents <- pseudoAnalysisNoDeadParents[is.na(delete)]

  ##1147836 participants left - the analysis:
  ##The geese way:
  pseudoFitFullPopulationNoDeadParents <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysisNoDeadParents ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoDeadParents)
  resultsPseudoFitFullPopulationNoDeadParents <- formatResultsGeese(pseudoFitFullPopulationNoDeadParents)
  fwrite(resultsPseudoFitFullPopulationNoDeadParents , "resultsPseudoFitFullPopulationNoDeadParents.csv")

  ##This does not deviate from the main analysis.

  ##Remove lethal cases:
  pseudoAnalysisNoLethalAbuse <- copy(pseudoAnalysis)

  pseudoAnalysisNoLethalAbuse[outcomePhysicalAbuse == 4 | outcomePhysicalAbuse == 5 | outcomePhysicalAbuse == 6 , outcomePhysicalAbuse := 0]
  pseudoAnalysisNoLethalAbuse[event == "Physical abuse" & outcomePhysicalAbuse == 0 , event := "Deceased"]
  pseudoAnalysisNoLethalAbuse[event == "Deceased" , anyPhysicalAbuse := NA]
  ##Do new pseudovalues as I am changing the outcome:
  pseudoAnalysisNoLethalAbuse[ , c("(s0)" , "physicalAbuse" , "Deceased") := NULL]
  pseudoAnalysisNoLethalAbuse1 <- pseudoAnalysisNoLethalAbuse[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisNoLethalAbuse2 <- pseudoAnalysisNoLethalAbuse[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisNoLethalAbuse3 <- pseudoAnalysisNoLethalAbuse[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisNoLethalAbusePseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisNoLethalAbuse1) , times = 214)
  pseudoAnalysisNoLethalAbusePseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisNoLethalAbuse2) , times = 214)
  pseudoAnalysisNoLethalAbusePseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisNoLethalAbuse3) , times = 214)

  pseudoAnalysisNoLethalAbusePseudoValues1 <-
      as.data.table(pseudoAnalysisNoLethalAbusePseudoValues1)
  pseudoAnalysisNoLethalAbusePseudoValues2 <-
      as.data.table(pseudoAnalysisNoLethalAbusePseudoValues2)
  pseudoAnalysisNoLethalAbusePseudoValues3 <-
      as.data.table(pseudoAnalysisNoLethalAbusePseudoValues3)

  pseudoAnalysisNoLethalAbuse1 <-
      cbind(pseudoAnalysisNoLethalAbuse1 ,
	    pseudoAnalysisNoLethalAbusePseudoValues1)
  pseudoAnalysisNoLethalAbuse2 <-
      cbind(pseudoAnalysisNoLethalAbuse2 ,
	    pseudoAnalysisNoLethalAbusePseudoValues2)
  pseudoAnalysisNoLethalAbuse3 <-
      cbind(pseudoAnalysisNoLethalAbuse3 ,
	    pseudoAnalysisNoLethalAbusePseudoValues3)

  pseudoAnalysisNoLethalAbuse <- rbindlist(list(pseudoAnalysisNoLethalAbuse1 ,
				   pseudoAnalysisNoLethalAbuse2 ,
				   pseudoAnalysisNoLethalAbuse3))

  setnames(pseudoAnalysisNoLethalAbuse , "Physical abuse" , "physicalAbuse")

  ##The geese way:
  pseudoFitFullPopulationNoLethalAbuse <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysisNoLethalAbuse ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoLethalAbuse)
  resultsPseudoFitFullPopulationNoLethalAbuse <- formatResultsGeese(pseudoFitFullPopulationNoLethalAbuse)
  fwrite(resultsPseudoFitFullPopulationNoLethalAbuse , "resultsPseudoFitFullPopulationNoLethalAbuse.csv")

  ##Save casesMatchedLong for subsequent analysis
  fwrite(casesMatchedLong , "casesMatchedLongTemp.csv")

  ##Parental psychiatric disease as exposure: simply exchange parentalPsychiatricDiseaseBinary with the charlson variable.

  ##Do matching for psychiatric disease
  analysisDataset[ , case := NULL]
  ##Get all the cases:
  setorder(analysisDataset , pnr , date , parentalPsychiatricDisease)
  casesPsych <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , "parentalPsychiatricDisease"))
  casesPsych <- casesPsych[parentalPsychiatricDisease == "Any psychiatric disease"]
  casesPsych <- unique(casesPsych , by = "pnr")

  ##There are 303921 individuals available for this analysis - that will make this analysis larger than the main analysis. The main analysis is highly demanding in computational power - therefore I randomly choose 100.000 cases for the remainder of the analysis:
  setseed(25328621)
  casesPsych[ , randomReduce := sample(1:.N , .N)]
  setorder(casesPsych , randomReduce)
  casesPsych <- casesPsych[1:100000]
  casesPsych[ , randomReduce := NULL]

  ##Reduce casesPsych to variables listed below:
  temp <- names(casesPsych)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesPsych[ , (temp) := NULL]
  rm(temp)

  ##Match these casesPsych with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetPsych <-
      analysisDataset[complete == TRUE ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			parentalPsychiatricDisease)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetPsych <-
      analysisMatchingSetPsych[parentalPsychiatricDisease == "No psychiatric disease"]
  ##Commenting this out, analysisDataset has been "cleaned" from incomplete records:
  ## ##CasesPsych and controls need data on matching variables
  ## casesPsych <-
  ##     casesPsych[!is.na(numberOfAdultsFactor) &
  ## 	  !is.na(numberOfChildrenFactor) &
  ## 	  !is.na(meanParentalAge) &
  ## 	  !is.na(childAge)]
  ## analysisMatchingSetPsych <-
  ##     analysisMatchingSetPsych[!is.na(numberOfAdultsFactor) &
  ## 			!is.na(numberOfChildrenFactor) &
  ## 			!is.na(meanParentalAge) &
  ## 			!is.na(childAge)]
  ##Cleaning data before merge
  ##casesPsych[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetPsych[ , parentalPsychiatricDisease := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetPsych[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetPsych[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetPsych[temp , on = "pnr" , randomOrder := i.randomOrder]

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetPsych , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesPsych , "casesPsychComplete.csv")
  fwrite(analysisMatchingSetPsych , "analysisMatchingSetPsychComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesPsych[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetPsych[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSetPsych:
  ## analysisMatchingSetPsych <-
  ##     fread("analysisMatchingSetPsychComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetPsych[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetPsych[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ## ##If you need to read the casesPsych-set:
  ## casesPsych <-
  ##     fread("casesPsychComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))

  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  ##Splitting casesPsych into m pieces by an index (number of m could be optimized for computer capacity, speed and number of matches):
  m <- 400
  casesPsych[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesPsych-dataset:
  casesPsychMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesPsychSplit <- casesPsych[randomSplit == i]
      ##For later ordering:
      casesPsychSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesPsychSplit <- casesPsychSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesPsychSplit)]
      print(paste0("Just after expansion of " , i , "part of casesPsych."))
      print(Sys.time())
      casesPsychSplit[ , nrow := NULL]
      casesPsychSplit[ , date := NULL]
      setnames(casesPsychSplit , "matchDate" , "date")

      casesPsychSplit <- merge(casesPsychSplit  ,
		 analysisMatchingSetPsych ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## casesPsych[analysisMatchingSetPsych[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesPsychSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesPsychSplit <- casesPsychSplit[parentalAgeDiff <= 5]
      ##casesPsychSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesPsychSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesPsychSplit <- casesPsychSplit[childAgeDiff <= 1]
      casesPsychSplit <- casesPsychSplit[!is.na(pnr) & pnr != pnrControl]
      casesPsychSplit <- casesPsychSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesPsychSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesPsychSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesPsychSplit <- casesPsychSplit[indexTempRandom <= 250]
      casesPsychSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesPsychSplit <- unique(casesPsychSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesPsychSplit[ , index := 1:.N , by = "pnr"]
      casesPsychSplit <- casesPsychSplit[index <= 5]
      ##Visually controlled - for first iteration, all casesPsych are shown to have 10 matches. 
      casesPsychSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesPsychSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetPsych[temp , on = "pnr" , delete := 1]
      analysisMatchingSetPsych <- analysisMatchingSetPsych[is.na(delete)]
      analysisMatchingSetPsych[ , delete := NULL]
      casesPsychMatchedJoint <- rbindlist(list(casesPsychMatchedJoint , casesPsychSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesPsychMatchedJoint , "casesPsychMatchedJointComplete.csv")


  ## ##Reading in the results from above:
  ## casesPsychMatchedJoint <-
  ##     fread("casesPsychMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesPsychMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesPsychMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]


  ##Establishing an index for all groups:
  temp <- casesPsychMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesPsychMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  casesPsychMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##As there are 99950 participants with 5 matches and this is not the main analysis, the few cases with less than 5 matches are not expected to have any relevant influence - thus not deleted: 


  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesPsychMatchedJoint[ , .(pnr)]) ,
		     casesPsychMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesPsychMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesPsychMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesPsychMatchedLong <- melt(casesPsychMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesPsychMatchedLong , "date" , "studyEntry")
  casesPsychMatchedLong[variable == "pnr" , case := 1]
  casesPsychMatchedLong[variable == "pnrControl" , case := 0]
  casesPsychMatchedLong[ , variable := NULL]
  setnames(casesPsychMatchedLong , "value" , "pnr")
  setorder(casesPsychMatchedLong , pnr , case , studyEntry)
  casesPsychMatchedLong <- unique(casesPsychMatchedLong , by = c("pnr" , "case"))

  ##Reading in casesPsych:
  ##If you need to read the casesPsych-set:
  ## casesPsych <-
  ##     fread("casesPsychComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))




  casesPsychMatchedLong[casesPsych , on = "pnr" , originalDate := i.date]
  casesPsychMatchedLong[case == 1 , studyEntry := originalDate]
  casesPsychMatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesPsychMatchedLong , "studyEntry" , "date")
  analysisDataset[casesPsychMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesPsychMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  ##The following command is out-commented - going through the full dataset, 9191 children dies during their childhood, which is a reasonable number considering national statistics on the subject(Denmark,2006-2018: 4534 deaths (dataset FOD207, Statistics Denmark) dataset, 1997-2018: 9191 deaths). 
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ## setnames(temp , "date" , "endDate")
  ## pseudoAnalysis <- merge(pseudoAnalysis , temp[ , .(pnr , event , endDate)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  ##A survival-version:


  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <-
      as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <-
      cbind(pseudoAnalysisSubjects3 ,
	    pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2 ,
				   pseudoAnalysis3))


  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationPsych <- geese(physicalAbuse ~ parentalPsychiatricDisease +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulation)
  resultsPseudoFitFullPopulationPsych <- formatResultsGeese(pseudoFitFullPopulationPsych)
  fwrite(resultsPseudoFitFullPopulationPsych , "resultsPseudoFitFullPopulationPsych.csv")



  ##Younger children: limit analysisDataset to 0-6 year olds and 6-17 year olds, maybe even more classes
  ##This needs new pseudovalues and custom times:

  casesMatchedLong <- fread("casesMatchedLongTemp.csv" ,
			    colClasses = c("studyEntry" = "Date" ,
					   "indexCasesMatches" = "numeric" ,
					   "pnr" = "character" ,
					   "case" = "numeric"))


  ##Restricting time:

  analysisDataset[ , case := NULL]
  ##Reducing to those included, on the dates that they are included:
  setnames(casesMatchedLong , "studyEntry" , "date")
  analysisDataset[casesMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesMatchedLong , "date" , "studyEntry")


  pseudoAnalysisSubjectsLessThan7 <- pseudoAnalysisSubjects[childAge < 7] 

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset[childAge < 7] , by = "pnr")
  pseudoAnalysisSubjectsLessThan7[ , deathCensoring := NULL]
  pseudoAnalysisSubjectsLessThan7[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjectsLessThan7[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjectsLessThan7[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjectsLessThan7[is.na(event) , event := 0]
  pseudoAnalysisSubjectsLessThan7[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ## setnames(temp , "date" , "endDate")
  ## pseudoAnalysis <- merge(pseudoAnalysis , temp[ , .(pnr , event , endDate)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjectsLessThan7[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjectsLessThan7[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjectsLessThan7[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjectsLessThan7[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 84)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 84)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 84)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <-
      as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <-
      cbind(pseudoAnalysisSubjects3 ,
	    pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2 ,
				   pseudoAnalysis3))

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##The geese way:
  pseudoFitFullPopulationLessThan7 <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationLessThan7)
  resultsPseudoFitFullPopulationLessThan7 <- formatResultsGeese(pseudoFitFullPopulationLessThan7)
  fwrite(resultsPseudoFitFullPopulationLessThan7 , "resultsPseudoFitFullPopulationLessThan7.csv")


  ##More than 7:
  ##Reducing to those included, on the dates that they are included:
  analysisDataset[ , case := NULL]
  setnames(casesMatchedLong , "studyEntry" , "date")
  analysisDataset[casesMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesMatchedLong , "date" , "studyEntry")


  pseudoAnalysisSubjectsMoreThan7 <- pseudoAnalysisSubjects[childAge > 7] 

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset[childAge > 7] , by = "pnr")
  pseudoAnalysisSubjectsMoreThan7[ , deathCensoring := NULL]
  pseudoAnalysisSubjectsMoreThan7[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjectsMoreThan7[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjectsMoreThan7[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjectsMoreThan7[is.na(event) , event := 0]
  pseudoAnalysisSubjectsMoreThan7[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ## setnames(temp , "date" , "endDate")
  ## pseudoAnalysis <- merge(pseudoAnalysis , temp[ , .(pnr , event , endDate)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjectsMoreThan7[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  ##A survival-version:
  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjectsMoreThan7[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjectsMoreThan7[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjectsMoreThan7[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 132)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 132)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 132)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <-
      as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <-
      cbind(pseudoAnalysisSubjects3 ,
	    pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2 ,
				   pseudoAnalysis3))

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##The geese way:
  pseudoFitFullPopulationMoreThan7 <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationMoreThan7)
  resultsPseudoFitFullPopulationMoreThan7 <- formatResultsGeese(pseudoFitFullPopulationMoreThan7)
  fwrite(resultsPseudoFitFullPopulationMoreThan7 , "resultsPseudoFitFullPopulationMoreThan7.csv")


  ##Re-splitting with other exposure fractions, for example charlson more than 4 and 10 or something


  ##Do matching for Charlson
  analysisDataset[ , case := NULL]
  ##Just discovered an error in the Charlson scoring - this does not affect the <2 cutoff, but all higher cutoffs. Re-scoring the charlson:

  analysisDataset[ , charlsonNonexclusiveCurrentParent1 := rowSums(.SD , na.rm = TRUE) ,
		  .SDcols = c("aidsHivCharlsonCurrentParent1" ,
			      "cerebrovascularDiseaseCharlsonCurrentParent1" ,
			      "chronicPulmonaryDiseaseCharlsonCurrentParent1" ,
			      "dementiaCharlsonCurrentParent1" ,
			      "heartFailureCharlsonCurrentParent1" ,
			      "hemiplegiaParaplegiaCharlsonCurrentParent1" ,
			      "myocardialInfarctionCharlsonCurrentParent1" ,
			      "pepticUlcerDiseaseCharlsonCurrentParent1" ,
			      "peripheralVascularDiseaseCharlsonCurrentParent1" ,
			      "renalDiseaseCharlsonCurrentParent1" ,
			      "rheumaticDiseaseCharlsonCurrentParent1" , 
			      "leukemiaCharlsonCurrentParent1" , 
			      "lymphomaCharlsonCurrentParent1")]

  ##analysisDataset[ , range(charlsonNonexclusiveCurrentParent1)]

  analysisDataset[is.na(metastaticSolidTumorCharlsonCurrentParent1) &
		 !is.na(anyMalignancyCharlsonCurrentParent1) ,
		  charlsonMalignancyCurrentParent1 :=
		      anyMalignancyCharlsonCurrentParent1]

  analysisDataset[!is.na(metastaticSolidTumorCharlsonCurrentParent1) ,
		  charlsonMalignancyCurrentParent1 :=
		      metastaticSolidTumorCharlsonCurrentParent1]

  ##analysisDataset[ , range(charlsonMalignancyCurrentParent1 , na.rm = TRUE)]

  analysisDataset[is.na(severeLiverDiseaseCharlsonCurrentParent1) &
		 !is.na(mildLiverDiseaseCharlsonCurrentParent1) ,
		  charlsonLiverCurrentParent1 :=
		      mildLiverDiseaseCharlsonCurrentParent1]

  analysisDataset[!is.na(severeLiverDiseaseCharlsonCurrentParent1) ,
		  charlsonLiverCurrentParent1 :=
		      severeLiverDiseaseCharlsonCurrentParent1]

  ##analysisDataset[ , range(charlsonLiverCurrentParent1 , na.rm = TRUE)]

  analysisDataset[is.na(diabetesWithComplicationsCharlsonCurrentParent1) &
		 !is.na(diabetesWithoutComplicationsCharlsonCurrentParent1) ,
		  charlsonDiabetesCurrentParent1 :=
		      diabetesWithoutComplicationsCharlsonCurrentParent1]

  analysisDataset[!is.na(diabetesWithComplicationsCharlsonCurrentParent1) ,
		  charlsonDiabetesCurrentParent1 :=
		      diabetesWithComplicationsCharlsonCurrentParent1]

  ##analysisDataset[ , range(charlsonDiabetesCurrentParent1 , na.rm = TRUE)]

  analysisDataset[ , charlsonCurrentParent1 :=
			 rowSums(.SD , na.rm = TRUE) ,
		  .SDcols = c("charlsonNonexclusiveCurrentParent1" ,
			      "charlsonMalignancyCurrentParent1" ,
			      "charlsonLiverCurrentParent1" ,
			      "charlsonDiabetesCurrentParent1")]

  ##analysisDataset[ , range(charlsonCurrentParent1)]

  analysisDataset[ , charlsonNonexclusiveCurrentParent2 := rowSums(.SD , na.rm = TRUE) ,
		  .SDcols = c("aidsHivCharlsonCurrentParent2" ,
			      "cerebrovascularDiseaseCharlsonCurrentParent2" ,
			      "chronicPulmonaryDiseaseCharlsonCurrentParent2" ,
			      "dementiaCharlsonCurrentParent2" ,
			      "heartFailureCharlsonCurrentParent2" ,
			      "hemiplegiaParaplegiaCharlsonCurrentParent2" ,
			      "myocardialInfarctionCharlsonCurrentParent2" ,
			      "pepticUlcerDiseaseCharlsonCurrentParent2" ,
			      "peripheralVascularDiseaseCharlsonCurrentParent2" ,
			      "renalDiseaseCharlsonCurrentParent2" ,
			      "rheumaticDiseaseCharlsonCurrentParent2" , 
			      "leukemiaCharlsonCurrentParent2" , 
			      "lymphomaCharlsonCurrentParent2")]

  ##analysisDataset[ , range(charlsonNonexclusiveCurrentParent2)]

  analysisDataset[is.na(metastaticSolidTumorCharlsonCurrentParent2) &
		 !is.na(anyMalignancyCharlsonCurrentParent2) ,
		  charlsonMalignancyCurrentParent2 :=
		      anyMalignancyCharlsonCurrentParent2]

  analysisDataset[!is.na(metastaticSolidTumorCharlsonCurrentParent2) ,
		  charlsonMalignancyCurrentParent2 :=
		      metastaticSolidTumorCharlsonCurrentParent2]

  ##analysisDataset[ , range(charlsonMalignancyCurrentParent2 , na.rm = TRUE)]

  analysisDataset[is.na(severeLiverDiseaseCharlsonCurrentParent2) &
		 !is.na(mildLiverDiseaseCharlsonCurrentParent2) ,
		  charlsonLiverCurrentParent2 :=
		      mildLiverDiseaseCharlsonCurrentParent2]

  analysisDataset[!is.na(severeLiverDiseaseCharlsonCurrentParent2) ,
		  charlsonLiverCurrentParent2 :=
		      severeLiverDiseaseCharlsonCurrentParent2]

  ##analysisDataset[ , range(charlsonLiverCurrentParent2 , na.rm = TRUE)]

  analysisDataset[is.na(diabetesWithComplicationsCharlsonCurrentParent2) &
		 !is.na(diabetesWithoutComplicationsCharlsonCurrentParent2) ,
		  charlsonDiabetesCurrentParent2 :=
		      diabetesWithoutComplicationsCharlsonCurrentParent2]

  analysisDataset[!is.na(diabetesWithComplicationsCharlsonCurrentParent2) ,
		  charlsonDiabetesCurrentParent2 :=
		      diabetesWithComplicationsCharlsonCurrentParent2]

  ##analysisDataset[ , range(charlsonDiabetesCurrentParent2 , na.rm = TRUE)]

  analysisDataset[ , charlsonCurrentParent2 :=
			 rowSums(.SD , na.rm = TRUE) ,
		  .SDcols = c("charlsonNonexclusiveCurrentParent2" ,
			      "charlsonMalignancyCurrentParent2" ,
			      "charlsonLiverCurrentParent2" ,
			      "charlsonDiabetesCurrentParent2")]

  analysisDataset[ , range(charlsonCurrentParent1 , na.rm = TRUE)]

  analysisDataset[ , jointCharlsonParents := charlsonCurrentParent1 + charlsonCurrentParent2]
  ##analysisDataset[ , range(jointCharlsonParents)]

  ##Further control:
  ## charlsonList <- grep('harlson' , names(analysisDataset) , value = TRUE)
  ## charlsonList <- c("pnr" , "date" , charlsonList)
  ## View(analysisDataset[jointCharlsonParents > 0 , charlsonList , with = FALSE][1:10000])
  ##All charlson scores now add up as they are supposed to. Before, the mutually exclusive categories were added and thus created a score that was too high. This error only affected cutoffs higher than 2. 

  ##Get all the cases:
  analysisDataset[ , case := NULL]
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesCharlson4 <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , "jointCharlsonParents"))
  casesCharlson4 <- casesCharlson4[jointCharlsonParents >= 4]
  casesCharlson4 <- unique(casesCharlson4 , by = "pnr")
  ##Reduce casesCharlson4 to variables listed below:
  temp <- names(casesCharlson4)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesCharlson4[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetCharlson4 <-
      analysisDataset[complete == TRUE ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetCharlson4 <-
      analysisMatchingSetCharlson4[jointCharlsonParents < 4]
  analysisMatchingSetCharlson4[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetCharlson4[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetCharlson4[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetCharlson4[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetCharlson4 , randomOrder , date)


  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesCharlson4 , "casesCharlson4Complete.csv")
  fwrite(analysisMatchingSetCharlson4 , "analysisMatchingSetCharlson4Complete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesCharlson4[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetCharlson4[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSetCharlson4:
  ## analysisMatchingSetCharlson4 <-
  ##     fread("analysisMatchingSetCharlson4Complete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetCharlson4[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetCharlson4[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ## ##If you need to read the cases-set:
  ## casesCharlson4 <-
  ##     fread("casesCharlson4Complete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  ##Splitting cases into m pieces by an index (number of m could be optimized for computer capacity, speed and number of matches):
  m <- 400
  casesCharlson4[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the cases-dataset:
  casesCharlson4MatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesCharlson4[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetCharlson4 ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSetCharlson4[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetCharlson4[temp , on = "pnr" , delete := 1]
      analysisMatchingSetCharlson4 <- analysisMatchingSetCharlson4[is.na(delete)]
      analysisMatchingSetCharlson4[ , delete := NULL]
      casesCharlson4MatchedJoint <- rbindlist(list(casesCharlson4MatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesCharlson4MatchedJoint , "casesCharlson4MatchedJointComplete.csv")

  ##The resulting dataset has been checked manually - there are no controls used twice, almost all cases have controls (see numbers below and each case has 5 controls available matched exactly on number of adults and number of children, and matched within 

  ##Reading in the results from above:
  ## casesCharlson4MatchedJoint <-
  ##     fread("casesCharlson4MatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesCharlson4MatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesCharlson4MatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesCharlson4MatchedJoint[ , .(pnr)]) ,
		     casesCharlson4MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesCharlson4MatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesCharlson4MatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesCharlson4MatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesCharlson4MatchedJoint[ , .(pnr)])
  ##208270 unique pnrs
  temp <- casesCharlson4MatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesCharlson4MatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesCharlson4MatchedJoint[ , table(keepThisRecord)]
  casesCharlson4MatchedJoint <- casesCharlson4MatchedJoint[!is.na(keepThisRecord)]
  ##casesCharlson4MatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesCharlson4MatchedJoint[ , .(pnr)])

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesCharlson4MatchedJoint[ , .(pnr)]) ,
		     casesCharlson4MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesCharlson4MatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesCharlson4MatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesCharlson4MatchedLong <- melt(casesCharlson4MatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesCharlson4MatchedLong , "date" , "studyEntry")
  casesCharlson4MatchedLong[variable == "pnr" , case := 1]
  casesCharlson4MatchedLong[variable == "pnrControl" , case := 0]
  casesCharlson4MatchedLong[ , variable := NULL]
  setnames(casesCharlson4MatchedLong , "value" , "pnr")
  setorder(casesCharlson4MatchedLong , pnr , case , studyEntry)
  casesCharlson4MatchedLong <- unique(casesCharlson4MatchedLong , by = c("pnr" , "case"))

  casesCharlson4MatchedLong[casesCharlson4 , on = "pnr" , originalDate := i.date]
  casesCharlson4MatchedLong[case == 1 , studyEntry := originalDate]
  casesCharlson4MatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesCharlson4MatchedLong , "studyEntry" , "date")
  analysisDataset[casesCharlson4MatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesCharlson4MatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]
  ##A survival-version:
  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <-
      as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <-
      cbind(pseudoAnalysisSubjects3 ,
	    pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2 ,
				   pseudoAnalysis3))



  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Have decided to use numbers from analysisDataset to avoid inflating the available follow-up time:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationCharlson4 <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationCharlson4)
  resultsPseudoFitFullPopulationCharlson4 <- formatResultsGeese(pseudoFitFullPopulationCharlson4)
  fwrite(resultsPseudoFitFullPopulationCharlson4 , "resultsPseudoFitFullPopulationCharlson4.csv")


  ##Charlson score above 8:
  analysisDataset[ , case := NULL]
  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesCharlson8 <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , "jointCharlsonParents"))
  casesCharlson8 <- casesCharlson8[jointCharlsonParents >= 8]
  casesCharlson8 <- unique(casesCharlson8 , by = "pnr")
  ##Reduce casesCharlson8 to variables listed below:
  temp <- names(casesCharlson8)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesCharlson8[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetCharlson8 <-
      analysisDataset[complete == TRUE ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetCharlson8 <-
      analysisMatchingSetCharlson8[jointCharlsonParents < 8]

  ##Cleaning data before merge
  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetCharlson8[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetCharlson8[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetCharlson8[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetCharlson8[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetCharlson8 , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesCharlson8 , "casesCharlson8Complete.csv")
  fwrite(analysisMatchingSetCharlson8 , "analysisMatchingSetCharlson8Complete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesCharlson8[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetCharlson8[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSetCharlson4:
  ## analysisMatchingSetCharlson4 <-
  ##     fread("analysisMatchingSetCharlson4Complete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetCharlson4[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetCharlson4[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ## ##If you need to read the cases-set:
  ## casesCharlson4 <-
  ##     fread("casesCharlson4Complete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesCharlson8[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the cases-dataset:
  casesCharlson8MatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesCharlson8[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetCharlson8 ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSetCharlson4[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetCharlson8[temp , on = "pnr" , delete := 1]
      analysisMatchingSetCharlson8 <- analysisMatchingSetCharlson8[is.na(delete)]
      analysisMatchingSetCharlson8[ , delete := NULL]
      casesCharlson8MatchedJoint <- rbindlist(list(casesCharlson8MatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesCharlson8MatchedJoint , "casesCharlson8MatchedJointComplete.csv")

  ##The resulting dataset has been checked manually - there are no controls used twice, almost all cases have controls (see numbers below and each case has 5 controls available matched exactly on number of adults and number of children, and matched within 

  ##Reading in the results from above:
  ## casesCharlson4MatchedJoint <-
  ##     fread("casesCharlson4MatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesCharlson4MatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesCharlson4MatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesCharlson8MatchedJoint[ , .(pnr)]) ,
		     casesCharlson8MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesCharlson8MatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesCharlson8MatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesCharlson8MatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesCharlson8MatchedJoint[ , .(pnr)])
  ##208270 unique pnrs
  temp <- casesCharlson8MatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesCharlson8MatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesCharlson8MatchedJoint[ , table(keepThisRecord)]
  casesCharlson8MatchedJoint <- casesCharlson8MatchedJoint[!is.na(keepThisRecord)]
  ##casesCharlson8MatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesCharlson8MatchedJoint[ , .(pnr)])
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesCharlson8MatchedJoint[ , .(pnr)]) ,
		     casesCharlson8MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesCharlson8MatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesCharlson8MatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesCharlson8MatchedLong <- melt(casesCharlson8MatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesCharlson8MatchedLong , "date" , "studyEntry")
  casesCharlson8MatchedLong[variable == "pnr" , case := 1]
  casesCharlson8MatchedLong[variable == "pnrControl" , case := 0]
  casesCharlson8MatchedLong[ , variable := NULL]
  setnames(casesCharlson8MatchedLong , "value" , "pnr")
  setorder(casesCharlson8MatchedLong , pnr , case , studyEntry)
  casesCharlson8MatchedLong <- unique(casesCharlson8MatchedLong , by = c("pnr" , "case"))

  casesCharlson8MatchedLong[casesCharlson8 , on = "pnr" , originalDate := i.date]
  casesCharlson8MatchedLong[case == 1 , studyEntry := originalDate]
  casesCharlson8MatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesCharlson8MatchedLong , "studyEntry" , "date")
  analysisDataset[casesCharlson8MatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesCharlson8MatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  ##A survival-version:
  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <-
      as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <-
      cbind(pseudoAnalysisSubjects3 ,
	    pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2 ,
				   pseudoAnalysis3))


  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationCharlson8 <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationCharlson8)
  resultsPseudoFitFullPopulationCharlson8 <- formatResultsGeese(pseudoFitFullPopulationCharlson8)
  fwrite(resultsPseudoFitFullPopulationCharlson8 , "resultsPseudoFitFullPopulationCharlson8.csv")


  ##Look at only 2001 and forth - remove earlier years from analysisDataset

  analysisDataset[ , case := NULL]
  ##Do matching for Charlson
  ##Get all the cases:
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesAfter2001 <- unique(analysisDataset[complete == TRUE & date >= as.Date("2001-01-01")] , by = c("pnr" , "jointCharlsonParents"))
  casesAfter2001 <- casesAfter2001[jointCharlsonParents >= 2]
  casesAfter2001 <- unique(casesAfter2001 , by = "pnr")
  ##Reduce casesAfter2001 to variables listed below:
  temp <- names(casesAfter2001)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesAfter2001[ , (temp) := NULL]
  rm(temp)

  ##Match these casesAfter2001 with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetAfter2001 <-
      analysisDataset[complete == TRUE &
		      date >= as.Date("2001-01-01") ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetAfter2001 <-
      analysisMatchingSetAfter2001[jointCharlsonParents < 2 & date >= as.Date("2001-01-01")]

  ##Cleaning data before merge
  ##casesAfter2001[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetAfter2001[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetAfter2001[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetAfter2001[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetAfter2001[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 
  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetAfter2001 , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesAfter2001 , "casesAfter2001Complete.csv")
  fwrite(analysisMatchingSetAfter2001 , "analysisMatchingSetAfter2001Complete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesAfter2001[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetAfter2001[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSetAfter2001:
  ## analysisMatchingSetAfter2001 <-
  ##     fread("analysisMatchingSetAfter2001Complete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetAfter2001[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetAfter2001[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ## If you need to read the casesAfter2001-set:
  casesAfter2001 <-
      fread("casesAfter2001Complete.csv" ,
	    colClasses = c("pnr" = "character" ,
			   "date" = "Date" ,
			   "childAge" = "numeric" ,
			   "newNoOfChildren" = "numeric" , 
			   "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesAfter2001[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesAfter2001-dataset:
  casesAfter2001MatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesAfter2001Split <- casesAfter2001[randomSplit == i]
      ##For later ordering:
      casesAfter2001Split[ , pnrRandomNumber := sample(1:.N , .N)]
      casesAfter2001Split <- casesAfter2001Split[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesAfter2001Split)]
      print(paste0("Just after expansion of " , i , "part of casesAfter2001."))
      print(Sys.time())
      casesAfter2001Split[ , nrow := NULL]
      casesAfter2001Split[ , date := NULL]
      setnames(casesAfter2001Split , "matchDate" , "date")

      casesAfter2001Split <- merge(casesAfter2001Split  ,
		 analysisMatchingSetAfter2001 ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## casesAfter2001[analysisMatchingSetAfter2001[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesAfter2001Split[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesAfter2001Split <- casesAfter2001Split[parentalAgeDiff <= 5]
      ##casesAfter2001Split[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesAfter2001Split[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesAfter2001Split <- casesAfter2001Split[childAgeDiff <= 1]
      ## casesAfter2001[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesAfter2001Split <- casesAfter2001Split[!is.na(pnr) & pnr != pnrControl]
      casesAfter2001Split <- casesAfter2001Split[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesAfter2001Split[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesAfter2001Split , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesAfter2001Split <- casesAfter2001Split[indexTempRandom <= 250]
      casesAfter2001Split[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesAfter2001Split <- unique(casesAfter2001Split , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesAfter2001Split[ , index := 1:.N , by = "pnr"]
      casesAfter2001Split <- casesAfter2001Split[index <= 5]
      ##Visually controlled - for first iteration, all casesAfter2001 are shown to have 10 matches. 
      casesAfter2001Split[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesAfter2001Split[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetAfter2001[temp , on = "pnr" , delete := 1]
      analysisMatchingSetAfter2001 <- analysisMatchingSetAfter2001[is.na(delete)]
      analysisMatchingSetAfter2001[ , delete := NULL]
      casesAfter2001MatchedJoint <- rbindlist(list(casesAfter2001MatchedJoint , casesAfter2001Split))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesAfter2001MatchedJoint , "casesAfter2001MatchedJointComplete.csv")

  ## ##Reading in the results from above:
  ## casesAfter2001MatchedJoint <-
  ##     fread("casesAfter2001MatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesAfter2001MatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesAfter2001MatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]

  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesAfter2001MatchedJoint[ , .(pnr)]) ,
		     casesAfter2001MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesAfter2001MatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesAfter2001MatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesAfter2001Matches := 1:.N]
  casesAfter2001MatchedJoint[temp , on = "pnr" , indexCasesAfter2001Matches := i.indexCasesAfter2001Matches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesAfter2001MatchedJoint[ , .(pnr)])
  ##208270 unique pnrs
  temp <- casesAfter2001MatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesAfter2001MatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesAfter2001MatchedJoint[ , table(keepThisRecord)]
  casesAfter2001MatchedJoint <- casesAfter2001MatchedJoint[!is.na(keepThisRecord)]
  ##casesAfter2001MatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesAfter2001MatchedJoint[ , .(pnr)])
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesAfter2001MatchedJoint[ , .(pnr)]) ,
		     casesAfter2001MatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesAfter2001MatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesAfter2001Matches")]
  casesAfter2001MatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesAfter2001MatchedLong <- melt(casesAfter2001MatchedJoint , id.vars = c("date" , "indexCasesAfter2001Matches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesAfter2001MatchedLong , "date" , "studyEntry")
  casesAfter2001MatchedLong[variable == "pnr" , case := 1]
  casesAfter2001MatchedLong[variable == "pnrControl" , case := 0]
  casesAfter2001MatchedLong[ , variable := NULL]
  setnames(casesAfter2001MatchedLong , "value" , "pnr")
  setorder(casesAfter2001MatchedLong , pnr , case , studyEntry)
  casesAfter2001MatchedLong <- unique(casesAfter2001MatchedLong , by = c("pnr" , "case"))

  casesAfter2001MatchedLong[casesAfter2001 , on = "pnr" , originalDate := i.date]
  casesAfter2001MatchedLong[case == 1 , studyEntry := originalDate]
  casesAfter2001MatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesAfter2001MatchedLong , "studyEntry" , "date")
  analysisDataset[casesAfter2001MatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesAfter2001MatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]

  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  ##A survival-version:


  ##As this dataset starts in 2001, and as the association between calendarTimeGroup and censoring was strongest in the last group by far, I add the two first groups to each other to avoid very small cells. 
  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009" |
						    calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)

  pseudoAnalysisPseudoValues1 <-
      as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <-
      as.data.table(pseudoAnalysisPseudoValues2)

  pseudoAnalysis1 <-
      cbind(pseudoAnalysisSubjects1 ,
	    pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <-
      cbind(pseudoAnalysisSubjects2 ,
	    pseudoAnalysisPseudoValues2)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 ,
				   pseudoAnalysis2))


  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Have decided to use numbers from analysisDataset to avoid inflating the available follow-up time:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of casesAfter2001 in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal casesAfter2001 in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationAfter2001 <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationAfter2001)
  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }
  resultsPseudoFitFullPopulationAfter2001 <- formatResultsGeese(pseudoFitFullPopulationAfter2001)
  fwrite(resultsPseudoFitFullPopulationAfter2001 , "resultsPseudoFitFullPopulationAfter2001.csv")


  ##Exclude immigrants:

  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  analysisDataset[ , case := NULL]
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesNoImmigrants <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , "jointCharlsonParents"))
  casesNoImmigrants <- casesNoImmigrants[jointCharlsonParents >= 2 &
		 oneForeignParent == "No foreign parents" &
		 familyNeedProtection == "Not in need of protection"]
  casesNoImmigrants <- unique(casesNoImmigrants , by = "pnr")
  ##Reduce casesNoImmigrants to variables listed below:
  temp <- names(casesNoImmigrants)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesNoImmigrants[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetNoImmigrants <-
      analysisDataset[complete == TRUE ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents ,
			oneForeignParent ,
			familyNeedProtection)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetNoImmigrants <-
      analysisMatchingSetNoImmigrants[jointCharlsonParents < 2 &
			  oneForeignParent == "No foreign parents" &
			  familyNeedProtection == "Not in need of protection"]
  analysisMatchingSetNoImmigrants[ , c("oneForeignParent" , "familyNeedProtection") := NULL]

  analysisMatchingSetNoImmigrants[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetNoImmigrants[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetNoImmigrants[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetNoImmigrants[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetNoImmigrants , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesNoImmigrants , "casesNoImmigrantsComplete.csv")
  fwrite(analysisMatchingSetNoImmigrants , "analysisMatchingSetNoImmigrantsComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesNoImmigrants[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetNoImmigrants[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSet:
  ## analysisMatchingSetNoImmigrants <-
  ##     fread("analysisMatchingSetNoImmigrantsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetNoImmigrants[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetNoImmigrants[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ##If you need to read the casesNoImmigrants-set:
  ## casesNoImmigrants <-
  ##     fread("casesNoImmigrantsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesNoImmigrants[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesNoImmigrants-dataset:
  casesNoImmigrantsMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesNoImmigrants[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetNoImmigrants ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSet[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetNoImmigrants[temp , on = "pnr" , delete := 1]
      analysisMatchingSetNoImmigrants <- analysisMatchingSetNoImmigrants[is.na(delete)]
      analysisMatchingSetNoImmigrants[ , delete := NULL]
      casesNoImmigrantsMatchedJoint <- rbindlist(list(casesNoImmigrantsMatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesNoImmigrantsMatchedJoint , "casesNoImmigrantsMatchedJointComplete.csv")

  ##Reading in the results from above:
  ## casesMatchedJoint <-
  ##     fread("casesMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesNoImmigrantsMatchedJoint[ , .(pnr)]) ,
		     casesNoImmigrantsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesNoImmigrantsMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesNoImmigrantsMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesNoImmigrantsMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesNoImmigrantsMatchedJoint[ , .(pnr)])
  temp <- casesNoImmigrantsMatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesNoImmigrantsMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesNoImmigrantsMatchedJoint[ , table(keepThisRecord)]
  casesNoImmigrantsMatchedJoint <- casesNoImmigrantsMatchedJoint[!is.na(keepThisRecord)]
  ##casesNoImmigrantsMatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesNoImmigrantsMatchedJoint[ , .(pnr)])
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesNoImmigrantsMatchedJoint[ , .(pnr)]) ,
		     casesNoImmigrantsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesNoImmigrantsMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesNoImmigrantsMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesNoImmigrantsMatchedLong <- melt(casesNoImmigrantsMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesNoImmigrantsMatchedLong , "date" , "studyEntry")
  casesNoImmigrantsMatchedLong[variable == "pnr" , case := 1]
  casesNoImmigrantsMatchedLong[variable == "pnrControl" , case := 0]
  casesNoImmigrantsMatchedLong[ , variable := NULL]
  setnames(casesNoImmigrantsMatchedLong , "value" , "pnr")
  setorder(casesNoImmigrantsMatchedLong , pnr , case , studyEntry)
  casesNoImmigrantsMatchedLong <- unique(casesNoImmigrantsMatchedLong , by = c("pnr" , "case"))

  casesNoImmigrantsMatchedLong[casesNoImmigrants , on = "pnr" , originalDate := i.date]
  casesNoImmigrantsMatchedLong[case == 1 , studyEntry := originalDate]
  casesNoImmigrantsMatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesNoImmigrantsMatchedLong , "studyEntry" , "date")
  analysisDataset[casesNoImmigrantsMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesNoImmigrantsMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  ##A survival-version:

  ##A downstream sensitivity analysis has shown that censoring is dependent on time periods - splitting on those and making pseudovalues:

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))


  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationNoImmigrants <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoImmigrants)
  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }
  resultsPseudoFitFullPopulationNoImmigrants <- formatResultsGeese(pseudoFitFullPopulationNoImmigrants)
  fwrite(resultsPseudoFitFullPopulationNoImmigrants , "resultsPseudoFitFullPopulationNoImmigrants.csv")



  ##Exclude families emigrating:

  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  analysisDataset[ , case := NULL]
  emigrantsList <- unique(analysisDataset[!is.na(emigrationCensoring) , .(pnr)])
  analysisDataset[emigrantsList , on = "pnr" , emigrant := 1]
  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesNoEmigrants <- unique(analysisDataset[complete == TRUE & is.na(emigrant)] , by = c("pnr" , "jointCharlsonParents"))
  casesNoEmigrants <- casesNoEmigrants[jointCharlsonParents >= 2]
  casesNoEmigrants <- unique(casesNoEmigrants , by = "pnr")
  ##Reduce casesNoEmigrants to variables listed below:
  temp <- names(casesNoEmigrants)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesNoEmigrants[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetNoEmigrants <-
      analysisDataset[complete == TRUE &
		     is.na(emigrant) ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetNoEmigrants <-
      analysisMatchingSetNoEmigrants[jointCharlsonParents < 2]

  ##Cleaning data before merge
  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetNoEmigrants[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetNoEmigrants[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetNoEmigrants[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetNoEmigrants[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 
  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetNoEmigrants , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesNoEmigrants , "casesNoEmigrantsComplete.csv")
  fwrite(analysisMatchingSetNoEmigrants , "analysisMatchingSetNoEmigrantsComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesNoEmigrants[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetNoEmigrants[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSet:
  ## analysisMatchingSetNoEmigrants <-
  ##     fread("analysisMatchingSetNoEmigrantsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetNoEmigrants[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetNoEmigrants[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ##If you need to read the casesNoEmigrants-set:
  ## casesNoEmigrants <-
  ##     fread("casesNoEmigrantsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesNoEmigrants[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesNoEmigrants-dataset:
  casesNoEmigrantsMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesNoEmigrants[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetNoEmigrants ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSet[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetNoEmigrants[temp , on = "pnr" , delete := 1]
      analysisMatchingSetNoEmigrants <- analysisMatchingSetNoEmigrants[is.na(delete)]
      analysisMatchingSetNoEmigrants[ , delete := NULL]
      casesNoEmigrantsMatchedJoint <- rbindlist(list(casesNoEmigrantsMatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesNoEmigrantsMatchedJoint , "casesNoEmigrantsMatchedJointComplete.csv")

  ##Reading in the results from above:
  ## casesMatchedJoint <-
  ##     fread("casesMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesNoEmigrantsMatchedJoint[ , .(pnr)]) ,
		     casesNoEmigrantsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesNoEmigrantsMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesNoEmigrantsMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesNoEmigrantsMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesNoEmigrantsMatchedJoint[ , .(pnr)])
  temp <- casesNoEmigrantsMatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesNoEmigrantsMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesNoEmigrantsMatchedJoint[ , table(keepThisRecord)]
  casesNoEmigrantsMatchedJoint <- casesNoEmigrantsMatchedJoint[!is.na(keepThisRecord)]
  ##casesNoEmigrantsMatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesNoEmigrantsMatchedJoint[ , .(pnr)])
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesNoEmigrantsMatchedJoint[ , .(pnr)]) ,
		     casesNoEmigrantsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesNoEmigrantsMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesNoEmigrantsMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesNoEmigrantsMatchedLong <- melt(casesNoEmigrantsMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesNoEmigrantsMatchedLong , "date" , "studyEntry")
  casesNoEmigrantsMatchedLong[variable == "pnr" , case := 1]
  casesNoEmigrantsMatchedLong[variable == "pnrControl" , case := 0]
  casesNoEmigrantsMatchedLong[ , variable := NULL]
  setnames(casesNoEmigrantsMatchedLong , "value" , "pnr")
  setorder(casesNoEmigrantsMatchedLong , pnr , case , studyEntry)
  casesNoEmigrantsMatchedLong <- unique(casesNoEmigrantsMatchedLong , by = c("pnr" , "case"))

  casesNoEmigrantsMatchedLong[casesNoEmigrants , on = "pnr" , originalDate := i.date]
  casesNoEmigrantsMatchedLong[case == 1 , studyEntry := originalDate]
  casesNoEmigrantsMatchedLong[ , originalDate := NULL]

  ##Testing how many entries are without full control:
  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesNoEmigrantsMatchedLong , "studyEntry" , "date")
  analysisDataset[casesNoEmigrantsMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesNoEmigrantsMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationNoEmigrants <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationNoEmigrants)
  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }
  resultsPseudoFitFullPopulationNoEmigrants <- formatResultsGeese(pseudoFitFullPopulationNoEmigrants)
  fwrite(resultsPseudoFitFullPopulationNoEmigrants , "resultsPseudoFitFullPopulationNoEmigrants.csv")

  ##Requested by supervisors: splitting on non-single and single parents
  ##Non-single parents:
  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  analysisDataset[ , case := NULL]
  ##Making a variable to split on single and not-single parents:
  ##Splitting on single and couple parents:

  ## ##Using the pnrs in the dataset:
  ## pseudoAnalysis[currentParent1 == "" | currentParent2 == "" , singleParentRegister := 1]
  ## pseudoAnalysis[is.na(singleParent) , singleParent := 0]
  ##Turns out this makes very, very few single parents. Only 196 single parents with complete data got the exposure. Any model based on this is expected to break. Trying with the FMMARK variable from the BEF register instead:

  bef <- fread("bef_pop_230921.csv" ,             
	       select = c("pnr" , "YEAR" , "FM_MARK") ,
	       colClasses = c("pnr" = "character"))
  bef <- bef[!is.na(pnr)]
  bef <- bef[pnr != ""]

  ##Creating a special YEAR variable in analysisDataset - this variable is shifted half a year. This is because FMMARK is only updated yearly - the best estimate of change, and the time assumed to be the time of parental change derived from BEF, is in the middle of the year when the actual change has taken place. This variable is not perfect - for parental changes with good date info (all changes derived from ftbarn) this info would more accurately be bound to this date. However, as the changes in the registry is not necessarily bound to the physical reality of the child's living arrangements on a date-to-date basis, and as this is only a sensitivity analysis, I'll stick with this solution. 

  analysisDataset[ , YEAR := year((date + months(6)))]
  ##This is (also) slow, mainly because of substr, and produces wrong years, commenting out:
  ##analysisDatase[ , YEAR := mondate(date + 6)]
  ##analysisDataset[ , YEAR := substr(as.character(YEAR) , 1 , 4)]
  analysisDataset[bef , on = c("pnr" , "YEAR") , FM_MARK := i.FM_MARK]
  analysisDataset[FM_MARK == 3 | FM_MARK == 5 , singleParentFM_MARK := 1]
  analysisDataset[is.na(singleParentFM_MARK) & !is.na(FM_MARK) , singleParentFM_MARK := 0]


  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesDoubleParents <- unique(analysisDataset[complete == TRUE & singleParentFM_MARK == 0] , by = c("pnr" , "jointCharlsonParents"))
  casesDoubleParents <- casesDoubleParents[jointCharlsonParents >= 2]
  casesDoubleParents <- unique(casesDoubleParents , by = "pnr")
  ##Reduce casesDoubleParents to variables listed below:
  temp <- names(casesDoubleParents)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesDoubleParents[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetDoubleParents <-
      analysisDataset[complete == TRUE &
		     singleParentFM_MARK == 0 ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetDoubleParents <-
      analysisMatchingSetDoubleParents[jointCharlsonParents < 2]

  ##Cleaning data before merge
  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetDoubleParents[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetDoubleParents[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetDoubleParents[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetDoubleParents[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetDoubleParents , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesDoubleParents , "casesDoubleParentsComplete.csv")
  fwrite(analysisMatchingSetDoubleParents , "analysisMatchingSetDoubleParentsComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesDoubleParents[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetDoubleParents[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSet:
  ## analysisMatchingSetDoubleParents <-
  ##     fread("analysisMatchingSetDoubleParentsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetDoubleParents[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetDoubleParents[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ##If you need to read the casesDoubleParents-set:
  ## casesDoubleParents <-
  ##     fread("casesDoubleParentsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesDoubleParents[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesDoubleParents-dataset:
  casesDoubleParentsMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesDoubleParents[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")

      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetDoubleParents ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSet[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetDoubleParents[temp , on = "pnr" , delete := 1]
      analysisMatchingSetDoubleParents <- analysisMatchingSetDoubleParents[is.na(delete)]
      analysisMatchingSetDoubleParents[ , delete := NULL]
      casesDoubleParentsMatchedJoint <- rbindlist(list(casesDoubleParentsMatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesDoubleParentsMatchedJoint , "casesDoubleParentsMatchedJointComplete.csv")

  ##Reading in the results from above:
  ## casesMatchedJoint <-
  ##     fread("casesMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesDoubleParentsMatchedJoint[ , .(pnr)]) ,
		     casesDoubleParentsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)



  casesDoubleParentsMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesDoubleParentsMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesDoubleParentsMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 


  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesDoubleParentsMatchedJoint[ , .(pnr)])
  ##208270 unique pnrs
  temp <- casesDoubleParentsMatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesDoubleParentsMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesDoubleParentsMatchedJoint[ , table(keepThisRecord)]
  casesDoubleParentsMatchedJoint <- casesDoubleParentsMatchedJoint[!is.na(keepThisRecord)]
  ##casesDoubleParentsMatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesDoubleParentsMatchedJoint[ , .(pnr)])
  ###208137 unique pnrs after this, meaning 141 lost pnrs - this seems acceptable
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesDoubleParentsMatchedJoint[ , .(pnr)]) ,
		     casesDoubleParentsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesDoubleParentsMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesDoubleParentsMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesDoubleParentsMatchedLong <- melt(casesDoubleParentsMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesDoubleParentsMatchedLong , "date" , "studyEntry")
  casesDoubleParentsMatchedLong[variable == "pnr" , case := 1]
  casesDoubleParentsMatchedLong[variable == "pnrControl" , case := 0]
  casesDoubleParentsMatchedLong[ , variable := NULL]
  setnames(casesDoubleParentsMatchedLong , "value" , "pnr")
  setorder(casesDoubleParentsMatchedLong , pnr , case , studyEntry)
  casesDoubleParentsMatchedLong <- unique(casesDoubleParentsMatchedLong , by = c("pnr" , "case"))

  casesDoubleParentsMatchedLong[casesDoubleParents , on = "pnr" , originalDate := i.date]
  casesDoubleParentsMatchedLong[case == 1 , studyEntry := originalDate]
  casesDoubleParentsMatchedLong[ , originalDate := NULL]

  ##The block above showed that all groups had 6 members - one case and 5 controls. After removing "doubles", that is only allowing any member of the population to count as case and control once, all groups are still complete. 

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesDoubleParentsMatchedLong , "studyEntry" , "date")
  analysisDataset[casesDoubleParentsMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesDoubleParentsMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]
  ## ##Classification inspected manually, performs as intended.
  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]
  ##A survival-version:

  ##A downstream sensitivity analysis has shown that censoring is dependent on time periods - splitting on those and making pseudovalues:

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Extracting some numbers for the article:
  ##Have decided to use numbers from analysisDataset to avoid inflating the available follow-up time:
  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationDoubleParents <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationDoubleParents)
  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }
  resultsPseudoFitFullPopulationDoubleParents <- formatResultsGeese(pseudoFitFullPopulationDoubleParents)
  fwrite(resultsPseudoFitFullPopulationDoubleParents , "resultsPseudoFitFullPopulationDoubleParents.csv")

  ##Single parents:

  ##library(broom)
  ##library(pseudo)
  ##Do matching for Charlson
  ##Get all the cases:
  analysisDataset[ , case := NULL]
  ##Making a variable to split on single and not-single parents:

  setorder(analysisDataset , pnr , date , jointCharlsonParents)
  casesSingleParents <- unique(analysisDataset[complete == TRUE & singleParentFM_MARK == 1] , by = c("pnr" , "jointCharlsonParents"))
  casesSingleParents <- casesSingleParents[jointCharlsonParents >= 2]
  casesSingleParents <- unique(casesSingleParents , by = "pnr")
  ##Reduce casesSingleParents to variables listed below:
  temp <- names(casesSingleParents)
  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
  casesSingleParents[ , (temp) := NULL]
  rm(temp)

  ##Match these cases with eligible individuals:
  ##Creating a reduced dataset for this:
  analysisMatchingSetSingleParents <-
      analysisDataset[complete == TRUE &
		     singleParentFM_MARK == 1 ,
		      .(pnr ,
			date ,
			childAge ,
			reconstitutedFamily ,
			newNoOfChildren ,
			meanParentalAge ,
			jointCharlsonParents)]
  ##Controls cannot have the exposure at the time of matching: 
  analysisMatchingSetSingleParents <-
      analysisMatchingSetSingleParents[jointCharlsonParents < 2]

  ##Cleaning data before merge
  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
  analysisMatchingSetSingleParents[ , jointCharlsonParents := NULL]

  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
  set.seed(25328621)
  analysisMatchingSetSingleParents[ , randomOrder := sample(1:.N , .N)]
  temp <- unique(analysisMatchingSetSingleParents[ , .(pnr , randomOrder)] , by = "pnr")
  analysisMatchingSetSingleParents[temp , on = "pnr" , randomOrder := i.randomOrder]
  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 

  ##Using the randomOrder from above to set a new order
  setorder(analysisMatchingSetSingleParents , randomOrder , date)

  ## ##To avoid having to re-load the big dataset too much:
  fwrite(casesSingleParents , "casesSingleParentsComplete.csv")
  fwrite(analysisMatchingSetSingleParents , "analysisMatchingSetSingleParentsComplete.csv")

  ##I forgot to factorize newNoOfChildren above - making up for this here:

  casesSingleParents[ , numberOfChildrenFactor :=
	       cut(newNoOfChildren ,
		   breaks = c(0 , 1 , 2 , 5 , 20) ,
		   labels = c("One child" ,
			      "Two children" ,
			      "Three to five children" ,
			      "Six children or more"))]

  analysisMatchingSetSingleParents[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

  ## ##If you need to read the analysisMatchingSet:
  ## analysisMatchingSetSingleParents <-
  ##     fread("analysisMatchingSetSingleParentsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "numberOfAdultsFactor" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "randomOrder" = "numeric"))

  ## analysisMatchingSetSingleParents[ , numberOfAdultsFactor :=
  ## 		       factor(numberOfAdultsFactor ,
  ## 			      levels = c("One adult" ,
  ## 					 "Two adults" ,
  ## 					 "Three or more adults"))]

  ## analysisMatchingSetSingleParents[ , numberOfChildrenFactor :=
  ## 		       factor(numberOfChildrenFactor ,
  ## 			      levels = c("One child" ,
  ## 					 "Two children" ,
  ## 					 "Three to five children" ,
  ## 					 "Six children or more"))]

  ##If you need to read the casesSingleParents-set:
  ## casesSingleParents <-
  ##     fread("casesSingleParentsComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "childAge" = "numeric" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "meanParentalAge" = "numeric"))



  ##To make sure there is enough space for the subsequent process:
  ##rm(analysisDataset)
  set.seed(25328621)
  gc(full = TRUE)
  print("Just before loop")

  m <- 400
  casesSingleParents[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
  ##New loop based on merge with chunks of the casesSingleParents-dataset:
  casesSingleParentsMatchedJoint <- data.table(NULL)
  set.seed(25328621)
  for (i in 1:m) { #should be 1:m - just putting in a number for test purposes
      casesSplit <- casesSingleParents[randomSplit == i]
      ##For later ordering:
      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
      casesSplit <- casesSplit[ , list(pnr =  pnr ,
			     date = date ,
			     childAge = childAge ,
			     reconstitutedFamily  = reconstitutedFamily,
			     numberOfChildrenFactor = numberOfChildrenFactor ,
			     meanParentalAge = meanParentalAge ,
			     pnrRandomNumber = pnrRandomNumber ,
			     matchDate = seq(from = date ,
					     length = 3 ,
					     by = "month")) , 
			     by = 1:nrow(casesSplit)]
      print(paste0("Just after expansion of " , i , "part of cases."))
      print(Sys.time())
      casesSplit[ , nrow := NULL]
      casesSplit[ , date := NULL]
      setnames(casesSplit , "matchDate" , "date")
      casesSplit <- merge(casesSplit  ,
		 analysisMatchingSetSingleParents ,
		 by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
		 all.x = TRUE ,
		 allow.cartesian = TRUE , suffixes = c("" , "Control"))
      print(paste0("Finished merge from split " , i , " out of " , m))
      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
      ## cases[analysisMatchingSet[ , .(pnr , date ,
      ## 			   ##adultsInFamily , childrenInFamily ,
      ## 			   parentAgeRounded, 
      ##                            childAgeYear , pnrMatch)] ,
      ##       on = .(date == date  ,
      ##              childAgeYear == childAgeYear ,
      ##              parentAgeLowerYear <= parentAgeRounded ,
      ##              parentAgeUpperYear >= parentAgeRounded) ,
      ##       pnrMatch := i.pnrMatch ,
      ##       allow.cartesian = TRUE]
      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
      casesSplit <- casesSplit[parentalAgeDiff <= 5]
      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
      ## ##Removing matches with childAge more than one year apart (matching on child age):
      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
      casesSplit <- casesSplit[childAgeDiff <= 1]
      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
      ##Avoiding children matching on themselves and matches on NA:
      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
      casesSplit <- casesSplit[!is.na(pnrControl)]
      ##Order the matches randomly:
      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
      ##Reduce to 250 matches:
      casesSplit <- casesSplit[indexTempRandom <= 250]
      casesSplit[ , indexTempRandom := NULL]
      ##De-duplicate matches:
      casesSplit <- unique(casesSplit , by = "pnrControl")
      ##Reduce to 5 matches for each pnr:
      casesSplit[ , index := 1:.N , by = "pnr"]
      casesSplit <- casesSplit[index <= 5]
      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
      casesSplit[ , index := NULL]
      ##Delete the matches used from the "match-pool":
      temp <- casesSplit[ , .(pnrControl)]
      temp <- unique(temp)
      setnames(temp , "pnrControl" , "pnr")
      analysisMatchingSetSingleParents[temp , on = "pnr" , delete := 1]
      analysisMatchingSetSingleParents <- analysisMatchingSetSingleParents[is.na(delete)]
      analysisMatchingSetSingleParents[ , delete := NULL]
      casesSingleParentsMatchedJoint <- rbindlist(list(casesSingleParentsMatchedJoint , casesSplit))
      print(paste0("Finished results from cycle " , i))
  }

  fwrite(casesSingleParentsMatchedJoint , "casesSingleParentsMatchedJointComplete.csv")

  ##Reading in the results from above:
  ## casesMatchedJoint <-
  ##     fread("casesMatchedJointComplete.csv" ,
  ## 	  colClasses = c("pnr" = "character" ,
  ## 			 "pnrControl" = "character" ,
  ## 			 "date" = "Date" ,
  ## 			 "reconstitutedFamily" = "factor" ,
  ## 			 "numberOfChildrenFactor" = "factor" ,
  ## 			 "newNoOfChildren" = "numeric" , 
  ## 			 "childAge" = "numeric" ,
  ## 			 "meanParentalAge" = "numeric" ,
  ## 			 "pnrRandomNumber" = "numeric" ,
  ## 			 "childAgeControl" = "numeric" ,
  ## 			 "meanParentalAgeControl" = "numeric" ,
  ## 			 "randomOrder" = "numeric" ,
  ## 			 "parentalAgeDiff" = "numeric" ,
  ## 			 "childAgeDiff" = "numeric"))

  ## casesMatchedJoint[ , reconstitutedFamily :=
  ## 			 factor(reconstitutedFamily ,
  ## 				levels = c("Living with biological parent(s)" ,
  ## 					   "Living with one or more unrelated adults" ,
  ## 					   "Adopted or in foster care"))]
  ## casesMatchedJoint[ , numberOfChildrenFactor :=
  ## 			 factor(numberOfChildrenFactor ,
  ## 				levels = c("One child" ,
  ## 					   "Two children" ,
  ## 					   "Three to five children" ,
  ## 					   "Six children or more"))]





  ##Extracting numbers for the article:

  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesSingleParentsMatchedJoint[ , .(pnr)]) ,
		     casesSingleParentsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)

  casesSingleParentsMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

  ##Numbering all unique case-pnrs:

  temp <- casesSingleParentsMatchedJoint[ , .(pnr)]
  temp <- unique(temp)
  temp[ , indexCasesMatches := 1:.N]
  casesSingleParentsMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 

  ##Deleting the few records with less than 5 matches:
  ##Counting pnrs before:
  temp <- unique(casesSingleParentsMatchedJoint[ , .(pnr)])
  temp <- casesSingleParentsMatchedJoint[matchesNumber == 5 , .(pnr)]
  temp <- unique(temp)
  casesSingleParentsMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
  ##casesSingleParentsMatchedJoint[ , table(keepThisRecord)]
  casesSingleParentsMatchedJoint <- casesSingleParentsMatchedJoint[!is.na(keepThisRecord)]
  ##casesSingleParentsMatchedJoint[ , table(index)]
  ##The above command now shows that everyone has exactly 5 matches.
  ##Counting pnrs after this:
  temp <- unique(casesSingleParentsMatchedJoint[ , .(pnr)])
  ##Preparing the selection of relevant persons in the dataset:

  ##Counting for the article:
  ##Children in the analysis:
  childrenAnalysis <-
      rbindlist(list(unique(casesSingleParentsMatchedJoint[ , .(pnr)]) ,
		     casesSingleParentsMatchedJoint[ , .(pnrControl)]) ,
		use.names = FALSE)
  ##Underlying biological children: 
  childrenAnalysis <- unique(childrenAnalysis)


  temp <- names(casesSingleParentsMatchedJoint)
  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
  casesSingleParentsMatchedJoint[ , (temp) := NULL]
  rm(temp)
  casesSingleParentsMatchedLong <- melt(casesSingleParentsMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
  setnames(casesSingleParentsMatchedLong , "date" , "studyEntry")
  casesSingleParentsMatchedLong[variable == "pnr" , case := 1]
  casesSingleParentsMatchedLong[variable == "pnrControl" , case := 0]
  casesSingleParentsMatchedLong[ , variable := NULL]
  setnames(casesSingleParentsMatchedLong , "value" , "pnr")
  setorder(casesSingleParentsMatchedLong , pnr , case , studyEntry)
  casesSingleParentsMatchedLong <- unique(casesSingleParentsMatchedLong , by = c("pnr" , "case"))

  casesSingleParentsMatchedLong[casesSingleParents , on = "pnr" , originalDate := i.date]
  casesSingleParentsMatchedLong[case == 1 , studyEntry := originalDate]
  casesSingleParentsMatchedLong[ , originalDate := NULL]

  ##This was forgotten upstream - adding:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Reducing to those included, on the dates that they are included:
  setnames(casesSingleParentsMatchedLong , "studyEntry" , "date")
  analysisDataset[casesSingleParentsMatchedLong , on = c("pnr" , "date") , case := i.case]
  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
  pseudoAnalysisSubjects[ , studyEntry := NULL]
  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
  setnames(casesSingleParentsMatchedLong , "date" , "studyEntry")

  ##Extracting the last line of all participating subjects:
  setorder(analysisDataset , pnr , -date)
  temp <- unique(analysisDataset , by = "pnr")
  pseudoAnalysisSubjects[ , deathCensoring := NULL]
  pseudoAnalysisSubjects[temp ,
			 on = "pnr" ,
			 c("endDate" ,
			   "outcomePhysicalAbuse" ,
			   "deathCensoring") :=
			     list(i.date ,
				  i.outcomePhysicalAbuse ,
				  i.deathCensoring)]
  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
  pseudoAnalysisSubjects[is.na(event) , event := 0]
  pseudoAnalysisSubjects[ , event := factor(event ,
			  levels = c(0 , 1 , 2) ,
			  labels = c("Censored" ,
				     "Physical abuse" ,
				     "Deceased"))]

  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]

  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]

  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)

  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)

  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)

  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))

  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

  pseudoAnalysis[ , case :=
			factor(case ,
			       levels = c(0 , 1) ,
			       labels = c("Control" , "Case"))] 

  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]

  followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
  ##Sum of follow-up time: 
  followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
  ##Number of cases in analysis:
  temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]
  ##Number of lethal cases in analysis:
  temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]
  ##Number of deaths not related to abuse:
  temp[partOfAnalysis == 1 &
       !is.na(deathCensoring) &
       (outcomePhysicalAbuse == 0 |
	is.na(outcomePhysicalAbuse)) ,
       .N]



  sink(file = "results.txt" , split = TRUE)
  ##The geese way:
  pseudoFitFullPopulationSingleParents <- geese(physicalAbuse ~ case +
				       ##Family characteristics                     
				       incomeVariable + 
				       parishQuantileDifference100Euros + 
				       oneForeignParent +
				       familyNeedProtection +
				       calendarTimeGroup +
				       ##Parental health and history
				       familyEducationalLevelReleveled +
				       parentalPsychiatricDisease +
				       interparentalViolence +
				       parentalSubstanceAbuse +
				       parentalAbuseAsChildReleveled ,
				   data = pseudoAnalysis ,
				   id = familyIndex ,
				   scale.fix = TRUE ,
				   family = gaussian ,
				   mean.link = "log" ,
				   corstr = "independence")
  summary(pseudoFitFullPopulationSingleParents)
  resultsPseudoFitFullPopulationSingleParents <- formatResultsGeese(pseudoFitFullPopulationSingleParents)
  fwrite(resultsPseudoFitFullPopulationSingleParents , "resultsPseudoFitFullPopulationSingleParents.csv")


  ##Making a G-model:
  ##This is done using one of the imputed datasets from above. 
  analysisDataset <- readAnalysisDatasetImputed(1)

  ##Re-code the exposure and outcome:

  analysisDataset[jointCharlsonParents <= 1 , gTreatment := 1]
  analysisDataset[jointCharlsonParents > 1 , gTreatment := 0]
  analysisDataset[outcomePhysicalAbuse > 0 , anyPhysicalAbuse := 1]
  analysisDataset[is.na(anyPhysicalAbuse) , anyPhysicalAbuse := 0]
  ##The next line if this is an end of follow-up outcome:
  #analysisDataset[time < 214 & anyPhysicalAbuse != 1 , anyPhysicalAbuse := NA]
  analysisDataset[deathCensoring == date & outcomePhysicalAbuse == 0 , deathCompetingEvent := 1]
  analysisDataset[deathCompetingEvent == 1 , anyPhysicalAbuse := NA]

  ##Set the order of data correctly:
  setorder(analysisDataset , pnr , time)

  ##Looking at the incomeVariable, trying to make it fit for something linear - it actually looks quite normally distributed, see the graph below, but with some very long tails. I will leave it as it is. 
  ##ggplot() + geom_histogram(data = analysisDataset , aes(x = incomeVariable) , breaks = seq(from = -250 , to = 500, by = 50))

  ##analysisDataset[ , logIncomeVariable := log(incomeVariable)]
  ##Recoding binary factors as a binary numeric variables- thus updating after the imputations:
  analysisDataset[familyEducationalLevelReleveled == "Primary or secondary education" , familyEducationalLevelBinary := 0]
  analysisDataset[familyEducationalLevelReleveled == "Tertiary education or higher" , familyEducationalLevelBinary := 1]
  analysisDataset[oneForeignParent == "No foreign parents" , oneForeignParentBinary := 0]
  analysisDataset[oneForeignParent == "One or more foreign parents" , oneForeignParentBinary := 1]
  ## analysisDataset[familyNeedProtection == "Not in need of protection" , familyNeedProtectionBinary := 0]
  ## analysisDataset[familyNeedProtection == "In need of protection" , familyNeedProtectionBinary := 1]
  ## analysisDataset[parentalPsychiatricDisease == "No psychiatric disease" , parentalPsychiatricDiseaseBinary := 0]
  ## analysisDataset[parentalPsychiatricDisease == "Any psychiatric disease" , parentalPsychiatricDiseaseBinary := 1]
  ## analysisDataset[parentalAbuseAsChildReleveled == "No maltreatment or neglect" , parentalAbuseAsChildBinary := 0]
  ## analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, one or both parents" , parentalAbuseAsChildBinary := 1]
  analysisDataset[interparentalViolence == "No interparental violence" , interparentalViolenceBinary := 0]
  analysisDataset[interparentalViolence == "Interparental violence" , interparentalViolenceBinary := 1]
  analysisDataset[parentalSubstanceAbuse == "No parental substance abuse" , parentalSubstanceAbuseBinary := 0]
  analysisDataset[parentalSubstanceAbuse == "Parental substance abuse" , parentalSubstanceAbuseBinary := 1]



  ##childAgeGroup is supposed to capture age at inclusion - but it is obviously not constant, as it currently changes with age. Changing this, also for time period:

  tempAge <- unique(analysisDataset[time == 0 , .(pnr , childAgeGroup)])
  analysisDataset[tempAge , on = "pnr" , childAgeGroupAtInclusion := i.childAgeGroup]
  tempCalendarTime <- unique(analysisDataset[time == 0 , .(pnr , calendarTimeGroup)])
  analysisDataset[tempCalendarTime , on = "pnr" , calendarTimeGroupAtInclusion  := i.calendarTimeGroup]

  ##Looking for errors - recoding childAgeGroupAtInclusion as a binary:
  analysisDataset[childAgeGroupAtInclusion == "Child 0-6 years old" , childAgeGroupAtInclusionBinary := 0]  
  analysisDataset[childAgeGroupAtInclusion == "Child 7-18 years old" , childAgeGroupAtInclusionBinary := 1]

  ##I forgot to factorize the new number of children-variable earlier:
  analysisDataset[ , numberOfChildrenFactor :=
			       cut(newNoOfChildren ,
				   breaks = c(0 , 1 , 2 , 5 , 20) ,
				   labels = c("One child" ,
					      "Two children" ,
					      "Three to five children" ,
					      "Six children or more"))]

  ##As the cuts above produces small cells in this draw of 50.000 children, the variable is redefined with fewer levels here and used in the second definition of the model (see below):

  analysisDataset[ , numberOfChildrenFactorReleveled :=
			       cut(newNoOfChildren ,
				   breaks = c(0 , 1 , 2 , 20) ,
				   labels = c("One child" ,
					      "Two children" ,
					      "Three children or more"
					      ))]


  ##Below is a number of models run because of various issues, see comments. Only the final model has not been commented out. In spite of various, and slightly different, specifications, the models produce remarkably similar results. Except for the models attempting to overcome non-convergence or too many parameters, all the specifications are as close as possible to the pre-specified DAG.

  ## Sys.time()
  ## gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
  ## 				  outcome_name = "anyPhysicalAbuse" ,
  ## 				  compevent_name = "deathCompetingEvent" ,
  ## 				  time_points = 34 ,
  ## 				  time_name = "time" ,
  ## 				  ref_int = 2 ,
  ## 				  intvars = list("gTreatment" , "gTreatment") , 
  ## 				  interventions = list(list(c(static , rep(0 , 34))) ,
  ## 						       list(c(static , rep(1 , 34)))) , 
  ## 				  int_descript = c("Never treat" , "Always treat") , 
  ## 				  ymodel = anyPhysicalAbuse ~ gTreatment +
  ## 				      time +
  ## 				      parishQuantileDifference100Euros +
  ## 				      numberOfChildrenFactor +
  ## 				      reconstitutedFamily +
  ## 				      familyEducationalLevelBinary +
  ## 				      incomeVariable +
  ## 				      parentalPsychiatricDiseaseBinary +
  ## 				      interparentalViolenceBinary +
  ## 				      parentalSubstanceAbuseBinary +
  ## 				      parentalAbuseAsChildBinary +
  ## 				      oneForeignParentBinary +
  ## 				      familyNeedProtectionBinary +
  ## 				      childAgeGroupAtInclusionBinary +
  ## 				      calendarTimeGroupAtInclusion +
  ## 				      meanParentalAge ,
  ## 				  compevent_model = deathCompetingEvent ~ gTreatment +
  ## 				      time +
  ## 				      parishQuantileDifference100Euros +
  ## 				      numberOfChildrenFactor +
  ## 				      reconstitutedFamily +
  ## 				      familyEducationalLevelBinary +
  ## 				      incomeVariable +
  ## 				      parentalPsychiatricDiseaseBinary +
  ## 				      interparentalViolenceBinary +
  ## 				      parentalSubstanceAbuseBinary +
  ## 				      parentalAbuseAsChildBinary +
  ## 				      oneForeignParentBinary +
  ## 				      familyNeedProtectionBinary +
  ## 				      childAgeGroupAtInclusionBinary +
  ## 				      calendarTimeGroupAtInclusion +
  ## 				      meanParentalAge ,
  ## 				  id = "pnr" ,
  ## 				  covnames = c("parishQuantileDifference100Euros" ,
  ## 					       "numberOfChildrenFactor" ,
  ## 					       "reconstitutedFamily" ,
  ## 					       "familyEducationalLevelBinary" ,
  ## 					       "incomeVariable" ,
  ## 					       "parentalPsychiatricDiseaseBinary" ,
  ## 					       "interparentalViolenceBinary" ,
  ## 					       "parentalSubstanceAbuseBinary" ,  
  ## 					       "parentalAbuseAsChildBinary" ,
  ## 					       "oneForeignParentBinary" ,
  ## 					       "familyNeedProtectionBinary" ,
  ## 					       "meanParentalAge" ,
  ## 					       "gTreatment") ,
  ## 				  histories = c(lagged) ,
  ## 				  histvars = list(c("parishQuantileDifference100Euros" ,
  ## 						    "numberOfChildrenFactor" ,
  ## 						    "reconstitutedFamily" ,
  ## 						    "familyEducationalLevelBinary" ,
  ## 						    "incomeVariable" ,
  ## 						    "parentalPsychiatricDiseaseBinary" ,
  ## 						    "interparentalViolenceBinary" ,
  ## 						    "parentalSubstanceAbuseBinary" ,
  ## 						    "parentalAbuseAsChildBinary" ,
  ## 						    "oneForeignParentBinary" , 
  ## 						    "familyNeedProtectionBinary" ,
  ## 						    "meanParentalAge" ,
  ## 						    "gTreatment")) , ##Remember that for parishQuantileDifference100Euros and logIncomeVariable they are actually already lagged - use only in special cases.
  ## 				  covtypes = c("normal" , #parishQuantileDifference100Euros
  ## 					       "categorical" , #numberOfChildrenFactor
  ## 					       "categorical" , #reconstitutedFamily
  ## 					       "binary" , #education
  ## 					       "normal" , #incomeVariable
  ## 					       "binary" , #parentalPsychiatricDiseaseBinary
  ## 					       "binary" , #interparentalViolenceBinary"
  ## 					       "binary" , #parentalSubstanceAbuseBinary
  ## 					       "binary" , #parentalAbuseAsChildBinary
  ## 					       "binary" , #oneForeignParentBinary"
  ## 					       "binary" , #familyNeedProtectionBinary
  ## 					       "normal" , #meanParentalAge
  ## 					       "binary") , #gTreatment 
  ## 				  covparams = list(covmodels = c(parishQuantileDifference100Euros ~ 
  ## 								     lag1_parishQuantileDifference100Euros +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     incomeVariable +
  ## 								     familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge , 
  ## 								 numberOfChildrenFactor ~
  ## 								     gTreatment +
  ## 								     lag1_numberOfChildrenFactor +
  ## 								     lag1_reconstitutedFamily +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     oneForeignParentBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 reconstitutedFamily ~
  ## 								     gTreatment +
  ## 								     lag1_reconstitutedFamily +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_interparentalViolenceBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 familyEducationalLevelBinary ~
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     meanParentalAge ,
  ## 								 incomeVariable ~
  ## 								     gTreatment + 
  ## 								     lag1_numberOfChildrenFactor +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_incomeVariable +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     meanParentalAge ,
  ## 								 parentalPsychiatricDiseaseBinary ~
  ## 								     gTreatment +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_interparentalViolenceBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     meanParentalAge ,
  ## 								 interparentalViolenceBinary ~
  ## 								     lag1_parishQuantileDifference100Euros +
  ## 								     lag1_reconstitutedFamily +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_interparentalViolenceBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 parentalSubstanceAbuseBinary ~
  ## 								     lag1_parishQuantileDifference100Euros +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     familyNeedProtectionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 parentalAbuseAsChildBinary ~
  ## 								     lag1_parentalAbuseAsChildBinary +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 oneForeignParentBinary ~
  ## 								     lag1_oneForeignParentBinary +
  ## 								     lag1_familyNeedProtectionBinary +
  ## 								     lag1_numberOfChildrenFactor +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 familyNeedProtectionBinary ~
  ## 								     lag1_oneForeignParentBinary +
  ## 								     lag1_familyNeedProtectionBinary +
  ## 								     lag1_numberOfChildrenFactor +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 meanParentalAge ~
  ## 								     lag1_meanParentalAge +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 gTreatment ~
  ## 								     lag1_gTreatment +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_parentalAbuseAsChildBinary)) ,
  ## 				  basecovs = c("childAgeGroupAtInclusionBinary" ,
  ## 					       "calendarTimeGroupAtInclusion") ,
  ## 				  ##nsimul = 10000 ,
  ## 				  seed = 25328621 , 
  ## 				  parallel = TRUE ,
  ## 				  ncores = 20 ,
  ## 				  threads = 15) 
  ## Sys.time()

  ## ##The model above produces errors indicating small cell problems. This is a feasible explanation given that only 50000 children are analyzed and that several variables are known to be distributed rather unevenly. Taking a number of variables out and re-running: 

  ## ##The model below is running. Reading in the modifications for the gfoRmula program (they are in another code block)

  ## ##Reduced model based on results from geese-model:
  ## sink("logGModel.txt" , split = TRUE)
  ## Sys.time()
  ## gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
  ## 				  outcome_name = "anyPhysicalAbuse" ,
  ## 				  compevent_name = "deathCompetingEvent" ,
  ## 				  time_points = 34 ,
  ## 				  time_name = "time" ,
  ## 				  ref_int = 2 ,
  ## 				  ##This is a straight linear model - is that okay? I will get an awful lot of parameters if I start putting in products.
  ## 				  ##I think what I am asking is to compare people who are always not ill with people who are always ill - need to confirm.
  ## 				  intvars = list("gTreatment" , "gTreatment") , 
  ## 				  interventions = list(list(c(static , rep(0 , 34))) ,
  ## 						       list(c(static , rep(1 , 34)))) , 
  ## 				  int_descript = c("Never treat" , "Always treat") , 
  ## 				  ymodel = anyPhysicalAbuse ~ gTreatment +
  ## 				      time +
  ## 				      parishQuantileDifference100Euros +
  ## 				      numberOfChildrenFactorReleveled +
  ## 				      reconstitutedFamily +
  ## 				      familyEducationalLevelBinary +
  ## 				      incomeVariable +
  ## 				      parentalPsychiatricDiseaseBinary +
  ## 				      ##interparentalViolenceBinary +
  ## 				      ##parentalSubstanceAbuseBinary +
  ## 				      parentalAbuseAsChildBinary +
  ## 				      oneForeignParentBinary +
  ## 				      ##familyNeedProtectionBinary +
  ## 				      childAgeGroupAtInclusionBinary +
  ## 				      calendarTimeGroupAtInclusion +
  ## 				      meanParentalAge ,
  ## 				  compevent_model = deathCompetingEvent ~ gTreatment +
  ## 				      time +
  ## 				      parishQuantileDifference100Euros +
  ## 				      numberOfChildrenFactorReleveled +
  ## 				      reconstitutedFamily +
  ## 				      familyEducationalLevelBinary +
  ## 				      incomeVariable +
  ## 				      parentalPsychiatricDiseaseBinary +
  ## 				      ##interparentalViolenceBinary +
  ## 				      ##parentalSubstanceAbuseBinary +
  ## 				      parentalAbuseAsChildBinary +
  ## 				      oneForeignParentBinary +
  ## 				      ##familyNeedProtectionBinary +
  ## 				      childAgeGroupAtInclusionBinary +
  ## 				      calendarTimeGroupAtInclusion +
  ## 				      meanParentalAge ,
  ## 				  id = "pnr" ,
  ## 				  covnames = c("parishQuantileDifference100Euros" ,
  ## 					       "numberOfChildrenFactorReleveled" ,
  ## 					       "reconstitutedFamily" ,
  ## 					       "familyEducationalLevelBinary" ,
  ## 					       "incomeVariable" ,
  ## 					       "parentalPsychiatricDiseaseBinary" ,
  ## 					       ##"interparentalViolenceBinary" ,
  ## 					       ##"parentalSubstanceAbuseBinary" ,  
  ## 					       "parentalAbuseAsChildBinary" ,
  ## 					       "oneForeignParentBinary" ,
  ## 					       ##"familyNeedProtectionBinary" ,
  ## 					       "meanParentalAge" ,
  ## 					       "gTreatment") ,
  ## 				  histories = c(lagged) ,
  ## 				  histvars = list(c("parishQuantileDifference100Euros" ,
  ## 						    "numberOfChildrenFactorReleveled" ,
  ## 						    "reconstitutedFamily" ,
  ## 						    "familyEducationalLevelBinary" ,
  ## 						    "incomeVariable" ,
  ## 						    "parentalPsychiatricDiseaseBinary" ,
  ## 						    ##"interparentalViolenceBinary" ,
  ## 						    ##"parentalSubstanceAbuseBinary" ,
  ## 						    "parentalAbuseAsChildBinary" ,
  ## 						    "oneForeignParentBinary" , 
  ## 						    ##"familyNeedProtectionBinary" ,
  ## 						    "meanParentalAge" ,
  ## 						    "gTreatment")) , ##Remember that for parishQuantileDifference100Euros and logIncomeVariable they are actually already lagged - use only in special cases.
  ## 				  ##May I look at distributions  in the data here when I set these?
  ## 				  covtypes = c("normal" , #parishQuantileDifference100Euros
  ## 					       "categorical" , #numberOfChildrenFactorReleveled
  ## 					       "categorical" , #reconstitutedFamily
  ## 					       "binary" , #education
  ## 					       "normal" , #incomeVariable
  ## 					       "binary" , #parentalPsychiatricDiseaseBinary
  ## 					       ##"binary" , #interparentalViolenceBinary"
  ## 					       ##"binary" , #parentalSubstanceAbuseBinary
  ## 					       "binary" , #parentalAbuseAsChildBinary
  ## 					       "binary" , #oneForeignParentBinary"
  ## 					       ##"binary" , #familyNeedProtectionBinary
  ## 					       "normal" , #meanParentalAge
  ## 					       "binary") , #gTreatment 
  ## 				  ##I've used the history-variable to generate lagged variables for all time-varying covariates. Now, the covmodels need to be specified - use lag1_parishQuantileDifference100Euros to name the previous value of a variable in a formula. Reduce the following formulas to reduce complexity. If it makes theoretical sense, you could use lag1_example to predict the current value of example.
  ## 				  covparams = list(covmodels = c(parishQuantileDifference100Euros ~ 
  ## 								     lag1_parishQuantileDifference100Euros +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     incomeVariable +
  ## 								     ##familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge , 
  ## 								 numberOfChildrenFactorReleveled ~
  ## 								     gTreatment +
  ## 								     lag1_numberOfChildrenFactorReleveled +
  ## 								     lag1_reconstitutedFamily +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     oneForeignParentBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 reconstitutedFamily ~
  ## 								     gTreatment +
  ## 								     lag1_reconstitutedFamily +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     ##lag1_interparentalViolenceBinary +
  ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     ##familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     calendarTimeGroupAtInclusion +
  ## 								     meanParentalAge ,
  ## 								 familyEducationalLevelBinary ~
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     ##familyNeedProtectionBinary +
  ## 								     meanParentalAge ,
  ## 								 incomeVariable ~
  ## 								     gTreatment + 
  ## 								     lag1_numberOfChildrenFactorReleveled +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_incomeVariable +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     oneForeignParentBinary +
  ## 								     ##familyNeedProtectionBinary +
  ## 								     childAgeGroupAtInclusionBinary +
  ## 								     meanParentalAge ,
  ## 								 parentalPsychiatricDiseaseBinary ~
  ## 								     gTreatment +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     ##lag1_interparentalViolenceBinary +
  ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## 								     parentalAbuseAsChildBinary +
  ## 								     ##familyNeedProtectionBinary +
  ## 								     meanParentalAge ,
  ## 								 ## interparentalViolenceBinary ~
  ## 								 ##     lag1_parishQuantileDifference100Euros +
  ## 								 ##     lag1_reconstitutedFamily +
  ## 								 ##     lag1_familyEducationalLevelBinary +
  ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## 								 ##     lag1_interparentalViolenceBinary +
  ## 								 ##     lag1_parentalSubstanceAbuseBinary +
  ## 								 ##     parentalAbuseAsChildBinary +
  ## 								 ##     oneForeignParentBinary +
  ## 								 ##     familyNeedProtectionBinary +
  ## 								 ##     childAgeGroupAtInclusionBinary +
  ## 								 ##     calendarTimeGroupAtInclusion +
  ## 								 ##     meanParentalAge ,
  ## 								 ## parentalSubstanceAbuseBinary ~
  ## 								 ##     lag1_parishQuantileDifference100Euros +
  ## 								 ##     lag1_familyEducationalLevelBinary +
  ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## 								 ##     lag1_parentalSubstanceAbuseBinary +
  ## 								 ##     parentalAbuseAsChildBinary +
  ## 								 ##     familyNeedProtectionBinary +
  ## 								 ##     calendarTimeGroupAtInclusion +
  ## 								 ##     meanParentalAge ,
  ## 								 parentalAbuseAsChildBinary ~
  ## 								     lag1_parentalAbuseAsChildBinary +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 oneForeignParentBinary ~
  ## 								     lag1_oneForeignParentBinary +
  ## 								     ##lag1_familyNeedProtectionBinary +
  ## 								     lag1_numberOfChildrenFactorReleveled +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 ## familyNeedProtectionBinary ~
  ## 								 ##     lag1_oneForeignParentBinary +
  ## 								 ##     lag1_familyNeedProtectionBinary +
  ## 								 ##     lag1_numberOfChildrenFactorReleveled +
  ## 								 ##     lag1_reconstitutedFamily ,
  ## 								 meanParentalAge ~
  ## 								     lag1_meanParentalAge +
  ## 								     lag1_reconstitutedFamily ,
  ## 								 gTreatment ~
  ## 								     lag1_gTreatment +
  ## 								     lag1_familyEducationalLevelBinary +
  ## 								     lag1_parentalPsychiatricDiseaseBinary +
  ## 								     lag1_parentalAbuseAsChildBinary)) ,
  ## 				  basecovs = c("childAgeGroupAtInclusionBinary" ,
  ## 					       "calendarTimeGroupAtInclusion") ,
  ## 				  ##nsimul = 10000 ,
  ## 				  seed = 25328621 , 
  ## 				  parallel = TRUE ,
  ## 				  ncores = 10 ,
  ## 				  threads = 15 ,
  ## 				  ##clusterID = "familyIndex" ,
  ## 				  nsamples = 0)
  ## 				  ##boot_diag = TRUE) 
  ## Sys.time()
  ## save.image("gModelOutput.RData")
  ## sink()

  ## ## ##The model above runs but not with confidence intervals - trying an even more simplified model to enable this; this did not improve anything, commenting out:

  ## ## sink("logGModelFurtherReduced.txt" , split = TRUE)
  ## ## Sys.time()
  ## ## gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
  ## ## 				  outcome_name = "anyPhysicalAbuse" ,
  ## ## 				  compevent_name = "deathCompetingEvent" ,
  ## ## 				  time_points = 34 ,
  ## ## 				  time_name = "time" ,
  ## ## 				  ref_int = 2 ,
  ## ## 				  ##This is a straight linear model - is that okay? I will get an awful lot of parameters if I start putting in products.
  ## ## 				  ##I think what I am asking is to compare people who are always not ill with people who are always ill - need to confirm.
  ## ## 				  intvars = list("gTreatment" , "gTreatment") , 
  ## ## 				  interventions = list(list(c(static , rep(0 , 34))) ,
  ## ## 						       list(c(static , rep(1 , 34)))) , 
  ## ## 				  int_descript = c("Never treat" , "Always treat") , 
  ## ## 				  ymodel = anyPhysicalAbuse ~ gTreatment +
  ## ## 				      time +
  ## ## 				      ##parishQuantileDifference100Euros +
  ## ## 				      numberOfChildrenFactorReleveled +
  ## ## 				      ##reconstitutedFamily +
  ## ## 				      familyEducationalLevelBinary +
  ## ## 				      incomeVariable +
  ## ## 				      ##parentalPsychiatricDiseaseBinary +
  ## ## 				      ##interparentalViolenceBinary +
  ## ## 				      ##parentalSubstanceAbuseBinary +
  ## ## 				      parentalAbuseAsChildBinary +
  ## ## 				      ##oneForeignParentBinary +
  ## ## 				      ##familyNeedProtectionBinary +
  ## ## 				      childAgeGroupAtInclusionBinary +
  ## ## 				      calendarTimeGroupAtInclusion +
  ## ## 				      meanParentalAge ,
  ## ## 				  compevent_model = deathCompetingEvent ~ gTreatment +
  ## ## 				      time +
  ## ## 				      ##parishQuantileDifference100Euros +
  ## ## 				      numberOfChildrenFactorReleveled +
  ## ## 				      ##reconstitutedFamily +
  ## ## 				      familyEducationalLevelBinary +
  ## ## 				      incomeVariable +
  ## ## 				      ##parentalPsychiatricDiseaseBinary +
  ## ## 				      ##interparentalViolenceBinary +
  ## ## 				      ##parentalSubstanceAbuseBinary +
  ## ## 				      parentalAbuseAsChildBinary +
  ## ## 				      ##oneForeignParentBinary +
  ## ## 				      ##familyNeedProtectionBinary +
  ## ## 				      childAgeGroupAtInclusionBinary +
  ## ## 				      calendarTimeGroupAtInclusion +
  ## ## 				      meanParentalAge ,
  ## ## 				  id = "pnr" ,
  ## ## 				  covnames = c(##"parishQuantileDifference100Euros" ,
  ## ## 					       "numberOfChildrenFactorReleveled" ,
  ## ## 					       ##"reconstitutedFamily" ,
  ## ## 					       "familyEducationalLevelBinary" ,
  ## ## 					       "incomeVariable" ,
  ## ## 					       ##"parentalPsychiatricDiseaseBinary" ,
  ## ## 					       ##"interparentalViolenceBinary" ,
  ## ## 					       ##"parentalSubstanceAbuseBinary" ,  
  ## ## 					       "parentalAbuseAsChildBinary" ,
  ## ## 					       ##"oneForeignParentBinary" ,
  ## ## 					       ##"familyNeedProtectionBinary" ,
  ## ## 					       "meanParentalAge" ,
  ## ## 					       "gTreatment") ,
  ## ## 				  histories = c(lagged) ,
  ## ## 				  histvars = list(c(##"parishQuantileDifference100Euros" ,
  ## ## 				      "numberOfChildrenFactorReleveled" ,
  ## ## 				      ##"reconstitutedFamily" ,
  ## ## 				      "familyEducationalLevelBinary" ,
  ## ## 				      "incomeVariable" ,
  ## ## 				      ##"parentalPsychiatricDiseaseBinary" ,
  ## ## 				      ##"interparentalViolenceBinary" ,
  ## ## 				      ##"parentalSubstanceAbuseBinary" ,
  ## ## 				      "parentalAbuseAsChildBinary" ,
  ## ## 				      ##"oneForeignParentBinary" , 
  ## ## 				      ##"familyNeedProtectionBinary" ,
  ## ## 				      "meanParentalAge" ,
  ## ## 				      "gTreatment")) , ##Remember that for parishQuantileDifference100Euros and logIncomeVariable they are actually already lagged - use only in special cases.
  ## ## 				  ##May I look at distributions  in the data here when I set these?
  ## ## 				  covtypes = c(##"normal" , #parishQuantileDifference100Euros
  ## ## 					       "categorical" , #numberOfChildrenFactorReleveled
  ## ## 					       ##"categorical" , #reconstitutedFamily
  ## ## 					       "binary" , #education
  ## ## 					       "normal" , #incomeVariable
  ## ## 					       ##"binary" , #parentalPsychiatricDiseaseBinary
  ## ## 					       ##"binary" , #interparentalViolenceBinary"
  ## ## 					       ##"binary" , #parentalSubstanceAbuseBinary
  ## ## 					       "binary" , #parentalAbuseAsChildBinary
  ## ## 					       ##"binary" , #oneForeignParentBinary"
  ## ## 					       ##"binary" , #familyNeedProtectionBinary
  ## ## 					       "normal" , #meanParentalAge
  ## ## 					       "binary") , #gTreatment 
  ## ## 				  ##I've used the history-variable to generate lagged variables for all time-varying covariates. Now, the covmodels need to be specified - use lag1_parishQuantileDifference100Euros to name the previous value of a variable in a formula. Reduce the following formulas to reduce complexity. If it makes theoretical sense, you could use lag1_example to predict the current value of example.
  ## ## 				  covparams = list(covmodels = c(## parishQuantileDifference100Euros ~ 
  ## ## 								 ##     lag1_parishQuantileDifference100Euros +
  ## ## 								 ##     lag1_familyEducationalLevelBinary +
  ## ## 								 ##     incomeVariable +
  ## ## 								 ##     ##familyNeedProtectionBinary +
  ## ## 								 ##     childAgeGroupAtInclusionBinary +
  ## ## 								 ##     calendarTimeGroupAtInclusion +
  ## ## 								 ##     meanParentalAge , 
  ## ## 								 numberOfChildrenFactorReleveled ~
  ## ## 								     gTreatment +
  ## ## 								     lag1_numberOfChildrenFactorReleveled +
  ## ## 								     ##lag1_reconstitutedFamily +
  ## ## 								     lag1_familyEducationalLevelBinary +
  ## ## 								     ##lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     ##oneForeignParentBinary +
  ## ## 								     childAgeGroupAtInclusionBinary +
  ## ## 								     calendarTimeGroupAtInclusion +
  ## ## 								     meanParentalAge ,
  ## ## 								 ## reconstitutedFamily ~
  ## ## 								 ##     gTreatment +
  ## ## 								 ##     lag1_reconstitutedFamily +
  ## ## 								 ##     lag1_familyEducationalLevelBinary +
  ## ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								 ##     ##lag1_interparentalViolenceBinary +
  ## ## 								 ##     ##lag1_parentalSubstanceAbuseBinary +
  ## ## 								 ##     parentalAbuseAsChildBinary +
  ## ## 								 ##     oneForeignParentBinary +
  ## ## 								 ##     ##familyNeedProtectionBinary +
  ## ## 								 ##     childAgeGroupAtInclusionBinary +
  ## ## 								 ##     calendarTimeGroupAtInclusion +
  ## ## 								 ##     meanParentalAge ,
  ## ## 								 familyEducationalLevelBinary ~
  ## ## 								     lag1_familyEducationalLevelBinary +
  ## ## 								     ##lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## ## 								     parentalAbuseAsChildBinary +
  ## ## 								     ##oneForeignParentBinary +
  ## ## 								     ##familyNeedProtectionBinary +
  ## ## 								     meanParentalAge ,
  ## ## 								 incomeVariable ~
  ## ## 								     gTreatment + 
  ## ## 								     lag1_numberOfChildrenFactorReleveled +
  ## ## 								     lag1_familyEducationalLevelBinary +
  ## ## 								     lag1_incomeVariable +
  ## ## 								     ##lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     ##lag1_parentalSubstanceAbuseBinary +
  ## ## 								     parentalAbuseAsChildBinary +
  ## ## 								     ##oneForeignParentBinary +
  ## ## 								     ##familyNeedProtectionBinary +
  ## ## 								     childAgeGroupAtInclusionBinary +
  ## ## 								     meanParentalAge ,
  ## ## 								 ## parentalPsychiatricDiseaseBinary ~
  ## ## 								 ##     gTreatment +
  ## ## 								 ##     lag1_familyEducationalLevelBinary +
  ## ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								 ##     ##lag1_interparentalViolenceBinary +
  ## ## 								 ##     ##lag1_parentalSubstanceAbuseBinary +
  ## ## 								 ##     parentalAbuseAsChildBinary +
  ## ## 								 ##     ##familyNeedProtectionBinary +
  ## ## 								 ##     meanParentalAge ,
  ## ## 								 ## interparentalViolenceBinary ~
  ## ## 								 ##     lag1_parishQuantileDifference100Euros +
  ## ## 								 ##     lag1_reconstitutedFamily +
  ## ## 								 ##     lag1_familyEducationalLevelBinary +
  ## ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								 ##     lag1_interparentalViolenceBinary +
  ## ## 								 ##     lag1_parentalSubstanceAbuseBinary +
  ## ## 								 ##     parentalAbuseAsChildBinary +
  ## ## 								 ##     oneForeignParentBinary +
  ## ## 								 ##     familyNeedProtectionBinary +
  ## ## 								 ##     childAgeGroupAtInclusionBinary +
  ## ## 								 ##     calendarTimeGroupAtInclusion +
  ## ## 								 ##     meanParentalAge ,
  ## ## 								 ## parentalSubstanceAbuseBinary ~
  ## ## 								 ##     lag1_parishQuantileDifference100Euros +
  ## ## 								 ##     lag1_familyEducationalLevelBinary +
  ## ## 								 ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								 ##     lag1_parentalSubstanceAbuseBinary +
  ## ## 								 ##     parentalAbuseAsChildBinary +
  ## ## 								 ##     familyNeedProtectionBinary +
  ## ## 								 ##     calendarTimeGroupAtInclusion +
  ## ## 								 ##     meanParentalAge ,
  ## ## 								 parentalAbuseAsChildBinary ~
  ## ## 								     lag1_parentalAbuseAsChildBinary ,
  ## ## 								     ##lag1_reconstitutedFamily ,
  ## ## 								 ## oneForeignParentBinary ~
  ## ## 								 ##     lag1_oneForeignParentBinary +
  ## ## 								 ##     ##lag1_familyNeedProtectionBinary +
  ## ## 								 ##     lag1_numberOfChildrenFactorReleveled +
  ## ## 								 ##     lag1_reconstitutedFamily ,
  ## ## 								 ## familyNeedProtectionBinary ~
  ## ## 								 ##     lag1_oneForeignParentBinary +
  ## ## 								 ##     lag1_familyNeedProtectionBinary +
  ## ## 								 ##     lag1_numberOfChildrenFactorReleveled +
  ## ## 								 ##     lag1_reconstitutedFamily ,
  ## ## 								 meanParentalAge ~
  ## ## 								     lag1_meanParentalAge ,
  ## ## 								     ##lag1_reconstitutedFamily ,
  ## ## 								 gTreatment ~
  ## ## 								     lag1_gTreatment +
  ## ## 								     lag1_familyEducationalLevelBinary +
  ## ## 								     ##lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     lag1_parentalAbuseAsChildBinary)) ,
  ## ## 				  basecovs = c("childAgeGroupAtInclusionBinary" ,
  ## ## 					       "calendarTimeGroupAtInclusion") ,
  ## ## 				  ##nsimul = 10000 ,
  ## ## 				  seed = 25328621 , 
  ## ## 				  parallel = TRUE ,
  ## ## 				  ncores = 10 ,
  ## ## 				  threads = 15 ,
  ## ## 				  ##clusterID = "familyIndex" ,
  ## ## 				  ##nsamples = 10 , 
  ## ## 				  boot_diag = TRUE) 
  ## ## Sys.time()
  ## ## save.image("gModelOutputFurtherReduced.RData")
  ## ## sink()

  ## ## ##This does not work either, even with as little as 10 bootstrap samples, as the system simply runs out of memory. I think I will simply let it be - the estimates are approximately the same as those found by geese and no matter what confidence interval, they will not lead to something clinically interesting. I think it is fair to say that this model confirms the findings in the geese model, from a vastly different specification.

  ## ##Re-running the large model on all bootstrap samples:

  ## ##This model was outcommented due to downstream checks - see comments for next model:

  ## ##Putting the model that runs without problems into a function (errors that were inconsistent with the DAG was corrected in this version - compare to the versions above to see changes): 
  ## ## gModelFitter <- function (datasetNo , logFile) {
  ## ##     ##This is done using one of the imputed datasets from above. 
  ## ##     analysisDataset <- readAnalysisDatasetImputed(datasetNo)
  ## ##     ##Do some pre-formatting to make sure the dataset looks as needed:
  ## ##     ##Re-code the exposure and outcome:

  ## ##     analysisDataset[jointCharlsonParents <= 1 , gTreatment := 1]
  ## ##     analysisDataset[jointCharlsonParents > 1 , gTreatment := 0]
  ## ##     analysisDataset[outcomePhysicalAbuse > 0 , anyPhysicalAbuse := 1]
  ## ##     analysisDataset[is.na(anyPhysicalAbuse) , anyPhysicalAbuse := 0]
  ## ##     ##The next line if this is an end of follow-up outcome:
  ## ##     ##analysisDataset[time < 214 & anyPhysicalAbuse != 1 , anyPhysicalAbuse := NA]
  ## ##     analysisDataset[deathCensoring == date & outcomePhysicalAbuse == 0 , deathCompetingEvent := 1]
  ## ##     analysisDataset[deathCompetingEvent == 1 , anyPhysicalAbuse := NA]

  ## ##     ##Set the order of data correctly:
  ## ##     setorder(analysisDataset , pnr , time)

  ## ##     ##Looking at the incomeVariable, trying to make it fit for something linear - it actually looks quite normally distributed, see the graph below, but with some very long tails. I will leave it as it is for now, unless advised otherwise by the statistician. 
  ## ##     ##ggplot() + geom_histogram(data = analysisDataset , aes(x = incomeVariable) , breaks = seq(from = -250 , to = 500, by = 50))

  ## ##     ##analysisDataset[ , logIncomeVariable := log(incomeVariable)]
  ## ##     ##Recoding binary factors as a binary numeric variables- thus updating after the imputations:
  ## ##     analysisDataset[familyEducationalLevelReleveled == "Primary or secondary education" , familyEducationalLevelBinary := 0]
  ## ##     analysisDataset[familyEducationalLevelReleveled == "Tertiary education or higher" , familyEducationalLevelBinary := 1]
  ## ##     analysisDataset[oneForeignParent == "No foreign parents" , oneForeignParentBinary := 0]
  ## ##     analysisDataset[oneForeignParent == "One or more foreign parents" , oneForeignParentBinary := 1]
  ## ##     ## analysisDataset[familyNeedProtection == "Not in need of protection" , familyNeedProtectionBinary := 0]
  ## ##     ## analysisDataset[familyNeedProtection == "In need of protection" , familyNeedProtectionBinary := 1]
  ## ##     ## analysisDataset[parentalPsychiatricDisease == "No psychiatric disease" , parentalPsychiatricDiseaseBinary := 0]
  ## ##     ## analysisDataset[parentalPsychiatricDisease == "Any psychiatric disease" , parentalPsychiatricDiseaseBinary := 1]
  ## ##     ## analysisDataset[parentalAbuseAsChildReleveled == "No maltreatment or neglect" , parentalAbuseAsChildBinary := 0]
  ## ##     ## analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, one or both parents" , parentalAbuseAsChildBinary := 1]
  ## ##     analysisDataset[interparentalViolence == "No interparental violence" , interparentalViolenceBinary := 0]
  ## ##     analysisDataset[interparentalViolence == "Interparental violence" , interparentalViolenceBinary := 1]
  ## ##     analysisDataset[parentalSubstanceAbuse == "No parental substance abuse" , parentalSubstanceAbuseBinary := 0]
  ## ##     analysisDataset[parentalSubstanceAbuse == "Parental substance abuse" , parentalSubstanceAbuseBinary := 1]



  ## ##     ##childAgeGroup is supposed to capture age at inclusion - but it is obviously not constant, as it currently changes with age. Changing this, also for time period:

  ## ##     tempAge <- unique(analysisDataset[time == 0 , .(pnr , childAgeGroup)])
  ## ##     analysisDataset[tempAge , on = "pnr" , childAgeGroupAtInclusion := i.childAgeGroup]
  ## ##     tempCalendarTime <- unique(analysisDataset[time == 0 , .(pnr , calendarTimeGroup)])
  ## ##     analysisDataset[tempCalendarTime , on = "pnr" , calendarTimeGroupAtInclusion  := i.calendarTimeGroup]

  ## ##     ##Looking for errors - recoding childAgeGroupAtInclusion as a binary:
  ## ##     analysisDataset[childAgeGroupAtInclusion == "Child 0-6 years old" , childAgeGroupAtInclusionBinary := 0]  
  ## ##     analysisDataset[childAgeGroupAtInclusion == "Child 7-18 years old" , childAgeGroupAtInclusionBinary := 1]

  ## ##     ##I forgot to factorize the new number of children-variable earlier:
  ## ##     analysisDataset[ , numberOfChildrenFactor :=
  ## ## 			   cut(newNoOfChildren ,
  ## ## 			       breaks = c(0 , 1 , 2 , 5 , 20) ,
  ## ## 			       labels = c("One child" ,
  ## ## 					  "Two children" ,
  ## ## 					  "Three to five children" ,
  ## ## 					  "Six children or more"))]

  ## ##     ##As the cuts above produces small cells in this draw of 50.000 children, the variable is redefined with fewer levels here and used in the second definition of the model (see below):

  ## ##     analysisDataset[ , numberOfChildrenFactorReleveled :=
  ## ## 			   cut(newNoOfChildren ,
  ## ## 			       breaks = c(0 , 1 , 2 , 20) ,
  ## ## 			       labels = c("One child" ,
  ## ## 					  "Two children" ,
  ## ## 					  "Three children or more"
  ## ## 					  ))]

  ## ##     ##Proceeding with the actual fitting: 
  ## ##     gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
  ## ## 				      outcome_name = "anyPhysicalAbuse" ,
  ## ## 				      compevent_name = "deathCompetingEvent" ,
  ## ## 				      time_points = 35 ,
  ## ## 				      time_name = "time" ,
  ## ## 				      ref_int = 2 ,
  ## ## 				      ##This is a straight linear model - is that okay? I will get an awful lot of parameters if I start putting in products.
  ## ## 				      ##I think what I am asking is to compare people who are always not ill with people who are always ill - need to confirm.
  ## ## 				      intvars = list("gTreatment" , "gTreatment") , 
  ## ## 				      interventions = list(list(c(static , rep(0 , 35))) ,
  ## ## 							   list(c(static , rep(1 , 35)))) , 
  ## ## 				      int_descript = c("Never treat" , "Always treat") , 
  ## ## 				      ymodel = anyPhysicalAbuse ~ gTreatment +
  ## ## 					  time +
  ## ## 					  parishQuantileDifference100Euros +
  ## ## 					  numberOfChildrenFactorReleveled +
  ## ## 					  reconstitutedFamily +
  ## ## 					  familyEducationalLevelBinary +
  ## ## 					  incomeVariable +
  ## ## 					  parentalPsychiatricDiseaseBinary +
  ## ## 					  ##interparentalViolenceBinary +
  ## ## 					  ##parentalSubstanceAbuseBinary +
  ## ## 					  parentalAbuseAsChildBinary +
  ## ## 					  oneForeignParentBinary +
  ## ## 					  ##familyNeedProtectionBinary +
  ## ## 					  childAgeGroupAtInclusionBinary +
  ## ## 					  calendarTimeGroupAtInclusion +
  ## ## 					  meanParentalAge ,
  ## ## 				      compevent_model = deathCompetingEvent ~ gTreatment +
  ## ## 					  time +
  ## ## 					  parishQuantileDifference100Euros +
  ## ## 					  numberOfChildrenFactorReleveled +
  ## ## 					  reconstitutedFamily +
  ## ## 					  familyEducationalLevelBinary +
  ## ## 					  incomeVariable +
  ## ## 					  parentalPsychiatricDiseaseBinary +
  ## ## 					  ##interparentalViolenceBinary +
  ## ## 					  ##parentalSubstanceAbuseBinary +
  ## ## 					  parentalAbuseAsChildBinary +
  ## ## 					  oneForeignParentBinary +
  ## ## 					  ##familyNeedProtectionBinary +
  ## ## 					  childAgeGroupAtInclusionBinary +
  ## ## 					  calendarTimeGroupAtInclusion +
  ## ## 					  meanParentalAge ,
  ## ## 				      id = "pnr" ,
  ## ## 				      covnames = c("parishQuantileDifference100Euros" ,
  ## ## 						   "numberOfChildrenFactorReleveled" ,
  ## ## 						   "reconstitutedFamily" ,
  ## ## 						   "familyEducationalLevelBinary" ,
  ## ## 						   "incomeVariable" ,
  ## ## 						   "parentalPsychiatricDiseaseBinary" ,
  ## ## 						   ##"interparentalViolenceBinary" ,
  ## ## 						   ##"parentalSubstanceAbuseBinary" ,  
  ## ## 						   "parentalAbuseAsChildBinary" ,
  ## ## 						   "oneForeignParentBinary" ,
  ## ## 						   ##"familyNeedProtectionBinary" ,
  ## ## 						   "meanParentalAge" ,
  ## ## 						   "gTreatment") ,
  ## ## 				      histories = c(lagged) ,
  ## ## 				      histvars = list(c("parishQuantileDifference100Euros" ,
  ## ## 							"numberOfChildrenFactorReleveled" ,
  ## ## 							"reconstitutedFamily" ,
  ## ## 							"familyEducationalLevelBinary" ,
  ## ## 							"incomeVariable" ,
  ## ## 							"parentalPsychiatricDiseaseBinary" ,
  ## ## 							##"interparentalViolenceBinary" ,
  ## ## 							##"parentalSubstanceAbuseBinary" ,
  ## ## 							"parentalAbuseAsChildBinary" ,
  ## ## 							"oneForeignParentBinary" , 
  ## ## 							##"familyNeedProtectionBinary" ,
  ## ## 							"meanParentalAge" ,
  ## ## 							"gTreatment")) , ##Remember that for parishQuantileDifference100Euros and incomeVariable they are actually already lagged - use only in special cases as lagged.
  ## ## 				      ##May I look at distributions  in the data here when I set these?
  ## ## 				      covtypes = c("normal" , #parishQuantileDifference100Euros
  ## ## 						   "categorical" , #numberOfChildrenFactorReleveled
  ## ## 						   "categorical" , #reconstitutedFamily
  ## ## 						   "binary" , #education
  ## ## 						   "normal" , #incomeVariable
  ## ## 						   "binary" , #parentalPsychiatricDiseaseBinary
  ## ## 						   ##"binary" , #interparentalViolenceBinary"
  ## ## 						   ##"binary" , #parentalSubstanceAbuseBinary
  ## ## 						   "binary" , #parentalAbuseAsChildBinary
  ## ## 						   "binary" , #oneForeignParentBinary"
  ## ## 						   ##"binary" , #familyNeedProtectionBinary
  ## ## 						   "normal" , #meanParentalAge
  ## ## 						   "binary") , #gTreatment 
  ## ## 				      ##I've used the history-variable to generate lagged variables for all time-varying covariates. Now, the covmodels need to be specified - use lag1_parishQuantileDifference100Euros to name the previous value of a variable in a formula. Reduce the following formulas to reduce complexity. If it makes theoretical sense, you could use lag1_example to predict the current value of example.
  ## ## 				      covparams = list(covmodels = c(parishQuantileDifference100Euros ~ 
  ## ## 									 lag1_parishQuantileDifference100Euros +
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 incomeVariable +
  ## ## 									 ##familyNeedProtectionBinary +
  ## ## 									 childAgeGroupAtInclusionBinary +
  ## ## 									 calendarTimeGroupAtInclusion +
  ## ## 									 meanParentalAge +
  ## ## 									 time , 
  ## ## 								     numberOfChildrenFactorReleveled ~
  ## ## 									 gTreatment +
  ## ## 									 lag1_numberOfChildrenFactorReleveled +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 oneForeignParentBinary +
  ## ## 									 childAgeGroupAtInclusionBinary +
  ## ## 									 calendarTimeGroupAtInclusion +
  ## ## 									 meanParentalAge +
  ## ## 									 time ,
  ## ## 								     reconstitutedFamily ~
  ## ## 									 gTreatment +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 ##lag1_interparentalViolenceBinary +
  ## ## 									 ##lag1_parentalSubstanceAbuseBinary +
  ## ## 									 parentalAbuseAsChildBinary +
  ## ## 									 oneForeignParentBinary +
  ## ## 									 ##familyNeedProtectionBinary +
  ## ## 									 childAgeGroupAtInclusionBinary +
  ## ## 									 calendarTimeGroupAtInclusion +
  ## ## 									 meanParentalAge +
  ## ## 									 time ,
  ## ## 								     familyEducationalLevelBinary ~
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 ##lag1_parentalSubstanceAbuseBinary +
  ## ## 									 parentalAbuseAsChildBinary +
  ## ## 									 oneForeignParentBinary +
  ## ## 									 ##familyNeedProtectionBinary +
  ## ## 									 meanParentalAge +
  ## ## 									 incomeVariable +
  ## ## 									 time ,
  ## ## 								     incomeVariable ~
  ## ## 									 gTreatment + 
  ## ## 									 lag1_numberOfChildrenFactorReleveled +
  ## ## 									 lag1_incomeVariable +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 ##lag1_parentalSubstanceAbuseBinary +
  ## ## 									 parentalAbuseAsChildBinary +
  ## ## 									 oneForeignParentBinary +
  ## ## 									 ##familyNeedProtectionBinary +
  ## ## 									 childAgeGroupAtInclusionBinary +
  ## ## 									 meanParentalAge +
  ## ## 									 time ,
  ## ## 								     parentalPsychiatricDiseaseBinary ~
  ## ## 									 gTreatment +
  ## ## 									 incomeVariable + 
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 ##lag1_interparentalViolenceBinary +
  ## ## 									 ##lag1_parentalSubstanceAbuseBinary +
  ## ## 									 parentalAbuseAsChildBinary +
  ## ## 									 ##familyNeedProtectionBinary +
  ## ## 									 meanParentalAge +
  ## ## 									 time ,
  ## ## 								     ## interparentalViolenceBinary ~
  ## ## 								     ##     lag1_parishQuantileDifference100Euros +
  ## ## 								     ##     lag1_reconstitutedFamily +
  ## ## 								     ##     lag1_familyEducationalLevelBinary +
  ## ## 								     ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     ##     lag1_interparentalViolenceBinary +
  ## ## 								     ##     lag1_parentalSubstanceAbuseBinary +
  ## ## 								     ##     parentalAbuseAsChildBinary +
  ## ## 								     ##     oneForeignParentBinary +
  ## ## 								     ##     familyNeedProtectionBinary +
  ## ## 								     ##     childAgeGroupAtInclusionBinary +
  ## ## 								     ##     calendarTimeGroupAtInclusion +
  ## ## 								     ##     meanParentalAge ,
  ## ## 								     ## parentalSubstanceAbuseBinary ~
  ## ## 								     ##     lag1_parishQuantileDifference100Euros +
  ## ## 								     ##     lag1_familyEducationalLevelBinary +
  ## ## 								     ##     lag1_parentalPsychiatricDiseaseBinary +
  ## ## 								     ##     lag1_parentalSubstanceAbuseBinary +
  ## ## 								     ##     parentalAbuseAsChildBinary +
  ## ## 								     ##     familyNeedProtectionBinary +
  ## ## 								     ##     calendarTimeGroupAtInclusion +
  ## ## 								     ##     meanParentalAge ,
  ## ## 								     parentalAbuseAsChildBinary ~
  ## ## 									 lag1_parentalAbuseAsChildBinary +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 time ,
  ## ## 								     oneForeignParentBinary ~
  ## ## 									 lag1_oneForeignParentBinary +
  ## ## 									 ##lag1_familyNeedProtectionBinary +
  ## ## 									 lag1_numberOfChildrenFactorReleveled +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 time ,
  ## ## 								     ## familyNeedProtectionBinary ~
  ## ## 								     ##     lag1_oneForeignParentBinary +
  ## ## 								     ##     lag1_familyNeedProtectionBinary +
  ## ## 								     ##     lag1_numberOfChildrenFactorReleveled +
  ## ## 								     ##     lag1_reconstitutedFamily ,
  ## ## 								     meanParentalAge ~
  ## ## 									 lag1_meanParentalAge +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 time ,
  ## ## 								     gTreatment ~
  ## ## 									 lag1_gTreatment +
  ## ## 									 lag1_reconstitutedFamily +
  ## ## 									 lag1_numberOfChildrenFactorReleveled +
  ## ## 									 incomeVariable +
  ## ## 									 lag1_familyEducationalLevelBinary +
  ## ## 									 lag1_parentalPsychiatricDiseaseBinary +
  ## ## 									 lag1_parentalAbuseAsChildBinary +
  ## ## 									 time)) ,
  ## ## 				      basecovs = c("childAgeGroupAtInclusionBinary" ,
  ## ## 						   "calendarTimeGroupAtInclusion") ,
  ## ## 				      ##nsimul = 10000 ,
  ## ## 				      seed = 25328621 , 
  ## ## 				      parallel = TRUE ,
  ## ## 				      ncores = 10 ,
  ## ## 				      threads = 15 ,
  ## ## 				      ##clusterID = "familyIndex" ,
  ## ## 				      nsamples = 0)
  ## ##     ##boot_diag = TRUE) 
  ## ##     gFitCharlson
  ## ## }

  ## ## ##Going through all the imputed datasets, fitting the model and printing the results:
  ## ## numberImputedDatasets <- c(1:5)
  ## ## sink("logFileCharlson2.txt" , split = TRUE)
  ## ## for (i in numberImputedDatasets) {
  ## ##     print(paste0("Started analysis of imputation " , i , ", time is " , Sys.time()))
  ## ##     gFitCharlson <- gModelFitter(i , paste0("resultsImputedDataset" , i , ".txt"))
  ## ##     print(paste0("Finished analysis of imputation " , i , ", time is " , Sys.time()))
  ## ##     cat(print(gFitCharlson) , print(summary(gFitCharlson)) , '\n')
  ## ## }
  ## ## sink()

  ## ##After this, assuming the results are not terribly different, take the log, find the mean and exp them back into RR - this is according to Stef Van Buuren's book section 5.2. 

  ## ##The code for joining the results:
  ## resultsTable <- data.table(RR = c(1.082015 , 1.083591 , 1.077847 , 1.081295 , 1.080086))
  ## resultsTable[ , logRR := log(RR)]
  ## resultAcrossImputations <- exp(resultsTable[ , mean(logRR)])


  ##Did minor changes in the specifications above and were disturbed to note that they made no difference at all. Turns out the model is surprisingly robust - there are changes, but after the 12th digit. Use print(resultObject$result , digits = 17) to see. 

  ##During error checking, statistical professor Erik Parner recommended reducing model complexity, as number of estimated parameters is 151, but number of events is 1270. Number of events/number of parameters should be more than 15. This situation happened as the size of the dataset was reduced because of imputation problems. Trying a reduced model (less than 127 parameters) to see if this changes anything:

  gModelFitter <- function (datasetNo , logFile) {
      ##This is done using one of the imputed datasets from above. 
      analysisDataset <- readAnalysisDatasetImputed(datasetNo)
      ##Do some pre-formatting to make sure the dataset looks as needed:
      ##Re-code the exposure and outcome:

      analysisDataset[jointCharlsonParents <= 1 , gTreatment := 1]
      analysisDataset[jointCharlsonParents > 1 , gTreatment := 0]
      analysisDataset[outcomePhysicalAbuse > 0 , anyPhysicalAbuse := 1]
      analysisDataset[is.na(anyPhysicalAbuse) , anyPhysicalAbuse := 0]
      ##The next line if this is an end of follow-up outcome:
      ##analysisDataset[time < 214 & anyPhysicalAbuse != 1 , anyPhysicalAbuse := NA]
      analysisDataset[deathCensoring == date & outcomePhysicalAbuse == 0 , deathCompetingEvent := 1]
      analysisDataset[deathCompetingEvent == 1 , anyPhysicalAbuse := NA]

      ##Set the order of data correctly:
      setorder(analysisDataset , pnr , time)

      ##Looking at the incomeVariable, trying to make it fit for something linear - it actually looks quite normally distributed, see the graph below, but with some very long tails. I will leave it as it is for now, unless advised otherwise by the statistician. 
      ##ggplot() + geom_histogram(data = analysisDataset , aes(x = incomeVariable) , breaks = seq(from = -250 , to = 500, by = 50))

      ##analysisDataset[ , logIncomeVariable := log(incomeVariable)]
      ##Recoding binary factors as a binary numeric variables- thus updating after the imputations:
      analysisDataset[familyEducationalLevelReleveled == "Primary or secondary education" , familyEducationalLevelBinary := 0]
      analysisDataset[familyEducationalLevelReleveled == "Tertiary education or higher" , familyEducationalLevelBinary := 1]
      analysisDataset[oneForeignParent == "No foreign parents" , oneForeignParentBinary := 0]
      analysisDataset[oneForeignParent == "One or more foreign parents" , oneForeignParentBinary := 1]
      ## analysisDataset[familyNeedProtection == "Not in need of protection" , familyNeedProtectionBinary := 0]
      ## analysisDataset[familyNeedProtection == "In need of protection" , familyNeedProtectionBinary := 1]
      ## analysisDataset[parentalPsychiatricDisease == "No psychiatric disease" , parentalPsychiatricDiseaseBinary := 0]
      ## analysisDataset[parentalPsychiatricDisease == "Any psychiatric disease" , parentalPsychiatricDiseaseBinary := 1]
      ## analysisDataset[parentalAbuseAsChildReleveled == "No maltreatment or neglect" , parentalAbuseAsChildBinary := 0]
      ## analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, one or both parents" , parentalAbuseAsChildBinary := 1]
      analysisDataset[interparentalViolence == "No interparental violence" , interparentalViolenceBinary := 0]
      analysisDataset[interparentalViolence == "Interparental violence" , interparentalViolenceBinary := 1]
      analysisDataset[parentalSubstanceAbuse == "No parental substance abuse" , parentalSubstanceAbuseBinary := 0]
      analysisDataset[parentalSubstanceAbuse == "Parental substance abuse" , parentalSubstanceAbuseBinary := 1]



      ##childAgeGroup is supposed to capture age at inclusion - but it is obviously not constant, as it currently changes with age. Changing this, also for time period:

      tempAge <- unique(analysisDataset[time == 0 , .(pnr , childAgeGroup)])
      analysisDataset[tempAge , on = "pnr" , childAgeGroupAtInclusion := i.childAgeGroup]
      tempCalendarTime <- unique(analysisDataset[time == 0 , .(pnr , calendarTimeGroup)])
      analysisDataset[tempCalendarTime , on = "pnr" , calendarTimeGroupAtInclusion  := i.calendarTimeGroup]

      ##Looking for errors - recoding childAgeGroupAtInclusion as a binary:
      analysisDataset[childAgeGroupAtInclusion == "Child 0-6 years old" , childAgeGroupAtInclusionBinary := 0]  
      analysisDataset[childAgeGroupAtInclusion == "Child 7-18 years old" , childAgeGroupAtInclusionBinary := 1]

      ##I forgot to factorize the new number of children-variable earlier:
      analysisDataset[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

      ##As the cuts above produces small cells in this draw of 50.000 children, the variable is redefined with fewer levels here and used in the second definition of the model (see below):

      analysisDataset[ , numberOfChildrenFactorReleveled :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three children or more"
					    ))]

      ##Proceeding with the actual fitting: 
      gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
					outcome_name = "anyPhysicalAbuse" ,
					compevent_name = "deathCompetingEvent" ,
					time_points = 35 ,
					time_name = "time" ,
					ref_int = 2 ,
					##This is a straight linear model - is that okay? I will get an awful lot of parameters if I start putting in products.
					##I think what I am asking is to compare people who are always not ill with people who are always ill - need to confirm.
					intvars = list("gTreatment" , "gTreatment") , 
					interventions = list(list(c(static , rep(0 , 35))) ,
							     list(c(static , rep(1 , 35)))) , 
					int_descript = c("Never treat" , "Always treat") , 
					ymodel = anyPhysicalAbuse ~ gTreatment +
					    time +
					    parishQuantileDifference100Euros +
					    numberOfChildrenFactorReleveled +
					    reconstitutedFamily +
					    familyEducationalLevelBinary +
					    incomeVariable +
					    parentalPsychiatricDiseaseBinary +
					    ##interparentalViolenceBinary +
					    ##parentalSubstanceAbuseBinary +
					    parentalAbuseAsChildBinary +
					    oneForeignParentBinary +
					    ##familyNeedProtectionBinary +
					    childAgeGroupAtInclusionBinary +
					    calendarTimeGroupAtInclusion +
					    meanParentalAge ,
					compevent_model = deathCompetingEvent ~ gTreatment +
					    time +
					    parishQuantileDifference100Euros +
					    numberOfChildrenFactorReleveled +
					    reconstitutedFamily +
					    familyEducationalLevelBinary +
					    incomeVariable +
					    parentalPsychiatricDiseaseBinary +
					    ##interparentalViolenceBinary +
					    ##parentalSubstanceAbuseBinary +
					    parentalAbuseAsChildBinary +
					    oneForeignParentBinary +
					    ##familyNeedProtectionBinary +
					    childAgeGroupAtInclusionBinary +
					    calendarTimeGroupAtInclusion +
					    meanParentalAge ,
					id = "pnr" ,
					covnames = c("parishQuantileDifference100Euros" ,
						     "numberOfChildrenFactorReleveled" ,
						     "reconstitutedFamily" ,
						     "familyEducationalLevelBinary" ,
						     "incomeVariable" ,
						     "parentalPsychiatricDiseaseBinary" ,
						     ##"interparentalViolenceBinary" ,
						     ##"parentalSubstanceAbuseBinary" ,  
						     "parentalAbuseAsChildBinary" ,
						     "oneForeignParentBinary" ,
						     ##"familyNeedProtectionBinary" ,
						     "meanParentalAge" ,
						     "gTreatment") ,
					histories = c(lagged) ,
					histvars = list(c("parishQuantileDifference100Euros" ,
							  "numberOfChildrenFactorReleveled" ,
							  "reconstitutedFamily" ,
							  "familyEducationalLevelBinary" ,
							  "incomeVariable" ,
							  "parentalPsychiatricDiseaseBinary" ,
							  ##"interparentalViolenceBinary" ,
							  ##"parentalSubstanceAbuseBinary" ,
							  "parentalAbuseAsChildBinary" ,
							  "oneForeignParentBinary" , 
							  ##"familyNeedProtectionBinary" ,
							  "meanParentalAge" ,
							  "gTreatment")) , ##Remember that for parishQuantileDifference100Euros and incomeVariable they are actually already lagged - use only in special cases as lagged.
					##May I look at distributions  in the data here when I set these?
					covtypes = c("normal" , #parishQuantileDifference100Euros
						     "categorical" , #numberOfChildrenFactorReleveled
						     "categorical" , #reconstitutedFamily
						     "binary" , #education
						     "normal" , #incomeVariable
						     "binary" , #parentalPsychiatricDiseaseBinary
						     ##"binary" , #interparentalViolenceBinary"
						     ##"binary" , #parentalSubstanceAbuseBinary
						     "binary" , #parentalAbuseAsChildBinary
						     "binary" , #oneForeignParentBinary"
						     ##"binary" , #familyNeedProtectionBinary
						     "normal" , #meanParentalAge
						     "binary") , #gTreatment 
					##I've used the history-variable to generate lagged variables for all time-varying covariates. Now, the covmodels need to be specified - use lag1_parishQuantileDifference100Euros to name the previous value of a variable in a formula. Reduce the following formulas to reduce complexity. If it makes theoretical sense, you could use lag1_example to predict the current value of example.
					covparams = list(covmodels = c(parishQuantileDifference100Euros ~ 
									   lag1_parishQuantileDifference100Euros +
									   lag1_familyEducationalLevelBinary +
									   incomeVariable +
									   ##familyNeedProtectionBinary +
									   ##childAgeGroupAtInclusionBinary +
									   ##calendarTimeGroupAtInclusion +
									   ##meanParentalAge +
									   time , 
								       numberOfChildrenFactorReleveled ~
									   gTreatment +
									   lag1_numberOfChildrenFactorReleveled +
									   lag1_reconstitutedFamily +
									   ##lag1_familyEducationalLevelBinary +
									   ##lag1_parentalPsychiatricDiseaseBinary +
									   ##oneForeignParentBinary +
									   childAgeGroupAtInclusionBinary +
									   calendarTimeGroupAtInclusion +
									   meanParentalAge +
									   time ,
								       reconstitutedFamily ~
									   gTreatment +
									   lag1_reconstitutedFamily +
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_interparentalViolenceBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   childAgeGroupAtInclusionBinary +
									   ##calendarTimeGroupAtInclusion +
									   ##meanParentalAge +
									   time ,
								       familyEducationalLevelBinary ~
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   ##parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   ##meanParentalAge +
									   ##incomeVariable +
									   time ,
								       incomeVariable ~
									   gTreatment + 
									   ##lag1_numberOfChildrenFactorReleveled +
									   lag1_incomeVariable +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   ##childAgeGroupAtInclusionBinary +
									   meanParentalAge +
									   time ,
								       parentalPsychiatricDiseaseBinary ~
									   gTreatment +
									   incomeVariable + 
									   ##lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_interparentalViolenceBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   ##familyNeedProtectionBinary +
									   ##meanParentalAge +
									   time ,
								       ## interparentalViolenceBinary ~
								       ##     lag1_parishQuantileDifference100Euros +
								       ##     lag1_reconstitutedFamily +
								       ##     lag1_familyEducationalLevelBinary +
								       ##     lag1_parentalPsychiatricDiseaseBinary +
								       ##     lag1_interparentalViolenceBinary +
								       ##     lag1_parentalSubstanceAbuseBinary +
								       ##     parentalAbuseAsChildBinary +
								       ##     oneForeignParentBinary +
								       ##     familyNeedProtectionBinary +
								       ##     childAgeGroupAtInclusionBinary +
								       ##     calendarTimeGroupAtInclusion +
								       ##     meanParentalAge ,
								       ## parentalSubstanceAbuseBinary ~
								       ##     lag1_parishQuantileDifference100Euros +
								       ##     lag1_familyEducationalLevelBinary +
								       ##     lag1_parentalPsychiatricDiseaseBinary +
								       ##     lag1_parentalSubstanceAbuseBinary +
								       ##     parentalAbuseAsChildBinary +
								       ##     familyNeedProtectionBinary +
								       ##     calendarTimeGroupAtInclusion +
								       ##     meanParentalAge ,
								       parentalAbuseAsChildBinary ~
									   lag1_parentalAbuseAsChildBinary +
									   lag1_reconstitutedFamily +
									   time ,
								       oneForeignParentBinary ~
									   lag1_oneForeignParentBinary +
									   ##lag1_familyNeedProtectionBinary +
									   ##lag1_numberOfChildrenFactorReleveled +
									   lag1_reconstitutedFamily +
									   time ,
								       ## familyNeedProtectionBinary ~
								       ##     lag1_oneForeignParentBinary +
								       ##     lag1_familyNeedProtectionBinary +
								       ##     lag1_numberOfChildrenFactorReleveled +
								       ##     lag1_reconstitutedFamily ,
								       meanParentalAge ~
									   lag1_meanParentalAge +
									   lag1_reconstitutedFamily +
									   time ,
								       gTreatment ~
									   lag1_gTreatment +
									   lag1_reconstitutedFamily +
									   lag1_numberOfChildrenFactorReleveled +
									   incomeVariable +
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   lag1_parentalAbuseAsChildBinary +
									   time)) ,
					basecovs = c("childAgeGroupAtInclusionBinary" ,
						     "calendarTimeGroupAtInclusion") ,
					##nsimul = 50000 ,
					seed = 25328621 , 
					parallel = TRUE ,
					ncores = 10 ,
					threads = 15 ,
					##clusterID = "familyIndex" ,
					nsamples = 0)
      ##boot_diag = TRUE) 
      gFitCharlson
  }


  ##Going through all the imputed datasets, fitting the model and printing the results:
  numberImputedDatasets <- c(1:1)
  sink("logFileCharlson2Parsimonious.txt" , split = TRUE)
  for (i in numberImputedDatasets) {
      print(paste0("Started analysis of imputation " , i , ", time is " , Sys.time()))
      gFitCharlson <- gModelFitter(i , paste0("resultsImputedDataset" , i , ".txt"))
      print(paste0("Finished analysis of imputation " , i , ", time is " , Sys.time()))
      cat(print(gFitCharlson) , print(summary(gFitCharlson)) , '\n')
  }
  sink()

  ##This model has 126 parameters and gives the same estimate down to the sixth digit and possibly beyond. For simplicity, this will be adopted as the main model and will be the one used for attempted bootstrapping.

  resultsTable <- data.table(RR = c(1.082015 , 1.083591 , 1.077847 , 1.081295 , 1.080086))
  resultsTable[ , logRR := log(RR)]
  resultAcrossImputations <- exp(resultsTable[ , mean(logRR)])
#+end_src
** Code for descriptive table of full dataset
#+begin_src R :session rsession :results output :exports both
  ##Assuming analysisDataset is loaded:
  ##Temporary load to test the code:
  ## readAnalysisDatasetHalfyearly <- function() {
  ##     analysisDatasetHalfyearlyReduced <-
  ## 	fread("analysisDatasetHalfyearly.csv" ,
  ## 	      colClasses = c("pnr" = "character" ,
  ## 			     "date" = "Date" ,
  ## 			     "currentParent2" = "character" ,
  ## 			     "currentParent1" = "character" ,
  ## 			     "reconstitutedFamily" = "factor" ,
  ## 			     "studyEntry" = "Date" ,
  ## 			     "ageCensoring" = "Date" ,
  ## 			     "deathCensoring" = "Date" ,
  ## 			     "emigrationCensoring" = "Date" ,
  ## 			     "meanParentalAge" = "numeric" ,
  ## 			     "birthDate" = "Date" ,
  ## 			     "childAge" = "numeric" ,
  ## 			     "hypertensionGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "hypertensionGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "dyslipidemiaGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "dyslipidemiaGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "atrialFibrillationGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "atrialFibrillationGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "heartFailureGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "heartFailureGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "peripheralArteryOcclusiveGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "peripheralArteryOcclusiveGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "strokeGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "strokeGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "diabetesMellitusGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "diabetesMellitusGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "thyroidDisorderGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "thyroidDisorderGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "goutGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "goutGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "allergyGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "allergyGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "ulcerChronicGastritisGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "ulcerChronicGastritisGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "chronicLiverDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "chronicLiverDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "inflammatoryBowelDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "inflammatoryBowelDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "chronicKidneyDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "chronicKidneyDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "prostateDisordersGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "prostateDisordersGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "connectiveTissueDisordersGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "connectiveTissueDisordersGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "osteoporosisGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "osteoporosisGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "anemiasGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "anemiasGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "cancerGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "cancerGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "visionProblemGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "visionProblemGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "migraineGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "migraineGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "epilepsyGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "epilepsyGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "parkinsonsDiseaseGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "parkinsonsDiseaseGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "multipleSclerosisGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "multipleSclerosisGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "neuropathiesGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "neuropathiesGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "anorexiaBulimiaGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "anorexiaBulimiaGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "personalityDisorderGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "personalityDisorderGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "dementiaGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "dementiaGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "otherGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "otherGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "pretermBirthGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "pretermBirthGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "acuteCaesarianSectionGroupDiagCurrentParent1" = "numeric" ,
  ## 			     "acuteCaesarianSectionGroupDiagCurrentParent2" = "numeric" ,
  ## 			     "aidsHivCharlsonCurrentParent1" = "numeric" ,
  ## 			     "aidsHivCharlsonCurrentParent2" = "numeric" ,
  ## 			     "anyMalignancyCharlsonCurrentParent1" = "numeric" ,
  ## 			     "anyMalignancyCharlsonCurrentParent2" = "numeric" ,
  ## 			     "cerebrovascularDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "cerebrovascularDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "dementiaCharlsonCurrentParent1" = "numeric" ,
  ## 			     "dementiaCharlsonCurrentParent2" = "numeric" ,
  ## 			     "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
  ## 			     "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
  ## 			     "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
  ## 			     "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
  ## 			     "heartFailureCharlsonCurrentParent1" = "numeric" ,
  ## 			     "heartFailureCharlsonCurrentParent2" = "numeric" ,
  ## 			     "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
  ## 			     "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
  ## 			     "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
  ## 			     "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
  ## 			     "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
  ## 			     "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
  ## 			     "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
  ## 			     "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
  ## 			     "alcoholAbuseCurrentParent1" = "numeric" ,
  ## 			     "alcoholAbuseCurrentParent2" = "numeric" ,
  ## 			     "substanceAbuseCurrentParent1" = "numeric" ,
  ## 			     "substanceAbuseCurrentParent2" = "numeric" ,
  ## 			     "unspecificEverCurrentParent1" = "numeric" ,
  ## 			     "unspecificEverCurrentParent2" = "numeric" , 
  ## 			     "unspecificTwoYearCurrentParent1" = "numeric" , 
  ## 			     "unspecificTwoYearCurrentParent2" = "numeric" , 
  ## 			     "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "allergyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "allergyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "allergyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "allergyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "osteoporosisGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "osteoporosisGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "osteoporosisGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "osteoporosisGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "painfulConditionGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "painfulConditionGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "painfulConditionGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "painfulConditionGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "migraineGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "migraineGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "migraineGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "migraineGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "epilepsyGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "epilepsyGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "epilepsyGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "epilepsyGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "dementiaGroupLmdbCurrentParent1LmdbTemp" = "numeric" ,
  ## 			     "dementiaGroupLmdbCurrentParent1LmdbTotal" = "numeric" ,
  ## 			     "dementiaGroupLmdbCurrentParent2LmdbTemp" = "numeric" ,
  ## 			     "dementiaGroupLmdbCurrentParent2LmdbTotal" = "numeric" ,
  ## 			     "jointCharlsonParents" = "numeric" ,
  ## 			     "outcomePhysicalAbuse" = "numeric" ,
  ## 			     "interparentalViolence" = "factor" ,
  ## 			     "familyEducationalLevel" = "factor" ,
  ## 			     "parentalAbuseAsChild" = "factor" ,
  ## 			     "oneForeignParent" = "factor" ,
  ## 			     "familyNeedProtection" = "factor" ,
  ## 			     "parentalPsychiatricDisease" = "factor" ,
  ## 			     "parentalSubstanceAbuse" = "factor" ,
  ## 			     "calendarTimeGroup" = "factor" ,
  ## 			     "childAgeGroup" = "factor" ,
  ## 			     "parentalAgeGroup" = "factor" ,
  ## 			     "incomeVariable" = "numeric" ,
  ## 			     "parishQuantileDifference100Euros" = "numeric" ,
  ## 			     "time" = "numeric" ,
  ## 			     "familyEducationalLevelReleveled" = "factor" ,
  ## 			     "parentalAbuseAsChildReleveled" = "factor" ,
  ## 			     "parentalAgeGroupReleveled"  = "factor" ,
  ## 			     "gTreatment" = "numeric" ,
  ## 			     "anyPhysicalAbuse" = "numeric" ,
  ## 			     "familyEducationalLevelBinary" = "numeric"  ,
  ## 			     "oneForeignParentBinary" = "numeric" ,
  ## 			     "familyNeedProtectionBinary" = "numeric" ,
  ## 			     "parentalPsychiatricDiseaseBinary" = "numeric" ,
  ## 			     "parentalAbuseAsChildBinary" = "numeric" ,
  ## 			     "childAgeGroupAtInclusion" = "factor" ,
  ## 			     "calendarTimeGroupAtInclusion" = "factor" ,
  ## 			     "childAgeGroupAtInclusionBinary" = "numeric"  ,
  ## 			     "familyIndex" = "numeric" ,
  ## 			     "newNoOfChildren" = "numeric"))

  ##     analysisDatasetHalfyearlyReduced[ , familyEducationalLevel :=
  ## 			   factor(familyEducationalLevel ,
  ## 				  levels = c("Primary education" ,
  ## 					     "Secondary education" ,
  ## 					     "Tertiary education or higher"))]

  ##     analysisDatasetHalfyearlyReduced[ , reconstitutedFamily :=
  ## 			   factor(
  ## 			       reconstitutedFamily ,
  ## 			       levels = c("Living with biological parent(s)" ,
  ## 					  "Living with one or more unrelated adults" ,
  ## 					  "Adopted or in foster care"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalPsychiatricDisease :=
  ## 			   factor(parentalPsychiatricDisease ,
  ## 				  levels = c("No psychiatric disease" ,
  ## 					     "Any psychiatric disease"))]

  ##     analysisDatasetHalfyearlyReduced[ ,
  ## 		    interparentalViolence :=
  ## 			factor(interparentalViolence ,
  ## 			       levels = c("No interparental violence" ,
  ## 					  "Interparental violence"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalSubstanceAbuse :=
  ## 			   factor(parentalSubstanceAbuse ,
  ## 				  levels = c("No parental substance abuse" ,
  ## 					     "Parental substance abuse"))]

  ##     analysisDatasetHalfyearlyReduced[ , calendarTimeGroup :=
  ## 			   factor(calendarTimeGroup ,
  ## 				  levels = c("1997-2002" ,
  ## 					     "2003-2009" ,
  ## 					     "2010-2018"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalAbuseAsChild :=
  ## 			   factor(parentalAbuseAsChild ,
  ## 				  levels = c("No maltreatment or neglect" ,
  ## 					     "Maltreatment or neglect, one parent" ,
  ## 					     "Maltreatment or neglect, both parents"))]

  ##     analysisDatasetHalfyearlyReduced[ , oneForeignParent :=
  ## 			   factor(oneForeignParent ,
  ## 				  levels = c("No foreign parents" ,
  ## 					     "One or more foreign parents"))]

  ##     analysisDatasetHalfyearlyReduced[ , familyNeedProtection :=
  ## 			   factor(familyNeedProtection ,
  ## 				  levels = c("Not in need of protection" ,
  ## 					     "In need of protection"))]

  ##     analysisDatasetHalfyearlyReduced[ , childAgeGroup :=
  ## 			   factor(childAgeGroup , 
  ## 				  levels = c("Child 0-6 years old" ,
  ## 					     "Child 7-18 years old"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalAgeGroup :=
  ## 			   factor(parentalAgeGroup , 
  ## 				  levels = c("Mean parental age 25 or less" ,
  ## 					     "Mean parental age >25-35" ,
  ## 					     "Mean parental age >35-65" ,
  ## 					     "Mean parental age >65-100"))]
  ##     analysisDatasetHalfyearlyReduced[ , familyEducationalLevelReleveled :=
  ## 			   factor(familyEducationalLevelReleveled ,
  ## 				  levels = c("Primary or secondary education" ,
  ## 					     "Tertiary education or higher"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalAbuseAsChildReleveled :=
  ## 			   factor(parentalAbuseAsChildReleveled ,
  ## 				  levels = c("No maltreatment or neglect" ,
  ## 					     "Maltreatment or neglect, one or both parents"))]

  ##     analysisDatasetHalfyearlyReduced[ , parentalAgeGroupReleveled :=
  ## 			   factor(parentalAgeGroupReleveled ,
  ## 				  levels = c("Mean parental age 25 or less" ,
  ## 					     "Mean parental age >25-35" ,
  ## 					     "Mean parental age >35"))]

  ##     analysisDatasetHalfyearlyReduced[ , childAgeGroupAtInclusion :=
  ## 			   factor(childAgeGroupAtInclusion ,
  ## 				  levels = c("Child 0-6 years old" ,
  ## 					     "Child 7-18 years old"))]

  ##     analysisDatasetHalfyearlyReduced[ , calendarTimeGroupAtInclusion :=
  ## 			   factor(calendarTimeGroupAtInclusion ,
  ## 				  levels = c("1997-2002" ,
  ## 					     "2003-2009" ,
  ## 					     "2010-2018"))]


  ##     return(analysisDatasetHalfyearlyReduced)
  ## }


  ##I forgot to factorize newNoOfChildren above - making up for this here:

  ##Remember to make sure this variable exist:
  analysisDataset[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]

  ##Making a table split on exposure
  makeTableCharacteristics <- function (dataset , nameOfDatasetFileIncludingExtension , severalLinesForEachIndividual = TRUE) {
      datasetForSummary <- get(dataset)
      ##This is to avoid collapsing a dataset that has already been collapsed for survival analysis:
      if (severalLinesForEachIndividual == TRUE) {
	  baselineTable <- datasetForSummary[time == 0]
      } else {
	  baselineTable <- datasetForSummary
      }
      characteristicsTable <- data.table(Characteristics = c("Child age, y, mean (SD)" ,
							     "Calendar year group, n (%)" ,
							     "1997-2002" ,
							     "2003-2009" ,
							     "2010-2018" ,
							     "Mean parental age, y, mean (SD)" ,
							     "Missing entries" ,
							     "Neighborhood resources, thousand Euros, mean (SD)" ,
							     "Missing entries" ,
							     "Number of children in family, n (%)" ,
							     "One child" ,
							     "Two children" ,
							     "Three to five children" ,
							     "Six or more children" ,
							     "Abuse of parent as a child, n (%)" ,
							     "No maltreatment or neglect" ,
							     "Maltreatment or neglect, one or both parents" ,
							     "Immigration background (ethnicity), n, (%)" ,
							     "No foreign parents" ,
							     "One or more foreign parents" ,
							     "Missing entries" ,
							     "Status as refugee, n, (%)" ,
							     "Not in need of protection" ,
							     "In need of protection" ,
							     ##"Missing entries" , only switching off to avoid problems with too small cells
							     "Reconstituted family, n, (%)" ,
							     "Living with biological parent(s)" ,         
							     "Living with one or more unrelated adults" , 
							     "Adopted or in foster care" ,
							     "Missing entries" , 
							     "Family highest education, n, (%)" ,
							     "Primary or secondary education" ,
							     "Tertiary education or higher" ,
							     "Missing entries" ,
							     "Income, thousand Euros, mean (SD)" ,
							     "Missing entries" ,
							     "Parental psychiatric disease, n, (%)" ,
							     "No psychiatric disease" ,
							     "Any psychiatric disease except substance abuse" , 
							     "Inter-parental violence, n, (%)" ,
							     "No interparental violence" ,
							     "Interparental violence" ,
							     "Parental substance abuse, n, (%)" ,
							     "No parental substance abuse" ,
							     "Any parental substance abuse") ,
					 JointCharlsonScoreLessThan2 = c(baselineTable[jointCharlsonParents <= 1 ,
										       paste0(round(mean(childAge) , 2) ,
											      " (" ,
											      round(sd(childAge) , 2) ,
											      ")")] , ##"Child age, y, mean (SD)" ,
									 "" , ##"Calendar year group, n (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(calendarTimeGroup)[1] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[1] , 2) ,
											      "%)")] , ##"1997-2002" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(calendarTimeGroup)[2] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[2] , 2) ,
											      "%)")] , ##"2003-2009" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(calendarTimeGroup)[3] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[3] , 2) ,
											      "%)")] , ##"2010-2018" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(round(mean(meanParentalAge , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(meanParentalAge , na.rm = TRUE) , 2) ,
											      ")")] , ##"Mean parental age, y, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(meanParentalAge) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(meanParentalAge) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ## , ##"Missing entries" , 
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(round(mean(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
											      ")")] , ##"Neighborhood resources, Euros, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(parishQuantileDifference100Euros) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(parishQuantileDifference100Euros) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Number of children in family, n (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(numberOfChildrenFactor)[1] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[1] , 2) ,
											      "%)")] , ##"One child" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(numberOfChildrenFactor)[2] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[2] , 2) ,
											      "%)")] , ##"Two children" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(numberOfChildrenFactor)[3] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[3] , 2) ,
											      "%)")] , ##"Three to five children" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(numberOfChildrenFactor)[4] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[4] , 2) ,
											      "%)")] , ##"Six or more children" ,
									 "" , ##"Abuse of parent as a child, n (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalAbuseAsChildReleveled)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalAbuseAsChildReleveled))[1] , 2) ,
											      "%)")] , ##"No maltreatment or neglect" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalAbuseAsChildReleveled)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalAbuseAsChildReleveled))[2] , 2) ,
											      "%)")] , ##"Maltreatment or neglect, one or both parents" ,
									 "" , ##"Immigration background (ethnicity), n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(oneForeignParent)[1] ,
											      " (" ,
											      round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No foreign parents" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(oneForeignParent)[2] ,
											      " (" ,
											      round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"One or more foreign parents" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(oneForeignParent) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(oneForeignParent) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Status as refugee, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(familyNeedProtection)[1] ,
											      " (" ,
											      round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Not in need of protection" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(familyNeedProtection)[2] ,
											      " (" ,
											      round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"In need of protection" ,
									 ## paste0(baselineTable[jointCharlsonParents <= 1 &
									 ##                      is.na(familyNeedProtection) , .N] ,
									 ##        " (" ,
									 ##        round(100*baselineTable[jointCharlsonParents <= 1 &
									 ##                                is.na(familyNeedProtection) , .N]/
									 ##              baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Reconstituted family, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(reconstitutedFamily)[1] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Living with biological parent(s)" ,         
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(reconstitutedFamily)[2] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Living with one or more unrelated adults" , 
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(reconstitutedFamily)[3] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[3] , 2) ,
											      "%)")] , ##"Adopted or in foster care" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(reconstitutedFamily) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(reconstitutedFamily) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" , 
									 "" , ##"Family highest education, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(familyEducationalLevelReleveled)[1] ,
											      " (" ,
											      round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Primary or secondary education" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(familyEducationalLevelReleveled)[2] ,
											      " (" ,
											      round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Tertiary education or higher" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(familyEducationalLevelReleveled) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(familyEducationalLevelReleveled) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(round(mean(incomeVariable , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(incomeVariable , na.rm = TRUE) , 2) ,
											      ")")] , ##"Income, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents <= 1 &
											      is.na(incomeVariable) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents <= 1 &
													is.na(incomeVariable) , .N]/
										      baselineTable[jointCharlsonParents <= 1 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Parental psychiatric disease, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalPsychiatricDisease)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No psychiatric disease" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalPsychiatricDisease)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Any psychiatric disease except substance abuse" , 
									 "" , ##"Inter-parental violence, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(interparentalViolence)[1] ,
											      " (" ,
											      round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No interparental violence" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(interparentalViolence)[2] ,
											      " (" ,
											      round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Interparental violence" ,
									 "" , ##"Parental substance abuse, n, (%)" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalSubstanceAbuse)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No parental substance abuse" ,
									 baselineTable[jointCharlsonParents <= 1 ,
										       paste0(table(parentalSubstanceAbuse)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[2] , 2) ,
											      "%)")]) ,
					 JointCharlsonScoreMoreThan2 = c(baselineTable[jointCharlsonParents >= 2 ,
										       paste0(round(mean(childAge) , 2) ,
											      " (" ,
											      round(sd(childAge) , 2) ,
											      ")")] , ##"Child age, y, mean (SD)" ,
									 "" , ##"Calendar year group, n (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(calendarTimeGroup)[1] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[1] , 2) ,
											      "%)")] , ##"1997-2002" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(calendarTimeGroup)[2] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[2] , 2) ,
											      "%)")] , ##"2003-2009" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(calendarTimeGroup)[3] ,
											      " (" ,
											      round(100*prop.table(table(calendarTimeGroup))[3] , 2) ,
											      "%)")] , ##"2010-2018" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(round(mean(meanParentalAge , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(meanParentalAge , na.rm = TRUE) , 2) ,
											      ")")] , ##"Mean parental age, y, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(meanParentalAge) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(meanParentalAge) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ## , ##"Missing entries" , 
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(round(mean(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
											      ")")] , ##"Neighborhood resources, Euros, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(parishQuantileDifference100Euros) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(parishQuantileDifference100Euros) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Number of children in family, n (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(numberOfChildrenFactor)[1] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[1] , 2) ,
											      "%)")] , ##"One child" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(numberOfChildrenFactor)[2] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[2] , 2) ,
											      "%)")] , ##"Two children" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(numberOfChildrenFactor)[3] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[3] , 2) ,
											      "%)")] , ##"Three to five children" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(numberOfChildrenFactor)[4] ,
											      " (" ,
											      round(100*prop.table(table(numberOfChildrenFactor))[4] , 2) ,
											      "%)")] , ##"Six or more children" ,
									 "" , ##"Abuse of parent as a child, n (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalAbuseAsChildReleveled)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalAbuseAsChildReleveled))[1] , 2) ,
											      "%)")] , ##"No maltreatment or neglect" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalAbuseAsChildReleveled)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalAbuseAsChildReleveled))[2] , 2) ,
											      "%)")] , ##"Maltreatment or neglect, one or both parents" ,
									 "" , ##"Immigration background (ethnicity), n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(oneForeignParent)[1] ,
											      " (" ,
											      round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No foreign parents" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(oneForeignParent)[2] ,
											      " (" ,
											      round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"One or more foreign parents" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(oneForeignParent) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(oneForeignParent) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Status as refugee, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(familyNeedProtection)[1] ,
											      " (" ,
											      round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Not in need of protection" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(familyNeedProtection)[2] ,
											      " (" ,
											      round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"In need of protection" ,
									 ## paste0(baselineTable[jointCharlsonParents >= 2 &
									 ##                      is.na(familyNeedProtection) , .N] ,
									 ##        " (" ,
									 ##        round(100*baselineTable[jointCharlsonParents >= 2 &
									 ##                                is.na(familyNeedProtection) , .N]/
									 ##              baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Reconstituted family, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(reconstitutedFamily)[1] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Living with biological parent(s)" ,         
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(reconstitutedFamily)[2] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Living with one or more unrelated adults" , 
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(reconstitutedFamily)[3] ,
											      " (" ,
											      round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[3] , 2) ,
											      "%)")] , ##"Adopted or in foster care" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(reconstitutedFamily) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(reconstitutedFamily) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" , 
									 "" , ##"Family highest education, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(familyEducationalLevelReleveled)[1] ,
											      " (" ,
											      round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"Primary or secondary education" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(familyEducationalLevelReleveled)[2] ,
											      " (" ,
											      round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Tertiary education or higher" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(familyEducationalLevelReleveled) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(familyEducationalLevelReleveled) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(round(mean(incomeVariable , na.rm = TRUE) , 2) ,
											      " (" ,
											      round(sd(incomeVariable , na.rm = TRUE) , 2) ,
											      ")")] , ##"Income, mean (SD)" ,
									 paste0(baselineTable[jointCharlsonParents >= 2 &
											      is.na(incomeVariable) , .N] ,
										" (" ,
										round(100*baselineTable[jointCharlsonParents >= 2 &
													is.na(incomeVariable) , .N]/
										      baselineTable[jointCharlsonParents >= 2 , .N] , 2) , "%)") , ##"Missing entries" ,
									 "" , ##"Parental psychiatric disease, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalPsychiatricDisease)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No psychiatric disease" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalPsychiatricDisease)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Any psychiatric disease except substance abuse" , 
									 "" , ##"Inter-parental violence, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(interparentalViolence)[1] ,
											      " (" ,
											      round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No interparental violence" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(interparentalViolence)[2] ,
											      " (" ,
											      round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[2] , 2) ,
											      "%)")] , ##"Interparental violence" ,
									 "" , ##"Parental substance abuse, n, (%)" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalSubstanceAbuse)[1] ,
											      " (" ,
											      round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[1] , 2) ,
											      "%)")] , ##"No parental substance abuse" ,
									 baselineTable[jointCharlsonParents >= 2 ,
										       paste0(table(parentalSubstanceAbuse)[2] ,
											      " (" ,
											      round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[2] , 2) ,
											      "%)")]) ,
					 Total = c(baselineTable[ ,
								 paste0(round(mean(childAge) , 2) ,
									" (" ,
									round(sd(childAge) , 2) ,
									")")] , ##"Child age, y, mean (SD)" ,
						   "" , ##"Calendar year group, n (%)" ,
						   baselineTable[ ,
								 paste0(table(calendarTimeGroup)[1] ,
									" (" ,
									round(100*prop.table(table(calendarTimeGroup))[1] , 2) ,
									"%)")] , ##"1997-2002" ,
						   baselineTable[ ,
								 paste0(table(calendarTimeGroup)[2] ,
									" (" ,
									round(100*prop.table(table(calendarTimeGroup))[2] , 2) ,
									"%)")] , ##"2003-2009" ,
						   baselineTable[ ,
								 paste0(table(calendarTimeGroup)[3] ,
									" (" ,
									round(100*prop.table(table(calendarTimeGroup))[3] , 2) ,
									"%)")] , ##"2010-2018" ,
						   baselineTable[ ,
								 paste0(round(mean(meanParentalAge , na.rm = TRUE) , 2) ,
									" (" ,
									round(sd(meanParentalAge , na.rm = TRUE) , 2) ,
									")")] , ##"Mean parental age, y, mean (SD)" ,
						   paste0(baselineTable[
						       is.na(meanParentalAge) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(meanParentalAge) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ## , ##"Missing entries" , 
						   baselineTable[ ,
								 paste0(round(mean(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
									" (" ,
									round(sd(parishQuantileDifference100Euros , na.rm = TRUE) , 2) ,
									")")] , ##"Neighborhood resources, Euros, mean (SD)" ,
						   paste0(baselineTable[
						       is.na(parishQuantileDifference100Euros) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(parishQuantileDifference100Euros) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" ,
						   "" , ##"Number of children in family, n (%)" ,
						   baselineTable[ ,
								 paste0(table(numberOfChildrenFactor)[1] ,
									" (" ,
									round(100*prop.table(table(numberOfChildrenFactor))[1] , 2) ,
									"%)")] , ##"One child" ,
						   baselineTable[ ,
								 paste0(table(numberOfChildrenFactor)[2] ,
									" (" ,
									round(100*prop.table(table(numberOfChildrenFactor))[2] , 2) ,
									"%)")] , ##"Two children" ,
						   baselineTable[ ,
								 paste0(table(numberOfChildrenFactor)[3] ,
									" (" ,
									round(100*prop.table(table(numberOfChildrenFactor))[3] , 2) ,
									"%)")] , ##"Three to five children" ,
						   baselineTable[ ,
								 paste0(table(numberOfChildrenFactor)[4] ,
									" (" ,
									round(100*prop.table(table(numberOfChildrenFactor))[4] , 2) ,
									"%)")] , ##"Six or more children" ,
						   "" , ##"Abuse of parent as a child, n (%)" ,
						   baselineTable[ ,
								 paste0(table(parentalAbuseAsChildReleveled)[1] ,
									" (" ,
									round(100*prop.table(table(parentalAbuseAsChildReleveled))[1] , 2) ,
									"%)")] , ##"No maltreatment or neglect" ,
						   baselineTable[ ,
								 paste0(table(parentalAbuseAsChildReleveled)[2] ,
									" (" ,
									round(100*prop.table(table(parentalAbuseAsChildReleveled))[2] , 2) ,
									"%)")] , ##"Maltreatment or neglect, one or both parents" ,
						   "" , ##"Immigration background (ethnicity), n, (%)" ,
						   baselineTable[ ,
								 paste0(table(oneForeignParent)[1] ,
									" (" ,
									round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"No foreign parents" ,
						   baselineTable[ ,
								 paste0(table(oneForeignParent)[2] ,
									" (" ,
									round(100*prop.table(table(oneForeignParent , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"One or more foreign parents" ,
						   paste0(baselineTable[
						       is.na(oneForeignParent) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(oneForeignParent) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" ,
						   "" , ##"Status as refugee, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(familyNeedProtection)[1] ,
									" (" ,
									round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"Not in need of protection" ,
						   baselineTable[ ,
								 paste0(table(familyNeedProtection)[2] ,
									" (" ,
									round(100*prop.table(table(familyNeedProtection , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"In need of protection" ,
						   ## paste0(baselineTable[
						   ##     is.na(familyNeedProtection) , .N] ,
						   ##     " (" ,
						   ##     round(100*baselineTable[
						   ##                   is.na(familyNeedProtection) , .N]/
						   ##           baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" ,
						   "" , ##"Reconstituted family, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(reconstitutedFamily)[1] ,
									" (" ,
									round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"Living with biological parent(s)" ,         
						   baselineTable[ ,
								 paste0(table(reconstitutedFamily)[2] ,
									" (" ,
									round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"Living with one or more unrelated adults" , 
						   baselineTable[ ,
								 paste0(table(reconstitutedFamily)[3] ,
									" (" ,
									round(100*prop.table(table(reconstitutedFamily , useNA = "ifany"))[3] , 2) ,
									"%)")] , ##"Adopted or in foster care" ,
						   paste0(baselineTable[
						       is.na(reconstitutedFamily) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(reconstitutedFamily) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" , 
						   "" , ##"Family highest education, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(familyEducationalLevelReleveled)[1] ,
									" (" ,
									round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"Primary or secondary education" ,
						   baselineTable[ ,
								 paste0(table(familyEducationalLevelReleveled)[2] ,
									" (" ,
									round(100*prop.table(table(familyEducationalLevelReleveled , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"Tertiary education or higher" ,
						   paste0(baselineTable[
						       is.na(familyEducationalLevelReleveled) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(familyEducationalLevelReleveled) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" ,
						   baselineTable[ ,
								 paste0(round(mean(incomeVariable , na.rm = TRUE) , 2) ,
									" (" ,
									round(sd(incomeVariable , na.rm = TRUE) , 2) ,
									")")] , ##"Income, mean (SD)" ,
						   paste0(baselineTable[
						       is.na(incomeVariable) , .N] ,
						       " (" ,
						       round(100*baselineTable[
								     is.na(incomeVariable) , .N]/
							     baselineTable[ , .N] , 2) , "%)") , ##"Missing entries" ,
						   "" , ##"Parental psychiatric disease, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(parentalPsychiatricDisease)[1] ,
									" (" ,
									round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"No psychiatric disease" ,
						   baselineTable[ ,
								 paste0(table(parentalPsychiatricDisease)[2] ,
									" (" ,
									round(100*prop.table(table(parentalPsychiatricDisease , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"Any psychiatric disease except substance abuse" , 
						   "" , ##"Inter-parental violence, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(interparentalViolence)[1] ,
									" (" ,
									round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"No interparental violence" ,
						   baselineTable[ ,
								 paste0(table(interparentalViolence)[2] ,
									" (" ,
									round(100*prop.table(table(interparentalViolence , useNA = "ifany"))[2] , 2) ,
									"%)")] , ##"Interparental violence" ,
						   "" , ##"Parental substance abuse, n, (%)" ,
						   baselineTable[ ,
								 paste0(table(parentalSubstanceAbuse)[1] ,
									" (" ,
									round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[1] , 2) ,
									"%)")] , ##"No parental substance abuse" ,
						   baselineTable[ ,
								 paste0(table(parentalSubstanceAbuse)[2] ,
									" (" ,
									round(100*prop.table(table(parentalSubstanceAbuse , useNA = "ifany"))[2] , 2) ,
									"%)")]))  ##"Any parental substance abuse"))
      fwrite(characteristicsTable , nameOfDatasetFileIncludingExtension , sep = "\t")
      print("REMEMBER TO CHECK FOR SMALL CELLS!")
  }

  makeTableCharacteristics("analysisDataset" , "analysisDatasetCharacteristics.csv")

  ##For pseudoAnalysis objects, the same pnr may repeat as both a case and a control. To avoid double-counts in this table:
  setorder(pseudoAnalysis , studyEntry)
  pseudoAnalysisTable <- unique(pseudoAnalysis , by = "pnr")
  makeTableCharacteristics("pseudoAnalysisTable" ,
			   "pseudoAnalysisCharacteristics.csv" ,
			   severalLinesForEachIndividual = FALSE)
  ##Remember to make sure this variable exist:
  imputedData[ , numberOfChildrenFactor :=
			 cut(newNoOfChildren ,
			     breaks = c(0 , 1 , 2 , 5 , 20) ,
			     labels = c("One child" ,
					"Two children" ,
					"Three to five children" ,
					"Six children or more"))]
  makeTableCharacteristics("imputedData" , "imputedDataCharacteristics.csv")


  ##Follow-up time:
  analysisDataset[ , summary(time)] ##Get the mean and convert it to years - it is in either months or half-years
  ##Total time: 
  setorder(analysisDataset , pnr , -time)
  temp <- unique(analysisDataset , by = "pnr")
  temp[ , sum(time)]
  ##Number of outcomes:
  analysisDataset[ , table(outcomePhysicalAbuse)]
  ##Number of deaths not related to outcomes: 
  temp[!is.na(deathCensoring) & (outcomePhysicalAbuse == 0 | is.na(outcomePhysicalAbuse)) , .N]
#+end_src
** Code for replacing the bootstrap-part of the gfoRmula package
#+begin_src R :session rsession :results output :exports both
  ##This code is tested and works as intended - but is too big for gfoRmula to run on my size of dataset. 

  library(data.table)
  library(gfoRmula)
  ##This first code modifies the result of gfoRmula:::bootstrap_helper (which is the engine of the bootstrapping procedure in gfoRmula)
  bootstrap_helper <- function (r, time_points, obs_data, bootseeds, outcome_type, 
      intvars, interventions, int_times, ref_int, covparams, covnames, 
      covtypes, covfits_custom, covpredict_custom, basecovs, histvars, 
      histvals, histories, ymodel, yrestrictions, compevent_restrictions, 
      restrictions, comprisk, compevent_model, time_name, outcome_name, 
      compevent_name, ranges, yrange, compevent_range, parallel, 
      ncores, max_visits, hazardratio, intcomp, boot_diag, nsimul, 
      baselags, below_zero_indicator, min_time, show_progress, 
      pb , clusterID) 
  {
      set.seed(bootseeds[r])
      if (!is.na(clusterID)) {
	  ##Set the correct name in obs_data (skip_absent is necessary, otherwise it will try again and throw an error for each bootstrap cycle):
	  setnames(obs_data , clusterID , "clusterID" , skip_absent = TRUE)
	  ##Sample a number of clusters equivalent to the number of clusters in the dataset:
	  clusters <-
	      data.table(clusterID = sample(unique(obs_data$clusterID) ,
					    length(unique(obs_data$clusterID)) ,
					    replace = TRUE))
	  ##Get the corresponding ids:
	  clusters <- merge(clusters ,
			    obs_data[ , .(clusterID , newid)] ,
			    by = "clusterID" , allow.cartesian = TRUE)
	  ids <- clusters[ , .(newid)]
	  ##Measure the length of the string of ids
	  data_len <- length(clusters$newid)
      } else {
	  ##If there is no clusterID, just use a copy of the code from the original:
	  data_len  <- length(unique(obs_data$newid))
	  ids <- as.data.table(sample(1:data_len , data_len , replace = TRUE))
      }
      print("Started a cycle of bootstrapping")
      ##...continue as usual
      ids[, `:=`("bid", 1:data_len)]
      colnames(ids) <- c("newid", "bid")
      resample_data <- copy(obs_data)
      setkey(resample_data, "newid")
      resample_data <- resample_data[J(ids), allow.cartesian = TRUE]
      resample_data[, `:=`("newid", resample_data$bid)]
      resample_data[, `:=`("bid", NULL)]
      resample_data_geq_0 <- resample_data[resample_data[[time_name]] >= 
	  0]
      fitcov <- pred_fun_cov(covparams = covparams, covnames = covnames, 
	  covtypes = covtypes, covfits_custom = covfits_custom, 
	  restrictions = restrictions, time_name = time_name, obs_data = resample_data_geq_0, 
	  model_fits = FALSE)
      fitY <- pred_fun_Y(ymodel, yrestrictions, outcome_type, outcome_name, 
	  time_name, resample_data_geq_0, model_fits = FALSE)
      if (comprisk) {
	  fitD <- pred_fun_D(compevent_model, compevent_restrictions, 
	      resample_data_geq_0, model_fits = FALSE)
      }
      else {
	  fitD <- NA
      }
      len <- length(unique(resample_data$newid))
      if (nsimul < len) {
	  ids <- as.data.table(sort(sample(unique(resample_data$newid), 
	      nsimul, replace = TRUE)))
	  colnames(ids) <- "newid"
	  ids[, `:=`("bid", seq_len(.N))]
	  resample_data <- merge(ids, resample_data, all.x = TRUE, 
	      by = "newid")
	  resample_data[, `:=`("newid", resample_data$bid)]
	  resample_data[, `:=`("bid", NULL)]
      }
      else if (nsimul > len) {
	  ids <- as.data.table(sample(unique(resample_data$newid), 
	      nsimul, replace = TRUE))
	  ids[, `:=`("newid", 1:nsimul)]
	  colnames(ids) <- c("newid", "bid")
	  setkeyv(resample_data, "newid")
	  resample_data <- resample_data[J(ids), allow.cartesian = TRUE]
	  resample_data[, `:=`("newid", resample_data$bid)]
	  resample_data[, `:=`("bid", NULL)]
      }
      comb_interventions <- interventions
      comb_intvars <- intvars
      comb_int_times <- int_times
      pools <- lapply(seq_along(comb_interventions), FUN = function(i) {
	  simulate(fitcov = fitcov, fitY = fitY, fitD = fitD, yrestrictions = yrestrictions, 
	      compevent_restrictions = compevent_restrictions, 
	      restrictions = restrictions, outcome_name = outcome_name, 
	      compevent_name = compevent_name, time_name = time_name, 
	      intvars = comb_intvars[[i]], interventions = comb_interventions[[i]], 
	      int_times = comb_int_times[[i]], histvars = histvars, 
	      histvals = histvals, histories = histories, covparams = covparams, 
	      covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
	      basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
	      yrange = yrange, compevent_range = compevent_range, 
	      outcome_type = outcome_type, subseed = bootseeds[r], 
	      time_points = time_points, obs_data = resample_data, 
	      parallel = FALSE, max_visits = max_visits, baselags = baselags, 
	      below_zero_indicator = below_zero_indicator, min_time = min_time, 
	      show_progress = show_progress, pb = pb)
      })
      nat_pool <- pools[[1]]
      pools <- pools[-1]
      if (outcome_type == "survival") {
	  param <- "poprisk"
      }
      else if (outcome_type == "continuous_eof") {
	  param <- "Ey"
      }
      else if (outcome_type == "binary_eof") {
	  param <- "Py"
      }
      if (grepl("eof", outcome_type)) {
	  result_ratio <- result_diff <- int_result <- rep(NA, 
	      length(pools) + 1)
      }
      else {
	  result_ratio <- result_diff <- int_result <- matrix(NA, 
	      nrow = length(pools) + 1, ncol = time_points)
      }
      if (grepl("eof", outcome_type)) {
	  nat_result <- mean(nat_pool[[param]], na.rm = TRUE)
      }
      else {
	  nat_result <- tapply(nat_pool[[param]], nat_pool[[time_name]], 
	      FUN = mean)
      }
      if (ref_int == 0) {
	  ref_result <- nat_result
      }
      else {
	  if (grepl("eof", outcome_type)) {
	      ref_result <- mean(pools[[ref_int]][[param]], na.rm = TRUE)
	  }
	  else {
	      ref_result <- tapply(pools[[ref_int]][[param]], pools[[ref_int]][[time_name]], 
		  FUN = mean)
	  }
      }
      if (grepl("eof", outcome_type)) {
	  int_result[1] <- nat_result
	  int_result[-1] <- sapply(pools, FUN = function(pool) {
	      mean(pool[[param]], na.rm = TRUE)
	  })
	  result_ratio <- int_result/ref_result
	  result_diff <- int_result - ref_result
      }
      else {
	  int_result[1, ] <- nat_result
	  result_ratio[1, ] <- int_result[1, ]/ref_result
	  result_diff[1, ] <- int_result[1, ] - ref_result
	  if (length(comb_interventions) > 1) {
	      for (i in 2:(length(pools) + 1)) {
		  int_result[i, ] <- tapply(pools[[i - 1]][[param]], 
		    pools[[i - 1]][[time_name]], FUN = mean)
		  result_ratio[i, ] <- int_result[i, ]/ref_result
		  result_diff[i, ] <- int_result[i, ] - ref_result
	      }
	  }
      }
      if (hazardratio) {
	  pools_hr <- lapply(seq_along(intcomp), FUN = hr_helper, 
	      intcomp = intcomp, time_name = time_name, pools = pools)
	  data_hr <- rbindlist(pools_hr)
	  names(data_hr)[names(data_hr) == time_name] <- "t0"
	  names(data_hr)[names(data_hr) == outcome_name] <- "Y"
	  data_hr$event <- factor(data_hr$Ycomp, 0:2, labels = c("censor", 
	      "Y", "D"))
	  if (comprisk) {
	      hr_data <- survival::finegray(survival::Surv(t0, 
		  event) ~ ., data = data_hr, etype = "Y")
	      hr_res <- survival::coxph(survival::Surv(fgstart, 
		  fgstop, fgstatus) ~ regime, data = hr_data)
	      hr_res <- exp(hr_res$coefficients)
	  }
	  else {
	      hr_res <- survival::coxph(formula = survival::Surv(t0, 
		  Y == "1") ~ regime, data = data_hr)
	      hr_res <- exp(hr_res$coefficients)
	  }
      }
      else {
	  hr_res <- NA
      }
      if (time_points > 1) {
	  fits <- fitcov
	  fits[[length(fits) + 1]] <- fitY
      }
      else {
	  fits <- list(fitY)
      }
      if (!is.na(fitD)[[1]]) {
	  fits[[length(fits) + 1]] <- fitD
      }
      if (boot_diag) {
	  bootcoeffs <- get_coeffs(fits = fits, fitD = fitD, time_points = time_points, 
	      outcome_name = outcome_name, compevent_name = compevent_name, 
	      covnames = covnames)
	  bootstderrs <- get_stderrs(fits = fits, fitD = fitD, 
	      time_points = time_points, outcome_name = outcome_name, 
	      compevent_name = compevent_name, covnames = covnames)
	  bootvcovs <- get_vcovs(fits = fits, fitD = fitD, time_points = time_points, 
	      outcome_name = outcome_name, compevent_name = compevent_name, 
	      covnames = covnames)
      }
      else {
	  bootcoeffs <- NA
	  bootstderrs <- NA
	  bootvcovs <- NA
      }
      final <- list(Result = int_result, ResultRatio = result_ratio, 
	  ResultDiff = result_diff, ResultHR = hr_res, bootcoeffs = bootcoeffs, 
	  bootstderrs = bootstderrs, bootvcovs = bootvcovs)
      return(final)
  }
  ##Putting the modified bootstrap_helper in its place in a running R session:
  environment(bootstrap_helper) <- asNamespace("gfoRmula")
  rlang::env_unlock(env = asNamespace("gfoRmula"))
  rlang::env_binding_unlock(env = asNamespace("gfoRmula"))
  assignInNamespace("bootstrap_helper" , bootstrap_helper , ns = "gfoRmula")
  rlang::env_binding_lock(env = asNamespace("gfoRmula"))
  rlang::env_lock(asNamespace("gfoRmula"))

  ##gformula: added clusterID = NA and clusterID to the calls of all the versions of the gfoRmula:
  gformula <- function (obs_data, id, time_points = NULL, time_name, covnames, 
      covtypes, covparams, covfits_custom = NA, covpredict_custom = NA, 
      histvars = NULL, histories = NA, basecovs = NA, outcome_name, 
      outcome_type, ymodel, compevent_name = NULL, compevent_model = NA, 
      compevent_cens = FALSE, censor_name = NULL, censor_model = NA, 
      intvars = NULL, interventions = NULL, int_times = NULL, int_descript = NULL, 
      ref_int = 0, intcomp = NA, visitprocess = NA, restrictions = NA, 
      yrestrictions = NA, compevent_restrictions = NA, baselags = FALSE, 
      nsimul = NA, sim_data_b = FALSE, seed, nsamples = 0, parallel = FALSE, 
      ncores = NA, ci_method = "percentile", threads, model_fits = FALSE, 
      boot_diag = FALSE, show_progress = TRUE, ipw_cutoff_quantile = NULL, 
      ipw_cutoff_value = NULL, clusterID = NA , ...) 
  {
      if (!outcome_type %in% c("survival", "continuous_eof", "binary_eof")) {
	  stop("outcome_type must be 'survival', 'continuous_eof', or 'binary_eof', but outcome_type was set to", 
	      outcome_type)
      }
      if (outcome_type == "survival") {
	  gformula_survival(obs_data = obs_data, id = id, time_points = time_points, 
	      time_name = time_name, covnames = covnames, covtypes = covtypes, 
	      covparams = covparams, covfits_custom = covfits_custom, 
	      covpredict_custom = covpredict_custom, histvars = histvars, 
	      histories = histories, basecovs = basecovs, outcome_name = outcome_name, 
	      ymodel = ymodel, compevent_name = compevent_name, 
	      compevent_model = compevent_model, compevent_cens = compevent_cens, 
	      censor_name = censor_name, censor_model = censor_model, 
	      intvars = intvars, interventions = interventions, 
	      int_times = int_times, int_descript = int_descript, 
	      ref_int = ref_int, intcomp = intcomp, visitprocess = visitprocess, 
	      restrictions = restrictions, yrestrictions = yrestrictions, 
	      compevent_restrictions = compevent_restrictions, 
	      baselags = baselags, nsimul = nsimul, sim_data_b = sim_data_b, 
	      seed = seed, nsamples = nsamples, parallel = parallel, 
	      ncores = ncores, ci_method = ci_method, threads = threads, 
	      model_fits = model_fits, boot_diag = boot_diag, show_progress = show_progress, 
	      ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value, clusterID = clusterID , 
	      ...)
      }
      else if (outcome_type == "continuous_eof") {
	  gformula_continuous_eof(obs_data = obs_data, id = id, 
	      time_name = time_name, covnames = covnames, covtypes = covtypes, 
	      covparams = covparams, covfits_custom = covfits_custom, 
	      covpredict_custom = covpredict_custom, histvars = histvars, 
	      histories = histories, basecovs = basecovs, outcome_name = outcome_name, 
	      ymodel = ymodel, censor_name = censor_name, censor_model = censor_model, 
	      intvars = intvars, interventions = interventions, 
	      int_times = int_times, int_descript = int_descript, 
	      ref_int = ref_int, visitprocess = visitprocess, restrictions = restrictions, 
	      yrestrictions = yrestrictions, baselags = baselags, 
	      nsimul = nsimul, sim_data_b = sim_data_b, seed = seed, 
	      nsamples = nsamples, parallel = parallel, ncores = ncores, 
	      ci_method = ci_method, threads = threads, model_fits = model_fits, 
	      boot_diag = boot_diag, show_progress = show_progress, 
	      ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value, clusterID = clusterID ,
	      ...)
      }
      else if (outcome_type == "binary_eof") {
	  gformula_binary_eof(obs_data = obs_data, id = id, time_name = time_name, 
	      covnames = covnames, covtypes = covtypes, covparams = covparams, 
	      covfits_custom = covfits_custom, covpredict_custom = covpredict_custom, 
	      histvars = histvars, histories = histories, basecovs = basecovs, 
	      outcome_name = outcome_name, ymodel = ymodel, intvars = intvars, 
	      censor_name = censor_name, censor_model = censor_model, 
	      interventions = interventions, int_times = int_times, 
	      int_descript = int_descript, ref_int = ref_int, visitprocess = visitprocess, 
	      restrictions = restrictions, yrestrictions = yrestrictions, 
	      baselags = baselags, nsimul = nsimul, sim_data_b = sim_data_b, 
	      seed = seed, nsamples = nsamples, parallel = parallel, 
	      ncores = ncores, ci_method = ci_method, threads = threads, 
	      model_fits = model_fits, boot_diag = boot_diag, show_progress = show_progress, 
	      ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value, clusterID = clusterID ,
	      ...)
      }
  }
  environment(gformula) <- asNamespace("gfoRmula")

  ##gformula_survival: added clusterID = NA
  gformula_survival <- function (obs_data, id, time_points = NULL, time_name, covnames, 
      covtypes, covparams, covfits_custom = NA, covpredict_custom = NA, 
      histvars = NULL, histories = NA, basecovs = NA, outcome_name, 
      ymodel, compevent_name = NULL, compevent_model = NA, compevent_cens = FALSE, 
      censor_name = NULL, censor_model = NA, intvars = NULL, interventions = NULL, 
      int_times = NULL, int_descript = NULL, ref_int = 0, intcomp = NA, 
      visitprocess = NA, restrictions = NA, yrestrictions = NA, 
      compevent_restrictions = NA, baselags = FALSE, nsimul = NA, 
      sim_data_b = FALSE, seed, nsamples = 0, parallel = FALSE, 
      ncores = NA, ci_method = "percentile", threads, model_fits = FALSE, 
      boot_diag = FALSE, show_progress = TRUE, ipw_cutoff_quantile = NULL, 
      ipw_cutoff_value = NULL, clusterID = NA , ...) 
  {
      lag_indicator <- lagavg_indicator <- cumavg_indicator <- c()
      lag_indicator <- update_lag_indicator(covparams$covmodels, 
	  lag_indicator)
      lagavg_indicator <- update_lagavg_indicator(covparams$covmodels, 
	  lagavg_indicator)
      cumavg_indicator <- update_cumavg_indicator(covparams$covmodels, 
	  cumavg_indicator)
      comprisk <- !(length(compevent_model) == 1 && is.na(compevent_model))
      censor <- !(length(censor_model) == 1 && is.na(censor_model))
      if (!missing(ymodel)) {
	  lag_indicator <- update_lag_indicator(ymodel, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(ymodel, lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(ymodel, cumavg_indicator)
      }
      if (comprisk) {
	  lag_indicator <- update_lag_indicator(compevent_model, 
	      lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(compevent_model, 
	      lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(compevent_model, 
	      cumavg_indicator)
      }
      if (censor) {
	  lag_indicator <- update_lag_indicator(censor_model, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(censor_model, 
	      lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(censor_model, 
	      cumavg_indicator)
      }
      histvals <- list(lag_indicator = lag_indicator, lagavg_indicator = lagavg_indicator, 
	  cumavg_indicator = cumavg_indicator)
      if (!missing(threads)) {
	  setDTthreads(threads = threads)
      }
      else {
	  threads <- getDTthreads()
      }
      outcome_type <- "survival"
      hazardratio <- !(length(intcomp) == 1 && is.na(intcomp))
      error_catch(id = id, nsimul = nsimul, intvars = intvars, 
	  interventions = interventions, int_times = int_times, 
	  int_descript = int_descript, covnames = covnames, covtypes = covtypes, 
	  basecovs = basecovs, histvars = histvars, histories = histories, 
	  compevent_model = compevent_model, hazardratio = hazardratio, 
	  intcomp = intcomp, time_points = time_points, outcome_type = outcome_type, 
	  time_name = time_name, obs_data = obs_data, parallel = parallel, 
	  ncores = ncores, nsamples = nsamples, sim_data_b = sim_data_b, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  comprisk = comprisk, censor = censor, censor_name = censor_name, 
	  covmodels = covparams$covmodels, histvals = histvals, 
	  ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value)
      if (comprisk & compevent_cens) {
	  comprisk2 <- TRUE
	  compevent2_name <- compevent_name
	  compevent2_model <- compevent_model
	  comprisk <- FALSE
	  compevent_name <- NULL
	  compevent_model <- NA
      }
      else {
	  comprisk2 <- FALSE
	  compevent2_name <- NULL
	  compevent2_model <- NA
      }
      min_time <- min(obs_data[[time_name]])
      below_zero_indicator <- min_time < 0
      obs_data <- copy(obs_data)
      max_visits <- NA
      if (!is.na(visitprocess[[1]][[1]])) {
	  for (vp in visitprocess) {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(vp[1], paste("lag1_ts_", vp[1], "!=", 
		    vp[3], sep = ""), simple_restriction, 1), c(vp[2], 
		    paste(vp[1], "==1", sep = ""), carry_forward)))
	      if (is.na(max_visits[1])) {
		  max_visits <- as.numeric(vp[3])
	      }
	      else {
		  max_visits <- c(max_visits, as.numeric(vp[3]))
	      }
	      if (is.na(histories[1])) {
		  histories <- c(visit_sum)
	      }
	      else {
		  histories <- c(visit_sum, histories)
		  histvars <- append(list(c(vp[1])), histvars)
	      }
	  }
      }
      for (t in 0:max(obs_data[[time_name]])) {
	  make_histories(pool = obs_data, histvars = histvars, 
	      histvals = histvals, histories = histories, time_name = time_name, 
	      t = t, id = id, max_visits = max_visits, baselags = baselags, 
	      below_zero_indicator = below_zero_indicator)
      }
      sample_size <- length(unique(obs_data[[id]]))
      if (is.null(time_points)) {
	  time_points <- max(obs_data[[time_name]]) + 1
      }
      for (i in seq_along(covnames)) {
	  if (covtypes[i] == "absorbing") {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(covnames[i], paste("lag1_", covnames[i], 
		    "==0", sep = ""), carry_forward, 1)))
	      covtypes[i] <- "binary"
	  }
      }
      ids <- as.data.table(sort(unique(obs_data[[id]])))
      ids[, `:=`("newid", seq_len(.N))]
      setkeyv(obs_data, id)
      obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
      obs_data_geq_0 <- obs_data[obs_data[[time_name]] >= 0]
      if (is.na(nsimul)) {
	  nsimul <- length(unique(obs_data$newid))
      }
      set.seed(seed)
      newseeds <- sample.int(2^30, size = nsamples + 1)
      subseed <- newseeds[1]
      bootseeds <- newseeds[2:(nsamples + 1)]
      ranges <- lapply(seq_along(covnames), FUN = function(i) {
	  if (covtypes[i] == "normal" || covtypes[i] == "bounded normal" || 
	      covtypes[i] == "truncated normal") {
	      range(obs_data_geq_0[[covnames[i]]])
	  }
	  else if (covtypes[i] == "zero-inflated normal") {
	      range(obs_data_geq_0[obs_data_geq_0[[covnames[i]]] > 
		  0][[covnames[i]]])
	  }
	  else {
	      NA
	  }
      })
      yrange <- range(obs_data_geq_0[[outcome_name]])
      if (time_points > 1) {
	  fitcov <- pred_fun_cov(covparams = covparams, covnames = covnames, 
	      covtypes = covtypes, covfits_custom = covfits_custom, 
	      restrictions = restrictions, time_name = time_name, 
	      obs_data = obs_data_geq_0, model_fits = model_fits)
	  names(fitcov) <- covnames
      }
      else {
	  fitcov <- NULL
      }
      fitY <- pred_fun_Y(ymodel, yrestrictions, outcome_type, outcome_name, 
	  time_name, obs_data_geq_0, model_fits = model_fits)
      if (comprisk) {
	  fitD <- pred_fun_D(compevent_model, compevent_restrictions, 
	      obs_data_geq_0, model_fits = model_fits)
	  compevent_range <- range(obs_data_geq_0[[compevent_name]])
      }
      else {
	  fitD <- NA
	  compevent_range <- NA
      }
      if (comprisk2) {
	  fitD2 <- pred_fun_D(compevent2_model, NA, obs_data_geq_0, 
	      model_fits = model_fits)
      }
      else {
	  fitD2 <- NA
      }
      if (censor) {
	  fitC <- pred_fun_D(censor_model, NA, obs_data_geq_0, 
	      model_fits = model_fits)
      }
      else {
	  fitC <- NA
      }
      obs_data_noresample <- copy(obs_data)
      len <- length(unique(obs_data$newid))
      if (nsimul < len) {
	  ids <- as.data.table(sort(sample(unique(obs_data$newid), 
	      nsimul, replace = TRUE)))
	  colnames(ids) <- "newid"
	  ids[, `:=`("sid", seq_len(.N))]
	  obs_data <- merge(ids, obs_data, all.x = TRUE, by = "newid")
	  obs_data[, `:=`("newid", obs_data$sid)]
	  obs_data[, `:=`("sid", NULL)]
      }
      else if (nsimul > len) {
	  ids <- as.data.table(sample(unique(obs_data$newid), nsimul, 
	      replace = TRUE))
	  ids[, `:=`("newid", 1:nsimul)]
	  colnames(ids) <- c("newid", "sid")
	  setkeyv(obs_data, "newid")
	  obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
	  obs_data[, `:=`("newid", obs_data$sid)]
	  obs_data[, `:=`("sid", NULL)]
      }
      if (!is.null(interventions)) {
	  comb_interventions <- c(list(list(c(natural))), interventions)
	  comb_intvars <- c(list("none"), intvars)
      }
      else {
	  comb_interventions <- list(list(c(natural)))
	  comb_intvars <- list("none")
      }
      if (is.null(int_times)) {
	  comb_int_times <- list()
	  for (i in seq_along(comb_interventions)) {
	      comb_int_times[[i]] <- lapply(seq_along(comb_interventions[[i]]), 
		  FUN = function(i) {
		    0:(time_points - 1)
		  })
	  }
      }
      else {
	  comb_int_times <- c(list(list(0:(time_points - 1))), 
	      int_times)
      }
      if (parallel) {
	  cl <- prep_cluster(ncores = ncores, threads = threads, 
	      covtypes = covtypes)
	  pools <- parallel::parLapply(cl, seq_along(comb_interventions), 
	      simulate, fitcov = fitcov, fitY = fitY, fitD = fitD, 
	      yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
	      restrictions = restrictions, outcome_name = outcome_name, 
	      compevent_name = compevent_name, time_name = time_name, 
	      intvars = comb_intvars, interventions = comb_interventions, 
	      int_times = comb_int_times, histvars = histvars, 
	      histvals = histvals, histories = histories, covparams = covparams, 
	      covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
	      basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
	      yrange = yrange, compevent_range = compevent_range, 
	      outcome_type = outcome_type, subseed = subseed, time_points = time_points, 
	      obs_data = obs_data, parallel = parallel, max_visits = max_visits, 
	      baselags = baselags, below_zero_indicator = below_zero_indicator, 
	      min_time = min_time, show_progress = FALSE, ...)
	  parallel::stopCluster(cl)
      }
      else {
	  pools <- lapply(seq_along(comb_interventions), FUN = function(i) {
	      simulate(fitcov = fitcov, fitY = fitY, fitD = fitD, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_name = outcome_name, 
		  compevent_name = compevent_name, time_name = time_name, 
		  intvars = comb_intvars[[i]], interventions = comb_interventions[[i]], 
		  int_times = comb_int_times[[i]], histvars = histvars, 
		  histvals = histvals, histories = histories, covparams = covparams, 
		  covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
		  basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
		  yrange = yrange, compevent_range = compevent_range, 
		  outcome_type = outcome_type, subseed = subseed, 
		  time_points = time_points, obs_data = obs_data, 
		  parallel = parallel, max_visits = max_visits, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, ...)
	  })
      }
      nat_pool <- pools[[1]]
      pools <- pools[-1]
      result_ratio <- result_diff <- int_result <- matrix(NA, nrow = length(pools) + 
	  1, ncol = time_points)
      nat_result <- tapply(nat_pool$poprisk, nat_pool[[time_name]], 
	  FUN = mean)
      if (ref_int == 0) {
	  ref_result <- nat_result
      }
      else {
	  ref_result <- tapply(pools[[ref_int]]$poprisk, pools[[ref_int]][[time_name]], 
	      FUN = mean)
      }
      int_result[1, ] <- nat_result
      result_ratio[1, ] <- int_result[1, ]/ref_result
      result_diff[1, ] <- int_result[1, ] - ref_result
      if (length(comb_interventions) > 1) {
	  for (i in 2:(length(pools) + 1)) {
	      int_result[i, ] <- tapply(pools[[i - 1]]$poprisk, 
		  pools[[i - 1]][[time_name]], FUN = mean)
	      result_ratio[i, ] <- int_result[i, ]/ref_result
	      result_diff[i, ] <- int_result[i, ] - ref_result
	  }
      }
      if (hazardratio) {
	  pools_hr <- lapply(seq_along(intcomp), FUN = hr_helper, 
	      intcomp = intcomp, time_name = time_name, pools = pools)
	  data_hr <- rbindlist(pools_hr)
	  names(data_hr)[names(data_hr) == time_name] <- "t0"
	  names(data_hr)[names(data_hr) == outcome_name] <- "Y"
	  data_hr$event <- factor(data_hr$Ycomp, 0:2, labels = c("censor", 
	      "Y", "D"))
	  if (comprisk) {
	      hr_data <- survival::finegray(survival::Surv(t0, 
		  event) ~ ., data = data_hr, etype = "Y")
	      hr_res <- survival::coxph(survival::Surv(fgstart, 
		  fgstop, fgstatus) ~ regime, data = hr_data)
	      hr_res <- exp(hr_res$coefficients)
	  }
	  else {
	      hr_res <- survival::coxph(formula = survival::Surv(t0, 
		  Y == "1") ~ regime, data = data_hr)
	      hr_res <- exp(hr_res$coefficients)
	  }
	  names(hr_res) <- "Est. HR"
      }
      else {
	  hr_res <- NA
      }
      if (nsamples > 0) {
	  if (parallel) {
	      cl <- prep_cluster(ncores = ncores, threads = threads, 
		  covtypes = covtypes, bootstrap_option = TRUE)
	      final_bs <- parallel::parLapply(cl, 1:nsamples, bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = compevent_range, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, clusterID = clusterID , ...)
	      parallel::stopCluster(cl)
	  }
	  else {
	      if (show_progress) {
		  pb <- progress::progress_bar$new(total = nsamples * 
		    length(comb_interventions), clear = FALSE, 
		    format = "Bootstrap progress [:bar] :percent, Elapsed time :elapsed, Est. time remaining :eta")
	      }
	      final_bs <- lapply(1:nsamples, FUN = bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = compevent_range, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = show_progress, 
		  pb = pb, clusterID = clusterID , ...)
	  }
	  comb_result <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$Result))
	  }))
	  comb_RR <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultRatio))
	  }))
	  comb_RD <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultDiff))
	  }))
	  comb_HR <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(m$ResultHR)
	  }))
	  comb_result$t0 <- comb_RR$t0 <- comb_RD$t0 <- rep(0:(time_points - 
	      1), nsamples)
	  se_result <- comb_result[, lapply(.SD, stats::sd), by = t0]
	  se_RR <- comb_RR[, lapply(.SD, stats::sd), by = t0]
	  se_RD <- comb_RD[, lapply(.SD, stats::sd), by = t0]
	  if (hazardratio) {
	      hr_res[2] <- stats::sd(comb_HR$V1)
	      names(hr_res)[2:4] <- c("HR SE", "HR lower 95% CI", 
		  "HR upper 95% CI")
	  }
	  if (ci_method == "normal") {
	      ci_lb_result <- t(int_result) - stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_lb_RR <- t(result_ratio) - stats::qnorm(0.975) * 
		  se_RR[, -c("t0")]
	      ci_lb_RD <- t(result_diff) - stats::qnorm(0.975) * 
		  se_RD[, -c("t0")]
	      ci_ub_result <- t(int_result) + stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_ub_RR <- t(result_ratio) + stats::qnorm(0.975) * 
		  se_RR[, -c("t0")]
	      ci_ub_RD <- t(result_diff) + stats::qnorm(0.975) * 
		  se_RD[, -c("t0")]
	      if (hazardratio) {
		  hr_res[3:4] <- c(hr_res[1] - stats::qnorm(0.975) * 
		    hr_res[2], hr_res[1] + stats::qnorm(0.975) * 
		    hr_res[2])
	      }
	  }
	  if (ci_method == "percentile") {
	      ci_lb_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_RR <- comb_RR[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_RD <- comb_RD[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_ub_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_RR <- comb_RR[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_RD <- comb_RD[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      if (hazardratio) {
		  hr_res[3:4] <- stats::quantile(comb_HR$V1, probs = c(0.025, 
		    0.975))
	      }
	  }
      }
      if (nsamples > 0 & boot_diag) {
	  bootcoeffs <- lapply(final_bs, "[[", "bootcoeffs")
	  bootstderrs <- lapply(final_bs, "[[", "bootstderrs")
	  bootvcovs <- lapply(final_bs, "[[", "bootvcovs")
      }
      else {
	  bootcoeffs <- NULL
	  bootstderrs <- NULL
	  bootvcovs <- NULL
      }
      plot_info <- get_plot_info(outcome_name = outcome_name, compevent_name = compevent_name, 
	  compevent2_name = compevent2_name, censor_name = censor_name, 
	  time_name = time_name, time_points = time_points, covnames = covnames, 
	  covtypes = covtypes, nat_pool = nat_pool, nat_result = nat_result, 
	  comprisk = comprisk, comprisk2 = comprisk2, censor = censor, 
	  fitD2 = fitD2, fitC = fitC, outcome_type = outcome_type, 
	  obs_data = obs_data_noresample, ipw_cutoff_quantile = ipw_cutoff_quantile, 
	  ipw_cutoff_value = ipw_cutoff_value)
      obs_results <- plot_info$obs_results
      if (!is.null(interventions)) {
	  resultdf <- lapply(1:time_points, function(i) {
	      if (nsamples > 0) {
		  rowdfs <- lapply(1:dim(int_result)[1], function(k) {
		    data.table(t = i - 1, Intervention = k - 1, 
		      Risk = int_result[k, ][i], Risk_SE = se_result[[paste0("V", 
			k)]][i], Risk_CI_LL95 = ci_lb_result[[paste0("V", 
			k)]][i], Risk_CI_UL95 = ci_ub_result[[paste0("V", 
			k)]][i], RiskRatio = result_ratio[k, ][i], 
		      RR_SE = se_RR[[paste0("V", k)]][i], RR_CI_LL95 = ci_lb_RR[[paste0("V", 
			k)]][i], RR_CI_UL95 = ci_ub_RR[[paste0("V", 
			k)]][i], RiskDiff = result_diff[k, ][i], 
		      RD_SE = se_RD[[paste0("V", k)]][i], RD_CI_LL95 = ci_lb_RD[[paste0("V", 
			k)]][i], RD_CI_UL95 = ci_ub_RD[[paste0("V", 
			k)]][i])
		  })
	      }
	      else {
		  rowdfs <- lapply(1:dim(int_result)[1], function(k) {
		    data.table(t = i - 1, Intervention = k - 1, 
		      Risk = int_result[k, ][i], RiskRatio = result_ratio[k, 
			][i], RiskDiff = result_diff[k, ][i])
		  })
	      }
	      rowdfs <- rbindlist(rowdfs)
	      rowdfs[, `:=`("obs_risk", c(obs_results[[2]][i], 
		  rep(NA, dim(rowdfs)[1] - 1)))]
	      return(rowdfs)
	  })
	  resultdf <- rbindlist(resultdf)
      }
      else {
	  if (nsamples > 0) {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  Risk = t(int_result), Risk_SE = se_RR[, -c("t0")], 
		  Risk_CI_LL95 = ci_lb_result[, -c("t0")], Risk_CI_UL95 = ci_ub_result[, 
		    -c("t0")], RiskRatio = t(result_ratio), RR_SE = se_RR[, 
		    -c("t0")], RR_CI_LL95 = ci_lb_RR[, -c("t0")], 
		  RR_CI_UL95 = ci_ub_RR[, -c("t0")], RiskDiff = t(result_diff), 
		  RD_SE = se_RD[, -c("t0")], RD_CI_LL95 = ci_lb_RD[, 
		    -c("t0")], RD_CI_UL95 = ci_ub_RD[, -c("t0")])
	  }
	  else {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  Risk = t(int_result), RiskRatio = t(result_ratio), 
		  RiskDiff = t(result_diff))
	  }
	  resultdf[, `:=`("obs_risk", obs_results[[2]])]
      }
      obs_risk_name <- ifelse(censor, "IP weighted risk", "NP Risk")
      if (nsamples > 0) {
	  colnames(resultdf) <- c("k", "Interv.", "g-form risk", 
	      "Risk SE", "Risk lower 95% CI", "Risk upper 95% CI", 
	      "Risk ratio", "RR SE", "RR lower 95% CI", "RR upper 95% CI", 
	      "Risk difference", "RD SE", "RD lower 95% CI", "RD upper 95% CI", 
	      obs_risk_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_risk_name, 
	      "g-form risk", "Risk SE", "Risk lower 95% CI", "Risk upper 95% CI", 
	      "Risk ratio", "RR SE", "RR lower 95% CI", "RR upper 95% CI", 
	      "Risk difference", "RD SE", "RD lower 95% CI", "RD upper 95% CI"))
      }
      else {
	  colnames(resultdf) <- c("k", "Interv.", "g-form risk", 
	      "Risk ratio", "Risk difference", obs_risk_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_risk_name, 
	      "g-form risk", "Risk ratio", "Risk difference"))
      }
      if (time_points > 1) {
	  fits <- fitcov
	  fits[[length(fits) + 1]] <- fitY
	  names(fits)[length(fits)] <- outcome_name
      }
      else {
	  fits <- list(fitY)
      }
      if (!is.na(fitD)[[1]]) {
	  fits[[length(fits) + 1]] <- fitD
	  names(fits)[length(fits)] <- compevent_name
      }
      if (!is.na(fitC)[[1]]) {
	  fits[[length(fits) + 1]] <- fitC
	  names(fits)[length(fits)] <- censor_name
      }
      if (!is.na(fitD2)[[1]]) {
	  fits[[length(fits) + 1]] <- fitD2
	  names(fits)[length(fits)] <- compevent2_name
      }
      coeffs <- get_coeffs(fits = fits, fitD = fitD, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      stderrs <- get_stderrs(fits = fits, fitD = fitD, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      vcovs <- get_vcovs(fits = fits, fitD = fitD, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      rmses <- lapply(seq_along(fits), FUN = rmse_calculate, fits = fits, 
	  covnames = covnames, covtypes = covtypes, obs_data = obs_data, 
	  outcome_name = outcome_name, time_name = time_name, restrictions = restrictions, 
	  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions)
      if (!is.na(fitD)[[1]]) {
	  if (time_points == 1) {
	      rmses <- stats::setNames(rmses, c(outcome_name, compevent_name))
	  }
	  else {
	      rmses <- stats::setNames(rmses, c(covnames, outcome_name, 
		  compevent_name))
	  }
      }
      else {
	  if (time_points == 1) {
	      rmses <- stats::setNames(rmses, outcome_name)
	  }
	  else {
	      rmses <- stats::setNames(rmses, c(covnames, outcome_name))
	  }
      }
      header <- get_header(int_descript, sample_size, nsimul, nsamples, 
	  ref_int)
      if (sim_data_b) {
	  sim_data <- c(list(`Natural course` = nat_pool), pools)
	  if (!is.null(int_descript)) {
	      names(sim_data)[2:length(sim_data)] <- int_descript
	  }
      }
      else {
	  sim_data <- NA
      }
      if (!model_fits) {
	  fits <- NULL
      }
      res <- list(result = resultdf, coeffs = coeffs, stderrs = stderrs, 
	  vcovs = vcovs, rmses = rmses, hazardratio_val = hr_res, 
	  fits = fits, sim_data = sim_data, IP_weights = obs_results$w, 
	  bootcoeffs = bootcoeffs, bootstderrs = bootstderrs, bootvcovs = bootvcovs, 
	  time_name = time_name, time_points = time_points, covnames = covnames, 
	  covtypes = covtypes, dt_cov_plot = plot_info$dt_cov_plot, 
	  dt_out_plot = plot_info$dt_out_plot, nsamples = nsamples, 
	  interventions = interventions, comprisk = comprisk, header = header)
      class(res) <- c("gformula_survival", "gformula")
      return(res)
  }
  environment(gformula_survival) <- asNamespace("gfoRmula")

  ##gformula_binary_eof: added clusterID = NA
  gformula_binary_eof <- function (obs_data, id, time_name, covnames, covtypes, covparams, 
      covfits_custom = NA, covpredict_custom = NA, histvars = NULL, 
      histories = NA, basecovs = NA, censor_name = NULL, censor_model = NA, 
      outcome_name, ymodel, intvars = NULL, interventions = NULL, 
      int_times = NULL, int_descript = NULL, ref_int = 0, visitprocess = NA, 
      restrictions = NA, yrestrictions = NA, baselags = FALSE, 
      nsimul = NA, sim_data_b = FALSE, seed, nsamples = 0, parallel = FALSE, 
      ncores = NA, ci_method = "percentile", threads, model_fits = FALSE, 
      boot_diag = FALSE, show_progress = TRUE, ipw_cutoff_quantile = NULL, 
      ipw_cutoff_value = NULL, clusterID = NA , ...) 
  {
      lag_indicator <- lagavg_indicator <- cumavg_indicator <- c()
      lag_indicator <- update_lag_indicator(covparams$covmodels, 
	  lag_indicator)
      lagavg_indicator <- update_lagavg_indicator(covparams$covmodels, 
	  lagavg_indicator)
      cumavg_indicator <- update_cumavg_indicator(covparams$covmodels, 
	  cumavg_indicator)
      censor <- !(length(censor_model) == 1 && is.na(censor_model))
      if (!missing(ymodel)) {
	  lag_indicator <- update_lag_indicator(ymodel, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(ymodel, lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(ymodel, cumavg_indicator)
      }
      if (censor) {
	  lag_indicator <- update_lag_indicator(censor_model, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(censor_model, 
	      lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(censor_model, 
	      cumavg_indicator)
      }
      histvals <- list(lag_indicator = lag_indicator, lagavg_indicator = lagavg_indicator, 
	  cumavg_indicator = cumavg_indicator)
      comprisk <- FALSE
      comprisk2 <- FALSE
      if (!missing(threads)) {
	  setDTthreads(threads = threads)
      }
      else {
	  threads <- getDTthreads()
      }
      outcome_type <- "binary_eof"
      compevent_model <- NA
      compevent2_model <- NA
      compevent_name <- NULL
      compevent2_name <- NULL
      compevent_restrictions <- NA
      hazardratio <- FALSE
      intcomp <- NA
      extra_args <- list(...)
      if ("time_points" %in% names(extra_args)) {
	  stop("Argument time_points cannot be supplied in this function. For end of follow up outcomes, the mean is calculated at the last time point in obs_data")
      }
      error_catch(id = id, nsimul = nsimul, intvars = intvars, 
	  interventions = interventions, int_times = int_times, 
	  int_descript = int_descript, covnames = covnames, covtypes = covtypes, 
	  basecovs = basecovs, histvars = histvars, histories = histories, 
	  compevent_model = compevent_model, hazardratio = hazardratio, 
	  intcomp = intcomp, time_points = NULL, outcome_type = outcome_type, 
	  time_name = time_name, obs_data = obs_data, parallel = parallel, 
	  ncores = ncores, nsamples = nsamples, sim_data_b = sim_data_b, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  comprisk = comprisk, censor = censor, censor_name = censor_name, 
	  covmodels = covparams$covmodels, histvals = histvals, 
	  ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value)
      min_time <- min(obs_data[[time_name]])
      below_zero_indicator <- min_time < 0
      obs_data <- copy(obs_data)
      max_visits <- NA
      if (!is.na(visitprocess[[1]][[1]])) {
	  for (vp in visitprocess) {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(vp[1], paste("lag1_ts_", vp[1], "!=", 
		    vp[3], sep = ""), simple_restriction, 1), c(vp[2], 
		    paste(vp[1], "==1", sep = ""), carry_forward)))
	      if (is.na(max_visits[1])) {
		  max_visits <- as.numeric(vp[3])
	      }
	      else {
		  max_visits <- c(max_visits, as.numeric(vp[3]))
	      }
	      if (is.na(histories[1])) {
		  histories <- c(visit_sum)
	      }
	      else {
		  histories <- c(visit_sum, histories)
		  histvars <- append(list(c(vp[1])), histvars)
	      }
	  }
      }
      for (t in 0:max(obs_data[[time_name]])) {
	  make_histories(pool = obs_data, histvars = histvars, 
	      histvals = histvals, histories = histories, time_name = time_name, 
	      t = t, id = id, baselags = baselags, below_zero_indicator = below_zero_indicator)
      }
      sample_size <- length(unique(obs_data[[id]]))
      time_points <- max(obs_data[[time_name]]) + 1
      for (i in seq_along(covnames)) {
	  if (covtypes[i] == "absorbing") {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(covnames[i], paste("lag1_", covnames[i], 
		    "==0", sep = ""), carry_forward, 1)))
	      covtypes[i] <- "binary"
	  }
      }
      ids <- as.data.table(sort(unique(obs_data[[id]])))
      ids[, `:=`("newid", seq_len(.N))]
      setkeyv(obs_data, id)
      obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
      obs_data_geq_0 <- obs_data[obs_data[[time_name]] >= 0]
      if (is.na(nsimul)) {
	  nsimul <- length(unique(obs_data$newid))
      }
      set.seed(seed)
      newseeds <- sample.int(2^30, size = nsamples + 1)
      subseed <- newseeds[1]
      bootseeds <- newseeds[2:(nsamples + 1)]
      ranges <- lapply(seq_along(covnames), FUN = function(i) {
	  if (covtypes[i] == "normal" || covtypes[i] == "bounded normal" || 
	      covtypes[i] == "truncated normal") {
	      range(obs_data_geq_0[[covnames[i]]])
	  }
	  else if (covtypes[i] == "zero-inflated normal") {
	      range(obs_data_geq_0[obs_data_geq_0[[covnames[i]]] > 
		  0][[covnames[i]]])
	  }
	  else {
	      NA
	  }
      })
      yrange <- range(obs_data_geq_0[[outcome_name]])
      if (time_points > 1) {
	  fitcov <- pred_fun_cov(covparams = covparams, covnames = covnames, 
	      covtypes = covtypes, covfits_custom = covfits_custom, 
	      restrictions = restrictions, time_name = time_name, 
	      obs_data = obs_data_geq_0, model_fits = model_fits)
	  names(fitcov) <- covnames
      }
      else {
	  fitcov <- NULL
      }
      fitY <- pred_fun_Y(ymodel, yrestrictions, outcome_type, outcome_name, 
	  time_name, obs_data_geq_0, model_fits = model_fits)
      if (censor) {
	  fitC <- pred_fun_D(censor_model, NA, obs_data_geq_0, 
	      model_fits = model_fits)
      }
      else {
	  fitC <- NA
      }
      obs_data_noresample <- copy(obs_data)
      len <- length(unique(obs_data$newid))
      if (nsimul < len) {
	  ids <- as.data.table(sort(sample(unique(obs_data$newid), 
	      nsimul, replace = TRUE)))
	  colnames(ids) <- "newid"
	  ids[, `:=`("sid", seq_len(.N))]
	  obs_data <- merge(ids, obs_data, all.x = TRUE, by = "newid")
	  obs_data[, `:=`("newid", obs_data$sid)]
	  obs_data[, `:=`("sid", NULL)]
      }
      else if (nsimul > len) {
	  ids <- as.data.table(sample(unique(obs_data$newid), nsimul, 
	      replace = TRUE))
	  ids[, `:=`("newid", 1:nsimul)]
	  colnames(ids) <- c("newid", "sid")
	  setkeyv(obs_data, "newid")
	  obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
	  obs_data[, `:=`("newid", obs_data$sid)]
	  obs_data[, `:=`("sid", NULL)]
      }
      if (!is.null(interventions)) {
	  comb_interventions <- c(list(list(c(natural))), interventions)
	  comb_intvars <- c(list("none"), intvars)
      }
      else {
	  comb_interventions <- list(list(c(natural)))
	  comb_intvars <- list("none")
      }
      if (is.null(int_times)) {
	  comb_int_times <- list()
	  for (i in seq_along(comb_interventions)) {
	      comb_int_times[[i]] <- lapply(seq_along(comb_interventions[[i]]), 
		  FUN = function(i) {
		    0:(time_points - 1)
		  })
	  }
      }
      else {
	  comb_int_times <- c(list(list(0:(time_points - 1))), 
	      int_times)
      }
      if (parallel) {
	  cl <- prep_cluster(ncores = ncores, threads = threads, 
	      covtypes = covtypes)
	  pools <- parallel::parLapply(cl, seq_along(comb_interventions), 
	      simulate, fitcov = fitcov, fitY = fitY, fitD = NA, 
	      yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
	      restrictions = restrictions, outcome_name = outcome_name, 
	      compevent_name = compevent_name, time_name = time_name, 
	      intvars = comb_intvars, interventions = comb_interventions, 
	      int_times = comb_int_times, histvars = histvars, 
	      histvals = histvals, histories = histories, covparams = covparams, 
	      covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
	      basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
	      yrange = yrange, compevent_range = NA, outcome_type = outcome_type, 
	      subseed = subseed, time_points = time_points, obs_data = obs_data, 
	      parallel = parallel, baselags = baselags, below_zero_indicator = below_zero_indicator, 
	      min_time = min_time, show_progress = FALSE, ...)
	  parallel::stopCluster(cl)
      }
      else {
	  pools <- lapply(seq_along(comb_interventions), FUN = function(i) {
	      simulate(fitcov = fitcov, fitY = fitY, fitD = NA, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_name = outcome_name, 
		  compevent_name = compevent_name, time_name = time_name, 
		  intvars = comb_intvars[[i]], interventions = comb_interventions[[i]], 
		  int_times = comb_int_times[[i]], histvars = histvars, 
		  histvals = histvals, histories = histories, covparams = covparams, 
		  covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
		  basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
		  yrange = yrange, compevent_range = NA, outcome_type = outcome_type, 
		  subseed = subseed, time_points = time_points, 
		  obs_data = obs_data, parallel = parallel, baselags = baselags, 
		  below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, ...)
	  })
      }
      nat_pool <- pools[[1]]
      pools <- pools[-1]
      result_ratio <- result_diff <- int_result <- rep(NA, length(pools) + 
	  1)
      nat_result <- mean(nat_pool$Py, na.rm = TRUE)
      if (ref_int == 0) {
	  ref_mean <- nat_result
      }
      else {
	  ref_mean <- mean(pools[[ref_int]]$Py, na.rm = TRUE)
      }
      int_result[1] <- nat_result
      int_result[-1] <- sapply(pools, FUN = function(pool) {
	  mean(pool$Py, na.rm = TRUE)
      })
      result_ratio <- int_result/ref_mean
      result_diff <- int_result - ref_mean
      if (nsamples > 0) {
	  if (parallel) {
	      cl <- prep_cluster(ncores = ncores, threads = threads, 
		  covtypes = covtypes, bootstrap_option = TRUE)
	      final_bs <- parallel::parLapply(cl, 1:nsamples, bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = NA, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, ...)
	      parallel::stopCluster(cl)
	  }
	  else {
	      if (show_progress) {
		  pb <- progress::progress_bar$new(total = nsamples * 
		    length(comb_interventions), clear = FALSE, 
		    format = "Bootstrap progress [:bar] :percent, Elapsed time :elapsed, Est. time remaining :eta")
	      }
	      final_bs <- lapply(1:nsamples, FUN = bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = NA, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = show_progress, 
		  pb = pb, ...)
	  }
	  comb_result <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$Result))
	  }))
	  comb_MR <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultRatio))
	  }))
	  comb_MD <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultDiff))
	  }))
	  comb_result$t0 <- comb_MR$t0 <- comb_MD$t0 <- time_points
	  se_result <- comb_result[, lapply(.SD, stats::sd), by = t0]
	  se_MR <- comb_MR[, lapply(.SD, stats::sd), by = t0]
	  se_MD <- comb_MD[, lapply(.SD, stats::sd), by = t0]
	  if (ci_method == "normal") {
	      ci_lb_result <- t(int_result) - stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_lb_MR <- t(int_result) - stats::qnorm(0.975) * 
		  se_MR[, -c("t0")]
	      ci_lb_MD <- t(int_result) - stats::qnorm(0.975) * 
		  se_MD[, -c("t0")]
	      ci_ub_result <- t(int_result) + stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_ub_MR <- t(int_result) + stats::qnorm(0.975) * 
		  se_MR[, -c("t0")]
	      ci_ub_MD <- t(int_result) + stats::qnorm(0.975) * 
		  se_MD[, -c("t0")]
	  }
	  if (ci_method == "percentile") {
	      ci_lb_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_MR <- comb_MR[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_MD <- comb_MD[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_ub_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_MR <- comb_MR[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_MD <- comb_MD[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	  }
      }
      if (nsamples > 0 & boot_diag) {
	  bootcoeffs <- lapply(final_bs, "[[", "bootcoeffs")
	  bootstderrs <- lapply(final_bs, "[[", "bootstderrs")
	  bootvcovs <- lapply(final_bs, "[[", "bootvcovs")
      }
      else {
	  bootcoeffs <- NULL
	  bootstderrs <- NULL
	  bootvcovs <- NULL
      }
      plot_info <- get_plot_info(outcome_name = outcome_name, compevent_name = compevent_name, 
	  compevent2_name = compevent2_name, censor_name = censor_name, 
	  time_name = time_name, time_points = time_points, covnames = covnames, 
	  covtypes = covtypes, nat_pool = nat_pool, nat_result = nat_result, 
	  comprisk = comprisk, comprisk2 = comprisk2, censor = censor, 
	  fitC = fitC, outcome_type = outcome_type, obs_data = obs_data_noresample, 
	  ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value)
      obs_results <- plot_info$obs_results
      if (!is.null(interventions)) {
	  resultdf <- lapply(seq_along(int_result), function(k) {
	      if (nsamples > 0) {
		  data.table(t = time_points - 1, Intervention = k - 
		    1, EOFMean = int_result[k], EOFMean_SE = se_result[[paste0("V", 
		    k)]], EOFMean_CI_LL95 = ci_lb_result[[paste0("V", 
		    k)]], EOFMean_CI_UL95 = ci_ub_result[[paste0("V", 
		    k)]], EOFMeanRatio = result_ratio[k], MR_SE = se_MR[[paste0("V", 
		    k)]], MR_CI_LL95 = ci_lb_MR[[paste0("V", k)]], 
		    MR_CI_UL95 = ci_ub_MR[[paste0("V", k)]], EOFMeanDiff = result_diff[k], 
		    MD_SE = se_MD[[paste0("V", k)]], MD_CI_LL95 = ci_lb_MD[[paste0("V", 
		      k)]], MD_CI_UL95 = ci_ub_MD[[paste0("V", 
		      k)]])
	      }
	      else {
		  data.table(t = time_points - 1, Intervention = k - 
		    1, OutcomeEOFMean = int_result[k], EOFMeanRatio = result_ratio[k], 
		    EOFMeanDiff = result_diff[k])
	      }
	  })
	  resultdf <- rbindlist(resultdf)
      }
      else {
	  if (nsamples > 0) {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  EOFMean = int_result, EOFMean_SE = se_MD[, -c("t0")], 
		  EOFMean_CI_LL95 = ci_lb_result[, -c("t0")], EOFMean_CI_UL95 = ci_ub_result[, 
		    -c("t0")], EOFMeanRatio = result_ratio, MR_SE = se_MR[, 
		    -c("t0")], MR_CI_LL95 = ci_lb_MR[, -c("t0")], 
		  MR_CI_UL95 = ci_ub_MR[, -c("t0")], EOFMeanDiff = result_diff, 
		  EOFMD_se = se_MD[, -c("t0")], MD_CI_LL95 = ci_lb_MD[, 
		    -c("t0")], MD_CI_UL95 = ci_ub_MD[, -c("t0")])
	  }
	  else {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  OutcomeEOFMean = int_result, EOFMeanRatio = result_ratio, 
		  EOFMeanDiff = result_diff)
	  }
      }
      resultdf[, `:=`("obs_risk", c(utils::tail(obs_results[[2]], 
	  1), rep(NA, dim(resultdf)[1] - 1)))]
      obs_mean_name <- ifelse(censor, "IP weighted mean", "NP mean")
      if (nsamples > 0) {
	  colnames(resultdf) <- c("k", "Interv.", "g-form mean", 
	      "Mean SE", "Mean lower 95% CI", "Mean upper 95% CI", 
	      "Mean ratio", "MR SE", "MR lower 95% CI", "MR upper 95% CI", 
	      "Mean difference", "MD SE", "MD lower 95% CI", "MD upper 95% CI", 
	      obs_mean_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_mean_name, 
	      "g-form mean", "Mean SE", "Mean lower 95% CI", "Mean upper 95% CI", 
	      "Mean ratio", "MR SE", "MR lower 95% CI", "MR upper 95% CI", 
	      "Mean difference", "MD SE", "MD lower 95% CI", "MD upper 95% CI"))
      }
      else {
	  colnames(resultdf) <- c("k", "Interv.", "g-form mean", 
	      "Mean ratio", "Mean difference", obs_mean_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_mean_name, 
	      "g-form mean", "Mean ratio", "Mean difference"))
      }
      if (time_points > 1) {
	  fits <- fitcov
	  fits[[length(fits) + 1]] <- fitY
	  names(fits)[length(fits)] <- outcome_name
      }
      else {
	  fits <- list(fitY)
      }
      if (!is.na(fitC)[[1]]) {
	  fits[[length(fits) + 1]] <- fitC
	  names(fits)[length(fits)] <- censor_name
      }
      coeffs <- get_coeffs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      stderrs <- get_stderrs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      vcovs <- get_vcovs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      rmses <- lapply(seq_along(fits), FUN = rmse_calculate, fits = fits, 
	  covnames = covnames, covtypes = covtypes, obs_data = obs_data, 
	  outcome_name = outcome_name, time_name = time_name, restrictions = restrictions, 
	  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions)
      if (time_points == 1) {
	  rmses <- stats::setNames(rmses, outcome_name)
      }
      else {
	  rmses <- stats::setNames(rmses, c(covnames, outcome_name))
      }
      header <- get_header(int_descript, sample_size, nsimul, nsamples, 
	  ref_int)
      if (sim_data_b) {
	  sim_data <- c(list(`Natural course` = nat_pool), pools)
	  if (!is.null(int_descript)) {
	      names(sim_data)[2:length(sim_data)] <- int_descript
	  }
      }
      else {
	  sim_data <- NA
      }
      if (!model_fits) {
	  fits <- NULL
      }
      res <- list(result = resultdf, coeffs = coeffs, stderrs = stderrs, 
	  vcovs = vcovs, rmses = rmses, fits = fits, sim_data = sim_data, 
	  IP_weights = obs_results$w, bootcoeffs = bootcoeffs, 
	  bootstderrs = bootstderrs, bootvcovs = bootvcovs, time_name = time_name, 
	  time_points = time_points, covnames = covnames, covtypes = covtypes, 
	  dt_cov_plot = plot_info$dt_cov_plot, dt_out_plot = plot_info$dt_out_plot, 
	  header = header)
      class(res) <- c("gformula_binary_eof", "gformula")
      return(res)
  }
  environment(gformula_binary_eof) <- asNamespace("gfoRmula")

  ##gformula_continuous_eof: added clusterID = NA
  gformula_continuous_eof <- function (obs_data, id, time_name, covnames, covtypes, covparams, 
      covfits_custom = NA, covpredict_custom = NA, histvars = NULL, 
      histories = NA, basecovs = NA, outcome_name, ymodel, censor_name = NULL, 
      censor_model = NA, intvars = NULL, interventions = NULL, 
      int_times = NULL, int_descript = NULL, ref_int = 0, visitprocess = NA, 
      restrictions = NA, yrestrictions = NA, baselags = FALSE, 
      nsimul = NA, sim_data_b = FALSE, seed, nsamples = 0, parallel = FALSE, 
      ncores = NA, ci_method = "percentile", threads, model_fits = FALSE, 
      boot_diag = FALSE, show_progress = TRUE, ipw_cutoff_quantile = NULL, 
      ipw_cutoff_value = NULL, clusterID = NA , ...) 
  {
      lag_indicator <- lagavg_indicator <- cumavg_indicator <- c()
      lag_indicator <- update_lag_indicator(covparams$covmodels, 
	  lag_indicator)
      lagavg_indicator <- update_lagavg_indicator(covparams$covmodels, 
	  lagavg_indicator)
      cumavg_indicator <- update_cumavg_indicator(covparams$covmodels, 
	  cumavg_indicator)
      censor <- !(length(censor_model) == 1 && is.na(censor_model))
      if (!missing(ymodel)) {
	  lag_indicator <- update_lag_indicator(ymodel, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(ymodel, lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(ymodel, cumavg_indicator)
      }
      if (censor) {
	  lag_indicator <- update_lag_indicator(censor_model, lag_indicator)
	  lagavg_indicator <- update_lagavg_indicator(censor_model, 
	      lagavg_indicator)
	  cumavg_indicator <- update_cumavg_indicator(censor_model, 
	      cumavg_indicator)
      }
      histvals <- list(lag_indicator = lag_indicator, lagavg_indicator = lagavg_indicator, 
	  cumavg_indicator = cumavg_indicator)
      comprisk <- FALSE
      comprisk2 <- FALSE
      if (!missing(threads)) {
	  setDTthreads(threads = threads)
      }
      else {
	  threads <- getDTthreads()
      }
      outcome_type <- "continuous_eof"
      compevent_model <- NA
      compevent2_model <- NA
      compevent_name <- NULL
      compevent2_name <- NULL
      compevent_restrictions <- NA
      hazardratio <- FALSE
      intcomp <- NA
      extra_args <- list(...)
      if ("time_points" %in% names(extra_args)) {
	  stop("Argument time_points cannot be supplied in this function. For end of follow up outcomes, the mean is calculated at the last time point in obs_data")
      }
      error_catch(id = id, nsimul = nsimul, intvars = intvars, 
	  interventions = interventions, int_times = int_times, 
	  int_descript = int_descript, covnames = covnames, covtypes = covtypes, 
	  basecovs = basecovs, histvars = histvars, histories = histories, 
	  compevent_model = compevent_model, hazardratio = hazardratio, 
	  intcomp = intcomp, time_points = NULL, outcome_type = outcome_type, 
	  time_name = time_name, obs_data = obs_data, parallel = parallel, 
	  ncores = ncores, nsamples = nsamples, sim_data_b = sim_data_b, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  comprisk = comprisk, censor = censor, censor_name = censor_name, 
	  covmodels = covparams$covmodels, histvals = histvals, 
	  ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value)
      min_time <- min(obs_data[[time_name]])
      below_zero_indicator <- min_time < 0
      obs_data <- copy(obs_data)
      max_visits <- NA
      if (!is.na(visitprocess[[1]][[1]])) {
	  for (vp in visitprocess) {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(vp[1], paste("lag1_ts_", vp[1], "!=", 
		    vp[3], sep = ""), simple_restriction, 1), c(vp[2], 
		    paste(vp[1], "==1", sep = ""), carry_forward)))
	      if (is.na(max_visits[1])) {
		  max_visits <- as.numeric(vp[3])
	      }
	      else {
		  max_visits <- c(max_visits, as.numeric(vp[3]))
	      }
	      if (is.na(histories[1])) {
		  histories <- c(visit_sum)
	      }
	      else {
		  histories <- c(visit_sum, histories)
		  histvars <- append(list(c(vp[1])), histvars)
	      }
	  }
      }
      for (t in 0:max(obs_data[[time_name]])) {
	  make_histories(pool = obs_data, histvars = histvars, 
	      histvals = histvals, histories = histories, time_name = time_name, 
	      t = t, id = id, max_visits = max_visits, baselags = baselags, 
	      below_zero_indicator = below_zero_indicator)
      }
      sample_size <- length(unique(obs_data[[id]]))
      time_points <- max(obs_data[[time_name]]) + 1
      for (i in seq_along(covnames)) {
	  if (covtypes[i] == "absorbing") {
	      restrictions <- c(restrictions[!is.na(restrictions)], 
		  list(c(covnames[i], paste("lag1_", covnames[i], 
		    "==0", sep = ""), carry_forward, 1)))
	      covtypes[i] <- "binary"
	  }
      }
      ids <- as.data.table(sort(unique(obs_data[[id]])))
      ids[, `:=`("newid", seq_len(.N))]
      setkeyv(obs_data, id)
      obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
      obs_data_geq_0 <- obs_data[obs_data[[time_name]] >= 0]
      if (is.na(nsimul)) {
	  nsimul <- length(unique(obs_data$newid))
      }
      set.seed(seed)
      newseeds <- sample.int(2^30, size = nsamples + 1)
      subseed <- newseeds[1]
      bootseeds <- newseeds[2:(nsamples + 1)]
      ranges <- lapply(seq_along(covnames), FUN = function(i) {
	  if (covtypes[i] == "normal" || covtypes[i] == "bounded normal" || 
	      covtypes[i] == "truncated normal") {
	      range(obs_data_geq_0[[covnames[i]]])
	  }
	  else if (covtypes[i] == "zero-inflated normal") {
	      range(obs_data_geq_0[obs_data_geq_0[[covnames[i]]] > 
		  0][[covnames[i]]])
	  }
	  else {
	      NA
	  }
      })
      yrange <- range(obs_data_geq_0[[outcome_name]])
      if (time_points > 1) {
	  fitcov <- pred_fun_cov(covparams = covparams, covnames = covnames, 
	      covtypes = covtypes, covfits_custom = covfits_custom, 
	      restrictions = restrictions, time_name = time_name, 
	      obs_data = obs_data_geq_0, model_fits = model_fits)
	  names(fitcov) <- covnames
      }
      else {
	  fitcov <- NULL
      }
      fitY <- pred_fun_Y(ymodel, yrestrictions, outcome_type, outcome_name, 
	  time_name, obs_data_geq_0, model_fits = model_fits)
      if (censor) {
	  fitC <- pred_fun_D(censor_model, NA, obs_data_geq_0, 
	      model_fits = model_fits)
      }
      else {
	  fitC <- NA
      }
      obs_data_noresample <- copy(obs_data)
      len <- length(unique(obs_data$newid))
      if (nsimul < len) {
	  ids <- as.data.table(sort(sample(unique(obs_data$newid), 
	      nsimul, replace = TRUE)))
	  colnames(ids) <- "newid"
	  ids[, `:=`("sid", seq_len(.N))]
	  obs_data <- merge(ids, obs_data, all.x = TRUE, by = "newid")
	  obs_data$newid <- obs_data$sid
	  obs_data$sid <- NULL
      }
      else if (nsimul > len) {
	  ids <- as.data.table(sample(unique(obs_data$newid), nsimul, 
	      replace = TRUE))
	  ids$newid <- 1:nsimul
	  colnames(ids) <- c("newid", "sid")
	  setkeyv(obs_data, "newid")
	  obs_data <- obs_data[J(ids), allow.cartesian = TRUE]
	  obs_data$newid <- obs_data$sid
	  obs_data$sid <- NULL
      }
      if (!is.null(interventions)) {
	  comb_interventions <- c(list(list(c(natural))), interventions)
	  comb_intvars <- c(list("none"), intvars)
      }
      else {
	  comb_interventions <- list(list(c(natural)))
	  comb_intvars <- list("none")
      }
      if (is.null(int_times)) {
	  comb_int_times <- list()
	  for (i in seq_along(comb_interventions)) {
	      comb_int_times[[i]] <- lapply(seq_along(comb_interventions[[i]]), 
		  FUN = function(i) {
		    0:(time_points - 1)
		  })
	  }
      }
      else {
	  comb_int_times <- c(list(list(0:(time_points - 1))), 
	      int_times)
      }
      if (parallel) {
	  cl <- prep_cluster(ncores = ncores, threads = threads, 
	      covtypes = covtypes)
	  pools <- parallel::parLapply(cl, seq_along(comb_interventions), 
	      simulate, fitcov = fitcov, fitY = fitY, fitD = NA, 
	      yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
	      restrictions = restrictions, outcome_name = outcome_name, 
	      compevent_name = compevent_name, time_name = time_name, 
	      intvars = comb_intvars, interventions = comb_interventions, 
	      int_times = comb_int_times, histvars = histvars, 
	      histvals = histvals, histories = histories, covparams = covparams, 
	      covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
	      basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
	      yrange = yrange, compevent_range = NA, outcome_type = outcome_type, 
	      subseed = subseed, time_points = time_points, obs_data = obs_data, 
	      parallel = parallel, baselags = baselags, below_zero_indicator = below_zero_indicator, 
	      min_time = min_time, show_progress = FALSE, ...)
	  parallel::stopCluster(cl)
      }
      else {
	  pools <- lapply(seq_along(comb_interventions), FUN = function(i) {
	      simulate(fitcov = fitcov, fitY = fitY, fitD = NA, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_name = outcome_name, 
		  compevent_name = compevent_name, time_name = time_name, 
		  intvars = comb_intvars[[i]], interventions = comb_interventions[[i]], 
		  int_times = comb_int_times[[i]], histvars = histvars, 
		  histvals = histvals, histories = histories, covparams = covparams, 
		  covnames = covnames, covtypes = covtypes, covpredict_custom = covpredict_custom, 
		  basecovs = basecovs, comprisk = comprisk, ranges = ranges, 
		  yrange = yrange, compevent_range = NA, outcome_type = outcome_type, 
		  subseed = subseed, time_points = time_points, 
		  obs_data = obs_data, parallel = parallel, baselags = baselags, 
		  below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, ...)
	  })
      }
      nat_pool <- pools[[1]]
      pools <- pools[-1]
      result_ratio <- result_diff <- int_result <- rep(NA, length(pools) + 
	  1)
      nat_result <- mean(nat_pool$Ey, na.rm = TRUE)
      if (ref_int == 0) {
	  ref_mean <- nat_result
      }
      else {
	  ref_mean <- mean(pools[[ref_int]]$Ey, na.rm = TRUE)
      }
      int_result[1] <- nat_result
      int_result[-1] <- sapply(pools, FUN = function(pool) {
	  mean(pool$Ey, na.rm = TRUE)
      })
      result_ratio <- int_result/ref_mean
      result_diff <- int_result - ref_mean
      if (nsamples > 0) {
	  if (parallel) {
	      cl <- prep_cluster(ncores = ncores, threads = threads, 
		  covtypes = covtypes, bootstrap_option = TRUE)
	      final_bs <- parallel::parLapply(cl, 1:nsamples, bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = NA, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = FALSE, ...)
	      parallel::stopCluster(cl)
	  }
	  else {
	      if (show_progress) {
		  pb <- progress::progress_bar$new(total = nsamples * 
		    length(comb_interventions), clear = FALSE, 
		    format = "Bootstrap progress [:bar] :percent, Elapsed time :elapsed, Est. time remaining :eta")
	      }
	      final_bs <- lapply(1:nsamples, FUN = bootstrap_helper, 
		  time_points = time_points, obs_data = obs_data_noresample, 
		  bootseeds = bootseeds, intvars = comb_intvars, 
		  interventions = comb_interventions, int_times = comb_int_times, 
		  ref_int = ref_int, covparams = covparams, covnames = covnames, 
		  covtypes = covtypes, covfits_custom = covfits_custom, 
		  covpredict_custom = covpredict_custom, basecovs = basecovs, 
		  ymodel = ymodel, histvars = histvars, histvals = histvals, 
		  histories = histories, comprisk = comprisk, compevent_model = compevent_model, 
		  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions, 
		  restrictions = restrictions, outcome_type = outcome_type, 
		  ranges = ranges, yrange = yrange, compevent_range = NA, 
		  time_name = time_name, outcome_name = outcome_name, 
		  compevent_name = compevent_name, parallel = parallel, 
		  ncores = ncores, max_visits = max_visits, hazardratio = hazardratio, 
		  intcomp = intcomp, boot_diag = boot_diag, nsimul = nsimul, 
		  baselags = baselags, below_zero_indicator = below_zero_indicator, 
		  min_time = min_time, show_progress = show_progress, 
		  pb = pb, ...)
	  }
	  comb_result <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$Result))
	  }))
	  comb_MR <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultRatio))
	  }))
	  comb_MD <- rbindlist(lapply(final_bs, FUN = function(m) {
	      as.data.table(t(m$ResultDiff))
	  }))
	  comb_result$t0 <- comb_MR$t0 <- comb_MD$t0 <- time_points
	  se_result <- comb_result[, lapply(.SD, stats::sd), by = t0]
	  se_MR <- comb_MR[, lapply(.SD, stats::sd), by = t0]
	  se_MD <- comb_MD[, lapply(.SD, stats::sd), by = t0]
	  if (ci_method == "normal") {
	      ci_lb_result <- t(int_result) - stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_lb_MR <- t(int_result) - stats::qnorm(0.975) * 
		  se_MR[, -c("t0")]
	      ci_lb_MD <- t(int_result) - stats::qnorm(0.975) * 
		  se_MD[, -c("t0")]
	      ci_ub_result <- t(int_result) + stats::qnorm(0.975) * 
		  se_result[, -c("t0")]
	      ci_ub_MR <- t(int_result) + stats::qnorm(0.975) * 
		  se_MR[, -c("t0")]
	      ci_ub_MD <- t(int_result) + stats::qnorm(0.975) * 
		  se_MD[, -c("t0")]
	  }
	  if (ci_method == "percentile") {
	      ci_lb_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_MR <- comb_MR[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_lb_MD <- comb_MD[, lapply(.SD, stats::quantile, 
		  probs = 0.025), by = t0]
	      ci_ub_result <- comb_result[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_MR <- comb_MR[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	      ci_ub_MD <- comb_MD[, lapply(.SD, stats::quantile, 
		  probs = 0.975), by = t0]
	  }
      }
      if (nsamples > 0 & boot_diag) {
	  bootcoeffs <- lapply(final_bs, "[[", "bootcoeffs")
	  bootstderrs <- lapply(final_bs, "[[", "bootstderrs")
	  bootvcovs <- lapply(final_bs, "[[", "bootvcovs")
      }
      else {
	  bootcoeffs <- NULL
	  bootstderrs <- NULL
	  bootvcovs <- NULL
      }
      plot_info <- get_plot_info(outcome_name = outcome_name, compevent_name = compevent_name, 
	  compevent2_name = compevent2_name, censor_name = censor_name, 
	  time_name = time_name, time_points = time_points, covnames = covnames, 
	  covtypes = covtypes, nat_pool = nat_pool, nat_result = nat_result, 
	  comprisk = comprisk, comprisk2 = comprisk2, censor = censor, 
	  fitC = fitC, outcome_type = outcome_type, obs_data = obs_data_noresample, 
	  ipw_cutoff_quantile = ipw_cutoff_quantile, ipw_cutoff_value = ipw_cutoff_value)
      obs_results <- plot_info$obs_results
      if (!is.null(interventions)) {
	  resultdf <- lapply(seq_along(int_result), function(k) {
	      if (nsamples > 0) {
		  data.table(t = time_points - 1, Intervention = k - 
		    1, EOFMean = int_result[k], EOFMean_SE = se_result[[paste0("V", 
		    k)]], EOFMean_CI_LL95 = ci_lb_result[[paste0("V", 
		    k)]], EOFMean_CI_UL95 = ci_ub_result[[paste0("V", 
		    k)]], EOFMeanRatio = result_ratio[k], MR_SE = se_MR[[paste0("V", 
		    k)]], MR_CI_LL95 = ci_lb_MR[[paste0("V", k)]], 
		    MR_CI_UL95 = ci_ub_MR[[paste0("V", k)]], EOFMeanDiff = result_diff[k], 
		    MD_SE = se_MD[[paste0("V", k)]], MD_CI_LL95 = ci_lb_MD[[paste0("V", 
		      k)]], MD_CI_UL95 = ci_ub_MD[[paste0("V", 
		      k)]])
	      }
	      else {
		  data.table(t = time_points - 1, Intervention = k - 
		    1, OutcomeEOFMean = int_result[k], EOFMeanRatio = result_ratio[k], 
		    EOFMeanDiff = result_diff[k])
	      }
	  })
	  resultdf <- rbindlist(resultdf)
      }
      else {
	  if (nsamples > 0) {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  EOFMean = int_result, EOFMean_SE = se_MD[, -c("t0")], 
		  EOFMean_CI_LL95 = ci_lb_result[, -c("t0")], EOFMean_CI_UL95 = ci_ub_result[, 
		    -c("t0")], EOFMeanRatio = result_ratio, MR_SE = se_MR[, 
		    -c("t0")], MR_CI_LL95 = ci_lb_MR[, -c("t0")], 
		  MR_CI_UL95 = ci_ub_MR[, -c("t0")], EOFMeanDiff = result_diff, 
		  EOFMD_se = se_MD[, -c("t0")], MD_CI_LL95 = ci_lb_MD[, 
		    -c("t0")], MD_CI_UL95 = ci_ub_MD[, -c("t0")])
	  }
	  else {
	      resultdf <- data.table(t = 0:(time_points - 1), Intervention = 0, 
		  OutcomeEOFMean = int_result, EOFMeanRatio = result_ratio, 
		  EOFMeanDiff = result_diff)
	  }
      }
      resultdf$obs_risk <- c(utils::tail(obs_results[[2]], 1), 
	  rep(NA, dim(resultdf)[1] - 1))
      obs_mean_name <- ifelse(censor, "IP weighted mean", "NP mean")
      if (nsamples > 0) {
	  colnames(resultdf) <- c("k", "Interv.", "g-form mean", 
	      "Mean SE", "Mean lower 95% CI", "Mean upper 95% CI", 
	      "Mean ratio", "MR SE", "MR lower 95% CI", "MR upper 95% CI", 
	      "Mean difference", "MD SE", "MD lower 95% CI", "MD upper 95% CI", 
	      obs_mean_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_mean_name, 
	      "g-form mean", "Mean SE", "Mean lower 95% CI", "Mean upper 95% CI", 
	      "Mean ratio", "MR SE", "MR lower 95% CI", "MR upper 95% CI", 
	      "Mean difference", "MD SE", "MD lower 95% CI", "MD upper 95% CI"))
      }
      else {
	  colnames(resultdf) <- c("k", "Interv.", "g-form mean", 
	      "Mean ratio", "Mean difference", obs_mean_name)
	  setcolorder(resultdf, c("k", "Interv.", obs_mean_name, 
	      "g-form mean", "Mean ratio", "Mean difference"))
      }
      if (time_points > 1) {
	  fits <- fitcov
	  fits[[length(fits) + 1]] <- fitY
	  names(fits)[length(fits)] <- outcome_name
      }
      else {
	  fits <- list(fitY)
      }
      if (!is.na(fitC)[[1]]) {
	  fits[[length(fits) + 1]] <- fitC
	  names(fits)[length(fits)] <- censor_name
      }
      coeffs <- get_coeffs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      stderrs <- get_stderrs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      vcovs <- get_vcovs(fits = fits, fitD = NA, time_points = time_points, 
	  outcome_name = outcome_name, compevent_name = compevent_name, 
	  covnames = covnames)
      rmses <- lapply(seq_along(fits), FUN = rmse_calculate, fits = fits, 
	  covnames = covnames, covtypes = covtypes, obs_data = obs_data, 
	  outcome_name = outcome_name, time_name = time_name, restrictions = restrictions, 
	  yrestrictions = yrestrictions, compevent_restrictions = compevent_restrictions)
      if (time_points == 1) {
	  rmses <- stats::setNames(rmses, outcome_name)
      }
      else {
	  rmses <- stats::setNames(rmses, c(covnames, outcome_name))
      }
      header <- get_header(int_descript, sample_size, nsimul, nsamples, 
	  ref_int)
      if (sim_data_b) {
	  sim_data <- c(list(`Natural course` = nat_pool), pools)
	  if (!is.null(int_descript)) {
	      names(sim_data)[2:length(sim_data)] <- int_descript
	  }
      }
      else {
	  sim_data <- NA
      }
      if (!model_fits) {
	  fits <- NULL
      }
      res <- list(result = resultdf, coeffs = coeffs, stderrs = stderrs, 
	  vcovs = vcovs, rmses = rmses, fits = fits, sim_data = sim_data, 
	  IP_weights = obs_results$w, bootcoeffs = bootcoeffs, 
	  bootstderrs = bootstderrs, bootvcovs = bootvcovs, time_name = time_name, 
	  time_points = time_points, covnames = covnames, covtypes = covtypes, 
	  dt_cov_plot = plot_info$dt_cov_plot, dt_out_plot = plot_info$dt_out_plot, 
	  header = header)
      class(res) <- c("gformula_continuous_eof", "gformula")
      return(res)
  }   
  environment(gformula_continuous_eof) <- asNamespace("gfoRmula")


  ##Code for testing - first a test of the gfoRmula package before modification:

  ## outcome_type <- "survival"
  ## id <- "id"
  ## time_points <- 7
  ## time_name <- "t0"
  ## covnames <- c("L1" , "L2" , "A")
  ## outcome_name <- "Y"
  ## covtypes <- c("binary" , "bounded normal" , "binary")
  ## histories <- c(lagged , lagavg)
  ## histvars <- list(c("A" , "L1" , "L2") , c("L1" , "L2"))
  ## covparams <- list(covmodels = c(L1 ~lag1_A + lag_cumavg1_L1 + lag_cumavg1_L2 + L3 + t0 ,
  ##                                 L2 ~ lag1_A + L1 + lag_cumavg1_L1 + lag_cumavg1_L2 + L3 + t0 ,
  ##                                 A ~ lag1_A + L1 + L2 + lag_cumavg1_L1 + lag_cumavg1_L2 + L3 + t0))
  ## ymodel <- Y ~ A + L1 + L2 + L3 + lag1_A + lag1_L1 + lag1_L2 + t0
  ## intvars <- list("A" , "A")
  ## interventions <- list(list(c(static , rep(0 , time_points))) ,
  ##                       list(c(static , rep(1 , time_points))))
  ## int_descript <- c("Never treat" , "Always treat")
  ## nsimul <- 10000
  ## gform_basic <- gformula(obs_data = basicdata_nocomp ,
  ##                         outcome_type = outcome_type ,
  ##                         id = id ,
  ##                         time_points = time_points ,
  ##                         time_name = time_name ,
  ##                         covnames = covnames ,
  ##                         outcome_name = outcome_name ,
  ##                         covtypes = covtypes ,
  ##                         covparams = covparams ,
  ##                         ymodel = ymodel ,
  ##                         intvars = intvars ,
  ##                         interventions = interventions ,
  ##                         int_descript = int_descript ,
  ##                         histories = histories ,
  ##                         histvars = histvars ,
  ##                         basecovs = c("L3") ,
  ##                         nsimul = nsimul ,
  ##                         seed = 1234 ,
  ##                         nsamples = 10)
  ## gform_basic

  ## ##The results here are identical to the results produced on my computer - thus validated that the package works as expected before I intervene. Now for the modification: 

  ## ##Generate clusters for basicdata_nocomp (50 clusters randomly assigned to all ids, with each id only being assigned one cluster):
  ## testData <- copy(basicdata_nocomp)
  ## ids <- unique(testData[ , .(id)])
  ## ids[ , testClusterID := sample(1:50 , .N , replace = TRUE)]
  ## testData[ids , on = "id" , testClusterID := i.testClusterID]

  ## ##Try this after modifying the package:
  ## gform_basic <- gformula(obs_data = testData ,
  ##                         outcome_type = outcome_type ,
  ##                         id = id ,
  ##                         time_points = time_points ,
  ##                         time_name = time_name ,
  ##                         covnames = covnames ,
  ##                         outcome_name = outcome_name ,
  ##                         covtypes = covtypes ,
  ##                         covparams = covparams ,
  ##                         ymodel = ymodel ,
  ##                         intvars = intvars ,
  ##                         interventions = interventions ,
  ##                         int_descript = int_descript ,
  ##                         histories = histories ,
  ##                         histvars = histvars ,
  ##                         basecovs = c("L3") ,
  ##                         nsimul = nsimul ,
  ##                         seed = 1234 ,
  ##                         nsamples = 10 ,
  ##                         clusterID = "testClusterID")
  ## gform_basic

  ##Running the above code after modifying gfoRmula, the same results are generated when run without the clusterID argument, but when this argument is added, the point estimates remain intact but the confidence intervals widen - which is what is to be expected when applying groupwise bootstrapping. Thus, the code seems to work exactly as intended. 
#+end_src

** Code for wrapping a bootstrapping around sequential runs of the gfoRmula - the modifications mentioned above works but breaks memory for unknown reasons
#+begin_src R :session rsession :results output :exports both
  ##This code block works perfectly - but the gmodel keeps throwing error messages related to too few data or too many variables, even when the model is reduced to absurdity. A confidence interval seems not feasible with the current hardware restrictions.

  library(data.table)
  library(gfoRmula)

  ##Modifying the function for fitting the G-model slightly to fit in below:
  gModelFitterBootstrap <- function (dataset) {
      ##This is done using one of the imputed datasets from above. 
      analysisDataset <- dataset
      ##Do some pre-formatting to make sure the dataset looks as needed:
      ##Re-code the exposure and outcome:

      analysisDataset[jointCharlsonParents <= 1 , gTreatment := 1]
      analysisDataset[jointCharlsonParents > 1 , gTreatment := 0]
      analysisDataset[outcomePhysicalAbuse > 0 , anyPhysicalAbuse := 1]
      analysisDataset[is.na(anyPhysicalAbuse) , anyPhysicalAbuse := 0]
      ##The next line if this is an end of follow-up outcome:
      ##analysisDataset[time < 214 & anyPhysicalAbuse != 1 , anyPhysicalAbuse := NA]
      analysisDataset[deathCensoring == date & outcomePhysicalAbuse == 0 , deathCompetingEvent := 1]
      analysisDataset[deathCompetingEvent == 1 , anyPhysicalAbuse := NA]

      ##Making a new timecode - this is necessary as participants are drawn from familyIndex, and if this changes, they may participate later than their first entry or earlier thann their censoring or the occurrance of an event in the main study.
      setorder(analysisDataset , bsId , date)
      analysisDataset[ , time := 0:(.N-1) , by = "bsId"]

      ##Set the order of data correctly:
      setorder(analysisDataset , bsId , time)

      ##Looking at the incomeVariable, trying to make it fit for something linear - it actually looks quite normally distributed, see the graph below, but with some very long tails. I will leave it as it is for now, unless advised otherwise by the statistician. 
      ##ggplot() + geom_histogram(data = analysisDataset , aes(x = incomeVariable) , breaks = seq(from = -250 , to = 500, by = 50))

      ##analysisDataset[ , logIncomeVariable := log(incomeVariable)]
      ##Recoding binary factors as a binary numeric variables- thus updating after the imputations:
      analysisDataset[familyEducationalLevelReleveled == "Primary or secondary education" , familyEducationalLevelBinary := 0]
      analysisDataset[familyEducationalLevelReleveled == "Tertiary education or higher" , familyEducationalLevelBinary := 1]
      analysisDataset[oneForeignParent == "No foreign parents" , oneForeignParentBinary := 0]
      analysisDataset[oneForeignParent == "One or more foreign parents" , oneForeignParentBinary := 1]
      ## analysisDataset[familyNeedProtection == "Not in need of protection" , familyNeedProtectionBinary := 0]
      ## analysisDataset[familyNeedProtection == "In need of protection" , familyNeedProtectionBinary := 1]
      ## analysisDataset[parentalPsychiatricDisease == "No psychiatric disease" , parentalPsychiatricDiseaseBinary := 0]
      ## analysisDataset[parentalPsychiatricDisease == "Any psychiatric disease" , parentalPsychiatricDiseaseBinary := 1]
      ## analysisDataset[parentalAbuseAsChildReleveled == "No maltreatment or neglect" , parentalAbuseAsChildBinary := 0]
      ## analysisDataset[parentalAbuseAsChildReleveled == "Maltreatment or neglect, one or both parents" , parentalAbuseAsChildBinary := 1]
      analysisDataset[interparentalViolence == "No interparental violence" , interparentalViolenceBinary := 0]
      analysisDataset[interparentalViolence == "Interparental violence" , interparentalViolenceBinary := 1]
      analysisDataset[parentalSubstanceAbuse == "No parental substance abuse" , parentalSubstanceAbuseBinary := 0]
      analysisDataset[parentalSubstanceAbuse == "Parental substance abuse" , parentalSubstanceAbuseBinary := 1]



      ##childAgeGroup is supposed to capture age at inclusion - but it is obviously not constant, as it currently changes with age. Changing this, also for time period:

      tempAge <- unique(analysisDataset[time == 0 , .(bsId , childAgeGroup)])
      analysisDataset[tempAge , on = "bsId" , childAgeGroupAtInclusion := i.childAgeGroup]
      tempCalendarTime <- unique(analysisDataset[time == 0 , .(bsId , calendarTimeGroup)])
      analysisDataset[tempCalendarTime , on = "bsId" , calendarTimeGroupAtInclusion  := i.calendarTimeGroup]

      ##Looking for errors - recoding childAgeGroupAtInclusion as a binary:
      analysisDataset[childAgeGroupAtInclusion == "Child 0-6 years old" , childAgeGroupAtInclusionBinary := 0]  
      analysisDataset[childAgeGroupAtInclusion == "Child 7-18 years old" , childAgeGroupAtInclusionBinary := 1]

      ##I forgot to factorize the new number of children-variable earlier:
      analysisDataset[ , numberOfChildrenFactor :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 5 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three to five children" ,
					    "Six children or more"))]

      ##As the cuts above produces small cells in this draw of 50.000 children, the variable is redefined with fewer levels here and used in the second definition of the model (see below):

      analysisDataset[ , numberOfChildrenFactorReleveled :=
			     cut(newNoOfChildren ,
				 breaks = c(0 , 1 , 2 , 20) ,
				 labels = c("One child" ,
					    "Two children" ,
					    "Three children or more"
					    ))]

      ##Proceeding with the actual fitting: 
      gFitCharlson <- gformula_survival(obs_data = analysisDataset ,
					outcome_name = "anyPhysicalAbuse" ,
					compevent_name = "deathCompetingEvent" ,
					time_points = 35 ,
					time_name = "time" ,
					ref_int = 2 ,
					##This is a straight linear model - is that okay? I will get an awful lot of parameters if I start putting in products.
					##I think what I am asking is to compare people who are always not ill with people who are always ill - need to confirm.
					intvars = list("gTreatment" , "gTreatment") , 
					interventions = list(list(c(static , rep(0 , 35))) ,
							     list(c(static , rep(1 , 35)))) , 
					int_descript = c("Never treat" , "Always treat") , 
					ymodel = anyPhysicalAbuse ~ gTreatment +
					    time +
					    parishQuantileDifference100Euros +
					    numberOfChildrenFactorReleveled +
					    reconstitutedFamily +
					    familyEducationalLevelBinary +
					    incomeVariable +
					    parentalPsychiatricDiseaseBinary +
					    ##interparentalViolenceBinary +
					    parentalSubstanceAbuseBinary +
					    ##parentalAbuseAsChildBinary +
					    oneForeignParentBinary +
					    ##familyNeedProtectionBinary +
					    childAgeGroupAtInclusionBinary +
					    calendarTimeGroupAtInclusion +
					    meanParentalAge ,
					compevent_model = deathCompetingEvent ~ gTreatment +
					    time +
					    parishQuantileDifference100Euros +
					    numberOfChildrenFactorReleveled +
					    reconstitutedFamily +
					    familyEducationalLevelBinary +
					    incomeVariable +
					    parentalPsychiatricDiseaseBinary +
					    ##interparentalViolenceBinary +
					    parentalSubstanceAbuseBinary +
					    ##parentalAbuseAsChildBinary +
					    oneForeignParentBinary +
					    ##familyNeedProtectionBinary +
					    childAgeGroupAtInclusionBinary +
					    calendarTimeGroupAtInclusion +
					    meanParentalAge ,
					id = "bsId" ,
					covnames = c("parishQuantileDifference100Euros" ,
						     "numberOfChildrenFactorReleveled" ,
						     "reconstitutedFamily" ,
						     "familyEducationalLevelBinary" ,
						     "incomeVariable" ,
						     "parentalPsychiatricDiseaseBinary" ,
						     ##"interparentalViolenceBinary" ,
						     "parentalSubstanceAbuseBinary" ,  
						     ##"parentalAbuseAsChildBinary" ,
						     "oneForeignParentBinary" ,
						     ##"familyNeedProtectionBinary" ,
						     "meanParentalAge" ,
						     "gTreatment") ,
					histories = c(lagged) ,
					histvars = list(c("parishQuantileDifference100Euros" ,
							  "numberOfChildrenFactorReleveled" ,
							  "reconstitutedFamily" ,
							  "familyEducationalLevelBinary" ,
							  "incomeVariable" ,
							  "parentalPsychiatricDiseaseBinary" ,
							  ##"interparentalViolenceBinary" ,
							  ##"parentalSubstanceAbuseBinary" ,
							  "parentalAbuseAsChildBinary" ,
							  "oneForeignParentBinary" , 
							  ##"familyNeedProtectionBinary" ,
							  "meanParentalAge" ,
							  "gTreatment")) , ##Remember that for parishQuantileDifference100Euros and incomeVariable they are actually already lagged - use only in special cases as lagged.
					##May I look at distributions  in the data here when I set these?
					covtypes = c("normal" , #parishQuantileDifference100Euros
						     "categorical" , #numberOfChildrenFactorReleveled
						     "categorical" , #reconstitutedFamily
						     "binary" , #education
						     "normal" , #incomeVariable
						     "binary" , #parentalPsychiatricDiseaseBinary
						     ##"binary" , #interparentalViolenceBinary"
						     ##"binary" , #parentalSubstanceAbuseBinary
						     "binary" , #parentalAbuseAsChildBinary
						     "binary" , #oneForeignParentBinary"
						     ##"binary" , #familyNeedProtectionBinary
						     "normal" , #meanParentalAge
						     "binary") , #gTreatment 
					##I've used the history-variable to generate lagged variables for all time-varying covariates. Now, the covmodels need to be specified - use lag1_parishQuantileDifference100Euros to name the previous value of a variable in a formula. Reduce the following formulas to reduce complexity. If it makes theoretical sense, you could use lag1_example to predict the current value of example.
					covparams = list(covmodels = c(parishQuantileDifference100Euros ~ 
									   lag1_parishQuantileDifference100Euros +
									   lag1_familyEducationalLevelBinary +
									   incomeVariable +
									   ##familyNeedProtectionBinary +
									   ##childAgeGroupAtInclusionBinary +
									   ##calendarTimeGroupAtInclusion +
									   ##meanParentalAge +
									   time , 
								       numberOfChildrenFactorReleveled ~
									   gTreatment +
									   lag1_numberOfChildrenFactorReleveled +
									   lag1_reconstitutedFamily +
									   ##lag1_familyEducationalLevelBinary +
									   ##lag1_parentalPsychiatricDiseaseBinary +
									   oneForeignParentBinary +
									   childAgeGroupAtInclusionBinary +
									   calendarTimeGroupAtInclusion +
									   meanParentalAge +
									   time ,
								       reconstitutedFamily ~
									   gTreatment +
									   lag1_reconstitutedFamily +
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_interparentalViolenceBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   childAgeGroupAtInclusionBinary +
									   ##calendarTimeGroupAtInclusion +
									   ##meanParentalAge +
									   time ,
								       familyEducationalLevelBinary ~
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   ##meanParentalAge +
									   ##incomeVariable +
									   time ,
								       incomeVariable ~
									   gTreatment + 
									   ##lag1_numberOfChildrenFactorReleveled +
									   lag1_incomeVariable +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   oneForeignParentBinary +
									   ##familyNeedProtectionBinary +
									   ##childAgeGroupAtInclusionBinary +
									   meanParentalAge +
									   time ,
								       parentalPsychiatricDiseaseBinary ~
									   gTreatment +
									   incomeVariable + 
									   ##lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   ##lag1_interparentalViolenceBinary +
									   ##lag1_parentalSubstanceAbuseBinary +
									   parentalAbuseAsChildBinary +
									   ##familyNeedProtectionBinary +
									   ##meanParentalAge +
									   time ,
								       ## interparentalViolenceBinary ~
								       ##     lag1_parishQuantileDifference100Euros +
								       ##     lag1_reconstitutedFamily +
								       ##     lag1_familyEducationalLevelBinary +
								       ##     lag1_parentalPsychiatricDiseaseBinary +
								       ##     lag1_interparentalViolenceBinary +
								       ##     lag1_parentalSubstanceAbuseBinary +
								       ##     parentalAbuseAsChildBinary +
								       ##     oneForeignParentBinary +
								       ##     familyNeedProtectionBinary +
								       ##     childAgeGroupAtInclusionBinary +
								       ##     calendarTimeGroupAtInclusion +
								       ##     meanParentalAge ,
								       ## parentalSubstanceAbuseBinary ~
								       ##     lag1_parishQuantileDifference100Euros +
								       ##     lag1_familyEducationalLevelBinary +
								       ##     lag1_parentalPsychiatricDiseaseBinary +
								       ##     lag1_parentalSubstanceAbuseBinary +
								       ##     parentalAbuseAsChildBinary +
								       ##     familyNeedProtectionBinary +
								       ##     calendarTimeGroupAtInclusion +
								       ##     meanParentalAge ,
								       ## parentalAbuseAsChildBinary ~
								       ##     lag1_parentalAbuseAsChildBinary +
								       ##     lag1_reconstitutedFamily +
								       ##     time ,
								       ## oneForeignParentBinary ~
								       ##     lag1_oneForeignParentBinary +
								       ##     ##lag1_familyNeedProtectionBinary +
								       ##     ##lag1_numberOfChildrenFactorReleveled +
								       ##     lag1_reconstitutedFamily +
								       ##     time ,
								       ## familyNeedProtectionBinary ~
								       ##     lag1_oneForeignParentBinary +
								       ##     lag1_familyNeedProtectionBinary +
								       ##     lag1_numberOfChildrenFactorReleveled +
								       ##     lag1_reconstitutedFamily ,
								       meanParentalAge ~
									   lag1_meanParentalAge +
									   lag1_reconstitutedFamily +
									   time ,
								       gTreatment ~
									   lag1_gTreatment +
									   lag1_reconstitutedFamily +
									   lag1_numberOfChildrenFactorReleveled +
									   incomeVariable +
									   lag1_familyEducationalLevelBinary +
									   lag1_parentalPsychiatricDiseaseBinary +
									   lag1_parentalAbuseAsChildBinary +
									   time)) ,
					basecovs = c("childAgeGroupAtInclusionBinary" ,
						     "calendarTimeGroupAtInclusion") ,
					##nsimul = 10000 ,
					seed = sample(1:100000 , 1) , ##The reason for setting seed by random is that the random seed is controlled outside of the loop that this function will be executed in
					parallel = TRUE ,
					ncores = 10 ,
					threads = 15 ,
					##clusterID = "familyIndex" ,
					nsamples = 0)
      ##boot_diag = TRUE) 
      gFitCharlson
  }

  bootstrapWrapperGfoRmula <- function(data , clusterIDBW , individualID , date , iterations , splitVariable = NA) {
      bootstrapResultsPointEstimate <-
	  data.table(pointEstimate = numeric() ,
		     bootstrapNo = numeric())
      sampleData <- copy(data)
      setnames(sampleData , clusterIDBW , "clusterIDBW")
      setnames(sampleData , individualID , "individualID")
      setnames(sampleData , date , "date")
      if (is.na(splitVariable)) {
	  setorder(sampleData , individualID , date)
	  uniqueClusters <- as.data.table(unique(sampleData$clusterIDBW))
	  ##Make a list of unique individualIDs and their corresponding clusterIDs
	  uniqueClusterId <- unique(sampleData ,
				    by = c("individualID" , "clusterIDBW"))[ ,
									    .(clusterIDBW , individualID)]
	  for (i in 1:iterations) {
	      ##Sample a number of clusters equivalent to the number of clusters in the dataset:
	      clusters <-
		  data.table(clusterIDBW = sample(uniqueClusters[ , V1] ,
						  uniqueClusters[ , .N] ,
						  replace = TRUE))
	      ##Checking this algorithm, clusters[ , range(table(clusterIDBoot))] shows that included numbers were drawn between 1 and 6 times (and also 0 but this cannot be seen here) - this seems reasonable.
	      ##Merge the list and the clusters drawn:
	      bsDataset <- merge(clusters ,
				 uniqueClusterId ,
				 by = "clusterIDBW" ,
				 allow.cartesian = TRUE)
	      ##Give new numbers to the ids:
	      bsDataset[ , bsId := 1:.N]

	      ##Make a full bootstrapped dataset:
	      bsDataset <- merge(bsDataset ,
				 sampleData ,
				 by = c("clusterIDBW" ,
					"individualID") ,
				 allow.cartesian = TRUE)
	      ##Checked manually - the size is approximately the same as for the input dataset and the original id can be seen to be repeated with new bootstrap ids if it has been drawn several times. No reason for doubting the validity. There will be individuals here that are "censored out" when they stop contributing data because they are members of a new family that was not drawn in this bootstrap - this will be treated as censoring in the analysis, which should be fine.
	      ##Cleaning up:
	      bsDataset[ , c("clusterIDBW" , "individualID") := NULL]        
	      ##Fit the model:
	      print(paste0("Fitting sample no " , i , "at time " , Sys.time()))
	      gFitCharlson <- gModelFitterBootstrap(bsDataset)
	      ##Extract the point estimate:
	      pointEstimate <- as.numeric(gFitCharlson$result[k == 34 & Interv. == 1][ , 5])
	      bootstrapNo <- i
	      ##...and put them in a table:
	      bootstrapResultsPointEstimate <-
		  rbindlist(list(bootstrapResultsPointEstimate ,
				 list(pointEstimate , bootstrapNo)))
	      fwrite(bootstrapResultsPointEstimate , "bootstrapResultsPointEstimate.csv")

	      ##Also save latest random seed:
	      randomSeed <- .Random.seed
	      save(randomSeed , file = "latestRandomSeed.RData")
	      ##In the event of a reboot, simply reload latestRandomSeed and send it to .Random.seed
	  }
      } else {
	  eval(parse(text = paste0("sampleData[ , splitVariable := " , splitVariable , "]")))
	  ##Sample the available clusters
	  setorderv(sampleData , c("splitVariable" , "individualID" , "date"))
	  uniqueClusters0 <- unique(sampleData[splitVariable == 0 , .(clusterIDBW)])
	  uniqueClusters1 <- unique(sampleData[splitVariable == 1 , .(clusterIDBW)])
	  ##Some familyIds are in both groups - avoid overlap (every id has to have the same chance as all other ids to be drawn), favoring the smaller group:
	  uniqueClusters1[uniqueClusters0 , on = "clusterIDBW" , delete := 1]
	  uniqueClusters1 <- uniqueClusters1[is.na(delete)]
	  uniqueClusters1[ , delete := NULL]
	  ##Make a list of unique individualIDs and their corresponding clusterIDs
	  uniqueClusterId <- unique(sampleData ,
				    by = c("individualID" , "clusterIDBW"))[ ,
									    .(clusterIDBW , individualID)]
	  for (i in 1:iterations) {
	      ##Sample a number of clusters equivalent to the number of clusters in the dataset:
	      clusters0 <-
		  data.table(clusterIDBW = sample(uniqueClusters0[ , clusterIDBW] ,
						  uniqueClusters0[ , .N] ,
						  replace = TRUE))
	      clusters1 <-
		  data.table(clusterIDBW = sample(uniqueClusters1[ , clusterIDBW] ,
						  uniqueClusters1[ , .N] ,
						  replace = TRUE))
	      clusters <- rbindlist(list(clusters0 , clusters1))
	      ##Checking this algorithm, clusters[ , range(table(clusterIDBoot))] shows that included numbers were drawn between 1 and 6 times (and also 0 but this cannot be seen here) - this seems reasonable.
	      ##Merge the list and the clusters drawn:
	      bsDataset <- merge(clusters ,
				 uniqueClusterId ,
				 by = "clusterIDBW" ,
				 allow.cartesian = TRUE)
	      ##Give new numbers to the ids:
	      bsDataset[ , bsId := 1:.N]

	      ##Make a full bootstrapped dataset:
	      bsDataset <- merge(bsDataset ,
				 sampleData ,
				 by = c("clusterIDBW" ,
					"individualID") ,
				 allow.cartesian = TRUE)
	      ##Checked manually - the size is approximately the same as for the input dataset and the original id can be seen to be repeated with new bootstrap ids if it has been drawn several times. No reason for doubting the validity. There will be individuals here that are "censored out" when they stop contributing data because they are members of a new family that was not drawn in this bootstrap - this will be treated as censoring in the analysis, which should be fine.
	      ##Cleaning up:
	      bsDataset[ , c("clusterIDBW" , "individualID") := NULL]        
	      ##Fit the model:
	      print(paste0("Fitting sample no " , i , "at time " , Sys.time()))
	      gFitCharlson <- gModelFitterBootstrap(bsDataset)
	      ##Extract the point estimate:
	      pointEstimate <- as.numeric(gFitCharlson$result[k == 34 & Interv. == 1][ , 5])
	      bootstrapNo <- i
	      ##...and put them in a table:
	      bootstrapResultsPointEstimate <-
		  rbindlist(list(bootstrapResultsPointEstimate ,
				 list(pointEstimate , bootstrapNo)))
	      fwrite(bootstrapResultsPointEstimate , "bootstrapResultsPointEstimate.csv")

	      ##Also save latest random seed:
	      randomSeed <- .Random.seed
	      save(randomSeed , file = "latestRandomSeed.RData")
	      ##In the event of a reboot, simply reload latestRandomSeed and send it to .Random.seed
	  }
      }
  }




  ##...and now do it!


  imputedData <- readAnalysisDatasetImputed(1)
  ##If you want to stratify the bootstrap on two levels, define some variable with 0 and 1 for the levels; here gTreatment is already defined for that purpose.
  ##Remember to set seed beforehand!
  set.seed(25328621)
  bootstrapWrapperGfoRmula(data = imputedData ,
			   clusterIDBW = "familyIndex" ,
			   individualID = "pnr" ,
			   date = "date" ,
			   iterations = 5 ,
			   splitVariable = "gTreatment")
  ##The intended output should be in the bootstrapResultsPointEstimate.csv file.

  ##This model failed. For the moment I will stop doing new tries, otherwise I might end up with the results from a severely simplified model that may or may not be the same as those from the original model. The meaning of any differences will however be difficult to interpret. 

  ## ##If I need to restart the process after a server reboot:

  ## load("latestRandomSeed.RData")

  ## imputedData <- readAnalysisDatasetImputed(1)
  ## .Random.seed <- randomSeed
  ## bootstrapWrapperGfoRmula(data = imputedData , clusterIDBW = "familyIndex" , individualID = "pnr" , date = "date" , iterations = 38)

#+end_src

** Code block for iterating over disease categories
#+begin_src R :session rsession :results output :exports both
  ##Re-loading of the full dataset: 
  readAnalysisDatasetExplorative <- function() {
      analysisDataset <-
	  fread("analysisDatasetExplorative.csv" ,
		colClasses = c("pnr" = "character" ,
			       "date" = "Date" ,
			       "currentParent2" = "character" ,
			       "currentParent1" = "character" ,
			       "reconstitutedFamily" = "factor" ,
			       "studyEntry" = "Date" ,
			       "ageCensoring" = "Date" ,
			       "deathCensoring" = "Date" ,
			       "emigrationCensoring" = "Date" ,
			       "meanParentalAge" = "numeric" ,
			       "birthDate" = "Date" ,
			       "childAge" = "numeric" ,
			       "hearingProblemGroupDiagCurrentParent1" = "numeric" ,
			       "hearingProblemGroupDiagCurrentParent2" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent1" = "numeric" ,
			       "diabetesWithoutComplicationsCharlsonCurrentParent2" = "numeric" ,
			       "heartFailureCharlsonCurrentParent1" = "numeric" ,
			       "heartFailureCharlsonCurrentParent2" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent1" = "numeric" ,
			       "hemiplegiaParaplegiaCharlsonCurrentParent2" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent1" = "numeric" ,
			       "metastaticSolidTumorCharlsonCurrentParent2" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "mildLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent1" = "numeric" ,
			       "myocardialInfarctionCharlsonCurrentParent2" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "pepticUlcerDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "peripheralVascularDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "renalDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "rheumaticDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent1" = "numeric" ,
			       "severeLiverDiseaseCharlsonCurrentParent2" = "numeric" ,
			       "alcoholAbuseCurrentParent1" = "numeric" ,
			       "alcoholAbuseCurrentParent2" = "numeric" ,
			       "substanceAbuseCurrentParent1" = "numeric" ,
			       "substanceAbuseCurrentParent2" = "numeric" ,
			       "jointCharlsonParents" = "numeric" ,
			       "outcomePhysicalAbuse" = "numeric" ,
			       "interparentalViolence" = "factor" ,
			       "familyEducationalLevel" = "factor" ,
			       "parentalAbuseAsChild" = "factor" ,
			       "oneForeignParent" = "factor" ,
			       "familyNeedProtection" = "factor" ,
			       "parentalPsychiatricDisease" = "factor" ,
			       "parentalSubstanceAbuse" = "factor" ,
			       "calendarTimeGroup" = "factor" ,
			       "childAgeGroup" = "factor" ,
			       "parentalAgeGroup" = "factor" ,
			       "incomeVariable" = "numeric" ,
			       "parishQuantileDifference100Euros" = "numeric" ,
			       "time" = "numeric" ,
			       "familyEducationalLevelReleveled" = "factor" ,
			       "parentalAbuseAsChildReleveled" = "factor" ,
			       "parentalAgeGroupReleveled"  = "factor" ,
			       "gTreatment" = "numeric" ,
			       "anyPhysicalAbuse" = "numeric" ,
			       "familyEducationalLevelBinary" = "numeric"  ,
			       "oneForeignParentBinary" = "numeric" ,
			       "familyNeedProtectionBinary" = "numeric" ,
			       "parentalPsychiatricDiseaseBinary" = "numeric" ,
			       "parentalAbuseAsChildBinary" = "numeric" ,
			       "childAgeGroupAtInclusion" = "factor" ,
			       "calendarTimeGroupAtInclusion" = "factor" ,
			       "childAgeGroupAtInclusionBinary" = "numeric"  ,
			       "familyIndex" = "numeric" ,
			       "newNoOfChildren" = "numeric" ,
			       "painfulConditionGroupFamily" = "numeric" ,
			       "dyslipidemiaGroupFamily" = "numeric" ,
			       "ischemicHeartDiseaseGroupFamily" = "numeric" ,
			       "diabetesMellitusGroupFamily" = "numeric" ,
			       "thyroidDisorderGroupFamily" = "numeric" ,
			       "chronicPulmonaryDiseaseGroupFamily" = "numeric" ,
			       "allergyGroupFamily" = "numeric" ,
			       "osteoporosisGroupFamily" = "numeric" ,
			       "migraineGroupFamily" = "numeric" ,
			       "epilepsyGroupFamily" = "numeric" ,
			       "bipolarAffectiveDisorderGroupFamily" = "numeric" ,
			       "dementiaGroupFamily" = "numeric" ,
			       "hypertensionGroupFamily" = "numeric" ,
			       "atrialFibrillationGroupFamily" = "numeric" ,
			       "heartFailureGroupFamily" = "numeric" ,
			       "peripheralArteryOcclusiveGroupFamily" = "numeric" ,
			       "strokeGroupFamily" = "numeric" ,
			       "goutGroupFamily" = "numeric" ,
			       "ulcerChronicGastritisGroupFamily" = "numeric" ,
			       "chronicLiverDiseaseGroupFamily" = "numeric" ,
			       "inflammatoryBowelDiseaseGroupFamily" = "numeric" ,
			       "diverticularDiseaseOfIntestineGroupFamily" = "numeric" ,
			       "chronicKidneyDiseaseGroupFamily" = "numeric" ,
			       "prostateDisordersGroupFamily" = "numeric" ,
			       "connectiveTissueDisordersGroupFamily" = "numeric" ,
			       "anemiasGroupFamily" = "numeric" ,
			       "cancerGroupFamily" = "numeric" ,
			       "visionProblemGroupFamily" = "numeric" ,
			       "parkinsonsDiseaseGroupFamily" = "numeric" ,
			       "multipleSclerosisGroupFamily" = "numeric" ,
			       "neuropathiesGroupFamily" = "numeric" ,
			       "moodStressrelatedOrAnxietyDisordersGroupFamily" = "numeric" ,
			       "anorexiaBulimiaGroupFamily" = "numeric" ,
			       "schizophreniaOrSchizoaffectiveDisorderGroupFamily" = "numeric" ,
			       "personalityDisorderGroupFamily" = "numeric" ,
			       "otherGroupFamily" = "numeric" ,
			       "pretermBirthGroupFamily" = "numeric" ,
			       "acuteCaesarianSectionGroupFamily" = "numeric" ,
			       "unspecificEverFamily" = "numeric" ,
			       "unspecificTwoYearFamily" = "numeric" ,
			       "complete" = "logical"))                               
      analysisDataset[ , familyEducationalLevel :=
			     factor(familyEducationalLevel ,
				    levels = c("Primary education" ,
					       "Secondary education" ,
					       "Tertiary education or higher"))]

      analysisDataset[ , reconstitutedFamily :=
			     factor(
				 reconstitutedFamily ,
				 levels = c("Living with biological parent(s)" ,
					    "Living with one or more unrelated adults" ,
					    "Adopted or in foster care"))]

      analysisDataset[ , parentalPsychiatricDisease :=
			     factor(parentalPsychiatricDisease ,
				    levels = c("No psychiatric disease" ,
					       "Any psychiatric disease"))]

      analysisDataset[ ,
		      interparentalViolence :=
			  factor(interparentalViolence ,
				 levels = c("No interparental violence" ,
					    "Interparental violence"))]

      analysisDataset[ , parentalSubstanceAbuse :=
			     factor(parentalSubstanceAbuse ,
				    levels = c("No parental substance abuse" ,
					       "Parental substance abuse"))]

      analysisDataset[ , calendarTimeGroup :=
			     factor(calendarTimeGroup ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]

      analysisDataset[ , parentalAbuseAsChild :=
			     factor(parentalAbuseAsChild ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one parent" ,
					       "Maltreatment or neglect, both parents"))]

      analysisDataset[ , oneForeignParent :=
			     factor(oneForeignParent ,
				    levels = c("No foreign parents" ,
					       "One or more foreign parents"))]

      analysisDataset[ , familyNeedProtection :=
			     factor(familyNeedProtection ,
				    levels = c("Not in need of protection" ,
					       "In need of protection"))]

      analysisDataset[ , childAgeGroup :=
			     factor(childAgeGroup , 
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDataset[ , parentalAgeGroup :=
			     factor(parentalAgeGroup , 
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35-65" ,
					       "Mean parental age >65-100"))]
      analysisDataset[ , familyEducationalLevelReleveled :=
			     factor(familyEducationalLevelReleveled ,
				    levels = c("Primary or secondary education" ,
					       "Tertiary education or higher"))]

      analysisDataset[ , parentalAbuseAsChildReleveled :=
			     factor(parentalAbuseAsChildReleveled ,
				    levels = c("No maltreatment or neglect" ,
					       "Maltreatment or neglect, one or both parents"))]

      analysisDataset[ , parentalAgeGroupReleveled :=
			     factor(parentalAgeGroupReleveled ,
				    levels = c("Mean parental age 25 or less" ,
					       "Mean parental age >25-35" ,
					       "Mean parental age >35"))]

      analysisDataset[ , childAgeGroupAtInclusion :=
			     factor(childAgeGroupAtInclusion ,
				    levels = c("Child 0-6 years old" ,
					       "Child 7-18 years old"))]

      analysisDataset[ , calendarTimeGroupAtInclusion :=
			     factor(calendarTimeGroupAtInclusion ,
				    levels = c("1997-2002" ,
					       "2003-2009" ,
					       "2010-2018"))]


      return(analysisDataset)
  }

  analysisDataset <- readAnalysisDatasetExplorative()

  diagAndLmdbList <- c("dyslipidemiaGroup" , 
		       "ischemicHeartDiseaseGroup" , 
		       "diabetesMellitusGroup" , 
		       "thyroidDisorderGroup" , 
		       "chronicPulmonaryDiseaseGroup" , 
		       "allergyGroup" , 
		       "osteoporosisGroup" , 
		       "migraineGroup" , 
		       "epilepsyGroup" , 
		       "bipolarAffectiveDisorderGroup" , 
		       "dementiaGroup")

  ##A single category using lmdb only:
  analysisDataset[painfulConditionGroupLmdbCurrentParent1LmdbTotal >= 1 |
		  painfulConditionGroupLmdbCurrentParent2LmdbTotal >= 1 ,
		  painfulConditionGroupFamily := 1]
  analysisDataset[is.na(painfulConditionGroupFamily) , painfulConditionGroupFamily := 0]

  ##Syntax looks like this works:
  for (i in diagAndLmdbList) {
      eval(parse(text =
		     paste0("analysisDataset[" , i , "DiagCurrentParent1 == 1 | " ,
			    i , "DiagCurrentParent2 == 1 | " ,
			    i , "LmdbCurrentParent1LmdbTotal >= 1 | " ,
			    i , "LmdbCurrentParent2LmdbTotal >= 1 , " ,
			    i , "Family := 1]")))
      eval(parse(text =
		     paste0("analysisDataset[is.na(" , i , "Family) , " , i , "Family := 0]")))
  }

  ## ##To control if the syntax is actually what I want: 
  ## for (i in diagAndLmdbList) {
  ##     print(
  ##                    paste0("analysisDataset[" , i , "DiagCurrentParent1 == 1 | " ,
  ##                           i , "DiagCurrentParent2 == 1 | " ,
  ##                           i , "LmdbCurrentParent1LmdbTotal >= 1 | " ,
  ##                           i , "LmdbCurrentParent2LmdbTotal >= 1 , " ,
  ##                           i , "Family := 1]"))
  ##     print(
  ##                    paste0("analysisDataset[is.na(" , i , "Family) , " , i , "Family := 0]"))
  ## }

  onlyDiagList <- c("hypertensionGroup" , 
		    "atrialFibrillationGroup" , 
		    "heartFailureGroup" , 
		    "peripheralArteryOcclusiveGroup" , 
		    "strokeGroup" , 
		    "goutGroup" , 
		    "ulcerChronicGastritisGroup" , 
		    "chronicLiverDiseaseGroup" , 
		    "inflammatoryBowelDiseaseGroup" , 
		    "diverticularDiseaseOfIntestineGroup" , 
		    "chronicKidneyDiseaseGroup" , 
		    "prostateDisordersGroup" , 
		    "connectiveTissueDisordersGroup" , 
		    "anemiasGroup" , 
		    "cancerGroup" , 
		    "visionProblemGroup" , 
		    "parkinsonsDiseaseGroup" , 
		    "multipleSclerosisGroup" , 
		    "neuropathiesGroup" , 
		    "moodStressrelatedOrAnxietyDisordersGroup" , 
		    "anorexiaBulimiaGroup" , 
		    "bipolarAffectiveDisorderGroup" , 
		    "schizophreniaOrSchizoaffectiveDisorderGroup" , 
		    "personalityDisorderGroup" , 
		    "otherGroup" , 
		    "pretermBirthGroup" , 
		    "hearingProblemGroup" , 
		    "acuteCaesarianSectionGroup")

  for (i in onlyDiagList) {
      eval(parse(text =
		     paste0("analysisDataset[" , i , "DiagCurrentParent1 == 1 | " ,
			    i , "DiagCurrentParent2 == 1 , " ,
			    i , "Family := 1]")))
      eval(parse(text =
		     paste0("analysisDataset[is.na(" , i , "Family) , " , i , "Family := 0]")))
  }

  onlyDiagNoDiagEndingList <- c("unspecificEver" , 
				"unspecificEver" , 
				"unspecificTwoYear" , 
				"unspecificTwoYear")

  for (i in onlyDiagNoDiagEndingList) {
      eval(parse(text =
		     paste0("analysisDataset[" , i , "CurrentParent1 == 1 | " ,
			    i , "CurrentParent2 == 1 , " ,
			    i , "Family := 1]")))
      eval(parse(text =
		     paste0("analysisDataset[is.na(" , i , "Family) , " , i , "Family := 0]")))
  }

  ##A number of categories above have been checked by manual inspection of the data and are categorizing as expected. 

  ##Add complete to analysisDataset for relevant variables:
  addCompleteVariableToAnalysisDataset <- function () {
      ##Only use records with full data:
      analysisDataset[ , complete :=
			     complete.cases(.SD) ,
		      .SDcols = c(
			  ## "pnr" ,
			  "date" ,
			  ## "currentParent2" ,
			  ## "currentParent1" ,
			  "reconstitutedFamily" ,
			  ## "studyEntry" ,
			  ## "ageCensoring" ,
			  ## "deathCensoring" ,
			  ## "emigrationCensoring" ,
			  ## "meanParentalAge" ,
			  ## "birthDate" ,
			  "childAge" ,
			  ## "hypertensionGroupDiagCurrentParent1" ,
			  ## "hypertensionGroupDiagCurrentParent2" ,
			  ## "dyslipidemiaGroupDiagCurrentParent1" ,
			  ## "dyslipidemiaGroupDiagCurrentParent2" ,
			  ## "ischemicHeartDiseaseGroupDiagCurrentParent1" ,
			  ## "ischemicHeartDiseaseGroupDiagCurrentParent2" ,
			  ## "atrialFibrillationGroupDiagCurrentParent1" ,
			  ## "atrialFibrillationGroupDiagCurrentParent2" ,
			  ## "heartFailureGroupDiagCurrentParent1" ,
			  ## "heartFailureGroupDiagCurrentParent2" ,
			  ## "peripheralArteryOcclusiveGroupDiagCurrentParent1" ,
			  ## "peripheralArteryOcclusiveGroupDiagCurrentParent2" ,
			  ## "strokeGroupDiagCurrentParent1" ,
			  ## "strokeGroupDiagCurrentParent2" ,
			  ## "diabetesMellitusGroupDiagCurrentParent1" ,
			  ## "diabetesMellitusGroupDiagCurrentParent2" ,
			  ## "thyroidDisorderGroupDiagCurrentParent1" ,
			  ## "thyroidDisorderGroupDiagCurrentParent2" ,
			  ## "goutGroupDiagCurrentParent1" ,
			  ## "goutGroupDiagCurrentParent2" ,
			  ## "chronicPulmonaryDiseaseGroupDiagCurrentParent1" ,
			  ## "chronicPulmonaryDiseaseGroupDiagCurrentParent2" ,
			  ## "allergyGroupDiagCurrentParent1" ,
			  ## "allergyGroupDiagCurrentParent2" ,
			  ## "ulcerChronicGastritisGroupDiagCurrentParent1" ,
			  ## "ulcerChronicGastritisGroupDiagCurrentParent2" ,
			  ## "chronicLiverDiseaseGroupDiagCurrentParent1" ,
			  ## "chronicLiverDiseaseGroupDiagCurrentParent2" ,
			  ## "inflammatoryBowelDiseaseGroupDiagCurrentParent1" ,
			  ## "inflammatoryBowelDiseaseGroupDiagCurrentParent2" ,
			  ## "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" ,
			  ## "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" ,
			  ## "chronicKidneyDiseaseGroupDiagCurrentParent1" ,
			  ## "chronicKidneyDiseaseGroupDiagCurrentParent2" ,
			  ## "prostateDisordersGroupDiagCurrentParent1" ,
			  ## "prostateDisordersGroupDiagCurrentParent2" ,
			  ## "connectiveTissueDisordersGroupDiagCurrentParent1" ,
			  ## "connectiveTissueDisordersGroupDiagCurrentParent2" ,
			  ## "osteoporosisGroupDiagCurrentParent1" ,
			  ## "osteoporosisGroupDiagCurrentParent2" ,
			  ## "anemiasGroupDiagCurrentParent1" ,
			  ## "anemiasGroupDiagCurrentParent2" ,
			  ## "cancerGroupDiagCurrentParent1" ,
			  ## "cancerGroupDiagCurrentParent2" ,
			  ## "visionProblemGroupDiagCurrentParent1" ,
			  ## "visionProblemGroupDiagCurrentParent2" ,
			  ## "migraineGroupDiagCurrentParent1" ,
			  ## "migraineGroupDiagCurrentParent2" ,
			  ## "epilepsyGroupDiagCurrentParent1" ,
			  ## "epilepsyGroupDiagCurrentParent2" ,
			  ## "parkinsonsDiseaseGroupDiagCurrentParent1" ,
			  ## "parkinsonsDiseaseGroupDiagCurrentParent2" ,
			  ## "multipleSclerosisGroupDiagCurrentParent1" ,
			  ## "multipleSclerosisGroupDiagCurrentParent2" ,
			  ## "neuropathiesGroupDiagCurrentParent1" ,
			  ## "neuropathiesGroupDiagCurrentParent2" ,
			  ## "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" ,
			  ## "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" ,
			  ## "anorexiaBulimiaGroupDiagCurrentParent1" ,
			  ## "anorexiaBulimiaGroupDiagCurrentParent2" ,
			  ## "bipolarAffectiveDisorderGroupDiagCurrentParent1" ,
			  ## "bipolarAffectiveDisorderGroupDiagCurrentParent2" ,
			  ## "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" ,
			  ## "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" ,
			  ## "personalityDisorderGroupDiagCurrentParent1" ,
			  ## "personalityDisorderGroupDiagCurrentParent2" ,
			  ## "dementiaGroupDiagCurrentParent1" ,
			  ## "dementiaGroupDiagCurrentParent2" ,
			  ## "otherGroupDiagCurrentParent1" ,
			  ## "otherGroupDiagCurrentParent2" ,
			  ## "pretermBirthGroupDiagCurrentParent1" ,
			  ## "pretermBirthGroupDiagCurrentParent2" ,
			  ## "acuteCaesarianSectionGroupDiagCurrentParent1" ,
			  ## "acuteCaesarianSectionGroupDiagCurrentParent2" ,
			  ## "aidsHivCharlsonCurrentParent1" ,
			  ## "aidsHivCharlsonCurrentParent2" ,
			  ## "anyMalignancyCharlsonCurrentParent1" ,
			  ## "anyMalignancyCharlsonCurrentParent2" ,
			  ## "cerebrovascularDiseaseCharlsonCurrentParent1" ,
			  ## "cerebrovascularDiseaseCharlsonCurrentParent2" ,
			  ## "chronicPulmonaryDiseaseCharlsonCurrentParent1" ,
			  ## "chronicPulmonaryDiseaseCharlsonCurrentParent2" ,
			  ## "dementiaCharlsonCurrentParent1" ,
			  ## "dementiaCharlsonCurrentParent2" ,
			  ## "diabetesWithComplicationsCharlsonCurrentParent1" ,
			  ## "diabetesWithComplicationsCharlsonCurrentParent2" ,
			  ## "diabetesWithoutComplicationsCharlsonCurrentParent1" ,
			  ## "diabetesWithoutComplicationsCharlsonCurrentParent2" ,
			  ## "heartFailureCharlsonCurrentParent1" ,
			  ## "heartFailureCharlsonCurrentParent2" ,
			  ## "hemiplegiaParaplegiaCharlsonCurrentParent1" ,
			  ## "hemiplegiaParaplegiaCharlsonCurrentParent2" ,
			  ## "metastaticSolidTumorCharlsonCurrentParent1" ,
			  ## "metastaticSolidTumorCharlsonCurrentParent2" ,
			  ## "mildLiverDiseaseCharlsonCurrentParent1" ,
			  ## "mildLiverDiseaseCharlsonCurrentParent2" ,
			  ## "myocardialInfarctionCharlsonCurrentParent1" ,
			  ## "myocardialInfarctionCharlsonCurrentParent2" ,
			  ## "pepticUlcerDiseaseCharlsonCurrentParent1" ,
			  ## "pepticUlcerDiseaseCharlsonCurrentParent2" ,
			  ## "peripheralVascularDiseaseCharlsonCurrentParent1" ,
			  ## "peripheralVascularDiseaseCharlsonCurrentParent2" ,
			  ## "renalDiseaseCharlsonCurrentParent1" ,
			  ## "renalDiseaseCharlsonCurrentParent2" ,
			  ## "rheumaticDiseaseCharlsonCurrentParent1" ,
			  ## "rheumaticDiseaseCharlsonCurrentParent2" ,
			  ## "severeLiverDiseaseCharlsonCurrentParent1" ,
			  ## "severeLiverDiseaseCharlsonCurrentParent2" ,
			  ## "alcoholAbuseCurrentParent1" ,
			  ## "alcoholAbuseCurrentParent2" ,
			  ## "substanceAbuseCurrentParent1" ,
			  ## "substanceAbuseCurrentParent2" ,
			  ## "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "allergyGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "allergyGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "allergyGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "allergyGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "osteoporosisGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "osteoporosisGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "osteoporosisGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "osteoporosisGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "painfulConditionGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "painfulConditionGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "painfulConditionGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "painfulConditionGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "migraineGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "migraineGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "migraineGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "migraineGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "epilepsyGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "epilepsyGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "epilepsyGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "epilepsyGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" ,
			  ## "dementiaGroupLmdbCurrentParent1LmdbTemp" ,
			  ## "dementiaGroupLmdbCurrentParent1LmdbTotal" ,
			  ## "dementiaGroupLmdbCurrentParent2LmdbTemp" ,
			  ## "dementiaGroupLmdbCurrentParent2LmdbTotal" ,
			  "jointCharlsonParents" ,
			  "outcomePhysicalAbuse" ,
			  "interparentalViolence" ,
			  "familyEducationalLevel" ,
			  "parentalAbuseAsChild" ,
			  "oneForeignParent" ,
			  "familyNeedProtection" ,
			  "parentalPsychiatricDisease" ,
			  "parentalSubstanceAbuse" ,
			  "calendarTimeGroup" ,
			  "childAgeGroup" ,
			  "parentalAgeGroup" ,
			  "incomeVariable" ,
			  "parishQuantileDifference100Euros")]
      ## "numberOfAdults" ,
      ## "numberOfChildren" ,
      ## "numberOfAdultsFactor" ,
      ## "numberOfChildrenFactor" ,
      ## "genderChild" ,
      ## "deathCensoringImpute" ,
      ## "emigrationCensoringImpute" ,
      ## "time" ,
      ##"newNoOfChildren")]
      return(NULL)
  }

  addCompleteVariableToAnalysisDataset()

  ##Make the pseudoAnalysis object:
  ##I know the intense use of assign in the part after looping is silly, but there is some kind of scoping error that I cannot find. Everything works with the current assign-commands, and controls show that analyses are carried out on the objects that were intended.  
  makePseudoAnalysisObject <- function(diseaseCategory , split = 400) {
      suppressWarnings(analysisDataset[ , case := NULL])
      print(Sys.time())
      library(survival)
      library(geepack)
      library(lubridate)

      ##library(broom)
      ##library(pseudo)
      ##Do matching for Charlson
      ##Get all the cases, put them first:
      setorderv(analysisDataset , c("pnr" , "date" , diseaseCategory) , c(1 , 1 , -1))
      cases <- unique(analysisDataset[complete == TRUE] , by = c("pnr" , diseaseCategory))

      eval(parse(text = paste0("cases <- cases[" , diseaseCategory , " == 1]")))
      cases <- unique(cases , by = "pnr")
      if (cases[ , .N] == 0) {
	  return(next)
	  ##Next is returned but does not preserve the for-loop - this has not been fixed, I simply edited the loop list manually. 
      } else {
	  ##Reduce cases to variables listed below:
	  temp <- names(cases)
	  temp <- temp[!temp %in% c("pnr" , "date" , "childAge" , "reconstitutedFamily" , "newNoOfChildren" , "meanParentalAge")]
	  cases[ , (temp) := NULL]
	  rm(temp)

	  ##Match these cases with eligible individuals:
	  ##Creating a reduced dataset for this:
	  eval(parse(text =
			 paste0("analysisMatchingSet <- analysisDataset[complete == TRUE , .(pnr , date , childAge , reconstitutedFamily , newNoOfChildren , meanParentalAge , " ,
				diseaseCategory , ")]")))
	  ##Controls cannot have the exposure at the time of matching: 
	  eval(parse(text = paste0("analysisMatchingSet <- analysisMatchingSet[" , diseaseCategory , " == 0]")))
	  ##Cleaning data before merge
	  ##cases[ , c("nrow" , "jointCharlsonParents" , "date") := NULL]
	  eval(parse(text = paste0("analysisMatchingSet[ , " , diseaseCategory , " := NULL]")))

	  ##As every pnr will only be used for matching once, I will order these in some random order to avoid some bias from ordering on pnr:
	  set.seed(25328621)
	  analysisMatchingSet[ , randomOrder := sample(1:.N , .N)]
	  temp <- unique(analysisMatchingSet[ , .(pnr , randomOrder)] , by = "pnr")
	  analysisMatchingSet[temp , on = "pnr" , randomOrder := i.randomOrder]
	  ##Inspected, every pnr has a random, unique number attached that is permanent throughout this 
	  ##Using the randomOrder from above to set a new order
	  setorder(analysisMatchingSet , randomOrder , date)

	  ## ##To avoid having to re-load the big dataset too much:
	  fwrite(cases , "casesComplete.csv")
	  fwrite(analysisMatchingSet , "analysisMatchingSetComplete.csv")

	  ##I forgot to factorize newNoOfChildren above - making up for this here:

	  cases[ , numberOfChildrenFactor :=
		       cut(newNoOfChildren ,
			   breaks = c(0 , 1 , 2 , 5 , 20) ,
			   labels = c("One child" ,
				      "Two children" ,
				      "Three to five children" ,
				      "Six children or more"))]

	  analysisMatchingSet[ , numberOfChildrenFactor :=
				     cut(newNoOfChildren ,
					 breaks = c(0 , 1 , 2 , 5 , 20) ,
					 labels = c("One child" ,
						    "Two children" ,
						    "Three to five children" ,
						    "Six children or more"))]

	  ## ##If you need to read the analysisMatchingSet:
	  ## analysisMatchingSet <-
	  ##     fread("analysisMatchingSetComplete.csv" ,
	  ##       colClasses = c("pnr" = "character" ,
	  ##     		 "date" = "Date" ,
	  ##     		 "childAge" = "numeric" ,
	  ##     		 "numberOfAdultsFactor" = "factor" ,
	  ##     		 "numberOfChildrenFactor" = "factor" ,
	  ##     		 "meanParentalAge" = "numeric" ,
	  ##     		 "randomOrder" = "numeric"))

	  ## analysisMatchingSet[ , numberOfAdultsFactor :=
	  ##     	       factor(numberOfAdultsFactor ,
	  ##     		      levels = c("One adult" ,
	  ##     				 "Two adults" ,
	  ##     				 "Three or more adults"))]

	  ## analysisMatchingSet[ , numberOfChildrenFactor :=
	  ##     	       factor(numberOfChildrenFactor ,
	  ##     		      levels = c("One child" ,
	  ##     				 "Two children" ,
	  ##     				 "Three to five children" ,
	  ##     				 "Six children or more"))]

	  ## ## If you need to read the cases-set:
	  ## cases <-
	  ##     fread("casesComplete.csv" ,
	  ##       colClasses = c("pnr" = "character" ,
	  ##     		 "date" = "Date" ,
	  ##     		 "childAge" = "numeric" ,
	  ##     		 "newNoOfChildren" = "numeric" , 
	  ##     		 "meanParentalAge" = "numeric"))



	  ##To make sure there is enough space for the subsequent process:
	  ##rm(analysisDataset)
	  set.seed(25328621)
	  gc(full = TRUE)
	  print(paste0("Just before loop with " , diseaseCategory))

	  ##Splitting cases into m pieces by an index (number of m could be optimized for computer capacity, speed and number of matches) - I split for two reasons: one is computer power (the server cannot do the full match at once), the other one is to avoid one or a few individuals taking up too many matches. Without splitting, the first individuals gets a large number of matches while subsequent matches are (rightly) detected as duplicates and deleted - which makes the number of available matches small to the last on the list. By cutting the dataset into smaller chunks, limiting the number of matches to 300 (this number is arbitrary, picked to try and ensure 10 matches after de-duplicating but avoiding "over-use" on the small lists), de-duplicating and then reducing to only 10 matches for each person, I should mitigate the "over-use" of matches by the first individuals on the list: 
	  ##First run was with m = 200, 10 matches required and 300 matches before pruning for duplicates - this proved to be finished within 9 hours. Approx. 20000 individuals never found matches in this algorithm, but the results were vastly better than before. To optimize further, the number of splits is doubled to 400, the number of matches reduced to 5 and the number of "pre-matches" reduced to 250.
	  ## Experiencing, again, hardware resource constraints in the form of memory problems. Now trying with a random draw of 100.000 cases for categories with more than 100.000 cases:
	  if (cases[ , .N] > 100000) {
	      cases[ , tempRandom := sample(1:.N , 1:.N)]
	      setorder(cases , tempRandom)
	      cases <- cases[1:100000]
	  }
	  m <- split
	  cases[ , randomSplit :=  sample(1:m , .N , replace = TRUE)]
	  ##New loop based on merge with chunks of the cases-dataset:
	  casesMatchedJoint <- data.table(NULL)
	  set.seed(25328621)
	  for (j in 1:m) { #should be 1:m - just putting in a number for test purposes
	      casesSplit <- cases[randomSplit == j]
	      ##For later ordering:
	      casesSplit[ , pnrRandomNumber := sample(1:.N , .N)]
	      casesSplit <- casesSplit[ , list(pnr =  pnr ,
					       date = date ,
					       childAge = childAge ,
					       reconstitutedFamily  = reconstitutedFamily,
					       numberOfChildrenFactor = numberOfChildrenFactor ,
					       meanParentalAge = meanParentalAge ,
					       pnrRandomNumber = pnrRandomNumber ,
					       matchDate = seq(from = date ,
							       length = 3 ,
							       by = "month")) , 
				       by = 1:nrow(casesSplit)]
	      print(paste0("Just after expansion of " , j , "part of cases."))
	      print(Sys.time())
	      casesSplit[ , nrow := NULL]
	      casesSplit[ , date := NULL]
	      setnames(casesSplit , "matchDate" , "date")

	      casesSplit <- merge(casesSplit  ,
				  analysisMatchingSet ,
				  by.x = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
				  by.y = c("date" , "reconstitutedFamily" , "numberOfChildrenFactor") ,
				  all.x = TRUE ,
				  allow.cartesian = TRUE , suffixes = c("" , "Control"))
	      print(paste0("Finished merge from split " , j , " out of " , m))
	      ##If this gives an unruly number of matches, consider matching on date as usual - when the date is not connected to age, this simply means that the children have to be in the study at the same date. 
	      ## cases[analysisMatchingSet[ , .(pnr , date ,
	      ## 			   ##adultsInFamily , childrenInFamily ,
	      ## 			   parentAgeRounded, 
	      ##                            childAgeYear , pnrMatch)] ,
	      ##       on = .(date == date  ,
	      ##              childAgeYear == childAgeYear ,
	      ##              parentAgeLowerYear <= parentAgeRounded ,
	      ##              parentAgeUpperYear >= parentAgeRounded) ,
	      ##       pnrMatch := i.pnrMatch ,
	      ##       allow.cartesian = TRUE]
	      ## ##Removing matches with parentalAge more than five years apart (matching on parental age):
	      casesSplit[ , parentalAgeDiff := abs(meanParentalAge - meanParentalAgeControl)]
	      casesSplit <- casesSplit[parentalAgeDiff <= 5]
	      ##casesSplit[ , c("parentalAge" , "parentalAgeDiff" , "parentalAgeControl") := NULL]
	      ## ##Removing matches with childAge more than one year apart (matching on child age):
	      casesSplit[ , childAgeDiff := abs(childAge - childAgeControl)]
	      casesSplit <- casesSplit[childAgeDiff <= 1]
	      ## cases[ , c("childAge" , "childAgeControl" , "childAgeDiff") := NULL]
	      ##After manual inspection of several pnrs the method produces a myriad of matches and does so as intended. 
	      ##Avoiding children matching on themselves and matches on NA:
	      casesSplit <- casesSplit[!is.na(pnr) & pnr != pnrControl]
	      casesSplit <- casesSplit[!is.na(pnrControl)]
	      ##Order the matches randomly:
	      casesSplit[ , indexTempRandom := sample(1:.N , .N) , by = "pnr"]
	      setorder(casesSplit , pnrRandomNumber , indexTempRandom)
	      ##Reduce to 250 matches:
	      casesSplit <- casesSplit[indexTempRandom <= 250]
	      casesSplit[ , indexTempRandom := NULL]
	      ##De-duplicate matches:
	      casesSplit <- unique(casesSplit , by = "pnrControl")
	      ##Reduce to 5 matches for each pnr:
	      casesSplit[ , index := 1:.N , by = "pnr"]
	      casesSplit <- casesSplit[index <= 5]
	      ##Visually controlled - for first iteration, all cases are shown to have 10 matches. 
	      casesSplit[ , index := NULL]
	      ##Delete the matches used from the "match-pool":
	      temp <- casesSplit[ , .(pnrControl)]
	      temp <- unique(temp)
	      setnames(temp , "pnrControl" , "pnr")
	      analysisMatchingSet[temp , on = "pnr" , delete := 1]
	      analysisMatchingSet <- analysisMatchingSet[is.na(delete)]
	      analysisMatchingSet[ , delete := NULL]
	      casesMatchedJoint <- rbindlist(list(casesMatchedJoint , casesSplit))
	      print(paste0("Finished results from cycle " , j))
	  }

	  fwrite(casesMatchedJoint , paste0("casesMatchedJointComplete" , diseaseCategory , ".csv"))

	  ## Reading in the results from above:
	  ## casesMatchedJoint <-
	  ##     fread(paste0("casesMatchedJointComplete" , diseaseCategory , ".csv") ,
	  ##       colClasses = c("pnr" = "character" ,
	  ##     		 "pnrControl" = "character" ,
	  ##     		 "date" = "Date" ,
	  ##     		 "reconstitutedFamily" = "factor" ,
	  ##     		 "numberOfChildrenFactor" = "factor" ,
	  ##     		 "newNoOfChildren" = "numeric" , 
	  ##     		 "childAge" = "numeric" ,
	  ##     		 "meanParentalAge" = "numeric" ,
	  ##     		 "pnrRandomNumber" = "numeric" ,
	  ##     		 "childAgeControl" = "numeric" ,
	  ##     		 "meanParentalAgeControl" = "numeric" ,
	  ##     		 "randomOrder" = "numeric" ,
	  ##     		 "parentalAgeDiff" = "numeric" ,
	  ##     		 "childAgeDiff" = "numeric"))

	  ## casesMatchedJoint[ , reconstitutedFamily :=
	  ##     		 factor(reconstitutedFamily ,
	  ##     			levels = c("Living with biological parent(s)" ,
	  ##     				   "Living with one or more unrelated adults" ,
	  ##     				   "Adopted or in foster care"))]
	  ## casesMatchedJoint[ , numberOfChildrenFactor :=
	  ##     		 factor(numberOfChildrenFactor ,
	  ##     			levels = c("One child" ,
	  ##     				   "Two children" ,
	  ##     				   "Three to five children" ,
	  ##     				   "Six children or more"))]
	  assign("casesMatchedJoint" , casesMatchedJoint , envir = .GlobalEnv)

	  ##Extracting numbers for the article:

	  ##Children in the analysis:
	  childrenAnalysis <-
	      rbindlist(list(unique(casesMatchedJoint[ , .(pnr)]) ,
			     casesMatchedJoint[ , .(pnrControl)]) ,
			use.names = FALSE)
	  assign("childrenAnalysis" , childrenAnalysis , envir = .GlobalEnv)
	  ##Underlying biological children: 
	  childrenAnalysis <- unique(childrenAnalysis)



	  casesMatchedJoint[ , matchesNumber := 1:.N , by = "pnr"]

	  ##Numbering all unique case-pnrs:

	  temp <- casesMatchedJoint[ , .(pnr)]
	  temp <- unique(temp)
	  temp[ , indexCasesMatches := 1:.N]
	  assign("temp" , temp , envir = .GlobalEnv)
	  casesMatchedJoint[temp , on = "pnr" , indexCasesMatches := i.indexCasesMatches] 


	  ##Deleting the few records with less than 5 matches:
	  ##Counting pnrs before:
	  tempBefore <- unique(casesMatchedJoint[ , .(pnr)])
	  print(paste0("Pnrs before deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempBefore[ , .N]))
	  assign("tempBefore" , tempBefore , envir = .GlobalEnv)
	  temp <- casesMatchedJoint[matchesNumber == 5 , .(pnr)]
	  temp <- unique(temp)
	  casesMatchedJoint[temp , on = "pnr" , keepThisRecord := 1]
	  ##casesMatchedJoint[ , table(keepThisRecord)]
	  casesMatchedJoint <- casesMatchedJoint[!is.na(keepThisRecord)]
	  ##casesMatchedJoint[ , table(index)]
	  ##The above command now shows that everyone has exactly 5 matches.
	  ##Counting pnrs after this:
	  tempAfter <- unique(casesMatchedJoint[ , .(pnr)])
	  assign("tempAfter" , tempAfter , envir = .GlobalEnv)
	  print(paste0("Pnrs after deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempAfter[ , .N]))
	  ##Preparing the selection of relevant persons in the dataset:

	  ##Counting for the article:
	  ##Children in the analysis:
	  childrenAnalysis <-
	      rbindlist(list(unique(casesMatchedJoint[ , .(pnr)]) ,
			     casesMatchedJoint[ , .(pnrControl)]) ,
			use.names = FALSE)
	  childrenAnalysisNumber <- childrenAnalysis[ , .N]
	  assign("childrenAnalysisNumber" , childrenAnalysisNumber , envir = .GlobalEnv)
	  print(paste0("Children in the analysis of " , diseaseCategory , ": " , childrenAnalysisNumber))
	  ##Underlying biological children: 
	  childrenAnalysisBiological <- unique(childrenAnalysis)[ , .N]
	  assign("childrenAnalysisBiological" , childrenAnalysisBiological , envir = .GlobalEnv)
	  print(paste0("Underlying biological children in the analysis of " , diseaseCategory , ": " , childrenAnalysisBiological))

	  temp <- names(casesMatchedJoint)
	  temp <- temp[!temp %in% c("pnr" , "pnrControl" , "date" , "indexCasesMatches")]
	  casesMatchedJoint[ , (temp) := NULL]
	  rm(temp)
	  casesMatchedLong <- melt(casesMatchedJoint , id.vars = c("date" , "indexCasesMatches") , measure.vars = c("pnr" , "pnrControl"))
	  assign("casesMatchedLong" , casesMatchedLong , envir = .GlobalEnv)
	  setnames(casesMatchedLong , "date" , "studyEntry")
	  casesMatchedLong[variable == "pnr" , case := 1]
	  casesMatchedLong[variable == "pnrControl" , case := 0]
	  casesMatchedLong[ , variable := NULL]
	  setnames(casesMatchedLong , "value" , "pnr")
	  setorder(casesMatchedLong , pnr , case , studyEntry)
	  casesMatchedLong <- unique(casesMatchedLong , by = c("pnr" , "case"))
	  casesMatchedLong[cases , on = "pnr" , originalDate := i.date]
	  casesMatchedLong[case == 1 , studyEntry := originalDate]
	  casesMatchedLong[ , originalDate := NULL]

	  ##This was forgotten upstream - adding:
	  if (!("numberOfChildrenFactor" %in% names(analysisDataset))) {
	      analysisDataset[ , numberOfChildrenFactor :=
				     cut(newNoOfChildren ,
					 breaks = c(0 , 1 , 2 , 5 , 20) ,
					 labels = c("One child" ,
						    "Two children" ,
						    "Three to five children" ,
						    "Six children or more"))]
	  }


	  ##Reducing to those included, on the dates that they are included:
	  setnames(casesMatchedLong , "studyEntry" , "date")
	  analysisDataset[casesMatchedLong , on = c("pnr" , "date") , case := i.case]
	  pseudoAnalysisSubjects <- analysisDataset[!is.na(case)]
	  assign("pseudoAnalysiSubjects" , pseudoAnalysisSubjects , envir = .GlobalEnv)
	  pseudoAnalysisSubjects[ , studyEntry := NULL]
	  setnames(pseudoAnalysisSubjects , "date" , "studyEntry")
	  setnames(casesMatchedLong , "date" , "studyEntry")

	  ##Extracting the last line of all participating subjects:
	  setorder(analysisDataset , pnr , -date)
	  temp <- unique(analysisDataset , by = "pnr")
	  pseudoAnalysisSubjects[ , deathCensoring := NULL]
	  pseudoAnalysisSubjects[temp ,
				 on = "pnr" ,
				 c("endDate" ,
				   "outcomePhysicalAbuse" ,
				   "deathCensoring") :=
				     list(i.date ,
					  i.outcomePhysicalAbuse ,
					  i.deathCensoring)]
	  pseudoAnalysisSubjects[outcomePhysicalAbuse > 0 & !is.na(outcomePhysicalAbuse) , event := 1]
	  pseudoAnalysisSubjects[deathCensoring == endDate & outcomePhysicalAbuse == 0 , event := 2]
	  pseudoAnalysisSubjects[is.na(event) , event := 0]
	  pseudoAnalysisSubjects[ , event := factor(event ,
						    levels = c(0 , 1 , 2) ,
						    labels = c("Censored" ,
							       "Physical abuse" ,
							       "Deceased"))]
	  ## ##Classification inspected manually, performs as intended.
	  ## setnames(temp , "date" , "endDate")
	  ## pseudoAnalysis <- merge(pseudoAnalysis , temp[ , .(pnr , event , endDate)] , by.x = "pnr" , by.y = "pnr" , all.x = TRUE)
	  ##Transforming the dates into time on a monthly scale, with 0 being inclusion and all later times marking censoring or the outcome(this is different from the time in analysisDataset, as time here refers to inclusion date as case or control):
	  pseudoAnalysisSubjects[ , time := mapply(function(studyEntry , endDate) length(seq(studyEntry , endDate , by = "month")) - 1 , studyEntry , endDate)]
	  ##Now the dataset should include an event-variable with 0 as censoring and 1 as physical abuse, a time-variable and a unique identifier. This should be sufficient to do the pseudo-numbers (the 215 is a result of seq(as.Date("2000-01-01") , as.Date("2017-12-01") , by = "month")) - 1 , that is the number of months it takes for someone to be 18 and thus the longest time anyone could remain in the study):
	  ##A survival-version, using the survival-package:

	  ##A downstream sensitivity analysis has shown that censoring is dependent on time periods - splitting on those and making pseudovalues:
	  pseudoAnalysisSubjects1 <- pseudoAnalysisSubjects[calendarTimeGroup == "1997-2002"]
	  assign("pseudoAnalysisSubjects1" , pseudoAnalysisSubjects1 , envir = .GlobalEnv)
	  pseudoAnalysisSubjects2 <- pseudoAnalysisSubjects[calendarTimeGroup == "2003-2009"]
	  assign("pseudoAnalysisSubjects2" , pseudoAnalysisSubjects2 , envir = .GlobalEnv)
	  pseudoAnalysisSubjects3 <- pseudoAnalysisSubjects[calendarTimeGroup == "2010-2018"]
	  assign("pseudoAnalysisSubjects3" , pseudoAnalysisSubjects3 , envir = .GlobalEnv)

	  pseudoAnalysisPseudoValues1 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects1) , times = 214)
	  assign("pseudoAnalysisPseudoValues1" , pseudoAnalysisPseudoValues1 , envir = .GlobalEnv)
	  pseudoAnalysisPseudoValues2 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects2) , times = 214)
	  assign("pseudoAnalysisPseudoValues2" , pseudoAnalysisPseudoValues2 , envir = .GlobalEnv)
	  pseudoAnalysisPseudoValues3 <- pseudo(survfit(Surv(time , event) ~ 1 , data = pseudoAnalysisSubjects3) , times = 214)
	  assign("pseudoAnalysisPseudoValues3" , pseudoAnalysisPseudoValues3 , envir = .GlobalEnv)

	  pseudoAnalysisPseudoValues1 <- as.data.table(pseudoAnalysisPseudoValues1)
	  assign("pseudoAnalysisPseudoValues1" , pseudoAnalysisPseudoValues1 , envir = .GlobalEnv)
	  pseudoAnalysisPseudoValues2 <- as.data.table(pseudoAnalysisPseudoValues2)
	  assign("pseudoAnalysisPseudoValues2" , pseudoAnalysisPseudoValues2 , envir = .GlobalEnv)
	  pseudoAnalysisPseudoValues3 <- as.data.table(pseudoAnalysisPseudoValues3)
	  assign("pseudoAnalysisPseudoValues3" , pseudoAnalysisPseudoValues3 , envir = .GlobalEnv)

	  pseudoAnalysis1 <- cbind(pseudoAnalysisSubjects1 , pseudoAnalysisPseudoValues1)
	  assign("pseudoAnalysis1" , pseudoAnalysis1 , envir = .GlobalEnv)
	  pseudoAnalysis2 <- cbind(pseudoAnalysisSubjects2 , pseudoAnalysisPseudoValues2)
	  assign("pseudoAnalysis2" , pseudoAnalysis2 , envir = .GlobalEnv)
	  pseudoAnalysis3 <- cbind(pseudoAnalysisSubjects3 , pseudoAnalysisPseudoValues3)
	  assign("pseudoAnalysis3" , pseudoAnalysis3 , envir = .GlobalEnv)

	  pseudoAnalysis <- rbindlist(list(pseudoAnalysis1 , pseudoAnalysis2 , pseudoAnalysis3))
	  assign("pseudoAnalysis" , pseudoAnalysis , envir = .GlobalEnv)
	  setnames(pseudoAnalysis , "Physical abuse" , "physicalAbuse")

	  pseudoAnalysis[ , case :=
				factor(case ,
				       levels = c(0 , 1) ,
				       labels = c("Control" , "Case"))] 

	  ##Extracting some numbers for the article:
	  ##Repurposing an earlier object, temp, that contains the last lines of all subjects in analysisDataset:
	  temp[pseudoAnalysis , on = "pnr" , partOfAnalysis := 1]
	  ##Get the necessary objects for the analysis out into .GlobalEnv:
	  assign("temp" , temp , envir = .GlobalEnv)
	  assign("tempBefore" , tempBefore , envir = .GlobalEnv)
	  assign("tempAfter" , tempAfter , envir = .GlobalEnv)
	  assign("childrenAnalysisNumber" , childrenAnalysisNumber , envir = .GlobalEnv)
	  assign("childrenAnalysisBiological" , childrenAnalysisBiological , envir = .GlobalEnv)
	  assign("pseudoAnalysis" , pseudoAnalysis , envir = .GlobalEnv)
      }
  }

  doAnalysisAndStatistics <- function(nameOfAccumulateObject = NA) {
      closeAllConnections()
      sink(file = paste0("results" , diseaseCategory , ".txt") , split = TRUE)
      print(paste0("Analysis for " , diseaseCategory , " IF YOU JUST CREATED pseudoAnalysis for this caegory."))
      ##Some statistics:
      followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
      print(paste0("Mean of total follow-up time studying " , diseaseCategory , " : " , followUp))
      ##Sum of follow-up time: 
      followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
      print(paste0("Sum of total follow-up time studying " , diseaseCategory , " : " , followUpTotal))
      ##Number of cases in analysis:
      print(paste0("Number of abuse cases in analysis of " , diseaseCategory , " : " , temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]))
      ##Number of lethal cases in analysis:
      print(paste0("Number of lethal abuse cases in analysis of " , diseaseCategory , " : " , temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]))
      ##Number of deaths not related to abuse:
      print(paste0("Number of deaths not related to abuse in analysis of " ,
		   diseaseCategory , " : " ,
		   temp[partOfAnalysis == 1 &
			!is.na(deathCensoring) &
			(outcomePhysicalAbuse == 0 |
			 is.na(outcomePhysicalAbuse)) ,
			.N]))
      print(paste0("Pnrs before deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempBefore[ , .N]))
      print(paste0("Pnrs after deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempAfter[ , .N]))
      print(paste0("Children in the analysis of " , diseaseCategory , ": " , childrenAnalysisNumber))
      print(paste0("Underlying biological children in the analysis of " , diseaseCategory , ": " , childrenAnalysisBiological))

      ##The geese way:
      pseudoFitFullPopulation <- geese(physicalAbuse ~ case +
					   ##Family characteristics                     
					   incomeVariable + 
					   parishQuantileDifference100Euros + 
					   oneForeignParent +
					   familyNeedProtection +
					   calendarTimeGroup +
					   ##Parental health and history
					   familyEducationalLevelReleveled +
					   parentalPsychiatricDisease +
					   interparentalViolence +
					   parentalSubstanceAbuse +
					   parentalAbuseAsChildReleveled ,
				       data = pseudoAnalysis ,
				       id = familyIndex ,
				       scale.fix = TRUE ,
				       family = gaussian ,
				       mean.link = "log" ,
				       corstr = "independence")
      show(summary(pseudoFitFullPopulation))

      resultsPseudoFitFullPopulation <- formatResultsGeese(pseudoFitFullPopulation)
      fwrite(resultsPseudoFitFullPopulation , paste0("resultsPseudoFitFullPopulation" , diseaseCategory , ".csv"))

      ##Avoiding most obvious colinearity:
      ##The geese way:
      pseudoFitFullPopulationNoSmallCellsLessColinearity <- geese(physicalAbuse ~ case +
								      ##Family characteristics                     
								      incomeVariable + 
								      parishQuantileDifference100Euros +
								      ##reconstitutedFamily + 
								      ##oneForeignParent +
								      ##familyNeedProtection +
								      calendarTimeGroup +
								      ##Parental health and history
								      familyEducationalLevelReleveled +
								      parentalPsychiatricDisease +
								      ##interparentalViolence +
								      ##parentalSubstanceAbuse +
								      parentalAbuseAsChildReleveled ,
								  data = pseudoAnalysis ,
								  id = familyIndex ,
								  scale.fix = TRUE ,
								  family = gaussian ,
								  mean.link = "log" ,
								  corstr = "independence")
      show(summary(pseudoFitFullPopulationNoSmallCellsLessColinearity))
      resultsPseudoFitFullPopulationNoSmallCellsLessColinearity <- formatResultsGeese(pseudoFitFullPopulationNoSmallCellsLessColinearity)
      fwrite(resultsPseudoFitFullPopulationNoSmallCellsLessColinearity ,
	     paste0("resultsPseudoFitFullPopulation" ,
		    diseaseCategory ,
		    "NoSmallCellsLessColinearity.csv"))
      ##Code for generating a table from a loop of many categories:
      if (!is.na(nameOfAccumulateObject)) {
	  ##The tryCatch below is just a really complicated way of saying "get the object, and if you can't do it, don't give an error message, just return NA":
	  if (is.data.table(tryCatch(get(nameOfAccumulateObject) ,
				     error = function(cond){return(NA)}))) {
	      assign(nameOfAccumulateObject ,
		     rbindlist(list(get(nameOfAccumulateObject) , list(diseaseCategory ,
								       resultsPseudoFitFullPopulation$RR[2] ,
								       resultsPseudoFitFullPopulation$CILow[2] , 
								       resultsPseudoFitFullPopulation$CIHigh[2] ,
								       resultsPseudoFitFullPopulation$san.se[2] ,
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$RR[2] ,
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CILow[2] , 
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CIHigh[2] , 
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$san.se[2] ,
								       followUp ,
								       followUpTotal ,
								       temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N] ,
								       temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N] ,
								       temp[partOfAnalysis == 1 &
									    !is.na(deathCensoring) &
									    (outcomePhysicalAbuse == 0 |
									     is.na(outcomePhysicalAbuse)) ,
									    .N] ,
								       tempBefore[ , .N] ,
								       tempAfter[ , .N] ,
								       childrenAnalysisNumber ,
								       childrenAnalysisBiological))) ,
		     envir = .GlobalEnv)
	  } else {
	      assign(nameOfAccumulateObject ,
		     data.table(category = diseaseCategory ,
				RRFull = resultsPseudoFitFullPopulation$RR[2] ,
				CILowFull = resultsPseudoFitFullPopulation$CILow[2] , 
				CIHighFull = resultsPseudoFitFullPopulation$CIHigh[2] ,
				sanSeFull = resultsPseudoFitFullPopulation$san.se[2] ,
				RRParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$RR[2] ,
				CILowParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CILow[2] ,
				CIHighParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CIHigh[2] ,
				sanSeParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$san.se[2] ,
				meanFollowup = followUp ,
				totalFollowup = followUpTotal ,
				abuseCases = temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N] ,
				lethalAbuseCases = temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N] ,
				nonAbuseDeaths = temp[partOfAnalysis == 1 &
						      !is.na(deathCensoring) &
						      (outcomePhysicalAbuse == 0 |
						       is.na(outcomePhysicalAbuse)) ,
						      .N] ,
				allCases = tempBefore[ , .N] ,
				fullyMatchedCases = tempAfter[ , .N] ,
				childrenAnalyzed = childrenAnalysisNumber ,
				biologicalChildrenAnalyzed = childrenAnalysisBiological) ,
		     envir = .GlobalEnv)
	  }
      }
      sink()
  }

  formatResultsGeese <- function(fitByGeese) {
      results <- summary(fitByGeese)
      results <- results$mean
      setDT(results)
      results <- setDT(cbind(names(fitByGeese$beta) , results))
      setnames(results , "V1" , "names")
      results[ , RR := exp(estimate)]
      results[ , CILow := exp(estimate - qnorm(0.975)*san.se)]
      results[ , CIHigh := exp(estimate + qnorm(0.975)*san.se)]
      results[ , c("estimate" , "wald") := NULL]
      setcolorder(results , c("names" , "RR" , "CILow" , "CIHigh" , "p" , "san.se"))
      return(results)
  }

  ##Make some space after adding a lot of variables:
  analysisDataset[ , c("hypertensionGroupDiagCurrentParent1" , 
		       "hypertensionGroupDiagCurrentParent2" , 
		       "dyslipidemiaGroupDiagCurrentParent1" , 
		       "dyslipidemiaGroupDiagCurrentParent2" , 
		       "ischemicHeartDiseaseGroupDiagCurrentParent1" , 
		       "ischemicHeartDiseaseGroupDiagCurrentParent2" , 
		       "atrialFibrillationGroupDiagCurrentParent1" , 
		       "atrialFibrillationGroupDiagCurrentParent2" , 
		       "heartFailureGroupDiagCurrentParent1" , 
		       "heartFailureGroupDiagCurrentParent2" , 
		       "peripheralArteryOcclusiveGroupDiagCurrentParent1" , 
		       "peripheralArteryOcclusiveGroupDiagCurrentParent2" , 
		       "strokeGroupDiagCurrentParent1" , 
		       "strokeGroupDiagCurrentParent2" , 
		       "diabetesMellitusGroupDiagCurrentParent1" , 
		       "diabetesMellitusGroupDiagCurrentParent2" , 
		       "thyroidDisorderGroupDiagCurrentParent1" , 
		       "thyroidDisorderGroupDiagCurrentParent2" , 
		       "goutGroupDiagCurrentParent1" , 
		       "goutGroupDiagCurrentParent2" , 
		       "chronicPulmonaryDiseaseGroupDiagCurrentParent1" , 
		       "chronicPulmonaryDiseaseGroupDiagCurrentParent2" , 
		       "allergyGroupDiagCurrentParent1" , 
		       "allergyGroupDiagCurrentParent2" , 
		       "ulcerChronicGastritisGroupDiagCurrentParent1" , 
		       "ulcerChronicGastritisGroupDiagCurrentParent2" , 
		       "chronicLiverDiseaseGroupDiagCurrentParent1" , 
		       "chronicLiverDiseaseGroupDiagCurrentParent2" , 
		       "inflammatoryBowelDiseaseGroupDiagCurrentParent1" , 
		       "inflammatoryBowelDiseaseGroupDiagCurrentParent2" , 
		       "diverticularDiseaseOfIntestineGroupDiagCurrentParent1" , 
		       "diverticularDiseaseOfIntestineGroupDiagCurrentParent2" , 
		       "chronicKidneyDiseaseGroupDiagCurrentParent1" , 
		       "chronicKidneyDiseaseGroupDiagCurrentParent2" , 
		       "prostateDisordersGroupDiagCurrentParent1" , 
		       "prostateDisordersGroupDiagCurrentParent2" , 
		       "connectiveTissueDisordersGroupDiagCurrentParent1" , 
		       "connectiveTissueDisordersGroupDiagCurrentParent2" , 
		       "osteoporosisGroupDiagCurrentParent1" , 
		       "osteoporosisGroupDiagCurrentParent2" , 
		       "anemiasGroupDiagCurrentParent1" , 
		       "anemiasGroupDiagCurrentParent2" , 
		       "cancerGroupDiagCurrentParent1" , 
		       "cancerGroupDiagCurrentParent2" , 
		       "visionProblemGroupDiagCurrentParent1" , 
		       "visionProblemGroupDiagCurrentParent2" , 
		       "migraineGroupDiagCurrentParent1" , 
		       "migraineGroupDiagCurrentParent2" , 
		       "epilepsyGroupDiagCurrentParent1" , 
		       "epilepsyGroupDiagCurrentParent2" , 
		       "parkinsonsDiseaseGroupDiagCurrentParent1" , 
		       "parkinsonsDiseaseGroupDiagCurrentParent2" , 
		       "multipleSclerosisGroupDiagCurrentParent1" , 
		       "multipleSclerosisGroupDiagCurrentParent2" , 
		       "neuropathiesGroupDiagCurrentParent1" , 
		       "neuropathiesGroupDiagCurrentParent2" , 
		       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent1" , 
		       "moodStressrelatedOrAnxietyDisordersGroupDiagCurrentParent2" , 
		       "anorexiaBulimiaGroupDiagCurrentParent1" , 
		       "anorexiaBulimiaGroupDiagCurrentParent2" , 
		       "bipolarAffectiveDisorderGroupDiagCurrentParent1" , 
		       "bipolarAffectiveDisorderGroupDiagCurrentParent2" , 
		       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent1" , 
		       "schizophreniaOrSchizoaffectiveDisorderGroupDiagCurrentParent2" , 
		       "personalityDisorderGroupDiagCurrentParent1" , 
		       "personalityDisorderGroupDiagCurrentParent2" , 
		       "dementiaGroupDiagCurrentParent1" , 
		       "dementiaGroupDiagCurrentParent2" , 
		       "otherGroupDiagCurrentParent1" , 
		       "otherGroupDiagCurrentParent2" , 
		       "pretermBirthGroupDiagCurrentParent1" , 
		       "pretermBirthGroupDiagCurrentParent2" , 
		       "acuteCaesarianSectionGroupDiagCurrentParent1" , 
		       "acuteCaesarianSectionGroupDiagCurrentParent2" , 
		       "aidsHivCharlsonCurrentParent1" , 
		       "aidsHivCharlsonCurrentParent2" , 
		       "anyMalignancyCharlsonCurrentParent1" , 
		       "anyMalignancyCharlsonCurrentParent2" , 
		       "cerebrovascularDiseaseCharlsonCurrentParent1" , 
		       "cerebrovascularDiseaseCharlsonCurrentParent2" , 
		       "chronicPulmonaryDiseaseCharlsonCurrentParent1" , 
		       "chronicPulmonaryDiseaseCharlsonCurrentParent2" , 
		       "dementiaCharlsonCurrentParent1" , 
		       "dementiaCharlsonCurrentParent2" , 
		       "unspecificEverCurrentParent1" , 
		       "unspecificEverCurrentParent2" , 
		       "unspecificTwoYearCurrentParent1" , 
		       "unspecificTwoYearCurrentParent2" , 
		       "dyslipidemiaGroupLmdbCurrentParent1LmdbTemp" , 
		       "dyslipidemiaGroupLmdbCurrentParent1LmdbTotal" , 
		       "dyslipidemiaGroupLmdbCurrentParent2LmdbTemp" , 
		       "dyslipidemiaGroupLmdbCurrentParent2LmdbTotal" , 
		       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTemp" , 
		       "ischemicHeartDiseaseGroupLmdbCurrentParent1LmdbTotal" , 
		       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTemp" , 
		       "ischemicHeartDiseaseGroupLmdbCurrentParent2LmdbTotal" , 
		       "diabetesMellitusGroupLmdbCurrentParent1LmdbTemp" , 
		       "diabetesMellitusGroupLmdbCurrentParent1LmdbTotal" , 
		       "diabetesMellitusGroupLmdbCurrentParent2LmdbTemp" , 
		       "diabetesMellitusGroupLmdbCurrentParent2LmdbTotal" , 
		       "thyroidDisorderGroupLmdbCurrentParent1LmdbTemp" , 
		       "thyroidDisorderGroupLmdbCurrentParent1LmdbTotal" , 
		       "thyroidDisorderGroupLmdbCurrentParent2LmdbTemp" , 
		       "thyroidDisorderGroupLmdbCurrentParent2LmdbTotal" , 
		       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTemp" , 
		       "chronicPulmonaryDiseaseGroupLmdbCurrentParent1LmdbTotal" , 
		       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTemp" , 
		       "chronicPulmonaryDiseaseGroupLmdbCurrentParent2LmdbTotal" , 
		       "allergyGroupLmdbCurrentParent1LmdbTemp" , 
		       "allergyGroupLmdbCurrentParent1LmdbTotal" , 
		       "allergyGroupLmdbCurrentParent2LmdbTemp" , 
		       "allergyGroupLmdbCurrentParent2LmdbTotal" , 
		       "osteoporosisGroupLmdbCurrentParent1LmdbTemp" , 
		       "osteoporosisGroupLmdbCurrentParent1LmdbTotal" , 
		       "osteoporosisGroupLmdbCurrentParent2LmdbTemp" , 
		       "osteoporosisGroupLmdbCurrentParent2LmdbTotal" , 
		       "painfulConditionGroupLmdbCurrentParent1LmdbTemp" , 
		       "painfulConditionGroupLmdbCurrentParent1LmdbTotal" , 
		       "painfulConditionGroupLmdbCurrentParent2LmdbTemp" , 
		       "painfulConditionGroupLmdbCurrentParent2LmdbTotal" , 
		       "migraineGroupLmdbCurrentParent1LmdbTemp" , 
		       "migraineGroupLmdbCurrentParent1LmdbTotal" , 
		       "migraineGroupLmdbCurrentParent2LmdbTemp" , 
		       "migraineGroupLmdbCurrentParent2LmdbTotal" , 
		       "epilepsyGroupLmdbCurrentParent1LmdbTemp" , 
		       "epilepsyGroupLmdbCurrentParent1LmdbTotal" , 
		       "epilepsyGroupLmdbCurrentParent2LmdbTemp" , 
		       "epilepsyGroupLmdbCurrentParent2LmdbTotal" , 
		       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTemp" , 
		       "bipolarAffectiveDisorderGroupLmdbCurrentParent1LmdbTotal" , 
		       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTemp" , 
		       "bipolarAffectiveDisorderGroupLmdbCurrentParent2LmdbTotal" , 
		       "dementiaGroupLmdbCurrentParent1LmdbTemp" , 
		       "dementiaGroupLmdbCurrentParent1LmdbTotal" , 
		       "dementiaGroupLmdbCurrentParent2LmdbTemp" , 
		       "dementiaGroupLmdbCurrentParent2LmdbTotal") := NULL]

  ##After a lot of preparation, write a special version of analysisDataset to disk:
  fwrite(analysisDataset , "analysisDatasetExplorative.csv")

  ##Make a list of categories; this command captures all:
  listOfFamilyDiseaseCategories <- grep('Family' , names(analysisDataset) , value = TRUE)

  ##Removing a single category that got in by mistake because of the grep command above: 
  listOfFamilyDiseaseCategories <-
      listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
				    %in% c("reconstitutedFamily")] 

  ##Removing some categories where I think it would be feasible to hypothesize causal connections:
  listOfFamilyDiseaseCategories <-
      listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
				    %in%
				    c("pretermBirthGroupFamily" ,
				      "acuteCaesarianSectionGroupFamily")] 

  ##Removing psychiatric categories:
  listOfFamilyDiseaseCategories <-
      listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
				    %in%
				    c("moodStressrelatedOrAnxietyDisordersGroupFamily" ,
				      "anorexiaBulimiaGroupFamily" ,
				      "schizophreniaOrSchizoaffectiveDisorderGroupFamily" ,
				      "personalityDisorderGroupFamily" ,
				      "bipolarAffectiveDisorderGroupFamily" ,
				      "dementiaGroupFamily")]

  listOfFamilyDiseaseCategories <-
      listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
				    %in%
				    c("pretermBirthGroupFamily" ,
				      "acuteCaesarianSectionGroupFamily")] 


  ##Removing categories that has already been successfully run during testing (each model is very time consuming):
  ## listOfFamilyDiseaseCategories <-
  ##     listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
  ## 				  %in%
  ## 				  c("goutGroupFamily" ,
  ## 				    "migraineGroupFamily" ,
  ## 				    "painfulConditionGroupFamily" ,
  ## 				    "dyslipidemiaGroupFamily" ,
  ## 				    "ischemicHeartDiseaseGroupFamily")]

  ##I am getting strange errors, seems the system is overloaded by large categories. Putting some large processes at the end of the list, will try to re-run those later if they fail: 

  ## listOfFamilyDiseaseCategories <-
  ##     listOfFamilyDiseaseCategories[! listOfFamilyDiseaseCategories
  ## 				  %in%
  ## 				  c("chronicPulmonaryDiseaseGroupFamily" ,
  ## 				    "osteoporosisGroupFamily" ,
  ## 				    "hypertensionGroupFamily" ,
  ## 				    "otherGroupFamily" ,
  ## 				    "unspecificEverFamily" ,
  ## 				    "diabetesMellitusGroupFamily")]

  ## listOfFamilyDiseaseCategories <-
  ##     c(listOfFamilyDiseaseCategories ,
  ##       c("chronicPulmonaryDiseaseGroupFamily" ,
  ## 	"osteoporosisGroupFamily" ,
  ## 	"hypertensionGroupFamily" ,
  ## 	"otherGroupFamily" ,
  ## 	"unspecificEverFamily" ,
  ## 	"diabetesMellitusGroupFamily"))

  ##Having run all the above, I re-run these three to get analyses with as many cases as used for the previous:

  ## listOfFamilyDiseaseCategories <- c("migraineGroupFamily" ,
  ## 				   "painfulConditionGroupFamily" ,
  ## 				   "dyslipidemiaGroupFamily")

  ##Produce the actual analyses
  ##addCompleteVariableToAnalysisDataset()
  for (i in listOfFamilyDiseaseCategories) {
      diseaseCategory <- i
      makePseudoAnalysisObject(i)
      doAnalysisAndStatistics(nameOfAccumulateObject = "resultsListPriorCategories")
      fwrite(resultsListPriorCategories , "resultsListPriorCategories.csv")
  }


  ##There are a little more than 1500 cases of parkinsons. This is the reason for the breakdown - if these cases are split into 400 clusters, some of these will be empty and cause a failure in merging. Making a custom run, using only 50 clusters and reducing the complexity of the simple model even further:

  doAnalysisAndStatisticsEvenMoreParsimonious <- function(nameOfAccumulateObject = NA) {
      closeAllConnections()
      sink(file = paste0("results" , diseaseCategory , ".txt") , split = TRUE)
      print(paste0("Analysis for " , diseaseCategory , " IF YOU JUST CREATED pseudoAnalysis for this caegory."))
      ##Some statistics:
      followUp <- temp[partOfAnalysis == 1 , mean(time)]/12
      print(paste0("Mean of total follow-up time studying " , diseaseCategory , " : " , followUp))
      ##Sum of follow-up time: 
      followUpTotal <- temp[partOfAnalysis == 1 , sum(time)]/12
      print(paste0("Sum of total follow-up time studying " , diseaseCategory , " : " , followUpTotal))
      ##Number of cases in analysis:
      print(paste0("Number of abuse cases in analysis of " , diseaseCategory , " : " , temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N]))
      ##Number of lethal cases in analysis:
      print(paste0("Number of lethal abuse cases in analysis of " , diseaseCategory , " : " , temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N]))
      ##Number of deaths not related to abuse:
      print(paste0("Number of deaths not related to abuse in analysis of " ,
		   diseaseCategory , " : " ,
		   temp[partOfAnalysis == 1 &
			!is.na(deathCensoring) &
			(outcomePhysicalAbuse == 0 |
			 is.na(outcomePhysicalAbuse)) ,
			.N]))
      print(paste0("Pnrs before deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempBefore[ , .N]))
      print(paste0("Pnrs after deletion of those with less than 5 matches, studying " , diseaseCategory , " :" , tempAfter[ , .N]))
      print(paste0("Children in the analysis of " , diseaseCategory , ": " , childrenAnalysisNumber))
      print(paste0("Underlying biological children in the analysis of " , diseaseCategory , ": " , childrenAnalysisBiological))

      ##The geese way:
      pseudoFitFullPopulation <- geese(physicalAbuse ~ case +
					   ##Family characteristics                     
					   incomeVariable + 
					   parishQuantileDifference100Euros + 
					   oneForeignParent +
					   familyNeedProtection +
					   calendarTimeGroup +
					   ##Parental health and history
					   familyEducationalLevelReleveled +
					   parentalPsychiatricDisease +
					   interparentalViolence +
					   parentalSubstanceAbuse +
					   parentalAbuseAsChildReleveled ,
				       data = pseudoAnalysis ,
				       id = familyIndex ,
				       scale.fix = TRUE ,
				       family = gaussian ,
				       mean.link = "log" ,
				       corstr = "independence")
      show(summary(pseudoFitFullPopulation))

      resultsPseudoFitFullPopulation <- formatResultsGeese(pseudoFitFullPopulation)
      fwrite(resultsPseudoFitFullPopulation , paste0("resultsPseudoFitFullPopulation" , diseaseCategory , ".csv"))

      ##Avoiding most obvious colinearity:
      ##The geese way:
      pseudoFitFullPopulationNoSmallCellsLessColinearity <- geese(physicalAbuse ~ case +
								      ##Family characteristics                     
								      incomeVariable + 
								      ##parishQuantileDifference100Euros +
								      ##reconstitutedFamily + 
								      ##oneForeignParent +
								      ##familyNeedProtection +
								      calendarTimeGroup +
								      ##Parental health and history
								      familyEducationalLevelReleveled ,
								      ##parentalPsychiatricDisease +
								      ##interparentalViolence +
								      ##parentalSubstanceAbuse +
								      ##parentalAbuseAsChildReleveled ,
								  data = pseudoAnalysis ,
								  id = familyIndex ,
								  scale.fix = TRUE ,
								  family = gaussian ,
								  mean.link = "log" ,
								  corstr = "independence")
      show(summary(pseudoFitFullPopulationNoSmallCellsLessColinearity))
      resultsPseudoFitFullPopulationNoSmallCellsLessColinearity <- formatResultsGeese(pseudoFitFullPopulationNoSmallCellsLessColinearity)
      fwrite(resultsPseudoFitFullPopulationNoSmallCellsLessColinearity ,
	     paste0("resultsPseudoFitFullPopulation" ,
		    diseaseCategory ,
		    "NoSmallCellsLessColinearity.csv"))
      ##Code for generating a table from a loop of many categories:
      if (!is.na(nameOfAccumulateObject)) {
	  ##The tryCatch below is just a really complicated way of saying "get the object, and if you can't do it, don't give an error message, just return NA":
	  if (is.data.table(tryCatch(get(nameOfAccumulateObject) ,
				     error = function(cond){return(NA)}))) {
	      assign(nameOfAccumulateObject ,
		     rbindlist(list(get(nameOfAccumulateObject) , list(diseaseCategory ,
								       resultsPseudoFitFullPopulation$RR[2] ,
								       resultsPseudoFitFullPopulation$CILow[2] , 
								       resultsPseudoFitFullPopulation$CIHigh[2] ,
								       resultsPseudoFitFullPopulation$san.se[2] ,
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$RR[2] ,
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CILow[2] , 
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CIHigh[2] , 
								       resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$san.se[2] ,
								       followUp ,
								       followUpTotal ,
								       temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N] ,
								       temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N] ,
								       temp[partOfAnalysis == 1 &
									    !is.na(deathCensoring) &
									    (outcomePhysicalAbuse == 0 |
									     is.na(outcomePhysicalAbuse)) ,
									    .N] ,
								       tempBefore[ , .N] ,
								       tempAfter[ , .N] ,
								       childrenAnalysisNumber ,
								       childrenAnalysisBiological))) ,
		     envir = .GlobalEnv)
	  } else {
	      assign(nameOfAccumulateObject ,
		     data.table(category = diseaseCategory ,
				RRFull = resultsPseudoFitFullPopulation$RR[2] ,
				CILowFull = resultsPseudoFitFullPopulation$CILow[2] , 
				CIHighFull = resultsPseudoFitFullPopulation$CIHigh[2] ,
				sanSeFull = resultsPseudoFitFullPopulation$san.se[2] ,
				RRParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$RR[2] ,
				CILowParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CILow[2] ,
				CIHighParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$CIHigh[2] ,
				sanSeParsimonious = resultsPseudoFitFullPopulationNoSmallCellsLessColinearity$san.se[2] ,
				meanFollowup = followUp ,
				totalFollowup = followUpTotal ,
				abuseCases = temp[partOfAnalysis == 1 & anyPhysicalAbuse == 1 , .N] ,
				lethalAbuseCases = temp[partOfAnalysis == 1 & outcomePhysicalAbuse > 3 , .N] ,
				nonAbuseDeaths = temp[partOfAnalysis == 1 &
						      !is.na(deathCensoring) &
						      (outcomePhysicalAbuse == 0 |
						       is.na(outcomePhysicalAbuse)) ,
						      .N] ,
				allCases = tempBefore[ , .N] ,
				fullyMatchedCases = tempAfter[ , .N] ,
				childrenAnalyzed = childrenAnalysisNumber ,
				biologicalChildrenAnalyzed = childrenAnalysisBiological) ,
		     envir = .GlobalEnv)
	  }
      }
      sink()
  }

  diseaseCategory <- "parkinsonsDiseaseGroupFamily"
  makePseudoAnalysisObject(diseaseCategory , split = 50)
  doAnalysisAndStatisticsEvenMoreParsimonious(nameOfAccumulateObject = "resultsListPriorCategories")
  fwrite(resultsListPriorCategories , "resultsListPriorCategories.csv")


  ##Having run all the above, I re-run these three with the for-loop above to get analyses with as many cases as used for the previous (the limit of 100000 cases implemented above was introduced after running the first few analyses):

  listOfFamilyDiseaseCategories <- c("migraineGroupFamily" ,
				     "painfulConditionGroupFamily" ,
				     "dyslipidemiaGroupFamily")

  ##Making a function to simply count the number of exposed in each category (not only those with complete data):

  howManyCasesTable <- function(diseaseCategory , nOfFullPopulation , nameOfTableObject) {
      print(Sys.time())
      ##Get all the cases, put them first:
      setorderv(analysisDataset , c("pnr" , "date" , diseaseCategory) , c(1 , 1 , -1))
      cases <- unique(analysisDataset , by = c("pnr" , diseaseCategory))

      eval(parse(text = paste0("cases <- cases[" , diseaseCategory , " == 1]")))
      cases <- unique(cases , by = "pnr")
      if (!is.na(nameOfTableObject)) {
	  ##The tryCatch below is just a really complicated way of saying "get the object, and if you can't do it, don't give an error message, just return NA":
	  if (is.data.table(tryCatch(get(nameOfTableObject) ,
				     error = function(cond){return(NA)}))) {
	      assign(nameOfTableObject ,
		     rbindlist(list(get(nameOfTableObject) , list(diseaseCategory ,
								  cases[ , .N] ,
								  (cases[ , .N]/nOfFullPopulation)))) ,
		     envir = .GlobalEnv) 
	  } else {
	      assign(nameOfTableObject ,
		     data.table(category = diseaseCategory ,
				numberOfChildren = cases[ , .N] ,
				percentageOfFullPopulation = (cases[ , .N]/nOfFullPopulation)) ,
		     envir = .GlobalEnv)
	  }
      }
  }

  ##Re-using the listOfFamilyDiseaseCategories from above - check if all the categories are there:
  for (i in listOfFamilyDiseaseCategories) {
      ##Commenting out just to save time - the number is 2705770
      ##fullPopulation <- unique(analysisDataset , by = "pnr")[ , .N]
      fullPopulation <- 2705770
      print(fullPopulation)
      howManyCasesTable(diseaseCategory = i ,
			nOfFullPopulation = fullPopulation ,
			nameOfTableObject = "tableOfExposed")
      fwrite(tableOfExposed , "tableOfExposed.csv")
  }
#+end_src

